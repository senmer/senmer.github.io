<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kubeadm部署k8s集群 | WZ's Blog</title>
<meta name=keywords content><meta name=description content="一、 简介 1.1 k8s 是什么 Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构"><meta name=author content="wz"><link rel=canonical href=https://senmer.github.io/zh/posts/tech/kubernetes/kubeadm%E9%83%A8%E7%BD%B2k8s%E9%9B%86%E7%BE%A4/><link crossorigin=anonymous href=/assets/css/stylesheet.5a2b6d77cc78ad18bcb4914c5c639c7ce5ab55e956c461d4310747892b3f50c2.css integrity="sha256-Wittd8x4rRi8tJFMXGOcfOWrVelWxGHUMQdHiSs/UMI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://senmer.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://senmer.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://senmer.github.io/img/Q.gif><link rel=apple-touch-icon href=https://senmer.github.io/img/Q.gif><link rel=mask-icon href=https://senmer.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4d7c4710a089d70b71310f0e1ec7681b",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="Kubeadm部署k8s集群"><meta property="og:description" content="一、 简介 1.1 k8s 是什么 Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构"><meta property="og:type" content="article"><meta property="og:url" content="https://senmer.github.io/zh/posts/tech/kubernetes/kubeadm%E9%83%A8%E7%BD%B2k8s%E9%9B%86%E7%BE%A4/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-10-02T22:37:50+08:00"><meta property="article:modified_time" content="2023-10-02T22:37:50+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Kubeadm部署k8s集群"><meta name=twitter:description content="一、 简介 1.1 k8s 是什么 Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"📚文章","item":"https://senmer.github.io/zh/posts/"},{"@type":"ListItem","position":2,"name":"👨🏻‍💻 技术","item":"https://senmer.github.io/zh/posts/tech/"},{"@type":"ListItem","position":3,"name":"Kubeadm部署k8s集群","item":"https://senmer.github.io/zh/posts/tech/kubernetes/kubeadm%E9%83%A8%E7%BD%B2k8s%E9%9B%86%E7%BE%A4/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kubeadm部署k8s集群","name":"Kubeadm部署k8s集群","description":"一、 简介 1.1 k8s 是什么 Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构","keywords":[""],"articleBody":"一、 简介 1.1 k8s 是什么 Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构建、交付和运行容器化应用。\n1.2 k8s 的优势 Kubernetes 是一个开源的容器编排平台，它提供了一种管理容器化应用程序的强大方式。以下是 Kubernetes 的一些优势：\n自动化和自我修复： Kubernetes 可以自动监测应用程序状态并进行自我修复，确保应用持续稳定运行。如果某个容器或节点发生故障，Kubernetes 会自动重新启动容器或迁移工作负载。 弹性扩展： Kubernetes 允许根据需要扩展或缩减应用程序实例的数量。这种自动扩展能力可根据负载自动调整应用的规模，以满足流量需求，同时在需求减少时节约资源。 负载均衡： Kubernetes 支持内置的负载均衡，可以将传入的流量分发到不同的容器实例中，确保应用程序能够有效地处理高流量。 自动部署和滚动更新： 通过声明式的配置，Kubernetes 允许你轻松地进行应用程序的部署和更新。滚动更新功能可以逐步替换旧版本的容器，从而减少应用程序的停机时间。 多环境支持： Kubernetes 支持多个环境（例如开发、测试、生产）之间的轻松迁移，确保应用在不同阶段的一致性。 声明式配置： 你可以使用 Kubernetes 的 YAML 文件来定义应用程序的配置和部署要求。这种声明式的方法让你能够更清晰地定义应用程序状态，而 Kubernetes 负责将系统状态调整为所需状态。 自定义资源和扩展性： Kubernetes 允许你创建自定义资源和控制器，从而可以扩展平台的功能，满足特定应用程序或业务的需求。 多种容器运行时支持： Kubernetes 支持多种容器运行时，如 Docker、Containerd 等，使你可以选择最适合你的应用的运行时环境。 社区支持和生态系统： Kubernetes 拥有庞大的社区和丰富的生态系统，有大量的工具、插件和服务，可以帮助你更好地管理、监控和扩展你的应用程序。 跨云和本地环境： Kubernetes 可以在不同的云平台和本地环境中运行，使你能够在不同的基础架构上保持一致的部署和管理体验。 总之，Kubernetes 提供了强大的容器编排和管理功能，帮助开发人员和运维团队更有效地部署、扩展和管理容器化应用程序。它的优势在于自动化、弹性、灵活性以及丰富的生态系统。\n1.3 k8s 组件介绍 Kubernetes（通常简称为K8s）由多个组件组成，这些组件共同协作以管理容器化应用程序的生命周期。以下是常见的 Kubernetes 组件及其功能介绍：\nKubelet： 运行在每个节点上的代理，负责管理容器的生命周期。它与 Master 节点通信，确保容器在节点上按照所需的状态运行。 Kube-Proxy： 也运行在每个节点上，维护网络规则以实现 Service 暴露和负载均衡。它根据 Service 配置更新节点上的 iptables 规则。 Kube-Scheduler： 负责监视新创建的 Pod，并根据各种条件（如资源需求、亲和性、亲和性等）将其调度到集群中的适当节点上。 Kube-Controller-Manager： 包含多个控制器，用于监控集群状态并根据需要进行自动修复。其中一些控制器包括： Replication Controller 和 ReplicaSet 控制器： 确保在集群中运行指定数量的 Pod 副本。 Deployment 控制器： 管理应用程序的滚动更新和版本控制。 Namespace 控制器： 管理命名空间的创建、更新和删除。 Etcd： 是一个分布式键值存储系统，用于存储集群的配置信息、状态和元数据。Kubernetes 使用 Etcd 来存储所有关键信息，包括配置、部署和服务发现。 API Server： 提供了 Kubernetes 集群的 API，允许用户和其他组件与集群进行交互。所有的资源和操作都通过 API Server 进行访问和管理。 Container Runtime： 负责运行容器，常见的容器运行时包括 Docker、Containerd 等。 Controller Manager： 包含一系列控制器，这些控制器可以监控集群中的资源状态，并确保所需状态与实际状态保持一致。 Cloud Controller Manager： 在云平台上运行，用于集成 Kubernetes 集群与特定云提供商的功能，如自动扩展、负载均衡等。 Admission Controllers： 用于拦截和修改进入 Kubernetes 集群的请求。这些控制器可以执行验证、默认值设置和修改请求，以确保遵循集群策略。 Ingress Controller： 管理 Ingress 资源，将外部流量引导到集群内部的服务。 Pods： 是 Kubernetes 的最小调度单位，可以包含一个或多个容器。它们可以共享网络和存储，形成一个逻辑单元。 Services： 用于定义一组 Pod 的访问方式，提供负载均衡和服务发现功能，使应用程序能够在不同的 Pod 之间进行通信。 ConfigMaps 和 Secrets： 用于将配置和机密信息与应用程序分开，并在容器中以环境变量或卷的形式提供。 这些组件一起协同工作，使 Kubernetes 能够提供强大的容器编排和管理功能。每个组件都扮演着不同的角色，确保容器化应用程序能够以高可用性、自动化和弹性的方式运行。\n二、k8s 安装部署（kubeadm） 注意：本文安装的 k8s 版本为 v1.17.11，不能直接通过 kubeadm 执行升级操作。如果需要进行升级操作，需要满足 version \u003e= 1.18.0\n2.1 安装方式 Kubernetes 的安装可以分为多种方式，根据你的需求和环境选择合适的安装方式。以下是一些常见的 Kubernetes 安装方式：\nMinikube： 如果你想在本地开发环境中快速搭建一个单节点的 Kubernetes 集群，可以使用 Minikube。Minikube 创建一个虚拟机，并在其中运行一个单节点的 Kubernetes 集群。适合学习和开发目的。\nKubeadm： Kubeadm 是一个官方维护的工具，用于在生产环境中快速部署 Kubernetes 集群。它可以在多个节点上设置一个高度可配置的集群，适用于较小规模的生产环境。\nKubespray（原先叫Kargo）： Kubespray 是一个开源项目，用于部署高度定制化的 Kubernetes 集群。它支持多种操作系统和云平台，并且可以根据配置要求进行定制化部署。\nManaged Kubernetes Services： 主要云提供商（如AWS、Google Cloud、Azure）提供托管的 Kubernetes 服务，如Amazon EKS、Google Kubernetes Engine（GKE）、Azure Kubernetes Service（AKS）。这些服务会为你自动管理集群的维护、升级和可用性。\nRancher： Rancher 是一个开源的容器管理平台，可以帮助你在不同的基础设施上轻松部署和管理 Kubernetes 集群。\nK3s： K3s 是一个轻量级的 Kubernetes 发行版，旨在为资源受限的环境（如边缘计算）提供更轻便的安装和管理。\n自定义安装脚本： 你可以根据 Kubernetes 的官方文档，在自己的环境中编写自定义的安装脚本。这样可以更好地适应特定需求和架构。\n对于初学者来说，Minikube 和 Managed Kubernetes Services 是较为简单的入门方式。而对于生产环境，Kubeadm、Kubespray 和 Rancher 提供了更大的灵活性和控制权。在选择安装方式时，考虑到你的技术水平、部署规模和所在的基础设施环境是很重要的。无论选择哪种方式，确保参考官方文档和最佳实践来确保安装的正确性和可靠性。\n2.2 部署过程 安装前准备：\n禁用 swap 分区\n关闭 selinux\n关闭 iptables、NetworkManager 服务\n同步服务器时间\n# ntpdate ntp.aliyun.com # hwclock -w 优化内核参数并修改资源限制\n[root@centos7 ~]# cat /etc/sysctl.conf net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-arptables = 1 net.ipv4.tcp_tw_reuse = 0 net.ipv4.ip_nonlocal_bind = 1 net.core.somaxconn = 32768 net.netfilter.nf_conntrack_max = 1000000 vm.swappiness = 0 vm.max_map_count = 655360 fs.file-max = 655360 [root@centos7 ~]# cat /etc/security/limits.conf # * soft core unlimited * hard core unlimited * soft nproc 1000000 * hard nproc 1000000 * soft nofile 1000000 * hard nofile 1000000 * soft memlock 24800 * hard memlock 24800 * soft msgqueue 8192000 * hard msgqueue 8192000 root soft core unlimited root hard core unlimited root soft nproc 1000000 root hard nproc 1000000 root soft nofile 1000000 root hard nofile 1000000 root soft memlock 24800 root hard memlock 24800 root soft msgqueue 8192000 root hard msgqueue 8192000 2.2.1 具体步骤 基础环境准备 部署 harbor 和 haproxy 高可用反向代理，实现控制节点 API 的高可用 在所有 master 节点安装指定的 kubeadm、kubelet、kubectl、docker 在所有 node 节点按爪给你指定版本的 kubeadm、docker、kubelet（可选） 在 master 节点运行 kubeadm ini 初始化命令创建集群 验证 master 节点状态 在 node 节点使用 kubeadm 命令将自身加入集群 验证 ndoe 节点状态 创建 pod 并测试网络是否正常 部署 dashboard 集群升级 2.2.2 部署环境 如果是虚拟化环境，最好每个重要节点做好快照\n**操作系统：**Centos 7.8\n**安装方式：**最小化安装\n**部署方式：**VMware 16 Pro\n角色 主机名 IP 配置 k8s-master-01 master-01.example.local 10.0.0.11 2U 2G k8s-master-02 master-02.example.local 10.0.0.12 2U 2G k8s-master-03 master-03.example.local 10.0.0.13 2U 2G ha-01 ha-01.example.local 10.0.0.14 1U 2G ha-02 ha-02.example.local 10.0.0.15 1U 2G harbor harbor.example.local 10.0.0.16 2U 4G node-01 node-01.example.local 10.0.0.17 1U 2G node-02 node-02.example.local 10.0.0.18 1U 2G node-03 node-03.example.local 10.0.0.19 1U 2G 2.3 部署高可用反向代理 基于 Keepalived + haprox实现高可用反向代理，实现 k8s apiserver 服务的高可用\nha-01：\nyum install -y keepalived yum install -y haproxy cp /usr/share/doc/keepalived-1.3.5/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf [root@ha-01 ~]# cat /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { notification_email { acassen } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_instance k8s { state MASTER interface eth0 garp_master_delay 10 smtp_alert virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.188 label eth0:1 10.0.0.199 label eth0:2 } } [root@ha-01 ~]# tail -n 60 /etc/haproxy/haproxy.cfg ... defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth admin:passwd listen k8s-apiserver-6443 bind 10.0.0.188:6443 mode tcp balance roundrobin server 10.0.0.11 10.0.0.11:6443 check inter 3s fall 3 rise 5 server 10.0.0.12 10.0.0.12:6443 check inter 3s fall 3 rise 5 server 10.0.0.13 10.0.0.13:6443 check inter 3s fall 3 rise 5 listen k8s-node-80 bind 10.0.0.199:80 mode tcp balance roundrobin server 10.0.0.17 10.0.0.17:30004 check inter 3s fall 3 rise 5 server 10.0.0.18 10.0.0.18:30004 check inter 3s fall 3 rise 5 server 10.0.0.19 10.0.0.19:30004 check inter 3s fall 3 rise 5 [root@ha-01 ~]# systemctl enable --now keepalived.service [root@ha-01 ~]# systemctl enable --now haproxy.service ha2:\nyum install -y keepalived yum install -y haproxy cp /usr/share/doc/keepalived-1.3.5/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf [root@ha-01 ~]# cat /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { notification_email { acassen } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_instance k8s { state MASTER interface eth0 garp_master_delay 10 smtp_alert virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.188 label eth0:1 10.0.0.199 label eth0:2 } } [root@ha-02 ~]# tail -n 60 /etc/haproxy/haproxy.cfg ... defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth admin:passwd listen k8s-apiserver-6443 bind 10.0.0.188:6443 mode tcp balance roundrobin server 10.0.0.11 10.0.0.11:6443 check inter 3s fall 3 rise 5 server 10.0.0.12 10.0.0.12:6443 check inter 3s fall 3 rise 5 server 10.0.0.13 10.0.0.13:6443 check inter 3s fall 3 rise 5 listen k8s-node-80 bind 10.0.0.199:80 mode tcp balance roundrobin server 10.0.0.17 10.0.0.17:30004 check inter 3s fall 3 rise 5 server 10.0.0.18 10.0.0.18:30004 check inter 3s fall 3 rise 5 server 10.0.0.19 10.0.0.19:30004 check inter 3s fall 3 rise 5 [root@ha-02 ~]# systemctl enable --now keepalived.service [root@ha-02 ~]# systemctl enable --now haproxy.service # vip 在 ha-01 节点 [root@ha-01 ~]# ifconfig eth0:1 eth0:1: flags=4163 mtu 1500 inet 10.0.0.188 netmask 255.255.255.255 broadcast 0.0.0.0 ether 00:0c:29:cd:4b:70 txqueuelen 1000 (Ethernet) [root@ha-01 ~]# ifconfig eth0:2 eth0:2: flags=4163 mtu 1500 inet 10.0.0.199 netmask 255.255.255.255 broadcast 0.0.0.0 ether 00:0c:29:cd:4b:70 txqueuelen 1000 (Ethernet) 浏览器查看状态页\n2.4 部署 harbor https://goharbor.io/docs/2.9.0/install-config/installation-prereqs/\nhttps://docs.docker.com/engine/install/centos/\nsudo yum remove -y docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine # 安装 docker sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin systemctl enable --now docker [root@harbor harbor]# docker -v Docker version 24.0.6, build ed223bc # 下载并安装 harbor wget https://github.com/goharbor/harbor/releases/download/v2.8.4/harbor-offline-installer-v2.8.4.tgz tar xf harbor-offline-installer-v2.8.4.tgz cd harbor [root@harbor harbor]# cp harbor.yml.tmpl harbor.yml # 关闭 https [root@harbor harbor]# grep -A 7 \"https related config\" harbor.yml # https related config #https: # # https port for harbor, default is 443 # port: 443 # # The path of cert and key files for nginx # certificate: /your/certificate/path # private_key: /your/private/key/path # 修改 hostname [root@harbor harbor]# grep -m 1 hostname: harbor.yml hostname: harbor.example.local # 修改密码 [root@harbor harbor]# grep -m 1 passwd harbor.yml harbor_admin_password: passwd # 开始安装 ./install.sh # docker-compose 安装路径 [root@harbor harbor]# rpm -ql docker-compose-plugin |grep docker-compose /usr/libexec/docker/cli-plugins/docker-compose 登录 harbor 并创建项目\n注意： 自行在 window 主机添加 hosts 解析 10.0.0.16 harbor.example.local\n2.5 所有节点安装 docker Release v1.17.11 · kubernetes/kubernetes (github.com)\n所有节点（这里专指 master 和 node）安装 docker\n注意： 生产环境要选择 k8s 指定的版本，具体查阅对应版本的 CHANGELOG\nkubernetes/CHANGELOG/CHANGELOG-1.17.md at master · kubernetes/kubernetes (github.com)\n安装指定版本的 docker\nsudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 这里直接安装 19.03.9-3 版本的 docker # yum list docker-ce --showduplicates | sort -r | grep 19.03 docker-ce.x86_64 3:19.03.9-3.el7 docker-ce-stable # sudo yum install -y docker-ce-19.03.9 docker-ce-cli-19.03.9 containerd.io docker-compose-plugin # docker version Client: Docker Engine - Community Version: 19.03.9 API version: 1.40 Go version: go1.13.10 Git commit: 9d988398e7 Built: Fri May 15 00:25:27 2020 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.9 # 由于 harbor 仓库未启用 https ，因此需要在 service 文件加上该参数 # dockerd --help |grep insec --insecure-registry list Enable insecure registry communication # grep insecure-registry /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --insecure-registry harbor.example.com # systemctl enable --now docker 2.6 所有节点安装集群初始化工具 2.6.1 配置国内镜像源 cat \u003c /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 2.6.2 安装初始化工具 注意：kubectl 是客户端命令，因此在 node 可以选择性安装\nyum install -y kubelet-1.17.11 kubectl-1.17.11 kubeadm-1.17.11 systemctl enable --now kubelet # 配置 kubeadm 子命令自动补全 mkdir ~/.kube/ kubeadm completion bash \u003e ~/.kube/kubeadm_completion.sh source ~/.kube/kubeadm_completion.sh 2.6.3 kubeadm 命令的使用 查看帮助\nkubeadm --help 查看版本\n[root@master-01 ~]# kubeadm version kubeadm version: \u0026version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.11\", GitCommit:\"ea5f00d93211b7c80247bf607cfa422ad6fb5347\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T15:17:52Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"} 查看部署指定版本的集群所需要的镜像\n[root@master-01 ~]# kubeadm config images list --kubernetes-version v1.17.11 W0930 17:59:27.921963 6797 validation.go:28] Cannot validate kube-proxy config - no validator is available W0930 17:59:27.922001 6797 validation.go:28] Cannot validate kubelet config - no validator is available k8s.gcr.io/kube-apiserver:v1.17.11 k8s.gcr.io/kube-controller-manager:v1.17.11 k8s.gcr.io/kube-scheduler:v1.17.11 k8s.gcr.io/kube-proxy:v1.17.11 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/coredns:1.6.5 由于是国外的镜像，由于网络原因，大概率是下载不成功的。因此将镜像地址换成阿里的，然后手动 pull\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.3-0 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.5 2.7 k8s 单节点部署 2.7.1 开始部署 首先给 master-01 添加一个快照，名为 init，方便后续回退\n这里选择 master-01 进行演示\n[root@master-01 ~]# kubeadm init --apiserver-advertise-address=10.0.0.11 --apiserver-bind-port=6443 --kubernetes-version=v1.17.11 --pod-network-cidr=10.100.0.0/16 --service-cidr=10.200.0.0/16 --service-dns-domain=example.local --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers # --v=6 如果卡住或者超时可以加该选项来查看详细报错信息 安装结果打印在控制台，为方便后续添加 node 节点到集群等操作，最好将打印结果进行保存\n... Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: # 执行以下三行命令，可通过 kubectl 命令操作集群 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: # node 节点运行该命令可加入集群 kubeadm join 10.0.0.11:6443 --token s14pux.a81q4ai54mpumsz4 \\ --discovery-token-ca-cert-hash sha256:5ab171bccb95245c209ddcbb614ae943b31b05e3a4ce2eb47d349655955c185f 2.7.2 验证结果 [root@master-01 ~]# kubectl get pod The connection to the server localhost:8080 was refused - did you specify the right host or port? [root@master-01 ~]# [root@master-01 ~]# mkdir -p $HOME/.kube [root@master-01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@master-01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config [root@master-01 ~]# kubectl get pod No resources found in default namespace. 2.7.3 部署网络组件 k8s 支持的网络组件：安装扩展（Addon） | Kubernetes\n这里选择部署 flannel-io/flannel: flannel is a network fabric for containers, designed for Kubernetes (github.com)\n下载 yaml 文件并修改 network 为集群初始化时规划的 pod 网段 10.100.0.0/16\n[root@master-01 ~]# wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml [root@master-01 ~]# grep -m 1 Network kube-flannel.yml \"Network\": \"10.100.0.0/16\", 开始部署\n[root@master-01 ~]# kubectl apply -f kube-flannel.yml namespace/kube-flannel created serviceaccount/flannel created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created # 成功部署 [root@master-01 ~]# kubectl get pod -A | grep flannel kube-flannel kube-flannel-ds-zvcp7 1/1 Running 0 2m9s 去除 master-01 的污点\n# 默认情况下 master 被打上了污点，不会被调度 [root@master-01 ~]# kubectl describe node master-01.example.local | grep Taints Taints: node-role.kubernetes.io/master:NoSchedule # 去除 master-01 的污点 [root@master-01 ~]# kubectl taint nodes master-01.example.local node-role.kubernetes.io/master:NoSchedule- node/master-01.example.local untainted 部署 busybox 验证 pod 网络\n[root@master-01 ~]# kubectl run my-container --image=busybox --command -- bash kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. [root@master-01 ~]# kubectl run my-container --image=busybox --command -- ping www.baidu.com kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/my-container created [root@master-01 ~]# kubectl get pod NAME READY STATUS RESTARTS AGE my-container-84ff747745-sjd97 1/1 Running 0 10s # 网络正常 [root@master-01 ~]# kubectl exec -it my-container-84ff747745-sjd97 -- sh / # ping www.baidu.com -c 3 PING www.baidu.com (14.119.104.189): 56 data bytes 64 bytes from 14.119.104.189: seq=0 ttl=127 time=9.193 ms 64 bytes from 14.119.104.189: seq=1 ttl=127 time=9.475 ms 64 bytes from 14.119.104.189: seq=2 ttl=127 time=9.668 ms 2.8 k8s 多节点部署（高可用） 这里将用到所有三个 master 节点进行演示，由于 mater-01 部署了单节点，首先将其还原到快照 init （没有快照的话，可以参考 kubeadm reset )\n2.8.1 开始部署 相比单节点部署而言，多了一个选项 --control-plane-endpoint=10.0.0.188 指定了高可用反向代理的 VIP，这里还是选择 master-01 创建集群（任选一个 master 节点均可）\n如果负载均衡器未配置正确，会有以下报错：\nOct 1 14:06:58 master-01 kubelet: E1001 14:06:58.218726 2977 reflector.go:153] k8s.io/client-go/informers/factory.go:135: Failed to lisriver: Get https://load-balancer.example.com:6443/apis/storage.k8s.io/v1beta1/csidrivers?limit=500\u0026resourceVersion=0: EOF\n[root@master-01 ~]# echo 10.0.0.188 load-balancer.example.com \u003e\u003e /etc/hosts [root@master-01 ~]# kubeadm init --apiserver-advertise-address=10.0.0.11 --control-plane-endpoint=load-balancer.example.com --apiserver-bind-port=6443 --kubernetes-version=v1.17.11 --pod-network-cidr=10.100.0.0/16 --service-cidr=10.200.0.0/16 --service-dns-domain=example.local --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers ... Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: # 添加 master 节点到集群 kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a \\ --control-plane # 需要手动生成 Then you can join any number of worker nodes by running the following on each as root: # 添加 node 节点到集群 kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a # 准备集群认证文件 [root@master-01 ~]# mkdir -p $HOME/.kube [root@master-01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@master-01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config # 成功获取集群信息 [root@master-01 ~]# kubectl get node NAME STATUS ROLES AGE VERSION master-01.example.local Ready master 91m v1.17.11 # 部署 flannel， 参考 2.7.3 [root@master-01 ~]# kubectl apply -f kube-flannel.yml namespace/kube-flannel created serviceaccount/flannel created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created [root@master-01 ~]# kubectl get pod -A |grep flannel kube-flannel kube-flannel-ds-97c97 1/1 Running 0 94s 补充： 除了使用命令的方式，还可以基于 yaml 文件进行集群的初始化（这里仅给出关键命令）\n# 生成初始化配置 # kubeadm config print init-defaults \u003e cluster-init.yaml # 根据需要修改配置文件 # cat cluster-init.yaml apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: master-01.example.local taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: v1.17.0 networking: dnsDomain: cluster.local podSubnet: 10.100.0.0/16 serviceSubnet: 10.200.0.0/16 scheduler: {} # 创建集群 kubeadm init --config cluster-init.yaml 2.8.2 添加 master 节点 生成 --control-plane 参数所需 key\n[root@master-01 ~]# kubeadm init phase upload-certs --upload-certs I1001 16:10:41.762369 58794 version.go:251] remote version is much newer: v1.28.2; falling back to: stable-1.17 W1001 16:10:46.609771 58794 validation.go:28] Cannot validate kube-proxy config - no validator is available W1001 16:10:46.609786 58794 validation.go:28] Cannot validate kubelet config - no validator is available [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace [upload-certs] Using certificate key: c67c9859d32c5f7e1fd75cfca8569aac32ae4f9344fcd6b8d53ad9b998362e05 # 这就是需要的 key 分别执行以下命令，将 master-02 和 master-03 加入 control-plane\n# echo 10.0.0.188 load-balancer.example.com \u003e\u003e /etc/hosts # kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a \\ --control-plane --certificate-key c67c9859d32c5f7e1fd75cfca8569aac32ae4f9344fcd6b8d53ad9b998362e05 ... This node has joined the cluster and a new control plane instance was created: * Certificate signing request was sent to apiserver and approval was received. * The Kubelet was informed of the new secure connection details. * Control plane (master) label and taint were applied to the new node. * The Kubernetes control plane instances scaled up. * A new etcd member was added to the local/stacked etcd cluster. To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Run 'kubectl get nodes' to see this node join the cluster. # 成功加入节点 [root@master-02 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION master-01.example.local Ready master 132m v1.17.11 master-02.example.local Ready master 8m25s v1.17.11 master-03.example.local Ready master 14s v1.17.11 2.8.3 添加 node 节点 分别各个 node 节点执行以下命令\necho 10.0.0.188 load-balancer.example.com \u003e\u003e /etc/hosts kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a 添加完成后的结果\n[root@master-02 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION master-01.example.local Ready master 176m v1.17.11 master-02.example.local Ready master 52m v1.17.11 master-03.example.local Ready master 44m v1.17.11 node-01.example.local Ready 95s v1.17.11 node-02.example.local Ready 34m v1.17.11 node-03.example.local Ready 74s v1.17.11 2.8.4 查看集群证书 [root@master-02 ~]# kubectl get csr NAME AGE REQUESTOR CONDITION csr-4fsl6 47m system:bootstrap:tdi58m Approved,Issued csr-hc9g7 4m system:bootstrap:tdi58m Approved,Issued csr-jh7gj 55m system:bootstrap:tdi58m Approved,Issued csr-k8psl 3m39s system:bootstrap:tdi58m Approved,Issued csr-qcjln 36m system:bootstrap:tdi58m Approved,Issued csr-vvtfq 2m53s system:bootstrap:tdi58m Approved,Issued 2.8.5 创建 pod 验证集群网络 [root@master-01 ~]# kubectl run net-test --image=alpine sleep 3600 kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/net-test created [root@master-01 ~]# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES net-test-88ff4d957-rnrsk 1/1 Running 0 21s 10.100.4.2 node-01.example.local [root@master-01 ~]# kubectl exec -it net-test-88ff4d957-rnrsk -- sh / # ping www.baidu.com PING www.baidu.com (14.119.104.189): 56 data bytes 64 bytes from 14.119.104.189: seq=0 ttl=127 time=8.608 ms 64 bytes from 14.119.104.189: seq=1 ttl=127 time=9.249 ms 64 bytes from 14.119.104.189: seq=2 ttl=127 time=9.576 ms 三、部署 Dashboard 3.1 准备配置文件 [root@master-01 ~]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml [root@master-01 ~]# mv recommended.yaml dashboard.yaml # 默认的是以 ClusterIP 发布的，只能集群内访问。这里将其改为 NodePort 的方式部署 [root@master-01 ~]# grep NodePort -C 10 dashboard.yaml --- kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: type: NodePort # 新增 ports: - port: 443 targetPort: 8443 nodePort: 30000 # 新增 selector: k8s-app: kubernetes-dashboard --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard 3.2 部署并验证效果 [root@master-01 ~]# kubectl apply -f dashboard.yaml # 查看 pod 和 service 服务状态 [root@master-01 ~]# kubectl get pod,svc -n kubernetes-dashboard -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/dashboard-metrics-scraper-894c58c65-tsqb7 1/1 Running 0 32m 10.100.4.4 node-01.example.local pod/kubernetes-dashboard-fc4fc66cc-vvbht 1/1 Running 0 32m 10.100.4.3 node-01.example.local NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/dashboard-metrics-scraper ClusterIP 10.200.205.233 8000/TCP 32m k8s-app=dashboard-metrics-scraper service/kubernetes-dashboard NodePort 10.200.198.74 443:30000/TCP 32m k8s-app=kubernetes-dashboard # 节点监听了 30000 端口 [root@node-01 ~]# ss -ntl |grep 30000 LISTEN 0 32768 [::]:30000 [::]:* 由于是 https 协议，但是证书是私有的，使用 chrome 或 edge 浏览器无法访问 dashboard。因此选择 firefox 浏览器进行访问\n访问 dashboard 需要使用 token 或者 kubeconfig 文件进行认证，这里选择 token 进行验证。下面开始生成 token\n# 创建账号 [root@master-01 ~]# kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard serviceaccount/dashboard-admin created # 授权 [root@master-01 ~]# kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin # 获取账号 token [root@master-01 ~]# kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin dashboard-admin-token-wr4jl kubernetes.io/service-account-token 3 15s [root@master-01 ~]# kubectl describe secrets dashboard-admin-token-wr4jl -n kubernetes-dashboard Name: dashboard-admin-token-wr4jl Namespace: kubernetes-dashboard Labels: Annotations: kubernetes.io/service-account.name: dashboard-admin kubernetes.io/service-account.uid: 66e3f61f-9172-400c-b454-d9fb1a93be4c Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IndQay1pc3ctc3RyWDh3dXQtTHR1N09PLVVBdUExdXJkRVRQeFpmbWlmQ1kifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tN3NweDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMjQ5OTJlMzctNmI1Yi00ODZmLTkwYmUtYmQxYTU2NGM0MmJhIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.jXYf6lQQBW9kb3KUYpoAi57JbBFwMkUdx3Gb0jK4sN8E80WIM6lyGLktsTCmNoS21BN-bGyusqT5nNJAPhrVYaEjF6pSSLrd49LHF0Wetv04Jh5fdw-aHYuR15QKCZgGjedzuUHD4F8-6Ba5ZqMh67JjKI3Dhb-dIuBIVN3KLi2_D62F4VoCryZB3ExVfdRqZmQmI0EJ5XursMgCzL9v9VCPw9FatL604n5658CuXQNXc6uIpAVwuf3G_4uBoRQ-LcyPXov9JIoSv-qbxnotgZ2xXcHWZ7HIxa1pCRL8YG_bx03ZUE04GebjF9yNeki9Dxsp4gIxDcr09ByzO0gmgg 将上述 token 填入输入框(不要带多余空格），成功访问 dashboard\n四、k8s 部署 nginx + tomcat Deployments | Kubernetes\n目标：实现动静分离的效果，这里仅演示简单的实现效果\n4.1 部署 nginx [root@master-01 nginx]# pwd /root/yaml/nginx [root@master-01 nginx]# cat nginx.yml apiVersion: apps/v1 kind: Deployment metadata: namespace: default name: nginx-deployment labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.18.0 ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: labels: app: nginx-service-labels name: nginx-service namespace: default spec: type: NodePort ports: - name: http-nginx port: 80 protocol: TCP targetPort: 80 nodeport: 30004 selector: app: nginx [root@master-01 nginx]# kubectl apply -f nginx.yml 查看部署结果\n[root@master-01 nginx]# kubectl get pod,svc -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 4m11s 10.100.3.3 node-01.example.local NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/kubernetes ClusterIP 10.200.0.1 443/TCP 162m service/nginx-service NodePort 10.200.231.164 80:30004/TCP 4m11s app=nginx 根据以上结果可知，nginx 成功部署，且 pod 被调度到了 node-01 节点\n4.2 部署 tomcat [root@master-01 tomcat]# pwd /root/yaml/tomcat [root@master-01 tomcat]# cat tomcat.yml apiVersion: apps/v1 kind: Deployment metadata: namespace: default name: tomcat-deployment labels: apps: tomcat spec: replicas: 1 selector: matchLabels: app: tomcat template: metadata: labels: app: tomcat spec: containers: - name: tomcat image: tomcat ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: labels: app: tomcat-service-label name: tomcat-service namespace: spec: type: NodePort ports: - name: tomcat-http port: 80 protocol: TCP targetPort: 8080 nodePort: 30005 selector: app: tomcat [root@master-01 tomcat]# kubectl apply -f tomcat.yml 查看部署结果\n[root@master-01 ~]# kubectl get pod,svc -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 4m11s 10.100.3.3 node-01.example.local pod/tomcat-deployment-78c89857d6-9qtr9 1/1 Running 0 4m14s 10.100.3.2 node-01.example.local NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/kubernetes ClusterIP 10.200.0.1 443/TCP 162m service/nginx-service NodePort 10.200.231.164 80:30004/TCP 4m11s app=nginx service/tomcat-service NodePort 10.200.206.119 80:30005/TCP 4m14s app=tomcat 生成一个tomcat 临时页面\n[root@master-01 yaml]# kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 6m18s tomcat-deployment-78c89857d6-9qtr9 1/1 Running 0 6m21s [root@master-01 yaml]# [root@master-01 yaml]# kubectl exec -it tomcat-deployment-78c89857d6-9qtr9 bash root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat# cd webapps root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# mkdir tomcat root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# echo \"Tomcat test page for pod of k8s~\" \u003e tomcat/index.html root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# exit exit 4.3 从 dashboard 查看结果 4.4 配置 nginx 实现动静分离 [[root@master-01 ~]# kubectl get pod,svc NAME READY STATUS RESTARTS AGE pod/net-test-88ff4d957-krc9v 1/1 Running 0 44m pod/nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 70m pod/tomcat-deployment-78c89857d6-9qtr9 1/1 Running 0 70m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.200.0.1 443/TCP 3h49m service/nginx-service NodePort 10.200.231.164 80:30004/TCP 70m service/tomcat-service NodePort 10.200.206.119 80:30005/TCP 70m [root@master-01 ~]# kubectl exec -it nginx-deployment-d44c4d8f4-bftm4 bash root@nginx-deployment-d44c4d8f4-bftm4:/# root@nginx-deployment-d44c4d8f4-sfslr:/# cat \u003e /etc/nginx/conf.d/default.conf \u003c\u003c EOF server { listen 80; listen [::]:80; server_name localhost; location /tomcat { proxy_pass http://tomcat-service.default.svc.example.local; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } EOF root@nginx-deployment-d44c4d8f4-bftm4:/# nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful root@nginx-deployment-d44c4d8f4-bftm4:/# nginx -s reload 2023/10/02 11:44:15 [notice] 997#997: signal process started 五、k8s 集群管理 5.1 token 管理 [root@master-01 ~]# kubeadm # 双击 tab 补全得到的结果 alpha completion config init join reset token upgrade version [root@master-01 ~]# kubeadm token create delete generate list 5.2 reset 命令 在初始化集群时，如果生成了错误的配置，可以用该命令重置环境\n[root@master-01 ~]# kubeadm reset kubeadm reset 命令用于将Kubernetes节点（通常是工作节点）恢复到其初始状态，将节点从Kubernetes集群中分离并清理集群相关的配置和数据。这个命令的主要作用包括：\n节点的脱离集群：kubeadm reset 会将节点从Kubernetes集群中分离。这包括删除节点的证书、从集群中删除节点的信息，并且节点将不再参与集群中的通信和管理。\n清理配置文件：它会删除Kubernetes的配置文件，例如kubeconfig文件，以及CNI（容器网络接口）插件的配置，以确保不再影响Kubernetes集群。\n清理数据：kubeadm reset 还会清理节点上的Kubernetes数据，包括删除容器、卷、数据存储等，以确保节点不再包含与Kubernetes集群相关的残留数据。\n这个命令通常在以下情况下使用：\n当你需要卸载或移除节点上的Kubernetes时，可以使用 kubeadm reset 来清理节点，然后重新配置或重新部署Kubernetes。\n在测试环境中，当你需要重置一个节点以进行新的Kubernetes集群配置时，可以使用 kubeadm reset。\n请注意，kubeadm reset 只应该用于节点级别的操作，并且在生产环境中使用时需要谨慎，因为它会删除节点上的Kubernetes相关数据。如果你需要从整个Kubernetes集群中移除节点，请首先使用 kubectl drain 命令将节点上的工作负载迁移到其他节点，然后再使用 kubeadm reset 进行节点的重置和卸载。\n5.3 查看证书有效期 [root@master-01 ~]# kubeadm alpha certs kubeconfig kubelet selfhosting [root@master-01 ~]# kubeadm alpha certs certificate-key check-expiration renew # 检查证书是否过期，可以发现 kubeadm 部署的集群，证书有效期为 365d（一年） [root@master-01 ~]# kubeadm alpha certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf Oct 01, 2024 07:58 UTC 364d no apiserver Oct 01, 2024 07:58 UTC 364d ca no apiserver-etcd-client Oct 01, 2024 07:58 UTC 364d etcd-ca no apiserver-kubelet-client Oct 01, 2024 07:58 UTC 364d ca no controller-manager.conf Oct 01, 2024 07:58 UTC 364d no etcd-healthcheck-client Oct 01, 2024 07:58 UTC 364d etcd-ca no etcd-peer Oct 01, 2024 07:58 UTC 364d etcd-ca no etcd-server Oct 01, 2024 07:58 UTC 364d etcd-ca no front-proxy-client Oct 01, 2024 07:58 UTC 364d front-proxy-ca no scheduler.conf Oct 01, 2024 07:58 UTC 364d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca Sep 29, 2033 07:58 UTC 9y no etcd-ca Sep 29, 2033 07:58 UTC 9y no front-proxy-ca Sep 29, 2033 07:58 UTC 9y no 5.4 更新证书有效期 参考链接：\nhttps://www.qikqiak.com/post/update-k8s-10y-expire-certs/\nhttps://www.chenshaowen.com/blog/how-to-renew-kubernetes-certs-manually.html\n[root@master-01 ~]# kubeadm alpha certs renew admin.conf apiserver-etcd-client etcd-healthcheck-client front-proxy-client all apiserver-kubelet-client etcd-peer scheduler.conf apiserver controller-manager.conf etcd-server # 更新所有证书 [root@master-01 ~]# kubeadm alpha certs renew all 完成后重启 kube-apiserver、kube-controller、kube-scheduler 这 3个容器即可，我们可以查看 apiserver 的证书的有效期来验证是否更新成功：\n[root@master-01 ~]# docker ps |egrep \"k8s_kube-apiserver|k8s_kube-scheduler|k8s_kube-controller\"|awk '{print $1}'|xargs docker restart c2d987734f5a 043af8733130 5a87240ba97a [root@master-01 ~]# echo | openssl s_client -showcerts -connect 127.0.0.1:6443 -servername api 2\u003e/dev/null | openssl x509 -noout -enddate notAfter=Oct 1 13:17:56 2024 GMT 六、k8s 集群升级 kubeadm 部署的集群需要用 kubeadm 来升级，首先需要将 kubeadm 升级到目标版本，然后再继续其他操作。\n6.1 升级准备 本次升级，目标版本：v1.19.2\n查看当前版本\n[root@master-01 ~]# kubeadm version kubeadm version: \u0026version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.11\", GitCommit:\"ea5f00d93211b7c80247bf607cfa422ad6fb5347\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T15:17:52Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"} # 查看 yum 源是否有目标版本 [root@master-01 ~]# yum list kubectl kubeadm kubelet --showduplicates | grep 1.19.2 kubeadm.x86_64 1.19.2-0 kubernetes kubectl.x86_64 1.19.2-0 kubernetes kubelet.x86_64 1.19.2-0 kubernetes 6.2 升级 master 节点 滚动式升级 master 节点\n# 安装部署工具 yum install -y kubelet-1.19.2 kubectl-1.19.2 kubeadm-1.19.2 [root@master-01 ~]# kubeadm version kubeadm version: \u0026version.Info{Major:\"1\", Minor:\"19\", GitVersion:\"v1.19.2\", GitCommit:\"f5743093fd1c663cb0cbc89748f730662345d44d\", GitTreeState:\"clean\", BuildDate:\"2020-09-16T13:38:53Z\", GoVersion:\"go1.15\", Compiler:\"gc\", Platform:\"linux/amd64\"} 查看版本升级计划\n[root@master-01 ~]# kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [upgrade/config] FATAL: this version of kubeadm only supports deploying clusters with the control plane version \u003e= 1.18.0. Current version: v1.17.11 # 版本低于 1.18.0，kubeadm 不支持升级操作 To see the stack trace of this error execute with --v=5 or higher 如果选择的版本符合 kubeadm 的要求，则继续以下操作\n[root@master-01 ~]# kubeadm upgrade apply v1.19.2 升级完成后，可以查看镜像版本\n# docker images 6.3 升级 node 节点 同样是滚动升级的方式进行\n# 安装部署工具 yum install -y kubelet-1.19.2 kubectl-1.19.2 kubeadm-1.19.2 # 执行升级操作 kubeadm upgrade node --kubelet-version 1.19.2 ","wordCount":"8416","inLanguage":"zh","datePublished":"2023-10-02T22:37:50+08:00","dateModified":"2023-10-02T22:37:50+08:00","author":[{"@type":"Person","name":"wz"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://senmer.github.io/zh/posts/tech/kubernetes/kubeadm%E9%83%A8%E7%BD%B2k8s%E9%9B%86%E7%BE%A4/"},"publisher":{"@type":"Organization","name":"WZ's Blog","logo":{"@type":"ImageObject","url":"https://senmer.github.io/img/Q.gif"}}}</script></head><body id=top><script>(function(){let e,t=new RegExp("(^| )change-themes=([^;]*)(;|$)");(e=document.cookie.match(t))||((new Date).getHours()>=19||(new Date).getHours()<6?(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark")):(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")))})(),localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://senmer.github.io/zh/ accesskey=h title="WZ's Blog (Alt + H)"><img src=https://senmer.github.io/img/Q.gif alt=logo aria-label=logo height=35>WZ's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://senmer.github.io/zh/search title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://senmer.github.io/zh/ title="🏠 主页"><span>🏠 主页</span></a></li><li><a href=https://senmer.github.io/zh/posts/tech title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://senmer.github.io/zh/categories/ title="🧩 分类"><span>🧩 分类</span></a></li><li><a href=https://senmer.github.io/zh/archives/ title="⏱️ 时间轴"><span>⏱️ 时间轴</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://senmer.github.io/zh/>🏠 主页</a>&nbsp;»&nbsp;<a href=https://senmer.github.io/zh/posts/>📚文章</a>&nbsp;»&nbsp;<a href=https://senmer.github.io/zh/posts/tech/>👨🏻‍💻 技术</a></div><h1 class=post-title>Kubeadm部署k8s集群</h1><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2023-10-02
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>8416字
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>17分钟
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>wz
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta></span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://senmer.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:"https://hugo-api-khaki.vercel.app/# 填写自己的twikoo id",region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e4%b8%80-%e7%ae%80%e4%bb%8b aria-label="一、 简介">一、 简介</a><ul><li><a href=#11-k8s-%e6%98%af%e4%bb%80%e4%b9%88 aria-label="1.1 k8s 是什么">1.1 k8s 是什么</a></li><li><a href=#12-k8s-%e7%9a%84%e4%bc%98%e5%8a%bf aria-label="1.2 k8s 的优势">1.2 k8s 的优势</a></li><li><a href=#13-k8s-%e7%bb%84%e4%bb%b6%e4%bb%8b%e7%bb%8d aria-label="1.3 k8s 组件介绍">1.3 k8s 组件介绍</a></li></ul></li><li><a href=#%e4%ba%8ck8s-%e5%ae%89%e8%a3%85%e9%83%a8%e7%bd%b2kubeadm aria-label="二、k8s 安装部署（kubeadm）">二、k8s 安装部署（kubeadm）</a><ul><li><a href=#21-%e5%ae%89%e8%a3%85%e6%96%b9%e5%bc%8f aria-label="2.1 安装方式">2.1 安装方式</a></li><li><a href=#22-%e9%83%a8%e7%bd%b2%e8%bf%87%e7%a8%8b aria-label="2.2 部署过程">2.2 部署过程</a><ul><li><a href=#221-%e5%85%b7%e4%bd%93%e6%ad%a5%e9%aa%a4 aria-label="2.2.1 具体步骤">2.2.1 具体步骤</a></li><li><a href=#222--%e9%83%a8%e7%bd%b2%e7%8e%af%e5%a2%83 aria-label="2.2.2  部署环境">2.2.2 部署环境</a></li></ul></li><li><a href=#23-%e9%83%a8%e7%bd%b2%e9%ab%98%e5%8f%af%e7%94%a8%e5%8f%8d%e5%90%91%e4%bb%a3%e7%90%86 aria-label="2.3 部署高可用反向代理">2.3 部署高可用反向代理</a></li><li><a href=#24-%e9%83%a8%e7%bd%b2-harbor aria-label="2.4 部署 harbor">2.4 部署 harbor</a></li><li><a href=#25-%e6%89%80%e6%9c%89%e8%8a%82%e7%82%b9%e5%ae%89%e8%a3%85-docker aria-label="2.5 所有节点安装 docker">2.5 所有节点安装 docker</a></li><li><a href=#26-%e6%89%80%e6%9c%89%e8%8a%82%e7%82%b9%e5%ae%89%e8%a3%85%e9%9b%86%e7%be%a4%e5%88%9d%e5%a7%8b%e5%8c%96%e5%b7%a5%e5%85%b7 aria-label="2.6 所有节点安装集群初始化工具">2.6 所有节点安装集群初始化工具</a><ul><li><a href=#261-%e9%85%8d%e7%bd%ae%e5%9b%bd%e5%86%85%e9%95%9c%e5%83%8f%e6%ba%90 aria-label="2.6.1 配置国内镜像源">2.6.1 配置国内镜像源</a></li><li><a href=#262-%e5%ae%89%e8%a3%85%e5%88%9d%e5%a7%8b%e5%8c%96%e5%b7%a5%e5%85%b7 aria-label="2.6.2 安装初始化工具">2.6.2 安装初始化工具</a></li><li><a href=#263-kubeadm-%e5%91%bd%e4%bb%a4%e7%9a%84%e4%bd%bf%e7%94%a8 aria-label="2.6.3 kubeadm 命令的使用">2.6.3 kubeadm 命令的使用</a></li></ul></li><li><a href=#27-k8s-%e5%8d%95%e8%8a%82%e7%82%b9%e9%83%a8%e7%bd%b2 aria-label="2.7 k8s 单节点部署">2.7 k8s 单节点部署</a><ul><li><a href=#271-%e5%bc%80%e5%a7%8b%e9%83%a8%e7%bd%b2 aria-label="2.7.1 开始部署">2.7.1 开始部署</a></li><li><a href=#272-%e9%aa%8c%e8%af%81%e7%bb%93%e6%9e%9c aria-label="2.7.2 验证结果">2.7.2 验证结果</a></li><li><a href=#273-%e9%83%a8%e7%bd%b2%e7%bd%91%e7%bb%9c%e7%bb%84%e4%bb%b6 aria-label="2.7.3 部署网络组件">2.7.3 部署网络组件</a></li></ul></li><li><a href=#28-k8s-%e5%a4%9a%e8%8a%82%e7%82%b9%e9%83%a8%e7%bd%b2%e9%ab%98%e5%8f%af%e7%94%a8 aria-label="2.8 k8s 多节点部署（高可用）">2.8 k8s 多节点部署（高可用）</a><ul><li><a href=#281-%e5%bc%80%e5%a7%8b%e9%83%a8%e7%bd%b2 aria-label="2.8.1 开始部署">2.8.1 开始部署</a></li><li><a href=#282-%e6%b7%bb%e5%8a%a0-master-%e8%8a%82%e7%82%b9 aria-label="2.8.2 添加 master 节点">2.8.2 添加 master 节点</a></li><li><a href=#283-%e6%b7%bb%e5%8a%a0-node-%e8%8a%82%e7%82%b9 aria-label="2.8.3 添加 node 节点">2.8.3 添加 node 节点</a></li><li><a href=#284-%e6%9f%a5%e7%9c%8b%e9%9b%86%e7%be%a4%e8%af%81%e4%b9%a6 aria-label="2.8.4 查看集群证书">2.8.4 查看集群证书</a></li><li><a href=#285-%e5%88%9b%e5%bb%ba-pod-%e9%aa%8c%e8%af%81%e9%9b%86%e7%be%a4%e7%bd%91%e7%bb%9c aria-label="2.8.5 创建 pod 验证集群网络">2.8.5 创建 pod 验证集群网络</a></li></ul></li></ul></li><li><a href=#%e4%b8%89%e9%83%a8%e7%bd%b2-dashboard aria-label="三、部署 Dashboard">三、部署 Dashboard</a><ul><li><a href=#31-%e5%87%86%e5%a4%87%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="3.1 准备配置文件">3.1 准备配置文件</a></li><li><a href=#32-%e9%83%a8%e7%bd%b2%e5%b9%b6%e9%aa%8c%e8%af%81%e6%95%88%e6%9e%9c aria-label="3.2 部署并验证效果">3.2 部署并验证效果</a></li></ul></li><li><a href=#%e5%9b%9bk8s-%e9%83%a8%e7%bd%b2-nginx--tomcat aria-label="四、k8s 部署 nginx + tomcat">四、k8s 部署 nginx + tomcat</a><ul><li><a href=#41-%e9%83%a8%e7%bd%b2-nginx aria-label="4.1 部署 nginx">4.1 部署 nginx</a></li><li><a href=#42-%e9%83%a8%e7%bd%b2-tomcat aria-label="4.2 部署 tomcat">4.2 部署 tomcat</a></li><li><a href=#43-%e4%bb%8e-dashboard-%e6%9f%a5%e7%9c%8b%e7%bb%93%e6%9e%9c aria-label="4.3 从 dashboard 查看结果">4.3 从 dashboard 查看结果</a></li><li><a href=#44-%e9%85%8d%e7%bd%ae-nginx-%e5%ae%9e%e7%8e%b0%e5%8a%a8%e9%9d%99%e5%88%86%e7%a6%bb aria-label="4.4 配置 nginx 实现动静分离">4.4 配置 nginx 实现动静分离</a></li></ul></li><li><a href=#%e4%ba%94k8s-%e9%9b%86%e7%be%a4%e7%ae%a1%e7%90%86 aria-label="五、k8s 集群管理">五、k8s 集群管理</a><ul><li><a href=#51-token-%e7%ae%a1%e7%90%86 aria-label="5.1 token 管理">5.1 token 管理</a></li><li><a href=#52-reset-%e5%91%bd%e4%bb%a4 aria-label="5.2 reset 命令">5.2 reset 命令</a></li><li><a href=#53-%e6%9f%a5%e7%9c%8b%e8%af%81%e4%b9%a6%e6%9c%89%e6%95%88%e6%9c%9f aria-label="5.3 查看证书有效期">5.3 查看证书有效期</a></li><li><a href=#54-%e6%9b%b4%e6%96%b0%e8%af%81%e4%b9%a6%e6%9c%89%e6%95%88%e6%9c%9f aria-label="5.4 更新证书有效期">5.4 更新证书有效期</a></li></ul></li><li><a href=#%e5%85%adk8s-%e9%9b%86%e7%be%a4%e5%8d%87%e7%ba%a7 aria-label="六、k8s 集群升级">六、k8s 集群升级</a><ul><li><a href=#61-%e5%8d%87%e7%ba%a7%e5%87%86%e5%a4%87 aria-label="6.1 升级准备">6.1 升级准备</a></li><li><a href=#62-%e5%8d%87%e7%ba%a7-master-%e8%8a%82%e7%82%b9 aria-label="6.2 升级 master 节点">6.2 升级 master 节点</a></li><li><a href=#63-%e5%8d%87%e7%ba%a7-node-%e8%8a%82%e7%82%b9 aria-label="6.3 升级 node 节点">6.3 升级 node 节点</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=一-简介>一、 简介<a hidden class=anchor aria-hidden=true href=#一-简介>#</a></h2><h3 id=11-k8s-是什么>1.1 k8s 是什么<a hidden class=anchor aria-hidden=true href=#11-k8s-是什么>#</a></h3><p>Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构建、交付和运行容器化应用。</p><h3 id=12-k8s-的优势>1.2 k8s 的优势<a hidden class=anchor aria-hidden=true href=#12-k8s-的优势>#</a></h3><p>Kubernetes 是一个开源的容器编排平台，它提供了一种管理容器化应用程序的强大方式。以下是 Kubernetes 的一些优势：</p><ol><li><strong>自动化和自我修复：</strong> Kubernetes 可以自动监测应用程序状态并进行自我修复，确保应用持续稳定运行。如果某个容器或节点发生故障，Kubernetes 会自动重新启动容器或迁移工作负载。</li><li><strong>弹性扩展：</strong> Kubernetes 允许根据需要扩展或缩减应用程序实例的数量。这种自动扩展能力可根据负载自动调整应用的规模，以满足流量需求，同时在需求减少时节约资源。</li><li><strong>负载均衡：</strong> Kubernetes 支持内置的负载均衡，可以将传入的流量分发到不同的容器实例中，确保应用程序能够有效地处理高流量。</li><li><strong>自动部署和滚动更新：</strong> 通过声明式的配置，Kubernetes 允许你轻松地进行应用程序的部署和更新。滚动更新功能可以逐步替换旧版本的容器，从而减少应用程序的停机时间。</li><li><strong>多环境支持：</strong> Kubernetes 支持多个环境（例如开发、测试、生产）之间的轻松迁移，确保应用在不同阶段的一致性。</li><li><strong>声明式配置：</strong> 你可以使用 Kubernetes 的 YAML 文件来定义应用程序的配置和部署要求。这种声明式的方法让你能够更清晰地定义应用程序状态，而 Kubernetes 负责将系统状态调整为所需状态。</li><li><strong>自定义资源和扩展性：</strong> Kubernetes 允许你创建自定义资源和控制器，从而可以扩展平台的功能，满足特定应用程序或业务的需求。</li><li><strong>多种容器运行时支持：</strong> Kubernetes 支持多种容器运行时，如 Docker、Containerd 等，使你可以选择最适合你的应用的运行时环境。</li><li><strong>社区支持和生态系统：</strong> Kubernetes 拥有庞大的社区和丰富的生态系统，有大量的工具、插件和服务，可以帮助你更好地管理、监控和扩展你的应用程序。</li><li><strong>跨云和本地环境：</strong> Kubernetes 可以在不同的云平台和本地环境中运行，使你能够在不同的基础架构上保持一致的部署和管理体验。</li></ol><p>总之，Kubernetes 提供了强大的容器编排和管理功能，帮助开发人员和运维团队更有效地部署、扩展和管理容器化应用程序。它的优势在于自动化、弹性、灵活性以及丰富的生态系统。</p><h3 id=13-k8s-组件介绍>1.3 k8s 组件介绍<a hidden class=anchor aria-hidden=true href=#13-k8s-组件介绍>#</a></h3><p>Kubernetes（通常简称为K8s）由多个组件组成，这些组件共同协作以管理容器化应用程序的生命周期。以下是常见的 Kubernetes 组件及其功能介绍：</p><ol><li><strong>Kubelet：</strong> 运行在每个节点上的代理，负责管理容器的生命周期。它与 Master 节点通信，确保容器在节点上按照所需的状态运行。</li><li><strong>Kube-Proxy：</strong> 也运行在每个节点上，维护网络规则以实现 Service 暴露和负载均衡。它根据 Service 配置更新节点上的 iptables 规则。</li><li><strong>Kube-Scheduler：</strong> 负责监视新创建的 Pod，并根据各种条件（如资源需求、亲和性、亲和性等）将其调度到集群中的适当节点上。</li><li><strong>Kube-Controller-Manager：</strong> 包含多个控制器，用于监控集群状态并根据需要进行自动修复。其中一些控制器包括：<ul><li><strong>Replication Controller 和 ReplicaSet 控制器：</strong> 确保在集群中运行指定数量的 Pod 副本。</li><li><strong>Deployment 控制器：</strong> 管理应用程序的滚动更新和版本控制。</li><li><strong>Namespace 控制器：</strong> 管理命名空间的创建、更新和删除。</li></ul></li><li><strong>Etcd：</strong> 是一个分布式键值存储系统，用于存储集群的配置信息、状态和元数据。Kubernetes 使用 Etcd 来存储所有关键信息，包括配置、部署和服务发现。</li><li><strong>API Server：</strong> 提供了 Kubernetes 集群的 API，允许用户和其他组件与集群进行交互。所有的资源和操作都通过 API Server 进行访问和管理。</li><li><strong>Container Runtime：</strong> 负责运行容器，常见的容器运行时包括 Docker、Containerd 等。</li><li><strong>Controller Manager：</strong> 包含一系列控制器，这些控制器可以监控集群中的资源状态，并确保所需状态与实际状态保持一致。</li><li><strong>Cloud Controller Manager：</strong> 在云平台上运行，用于集成 Kubernetes 集群与特定云提供商的功能，如自动扩展、负载均衡等。</li><li><strong>Admission Controllers：</strong> 用于拦截和修改进入 Kubernetes 集群的请求。这些控制器可以执行验证、默认值设置和修改请求，以确保遵循集群策略。</li><li><strong>Ingress Controller：</strong> 管理 Ingress 资源，将外部流量引导到集群内部的服务。</li><li><strong>Pods：</strong> 是 Kubernetes 的最小调度单位，可以包含一个或多个容器。它们可以共享网络和存储，形成一个逻辑单元。</li><li><strong>Services：</strong> 用于定义一组 Pod 的访问方式，提供负载均衡和服务发现功能，使应用程序能够在不同的 Pod 之间进行通信。</li><li><strong>ConfigMaps 和 Secrets：</strong> 用于将配置和机密信息与应用程序分开，并在容器中以环境变量或卷的形式提供。</li></ol><p>这些组件一起协同工作，使 Kubernetes 能够提供强大的容器编排和管理功能。每个组件都扮演着不同的角色，确保容器化应用程序能够以高可用性、自动化和弹性的方式运行。</p><h2 id=二k8s-安装部署kubeadm>二、k8s 安装部署（kubeadm）<a hidden class=anchor aria-hidden=true href=#二k8s-安装部署kubeadm>#</a></h2><blockquote><p>注意：本文安装的 k8s 版本为 <code>v1.17.11</code>，不能直接通过 kubeadm 执行升级操作。如果需要进行升级操作，需要满足 <code>version >= 1.18.0</code></p></blockquote><h3 id=21-安装方式>2.1 安装方式<a hidden class=anchor aria-hidden=true href=#21-安装方式>#</a></h3><p>Kubernetes 的安装可以分为多种方式，根据你的需求和环境选择合适的安装方式。以下是一些常见的 Kubernetes 安装方式：</p><ol><li><p><strong>Minikube：</strong> 如果你想在本地开发环境中快速搭建一个单节点的 Kubernetes 集群，可以使用 Minikube。Minikube 创建一个虚拟机，并在其中运行一个单节点的 Kubernetes 集群。适合学习和开发目的。</p></li><li><p><strong>Kubeadm：</strong> Kubeadm 是一个官方维护的工具，用于在生产环境中快速部署 Kubernetes 集群。它可以在多个节点上设置一个高度可配置的集群，适用于较小规模的生产环境。</p></li><li><p><strong>Kubespray（原先叫Kargo）：</strong> Kubespray 是一个开源项目，用于部署高度定制化的 Kubernetes 集群。它支持多种操作系统和云平台，并且可以根据配置要求进行定制化部署。</p></li><li><p><strong>Managed Kubernetes Services：</strong> 主要云提供商（如AWS、Google Cloud、Azure）提供托管的 Kubernetes 服务，如Amazon EKS、Google Kubernetes Engine（GKE）、Azure Kubernetes Service（AKS）。这些服务会为你自动管理集群的维护、升级和可用性。</p></li><li><p><strong>Rancher：</strong> Rancher 是一个开源的容器管理平台，可以帮助你在不同的基础设施上轻松部署和管理 Kubernetes 集群。</p></li><li><p><strong>K3s：</strong> K3s 是一个轻量级的 Kubernetes 发行版，旨在为资源受限的环境（如边缘计算）提供更轻便的安装和管理。</p></li><li><p><strong>自定义安装脚本：</strong> 你可以根据 Kubernetes 的官方文档，在自己的环境中编写自定义的安装脚本。这样可以更好地适应特定需求和架构。</p></li></ol><p>对于初学者来说，Minikube 和 Managed Kubernetes Services 是较为简单的入门方式。而对于生产环境，Kubeadm、Kubespray 和 Rancher 提供了更大的灵活性和控制权。在选择安装方式时，考虑到你的技术水平、部署规模和所在的基础设施环境是很重要的。无论选择哪种方式，确保参考官方文档和最佳实践来确保安装的正确性和可靠性。</p><h3 id=22-部署过程>2.2 部署过程<a hidden class=anchor aria-hidden=true href=#22-部署过程>#</a></h3><p><strong>安装前准备：</strong></p><ul><li><p>禁用 swap 分区</p></li><li><p>关闭 selinux</p></li><li><p>关闭 iptables、NetworkManager 服务</p></li><li><p>同步服务器时间</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># ntpdate ntp.aliyun.com</span>
</span></span><span style=display:flex><span><span style=color:#75715e># hwclock -w</span>
</span></span></code></pre></div></li><li><p>优化内核参数并修改资源限制</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@centos7 ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/sysctl.conf </span>
</span></span><span style=display:flex><span>net.ipv4.ip_forward <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>net.bridge.bridge-nf-call-iptables <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>net.bridge.bridge-nf-call-ip6tables <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>net.bridge.bridge-nf-call-arptables <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>net.ipv4.tcp_tw_reuse <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>net.ipv4.ip_nonlocal_bind <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> 
</span></span><span style=display:flex><span>net.core.somaxconn <span style=color:#f92672>=</span> <span style=color:#ae81ff>32768</span>
</span></span><span style=display:flex><span>net.netfilter.nf_conntrack_max <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000000</span>
</span></span><span style=display:flex><span>vm.swappiness <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>vm.max_map_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>655360</span>
</span></span><span style=display:flex><span>fs.file-max <span style=color:#f92672>=</span> <span style=color:#ae81ff>655360</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@centos7 ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/security/limits.conf </span>
</span></span><span style=display:flex><span><span style=color:#75715e>#&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>*                soft    core            unlimited 
</span></span><span style=display:flex><span>*                hard    core            unlimited 
</span></span><span style=display:flex><span>*                soft    nproc           <span style=color:#ae81ff>1000000</span> 
</span></span><span style=display:flex><span>*                hard    nproc           <span style=color:#ae81ff>1000000</span> 
</span></span><span style=display:flex><span>*                soft    nofile          <span style=color:#ae81ff>1000000</span> 
</span></span><span style=display:flex><span>*                hard    nofile          <span style=color:#ae81ff>1000000</span> 
</span></span><span style=display:flex><span>*                soft    memlock         <span style=color:#ae81ff>24800</span> 
</span></span><span style=display:flex><span>*                hard    memlock         <span style=color:#ae81ff>24800</span> 
</span></span><span style=display:flex><span>*                soft    msgqueue        <span style=color:#ae81ff>8192000</span> 
</span></span><span style=display:flex><span>*                hard    msgqueue        <span style=color:#ae81ff>8192000</span> 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>root             soft    core            unlimited
</span></span><span style=display:flex><span>root             hard    core            unlimited
</span></span><span style=display:flex><span>root             soft    nproc           <span style=color:#ae81ff>1000000</span>
</span></span><span style=display:flex><span>root             hard    nproc           <span style=color:#ae81ff>1000000</span>
</span></span><span style=display:flex><span>root             soft    nofile          <span style=color:#ae81ff>1000000</span>
</span></span><span style=display:flex><span>root             hard    nofile          <span style=color:#ae81ff>1000000</span>
</span></span><span style=display:flex><span>root             soft    memlock         <span style=color:#ae81ff>24800</span>  
</span></span><span style=display:flex><span>root             hard    memlock         <span style=color:#ae81ff>24800</span>    
</span></span><span style=display:flex><span>root             soft    msgqueue        <span style=color:#ae81ff>8192000</span>
</span></span><span style=display:flex><span>root             hard    msgqueue        <span style=color:#ae81ff>8192000</span>
</span></span></code></pre></div></li></ul><h4 id=221-具体步骤>2.2.1 具体步骤<a hidden class=anchor aria-hidden=true href=#221-具体步骤>#</a></h4><ol><li>基础环境准备</li><li>部署 harbor 和 haproxy 高可用反向代理，实现控制节点 API 的高可用</li><li>在所有 master 节点安装指定的 kubeadm、kubelet、kubectl、docker</li><li>在所有 node 节点按爪给你指定版本的 kubeadm、docker、kubelet（可选）</li><li>在 master 节点运行 kubeadm ini 初始化命令创建集群</li><li>验证 master 节点状态</li><li>在 node 节点使用 kubeadm 命令将自身加入集群</li><li>验证 ndoe 节点状态</li><li>创建 pod 并测试网络是否正常</li><li>部署 dashboard</li><li>集群升级</li></ol><h4 id=222--部署环境>2.2.2 部署环境<a hidden class=anchor aria-hidden=true href=#222--部署环境>#</a></h4><blockquote><p>如果是虚拟化环境，最好每个重要节点做好快照</p></blockquote><p>**操作系统：**Centos 7.8</p><p>**安装方式：**最小化安装</p><p>**部署方式：**VMware 16 Pro</p><table><thead><tr><th>角色</th><th>主机名</th><th>IP</th><th>配置</th></tr></thead><tbody><tr><td>k8s-master-01</td><td>master-01.example.local</td><td>10.0.0.11</td><td>2U 2G</td></tr><tr><td>k8s-master-02</td><td>master-02.example.local</td><td>10.0.0.12</td><td>2U 2G</td></tr><tr><td>k8s-master-03</td><td>master-03.example.local</td><td>10.0.0.13</td><td>2U 2G</td></tr><tr><td>ha-01</td><td>ha-01.example.local</td><td>10.0.0.14</td><td>1U 2G</td></tr><tr><td>ha-02</td><td>ha-02.example.local</td><td>10.0.0.15</td><td>1U 2G</td></tr><tr><td>harbor</td><td>harbor.example.local</td><td>10.0.0.16</td><td>2U 4G</td></tr><tr><td>node-01</td><td>node-01.example.local</td><td>10.0.0.17</td><td>1U 2G</td></tr><tr><td>node-02</td><td>node-02.example.local</td><td>10.0.0.18</td><td>1U 2G</td></tr><tr><td>node-03</td><td>node-03.example.local</td><td>10.0.0.19</td><td>1U 2G</td></tr></tbody></table><h3 id=23-部署高可用反向代理>2.3 部署高可用反向代理<a hidden class=anchor aria-hidden=true href=#23-部署高可用反向代理>#</a></h3><p>基于 Keepalived + haprox实现高可用反向代理，实现 k8s apiserver 服务的高可用</p><p><strong>ha-01：</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install -y keepalived
</span></span><span style=display:flex><span>yum install -y haproxy
</span></span><span style=display:flex><span>cp /usr/share/doc/keepalived-1.3.5/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/keepalived/keepalived.conf </span>
</span></span><span style=display:flex><span>! Configuration File <span style=color:#66d9ef>for</span> keepalived
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>global_defs <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>   notification_email <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>     acassen
</span></span><span style=display:flex><span>   <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>   notification_email_from Alexandre.Cassen@firewall.loc
</span></span><span style=display:flex><span>   smtp_server 192.168.200.1
</span></span><span style=display:flex><span>   smtp_connect_timeout <span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>   router_id LVS_DEVEL
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>vrrp_instance k8s <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    state MASTER
</span></span><span style=display:flex><span>    interface eth0
</span></span><span style=display:flex><span>    garp_master_delay <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>    smtp_alert
</span></span><span style=display:flex><span>    virtual_router_id <span style=color:#ae81ff>51</span>
</span></span><span style=display:flex><span>    priority <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>    advert_int <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    authentication <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>        auth_type PASS
</span></span><span style=display:flex><span>        auth_pass <span style=color:#ae81ff>1111</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>    virtual_ipaddress <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>	10.0.0.188 label eth0:1
</span></span><span style=display:flex><span>	10.0.0.199 label eth0:2
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># tail -n 60 /etc/haproxy/haproxy.cfg</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>defaults
</span></span><span style=display:flex><span>    mode                    http
</span></span><span style=display:flex><span>    log                     global
</span></span><span style=display:flex><span>    option                  httplog
</span></span><span style=display:flex><span>    option                  dontlognull
</span></span><span style=display:flex><span>    option http-server-close
</span></span><span style=display:flex><span>    option forwardfor       except 127.0.0.0/8
</span></span><span style=display:flex><span>    option                  redispatch
</span></span><span style=display:flex><span>    retries                 <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>    timeout http-request    10s
</span></span><span style=display:flex><span>    timeout queue           1m
</span></span><span style=display:flex><span>    timeout connect         10s
</span></span><span style=display:flex><span>    timeout client          1m
</span></span><span style=display:flex><span>    timeout server          1m
</span></span><span style=display:flex><span>    timeout http-keep-alive 10s
</span></span><span style=display:flex><span>    timeout check           10s
</span></span><span style=display:flex><span>    maxconn                 <span style=color:#ae81ff>3000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>listen stats
</span></span><span style=display:flex><span>    mode http
</span></span><span style=display:flex><span>    bind 0.0.0.0:9999
</span></span><span style=display:flex><span>    stats enable
</span></span><span style=display:flex><span>    log global
</span></span><span style=display:flex><span>    stats uri /haproxy-status
</span></span><span style=display:flex><span>    stats auth admin:passwd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>listen k8s-apiserver-6443
</span></span><span style=display:flex><span>    bind 10.0.0.188:6443
</span></span><span style=display:flex><span>    mode tcp
</span></span><span style=display:flex><span>    balance roundrobin
</span></span><span style=display:flex><span>    server 10.0.0.11 10.0.0.11:6443 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.12 10.0.0.12:6443 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.13 10.0.0.13:6443 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>listen k8s-node-80
</span></span><span style=display:flex><span>    bind 10.0.0.199:80
</span></span><span style=display:flex><span>    mode tcp
</span></span><span style=display:flex><span>    balance roundrobin
</span></span><span style=display:flex><span>    server 10.0.0.17 10.0.0.17:30004 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.18 10.0.0.18:30004 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.19 10.0.0.19:30004 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl enable --now keepalived.service </span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl enable --now haproxy.service </span>
</span></span></code></pre></div><p><strong>ha2:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install -y keepalived
</span></span><span style=display:flex><span>yum install -y haproxy
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cp /usr/share/doc/keepalived-1.3.5/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/keepalived/keepalived.conf </span>
</span></span><span style=display:flex><span>! Configuration File <span style=color:#66d9ef>for</span> keepalived
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>global_defs <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>   notification_email <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>     acassen
</span></span><span style=display:flex><span>   <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>   notification_email_from Alexandre.Cassen@firewall.loc
</span></span><span style=display:flex><span>   smtp_server 192.168.200.1
</span></span><span style=display:flex><span>   smtp_connect_timeout <span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>   router_id LVS_DEVEL
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>vrrp_instance k8s <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    state MASTER
</span></span><span style=display:flex><span>    interface eth0
</span></span><span style=display:flex><span>    garp_master_delay <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>    smtp_alert
</span></span><span style=display:flex><span>    virtual_router_id <span style=color:#ae81ff>51</span>
</span></span><span style=display:flex><span>    priority <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>    advert_int <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    authentication <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>        auth_type PASS
</span></span><span style=display:flex><span>        auth_pass <span style=color:#ae81ff>1111</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>    virtual_ipaddress <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>	10.0.0.188 label eth0:1
</span></span><span style=display:flex><span>	10.0.0.199 label eth0:2
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-02 ~<span style=color:#f92672>]</span><span style=color:#75715e># tail -n 60 /etc/haproxy/haproxy.cfg</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>defaults
</span></span><span style=display:flex><span>    mode                    http
</span></span><span style=display:flex><span>    log                     global
</span></span><span style=display:flex><span>    option                  httplog
</span></span><span style=display:flex><span>    option                  dontlognull
</span></span><span style=display:flex><span>    option http-server-close
</span></span><span style=display:flex><span>    option forwardfor       except 127.0.0.0/8
</span></span><span style=display:flex><span>    option                  redispatch
</span></span><span style=display:flex><span>    retries                 <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>    timeout http-request    10s
</span></span><span style=display:flex><span>    timeout queue           1m
</span></span><span style=display:flex><span>    timeout connect         10s
</span></span><span style=display:flex><span>    timeout client          1m
</span></span><span style=display:flex><span>    timeout server          1m
</span></span><span style=display:flex><span>    timeout http-keep-alive 10s
</span></span><span style=display:flex><span>    timeout check           10s
</span></span><span style=display:flex><span>    maxconn                 <span style=color:#ae81ff>3000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>listen stats
</span></span><span style=display:flex><span>    mode http
</span></span><span style=display:flex><span>    bind 0.0.0.0:9999
</span></span><span style=display:flex><span>    stats enable
</span></span><span style=display:flex><span>    log global
</span></span><span style=display:flex><span>    stats uri /haproxy-status
</span></span><span style=display:flex><span>    stats auth admin:passwd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>listen k8s-apiserver-6443
</span></span><span style=display:flex><span>    bind 10.0.0.188:6443
</span></span><span style=display:flex><span>    mode tcp
</span></span><span style=display:flex><span>    balance roundrobin
</span></span><span style=display:flex><span>    server 10.0.0.11 10.0.0.11:6443 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.12 10.0.0.12:6443 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.13 10.0.0.13:6443 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>listen k8s-node-80
</span></span><span style=display:flex><span>    bind 10.0.0.199:80
</span></span><span style=display:flex><span>    mode tcp
</span></span><span style=display:flex><span>    balance roundrobin
</span></span><span style=display:flex><span>    server 10.0.0.17 10.0.0.17:30004 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.18 10.0.0.18:30004 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>    server 10.0.0.19 10.0.0.19:30004 check inter 3s fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-02 ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl enable --now keepalived.service </span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-02 ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl enable --now haproxy.service </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># vip 在 ha-01 节点</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># ifconfig eth0:1</span>
</span></span><span style=display:flex><span>eth0:1: flags<span style=color:#f92672>=</span>4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu <span style=color:#ae81ff>1500</span>
</span></span><span style=display:flex><span>        inet 10.0.0.188  netmask 255.255.255.255  broadcast 0.0.0.0
</span></span><span style=display:flex><span>        ether 00:0c:29:cd:4b:70  txqueuelen <span style=color:#ae81ff>1000</span>  <span style=color:#f92672>(</span>Ethernet<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@ha-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># ifconfig eth0:2</span>
</span></span><span style=display:flex><span>eth0:2: flags<span style=color:#f92672>=</span>4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu <span style=color:#ae81ff>1500</span>
</span></span><span style=display:flex><span>        inet 10.0.0.199  netmask 255.255.255.255  broadcast 0.0.0.0
</span></span><span style=display:flex><span>        ether 00:0c:29:cd:4b:70  txqueuelen <span style=color:#ae81ff>1000</span>  <span style=color:#f92672>(</span>Ethernet<span style=color:#f92672>)</span>
</span></span></code></pre></div><p>浏览器查看状态页</p><p><img loading=lazy src=/images/Kubernetes/image-20230929162915126.png alt=image-20230929162915126></p><h3 id=24-部署-harbor>2.4 部署 harbor<a hidden class=anchor aria-hidden=true href=#24-部署-harbor>#</a></h3><p><a href=https://goharbor.io/docs/2.9.0/install-config/installation-prereqs/>https://goharbor.io/docs/2.9.0/install-config/installation-prereqs/</a></p><p><a href=https://docs.docker.com/engine/install/centos/>https://docs.docker.com/engine/install/centos/</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo yum remove -y docker <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-client <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-client-latest <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-common <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-latest <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-latest-logrotate <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-logrotate <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-engine
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 安装 docker</span>
</span></span><span style=display:flex><span>sudo yum install -y yum-utils
</span></span><span style=display:flex><span>sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo yum install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin
</span></span><span style=display:flex><span>systemctl enable --now docker
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@harbor harbor<span style=color:#f92672>]</span><span style=color:#75715e># docker -v</span>
</span></span><span style=display:flex><span>Docker version 24.0.6, build ed223bc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 下载并安装 harbor</span>
</span></span><span style=display:flex><span>wget https://github.com/goharbor/harbor/releases/download/v2.8.4/harbor-offline-installer-v2.8.4.tgz
</span></span><span style=display:flex><span>tar xf harbor-offline-installer-v2.8.4.tgz
</span></span><span style=display:flex><span>cd harbor
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@harbor harbor<span style=color:#f92672>]</span><span style=color:#75715e># cp harbor.yml.tmpl harbor.yml</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭 https</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@harbor harbor<span style=color:#f92672>]</span><span style=color:#75715e># grep -A 7 &#34;https related config&#34; harbor.yml</span>
</span></span><span style=display:flex><span><span style=color:#75715e># https related config</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#https:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  # https port for harbor, default is 443</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  port: 443</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  # The path of cert and key files for nginx</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  certificate: /your/certificate/path</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  private_key: /your/private/key/path</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 修改 hostname</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@harbor harbor<span style=color:#f92672>]</span><span style=color:#75715e># grep -m 1  hostname: harbor.yml</span>
</span></span><span style=display:flex><span>hostname: harbor.example.local
</span></span><span style=display:flex><span><span style=color:#75715e># 修改密码</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@harbor harbor<span style=color:#f92672>]</span><span style=color:#75715e># grep -m 1  passwd harbor.yml</span>
</span></span><span style=display:flex><span>harbor_admin_password: passwd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 开始安装</span>
</span></span><span style=display:flex><span>./install.sh
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># docker-compose 安装路径</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@harbor harbor<span style=color:#f92672>]</span><span style=color:#75715e># rpm -ql docker-compose-plugin |grep docker-compose</span>
</span></span><span style=display:flex><span>/usr/libexec/docker/cli-plugins/docker-compose
</span></span></code></pre></div><p>登录 harbor 并创建项目</p><p><strong>注意：</strong> 自行在 window 主机添加 hosts 解析 <code>10.0.0.16 harbor.example.local</code></p><p><img loading=lazy src=/images/Kubernetes/image-20231002153741384.png alt=image-20231002153741384></p><h3 id=25-所有节点安装-docker>2.5 所有节点安装 docker<a hidden class=anchor aria-hidden=true href=#25-所有节点安装-docker>#</a></h3><p><a href=https://github.com/kubernetes/kubernetes/releases/tag/v1.17.11>Release v1.17.11 · kubernetes/kubernetes (github.com)</a></p><p>所有节点（这里专指 master 和 node）安装 docker</p><p><strong>注意：</strong> 生产环境要选择 k8s 指定的版本，具体查阅对应版本的 CHANGELOG</p><p><a href=https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.17.md#v11711>kubernetes/CHANGELOG/CHANGELOG-1.17.md at master · kubernetes/kubernetes (github.com)</a></p><p><img loading=lazy src=/images/Kubernetes/image-20230930170028721.png alt=image-20230930170028721></p><p>安装指定版本的 docker</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo yum remove docker <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-client <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-client-latest <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-common <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-latest <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-latest-logrotate <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-logrotate <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                  docker-engine
</span></span><span style=display:flex><span>                  
</span></span><span style=display:flex><span>sudo yum install -y yum-utils
</span></span><span style=display:flex><span>sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 这里直接安装 19.03.9-3 版本的 docker</span>
</span></span><span style=display:flex><span><span style=color:#75715e># yum list docker-ce --showduplicates | sort -r | grep 19.03</span>
</span></span><span style=display:flex><span>docker-ce.x86_64            3:19.03.9-3.el7                    docker-ce-stable
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># sudo yum install -y docker-ce-19.03.9 docker-ce-cli-19.03.9 containerd.io docker-compose-plugin</span>
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span> <span style=color:#75715e># docker version</span>
</span></span><span style=display:flex><span>Client: Docker Engine - Community
</span></span><span style=display:flex><span> Version:           19.03.9
</span></span><span style=display:flex><span> API version:       1.40
</span></span><span style=display:flex><span> Go version:        go1.13.10
</span></span><span style=display:flex><span> Git commit:        9d988398e7
</span></span><span style=display:flex><span> Built:             Fri May <span style=color:#ae81ff>15</span> 00:25:27 <span style=color:#ae81ff>2020</span>
</span></span><span style=display:flex><span> OS/Arch:           linux/amd64
</span></span><span style=display:flex><span> Experimental:      false
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Server: Docker Engine - Community
</span></span><span style=display:flex><span> Engine:
</span></span><span style=display:flex><span>  Version:          19.03.9
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 由于 harbor 仓库未启用 https ，因此需要在 service 文件加上该参数</span>
</span></span><span style=display:flex><span><span style=color:#75715e># dockerd --help |grep insec</span>
</span></span><span style=display:flex><span>      --insecure-registry list                  Enable insecure registry communication
</span></span><span style=display:flex><span>      
</span></span><span style=display:flex><span><span style=color:#75715e># grep insecure-registry /lib/systemd/system/docker.service</span>
</span></span><span style=display:flex><span>ExecStart<span style=color:#f92672>=</span>/usr/bin/dockerd -H fd:// --containerd<span style=color:#f92672>=</span>/run/containerd/containerd.sock --insecure-registry harbor.example.com
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># systemctl enable --now docker</span>
</span></span></code></pre></div><h3 id=26-所有节点安装集群初始化工具>2.6 所有节点安装集群初始化工具<a hidden class=anchor aria-hidden=true href=#26-所有节点安装集群初始化工具>#</a></h3><h4 id=261-配置国内镜像源>2.6.1 配置国内镜像源<a hidden class=anchor aria-hidden=true href=#261-配置国内镜像源>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=0
</span></span></span><span style=display:flex><span><span style=color:#e6db74>repo_gpgcheck=0
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span></code></pre></div><h4 id=262-安装初始化工具>2.6.2 安装初始化工具<a hidden class=anchor aria-hidden=true href=#262-安装初始化工具>#</a></h4><p><strong>注意：kubectl 是客户端命令，因此在 node 可以选择性安装</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install -y kubelet-1.17.11 kubectl-1.17.11 kubeadm-1.17.11
</span></span><span style=display:flex><span>systemctl enable --now kubelet
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 配置 kubeadm 子命令自动补全</span>
</span></span><span style=display:flex><span>mkdir ~/.kube/
</span></span><span style=display:flex><span>kubeadm completion bash &gt; ~/.kube/kubeadm_completion.sh
</span></span><span style=display:flex><span>source ~/.kube/kubeadm_completion.sh
</span></span></code></pre></div><h4 id=263-kubeadm-命令的使用>2.6.3 kubeadm 命令的使用<a hidden class=anchor aria-hidden=true href=#263-kubeadm-命令的使用>#</a></h4><p>查看帮助</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm --help 
</span></span></code></pre></div><p>查看版本</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm  version</span>
</span></span><span style=display:flex><span>kubeadm version: &amp;version.Info<span style=color:#f92672>{</span>Major:<span style=color:#e6db74>&#34;1&#34;</span>, Minor:<span style=color:#e6db74>&#34;17&#34;</span>, GitVersion:<span style=color:#e6db74>&#34;v1.17.11&#34;</span>, GitCommit:<span style=color:#e6db74>&#34;ea5f00d93211b7c80247bf607cfa422ad6fb5347&#34;</span>, GitTreeState:<span style=color:#e6db74>&#34;clean&#34;</span>, BuildDate:<span style=color:#e6db74>&#34;2020-08-13T15:17:52Z&#34;</span>, GoVersion:<span style=color:#e6db74>&#34;go1.13.15&#34;</span>, Compiler:<span style=color:#e6db74>&#34;gc&#34;</span>, Platform:<span style=color:#e6db74>&#34;linux/amd64&#34;</span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p>查看部署指定版本的集群所需要的镜像</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm config images list --kubernetes-version v1.17.11</span>
</span></span><span style=display:flex><span>W0930 17:59:27.921963    <span style=color:#ae81ff>6797</span> validation.go:28<span style=color:#f92672>]</span> Cannot validate kube-proxy config - no validator is available
</span></span><span style=display:flex><span>W0930 17:59:27.922001    <span style=color:#ae81ff>6797</span> validation.go:28<span style=color:#f92672>]</span> Cannot validate kubelet config - no validator is available
</span></span><span style=display:flex><span>k8s.gcr.io/kube-apiserver:v1.17.11
</span></span><span style=display:flex><span>k8s.gcr.io/kube-controller-manager:v1.17.11
</span></span><span style=display:flex><span>k8s.gcr.io/kube-scheduler:v1.17.11
</span></span><span style=display:flex><span>k8s.gcr.io/kube-proxy:v1.17.11
</span></span><span style=display:flex><span>k8s.gcr.io/pause:3.1
</span></span><span style=display:flex><span>k8s.gcr.io/etcd:3.4.3-0
</span></span><span style=display:flex><span>k8s.gcr.io/coredns:1.6.5
</span></span></code></pre></div><p>由于是国外的镜像，由于网络原因，大概率是下载不成功的。因此将镜像地址换成阿里的，然后手动 pull</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.17.11
</span></span><span style=display:flex><span>docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.17.11
</span></span><span style=display:flex><span>docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.17.11
</span></span><span style=display:flex><span>docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.11
</span></span><span style=display:flex><span>docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1
</span></span><span style=display:flex><span>docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.3-0
</span></span><span style=display:flex><span>docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.5
</span></span></code></pre></div><h3 id=27-k8s-单节点部署>2.7 k8s 单节点部署<a hidden class=anchor aria-hidden=true href=#27-k8s-单节点部署>#</a></h3><h4 id=271-开始部署>2.7.1 开始部署<a hidden class=anchor aria-hidden=true href=#271-开始部署>#</a></h4><blockquote><p>首先给 master-01 添加一个快照，名为 init，方便后续回退</p></blockquote><p>这里选择 master-01 进行演示</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm init --apiserver-advertise-address=10.0.0.11 --apiserver-bind-port=6443 --kubernetes-version=v1.17.11 --pod-network-cidr=10.100.0.0/16 --service-cidr=10.200.0.0/16 --service-dns-domain=example.local --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers  # --v=6 如果卡住或者超时可以加该选项来查看详细报错信息</span>
</span></span></code></pre></div><p>安装结果打印在控制台，为方便后续添加 node 节点到集群等操作，最好将打印结果进行保存</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Your Kubernetes control-plane has initialized successfully!
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>To start using your cluster, you need to run the following as a regular user:
</span></span><span style=display:flex><span><span style=color:#75715e># 执行以下三行命令，可通过 kubectl 命令操作集群</span>
</span></span><span style=display:flex><span>  mkdir -p $HOME/.kube
</span></span><span style=display:flex><span>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style=display:flex><span>  sudo chown <span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span>:<span style=color:#66d9ef>$(</span>id -g<span style=color:#66d9ef>)</span> $HOME/.kube/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>You should now deploy a pod network to the cluster.
</span></span><span style=display:flex><span>Run <span style=color:#e6db74>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span style=display:flex><span>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Then you can join any number of worker nodes by running the following on each as root:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># node 节点运行该命令可加入集群</span>
</span></span><span style=display:flex><span>kubeadm join 10.0.0.11:6443 --token s14pux.a81q4ai54mpumsz4 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:5ab171bccb95245c209ddcbb614ae943b31b05e3a4ce2eb47d349655955c185f
</span></span></code></pre></div><h4 id=272-验证结果>2.7.2 验证结果<a hidden class=anchor aria-hidden=true href=#272-验证结果>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod</span>
</span></span><span style=display:flex><span>The connection to the server localhost:8080 was refused - did you specify the right host or port?
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e>#   </span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e>#   mkdir -p $HOME/.kube</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e>#   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e>#   sudo chown $(id -u):$(id -g) $HOME/.kube/config</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod</span>
</span></span><span style=display:flex><span>No resources found in default namespace.
</span></span></code></pre></div><h4 id=273-部署网络组件>2.7.3 部署网络组件<a hidden class=anchor aria-hidden=true href=#273-部署网络组件>#</a></h4><p>k8s 支持的网络组件：<a href=https://kubernetes.io/zh-cn/docs/concepts/cluster-administration/addons/>安装扩展（Addon） | Kubernetes</a></p><p>这里选择部署 <a href=https://github.com/flannel-io/flannel#deploying-flannel-manually>flannel-io/flannel: flannel is a network fabric for containers, designed for Kubernetes (github.com)</a></p><p>下载 yaml 文件并修改 network 为集群初始化时规划的 pod 网段 10.100.0.0/16</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># grep -m 1 Network kube-flannel.yml </span>
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#34;Network&#34;</span>: <span style=color:#e6db74>&#34;10.100.0.0/16&#34;</span>,
</span></span></code></pre></div><p>开始部署</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl apply -f kube-flannel.yml </span>
</span></span><span style=display:flex><span>namespace/kube-flannel created
</span></span><span style=display:flex><span>serviceaccount/flannel created
</span></span><span style=display:flex><span>clusterrole.rbac.authorization.k8s.io/flannel created
</span></span><span style=display:flex><span>clusterrolebinding.rbac.authorization.k8s.io/flannel created
</span></span><span style=display:flex><span>configmap/kube-flannel-cfg created
</span></span><span style=display:flex><span>daemonset.apps/kube-flannel-ds created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 成功部署</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod -A | grep flannel</span>
</span></span><span style=display:flex><span>kube-flannel   kube-flannel-ds-zvcp7                             1/1     Running   <span style=color:#ae81ff>0</span>          2m9s
</span></span></code></pre></div><p>去除 master-01 的污点</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 默认情况下 master 被打上了污点，不会被调度</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl describe node master-01.example.local | grep Taints</span>
</span></span><span style=display:flex><span>Taints:             node-role.kubernetes.io/master:NoSchedule
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 去除 master-01 的污点</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl taint nodes master-01.example.local node-role.kubernetes.io/master:NoSchedule-</span>
</span></span><span style=display:flex><span>node/master-01.example.local untainted
</span></span></code></pre></div><p>部署 busybox 验证 pod 网络</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl run my-container --image=busybox --command -- bash</span>
</span></span><span style=display:flex><span>kubectl run --generator<span style=color:#f92672>=</span>deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator<span style=color:#f92672>=</span>run-pod/v1 or kubectl create instead.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl run my-container --image=busybox --command -- ping www.baidu.com</span>
</span></span><span style=display:flex><span>kubectl run --generator<span style=color:#f92672>=</span>deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator<span style=color:#f92672>=</span>run-pod/v1 or kubectl create instead.
</span></span><span style=display:flex><span>deployment.apps/my-container created
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod </span>
</span></span><span style=display:flex><span>NAME                            READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>my-container-84ff747745-sjd97   1/1     Running   <span style=color:#ae81ff>0</span>          10s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 网络正常</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl exec -it my-container-84ff747745-sjd97 -- sh</span>
</span></span><span style=display:flex><span>/ <span style=color:#75715e># ping www.baidu.com -c 3</span>
</span></span><span style=display:flex><span>PING www.baidu.com <span style=color:#f92672>(</span>14.119.104.189<span style=color:#f92672>)</span>: <span style=color:#ae81ff>56</span> data bytes
</span></span><span style=display:flex><span><span style=color:#ae81ff>64</span> bytes from 14.119.104.189: seq<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span> ttl<span style=color:#f92672>=</span><span style=color:#ae81ff>127</span> time<span style=color:#f92672>=</span>9.193 ms
</span></span><span style=display:flex><span><span style=color:#ae81ff>64</span> bytes from 14.119.104.189: seq<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> ttl<span style=color:#f92672>=</span><span style=color:#ae81ff>127</span> time<span style=color:#f92672>=</span>9.475 ms
</span></span><span style=display:flex><span><span style=color:#ae81ff>64</span> bytes from 14.119.104.189: seq<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> ttl<span style=color:#f92672>=</span><span style=color:#ae81ff>127</span> time<span style=color:#f92672>=</span>9.668 ms
</span></span></code></pre></div><h3 id=28-k8s-多节点部署高可用>2.8 k8s 多节点部署（高可用）<a hidden class=anchor aria-hidden=true href=#28-k8s-多节点部署高可用>#</a></h3><p>这里将用到所有三个 master 节点进行演示，由于 mater-01 部署了单节点，首先将其还原到快照 init （没有快照的话，可以参考 <code>kubeadm reset </code>)</p><h4 id=281-开始部署>2.8.1 开始部署<a hidden class=anchor aria-hidden=true href=#281-开始部署>#</a></h4><p>相比单节点部署而言，多了一个选项 <code>--control-plane-endpoint=10.0.0.188</code> 指定了高可用反向代理的 VIP，这里还是选择 master-01 创建集群（任选一个 master 节点均可）</p><blockquote><p>如果负载均衡器未配置正确，会有以下报错：</p><p><code>Oct 1 14:06:58 master-01 kubelet: E1001 14:06:58.218726 2977 reflector.go:153] k8s.io/client-go/informers/factory.go:135: Failed to lisriver: Get https://load-balancer.example.com:6443/apis/storage.k8s.io/v1beta1/csidrivers?limit=500&amp;resourceVersion=0: EOF</code></p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># echo 10.0.0.188  load-balancer.example.com &gt;&gt; /etc/hosts</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm init --apiserver-advertise-address=10.0.0.11 --control-plane-endpoint=load-balancer.example.com --apiserver-bind-port=6443 --kubernetes-version=v1.17.11 --pod-network-cidr=10.100.0.0/16 --service-cidr=10.200.0.0/16 --service-dns-domain=example.local --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>Your Kubernetes control-plane has initialized successfully!
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>To start using your cluster, you need to run the following as a regular user:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  mkdir -p $HOME/.kube
</span></span><span style=display:flex><span>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style=display:flex><span>  sudo chown <span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span>:<span style=color:#66d9ef>$(</span>id -g<span style=color:#66d9ef>)</span> $HOME/.kube/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>You should now deploy a pod network to the cluster.
</span></span><span style=display:flex><span>Run <span style=color:#e6db74>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span style=display:flex><span>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>You can now join any number of control-plane nodes by copying certificate authorities
</span></span><span style=display:flex><span>and service account keys on each node and <span style=color:#66d9ef>then</span> running the following as root:
</span></span><span style=display:flex><span><span style=color:#75715e># 添加 master 节点到集群 </span>
</span></span><span style=display:flex><span>  kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --control-plane <span style=color:#75715e># 需要手动生成</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Then you can join any number of worker nodes by running the following on each as root:
</span></span><span style=display:flex><span><span style=color:#75715e># 添加 node 节点到集群</span>
</span></span><span style=display:flex><span>kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 准备集群认证文件</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># mkdir -p $HOME/.kube</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo chown $(id -u):$(id -g) $HOME/.kube/config</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 成功获取集群信息</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get node</span>
</span></span><span style=display:flex><span>NAME                      STATUS   ROLES    AGE   VERSION
</span></span><span style=display:flex><span>master-01.example.local   Ready    master   91m   v1.17.11
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 部署 flannel， 参考 2.7.3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl apply -f kube-flannel.yml</span>
</span></span><span style=display:flex><span>namespace/kube-flannel created
</span></span><span style=display:flex><span>serviceaccount/flannel created
</span></span><span style=display:flex><span>clusterrole.rbac.authorization.k8s.io/flannel created
</span></span><span style=display:flex><span>clusterrolebinding.rbac.authorization.k8s.io/flannel created
</span></span><span style=display:flex><span>configmap/kube-flannel-cfg created
</span></span><span style=display:flex><span>daemonset.apps/kube-flannel-ds created
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod -A |grep flannel</span>
</span></span><span style=display:flex><span>kube-flannel   kube-flannel-ds-97c97                             1/1     Running   <span style=color:#ae81ff>0</span>          94s
</span></span></code></pre></div><p><strong>补充：</strong> 除了使用命令的方式，还可以基于 yaml 文件进行集群的初始化（这里仅给出关键命令）</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 生成初始化配置</span>
</span></span><span style=display:flex><span><span style=color:#75715e># kubeadm config print init-defaults &gt; cluster-init.yaml</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 根据需要修改配置文件</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cat cluster-init.yaml </span>
</span></span><span style=display:flex><span>apiVersion: kubeadm.k8s.io/v1beta2
</span></span><span style=display:flex><span>bootstrapTokens:
</span></span><span style=display:flex><span>- groups:
</span></span><span style=display:flex><span>  - system:bootstrappers:kubeadm:default-node-token
</span></span><span style=display:flex><span>  token: abcdef.0123456789abcdef
</span></span><span style=display:flex><span>  ttl: 24h0m0s
</span></span><span style=display:flex><span>  usages:
</span></span><span style=display:flex><span>  - signing
</span></span><span style=display:flex><span>  - authentication
</span></span><span style=display:flex><span>kind: InitConfiguration
</span></span><span style=display:flex><span>localAPIEndpoint:
</span></span><span style=display:flex><span>  advertiseAddress: 1.2.3.4
</span></span><span style=display:flex><span>  bindPort: <span style=color:#ae81ff>6443</span>
</span></span><span style=display:flex><span>nodeRegistration:
</span></span><span style=display:flex><span>  criSocket: /var/run/dockershim.sock
</span></span><span style=display:flex><span>  name: master-01.example.local
</span></span><span style=display:flex><span>  taints:
</span></span><span style=display:flex><span>  - effect: NoSchedule
</span></span><span style=display:flex><span>    key: node-role.kubernetes.io/master
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiServer:
</span></span><span style=display:flex><span>  timeoutForControlPlane: 4m0s
</span></span><span style=display:flex><span>apiVersion: kubeadm.k8s.io/v1beta2
</span></span><span style=display:flex><span>certificatesDir: /etc/kubernetes/pki
</span></span><span style=display:flex><span>clusterName: kubernetes
</span></span><span style=display:flex><span>controllerManager: <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>dns:
</span></span><span style=display:flex><span>  type: CoreDNS
</span></span><span style=display:flex><span>etcd:
</span></span><span style=display:flex><span>  local:
</span></span><span style=display:flex><span>    dataDir: /var/lib/etcd
</span></span><span style=display:flex><span>imageRepository: k8s.gcr.io
</span></span><span style=display:flex><span>kind: ClusterConfiguration
</span></span><span style=display:flex><span>kubernetesVersion: v1.17.0
</span></span><span style=display:flex><span>networking:
</span></span><span style=display:flex><span>  dnsDomain: cluster.local
</span></span><span style=display:flex><span>  podSubnet: 10.100.0.0/16
</span></span><span style=display:flex><span>  serviceSubnet: 10.200.0.0/16
</span></span><span style=display:flex><span>scheduler: <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建集群</span>
</span></span><span style=display:flex><span>kubeadm init --config cluster-init.yaml
</span></span></code></pre></div><h4 id=282-添加-master-节点>2.8.2 添加 master 节点<a hidden class=anchor aria-hidden=true href=#282-添加-master-节点>#</a></h4><p>生成 <code>--control-plane</code> 参数所需 key</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm init phase upload-certs --upload-certs</span>
</span></span><span style=display:flex><span>I1001 16:10:41.762369   <span style=color:#ae81ff>58794</span> version.go:251<span style=color:#f92672>]</span> remote version is much newer: v1.28.2; falling back to: stable-1.17
</span></span><span style=display:flex><span>W1001 16:10:46.609771   <span style=color:#ae81ff>58794</span> validation.go:28<span style=color:#f92672>]</span> Cannot validate kube-proxy config - no validator is available
</span></span><span style=display:flex><span>W1001 16:10:46.609786   <span style=color:#ae81ff>58794</span> validation.go:28<span style=color:#f92672>]</span> Cannot validate kubelet config - no validator is available
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upload-certs<span style=color:#f92672>]</span> Storing the certificates in Secret <span style=color:#e6db74>&#34;kubeadm-certs&#34;</span> in the <span style=color:#e6db74>&#34;kube-system&#34;</span> Namespace
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upload-certs<span style=color:#f92672>]</span> Using certificate key:
</span></span><span style=display:flex><span>c67c9859d32c5f7e1fd75cfca8569aac32ae4f9344fcd6b8d53ad9b998362e05 <span style=color:#75715e># 这就是需要的 key</span>
</span></span></code></pre></div><p>分别执行以下命令，将 <code>master-02</code> 和 <code>master-03</code> 加入 <code>control-plane</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># echo 10.0.0.188  load-balancer.example.com &gt;&gt; /etc/hosts</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \</span>
</span></span><span style=display:flex><span>    --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --control-plane --certificate-key  c67c9859d32c5f7e1fd75cfca8569aac32ae4f9344fcd6b8d53ad9b998362e05
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>This node has joined the cluster and a new control plane instance was created:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>* Certificate signing request was sent to apiserver and approval was received.
</span></span><span style=display:flex><span>* The Kubelet was informed of the new secure connection details.
</span></span><span style=display:flex><span>* Control plane <span style=color:#f92672>(</span>master<span style=color:#f92672>)</span> label and taint were applied to the new node.
</span></span><span style=display:flex><span>* The Kubernetes control plane instances scaled up.
</span></span><span style=display:flex><span>* A new etcd member was added to the local/stacked etcd cluster.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>To start administering your cluster from this node, you need to run the following as a regular user:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	mkdir -p $HOME/.kube
</span></span><span style=display:flex><span>	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style=display:flex><span>	sudo chown <span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span>:<span style=color:#66d9ef>$(</span>id -g<span style=color:#66d9ef>)</span> $HOME/.kube/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Run <span style=color:#e6db74>&#39;kubectl get nodes&#39;</span> to see this node join the cluster.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 成功加入节点</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-02 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get nodes</span>
</span></span><span style=display:flex><span>NAME                      STATUS   ROLES    AGE     VERSION
</span></span><span style=display:flex><span>master-01.example.local   Ready    master   132m    v1.17.11
</span></span><span style=display:flex><span>master-02.example.local   Ready    master   8m25s   v1.17.11
</span></span><span style=display:flex><span>master-03.example.local   Ready    master   14s     v1.17.11
</span></span></code></pre></div><h4 id=283-添加-node-节点>2.8.3 添加 node 节点<a hidden class=anchor aria-hidden=true href=#283-添加-node-节点>#</a></h4><p>分别各个 node 节点执行以下命令</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo 10.0.0.188  load-balancer.example.com &gt;&gt; /etc/hosts
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a
</span></span></code></pre></div><p>添加完成后的结果</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-02 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get nodes</span>
</span></span><span style=display:flex><span>NAME                      STATUS   ROLES    AGE    VERSION
</span></span><span style=display:flex><span>master-01.example.local   Ready    master   176m   v1.17.11
</span></span><span style=display:flex><span>master-02.example.local   Ready    master   52m    v1.17.11
</span></span><span style=display:flex><span>master-03.example.local   Ready    master   44m    v1.17.11
</span></span><span style=display:flex><span>node-01.example.local     Ready    &lt;none&gt;   95s    v1.17.11
</span></span><span style=display:flex><span>node-02.example.local     Ready    &lt;none&gt;   34m    v1.17.11
</span></span><span style=display:flex><span>node-03.example.local     Ready    &lt;none&gt;   74s    v1.17.11
</span></span></code></pre></div><h4 id=284-查看集群证书>2.8.4 查看集群证书<a hidden class=anchor aria-hidden=true href=#284-查看集群证书>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-02 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get csr</span>
</span></span><span style=display:flex><span>NAME        AGE     REQUESTOR                 CONDITION
</span></span><span style=display:flex><span>csr-4fsl6   47m     system:bootstrap:tdi58m   Approved,Issued
</span></span><span style=display:flex><span>csr-hc9g7   4m      system:bootstrap:tdi58m   Approved,Issued
</span></span><span style=display:flex><span>csr-jh7gj   55m     system:bootstrap:tdi58m   Approved,Issued
</span></span><span style=display:flex><span>csr-k8psl   3m39s   system:bootstrap:tdi58m   Approved,Issued
</span></span><span style=display:flex><span>csr-qcjln   36m     system:bootstrap:tdi58m   Approved,Issued
</span></span><span style=display:flex><span>csr-vvtfq   2m53s   system:bootstrap:tdi58m   Approved,Issued
</span></span></code></pre></div><h4 id=285-创建-pod-验证集群网络>2.8.5 创建 pod 验证集群网络<a hidden class=anchor aria-hidden=true href=#285-创建-pod-验证集群网络>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl run net-test --image=alpine sleep 3600</span>
</span></span><span style=display:flex><span>kubectl run --generator<span style=color:#f92672>=</span>deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator<span style=color:#f92672>=</span>run-pod/v1 or kubectl create instead.
</span></span><span style=display:flex><span>deployment.apps/net-test created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod -o wide</span>
</span></span><span style=display:flex><span>NAME                       READY   STATUS    RESTARTS   AGE   IP           NODE                    NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>net-test-88ff4d957-rnrsk   1/1     Running   <span style=color:#ae81ff>0</span>          21s   10.100.4.2   node-01.example.local   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl exec -it net-test-88ff4d957-rnrsk -- sh</span>
</span></span><span style=display:flex><span>/ <span style=color:#75715e># ping www.baidu.com</span>
</span></span><span style=display:flex><span>PING www.baidu.com <span style=color:#f92672>(</span>14.119.104.189<span style=color:#f92672>)</span>: <span style=color:#ae81ff>56</span> data bytes
</span></span><span style=display:flex><span><span style=color:#ae81ff>64</span> bytes from 14.119.104.189: seq<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span> ttl<span style=color:#f92672>=</span><span style=color:#ae81ff>127</span> time<span style=color:#f92672>=</span>8.608 ms
</span></span><span style=display:flex><span><span style=color:#ae81ff>64</span> bytes from 14.119.104.189: seq<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> ttl<span style=color:#f92672>=</span><span style=color:#ae81ff>127</span> time<span style=color:#f92672>=</span>9.249 ms
</span></span><span style=display:flex><span><span style=color:#ae81ff>64</span> bytes from 14.119.104.189: seq<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> ttl<span style=color:#f92672>=</span><span style=color:#ae81ff>127</span> time<span style=color:#f92672>=</span>9.576 ms
</span></span></code></pre></div><h2 id=三部署-dashboard>三、部署 Dashboard<a hidden class=anchor aria-hidden=true href=#三部署-dashboard>#</a></h2><h3 id=31-准备配置文件>3.1 准备配置文件<a hidden class=anchor aria-hidden=true href=#31-准备配置文件>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># mv recommended.yaml dashboard.yaml</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 默认的是以 ClusterIP 发布的，只能集群内访问。这里将其改为 NodePort 的方式部署</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># grep NodePort -C 10 dashboard.yaml </span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kind: Service
</span></span><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    k8s-app: kubernetes-dashboard
</span></span><span style=display:flex><span>  name: kubernetes-dashboard
</span></span><span style=display:flex><span>  namespace: kubernetes-dashboard
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: NodePort <span style=color:#75715e># 新增</span>
</span></span><span style=display:flex><span>  ports:
</span></span><span style=display:flex><span>    - port: <span style=color:#ae81ff>443</span>
</span></span><span style=display:flex><span>      targetPort: <span style=color:#ae81ff>8443</span>
</span></span><span style=display:flex><span>      nodePort: <span style=color:#ae81ff>30000</span> <span style=color:#75715e># 新增</span>
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    k8s-app: kubernetes-dashboard
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Secret
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    k8s-app: kubernetes-dashboard
</span></span></code></pre></div><h3 id=32-部署并验证效果>3.2 部署并验证效果<a hidden class=anchor aria-hidden=true href=#32-部署并验证效果>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl apply -f dashboard.yaml</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看 pod 和 service 服务状态</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod,svc -n kubernetes-dashboard -o wide</span>
</span></span><span style=display:flex><span>NAME                                            READY   STATUS    RESTARTS   AGE   IP           NODE                    NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>pod/dashboard-metrics-scraper-894c58c65-tsqb7   1/1     Running   <span style=color:#ae81ff>0</span>          32m   10.100.4.4   node-01.example.local   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>pod/kubernetes-dashboard-fc4fc66cc-vvbht        1/1     Running   <span style=color:#ae81ff>0</span>          32m   10.100.4.3   node-01.example.local   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>         AGE   SELECTOR
</span></span><span style=display:flex><span>service/dashboard-metrics-scraper   ClusterIP   10.200.205.233   &lt;none&gt;        8000/TCP        32m   k8s-app<span style=color:#f92672>=</span>dashboard-metrics-scraper
</span></span><span style=display:flex><span>service/kubernetes-dashboard        NodePort    10.200.198.74    &lt;none&gt;        443:30000/TCP   32m   k8s-app<span style=color:#f92672>=</span>kubernetes-dashboard
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 节点监听了 30000 端口</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@node-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># ss -ntl |grep 30000</span>
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>32768</span>     <span style=color:#f92672>[</span>::<span style=color:#f92672>]</span>:30000                 <span style=color:#f92672>[</span>::<span style=color:#f92672>]</span>:* 
</span></span></code></pre></div><p>由于是 https 协议，但是证书是私有的，使用 chrome 或 edge 浏览器无法访问 dashboard。因此选择 firefox 浏览器进行访问</p><p><img loading=lazy src=/images/Kubernetes/image-20231001204858526.png alt=image-20231001204858526></p><p>访问 dashboard 需要使用 token 或者 kubeconfig 文件进行认证，这里选择 token 进行验证。下面开始生成 token</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 创建账号</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard</span>
</span></span><span style=display:flex><span>serviceaccount/dashboard-admin created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 授权</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 获取账号 token</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin</span>
</span></span><span style=display:flex><span>dashboard-admin-token-wr4jl        kubernetes.io/service-account-token   <span style=color:#ae81ff>3</span>      15s
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl describe secrets dashboard-admin-token-wr4jl -n kubernetes-dashboard</span>
</span></span><span style=display:flex><span>Name:         dashboard-admin-token-wr4jl
</span></span><span style=display:flex><span>Namespace:    kubernetes-dashboard
</span></span><span style=display:flex><span>Labels:       &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:  kubernetes.io/service-account.name: dashboard-admin
</span></span><span style=display:flex><span>              kubernetes.io/service-account.uid: 66e3f61f-9172-400c-b454-d9fb1a93be4c
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Type:  kubernetes.io/service-account-token
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data
</span></span><span style=display:flex><span><span style=color:#f92672>====</span>
</span></span><span style=display:flex><span>ca.crt:     <span style=color:#ae81ff>1025</span> bytes
</span></span><span style=display:flex><span>namespace:  <span style=color:#ae81ff>20</span> bytes
</span></span><span style=display:flex><span>token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IndQay1pc3ctc3RyWDh3dXQtTHR1N09PLVVBdUExdXJkRVRQeFpmbWlmQ1kifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tN3NweDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMjQ5OTJlMzctNmI1Yi00ODZmLTkwYmUtYmQxYTU2NGM0MmJhIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.jXYf6lQQBW9kb3KUYpoAi57JbBFwMkUdx3Gb0jK4sN8E80WIM6lyGLktsTCmNoS21BN-bGyusqT5nNJAPhrVYaEjF6pSSLrd49LHF0Wetv04Jh5fdw-aHYuR15QKCZgGjedzuUHD4F8-6Ba5ZqMh67JjKI3Dhb-dIuBIVN3KLi2_D62F4VoCryZB3ExVfdRqZmQmI0EJ5XursMgCzL9v9VCPw9FatL604n5658CuXQNXc6uIpAVwuf3G_4uBoRQ-LcyPXov9JIoSv-qbxnotgZ2xXcHWZ7HIxa1pCRL8YG_bx03ZUE04GebjF9yNeki9Dxsp4gIxDcr09ByzO0gmgg 
</span></span></code></pre></div><p>将上述 token 填入输入框(不要带多余空格），成功访问 dashboard</p><p><img loading=lazy src=/images/Kubernetes/image-20231001205626389.png alt=image-20231001205626389></p><h2 id=四k8s-部署-nginx--tomcat>四、k8s 部署 nginx + tomcat<a hidden class=anchor aria-hidden=true href=#四k8s-部署-nginx--tomcat>#</a></h2><p><a href=https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/deployment/>Deployments | Kubernetes</a></p><p>目标：实现动静分离的效果，这里仅演示简单的实现效果</p><h3 id=41-部署-nginx>4.1 部署 nginx<a hidden class=anchor aria-hidden=true href=#41-部署-nginx>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 nginx<span style=color:#f92672>]</span><span style=color:#75715e># pwd</span>
</span></span><span style=display:flex><span>/root/yaml/nginx
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 nginx<span style=color:#f92672>]</span><span style=color:#75715e># cat nginx.yml </span>
</span></span><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: Deployment
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  name: nginx-deployment
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    app: nginx
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      app: nginx
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        app: nginx
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>      - name: nginx
</span></span><span style=display:flex><span>        image: nginx:1.18.0
</span></span><span style=display:flex><span>        ports:
</span></span><span style=display:flex><span>        - containerPort: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Service
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    app: nginx-service-labels
</span></span><span style=display:flex><span>  name: nginx-service
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: NodePort
</span></span><span style=display:flex><span>  ports:
</span></span><span style=display:flex><span>  - name: http-nginx
</span></span><span style=display:flex><span>    port: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>    protocol: TCP
</span></span><span style=display:flex><span>    targetPort: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>    nodeport: <span style=color:#ae81ff>30004</span>
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    app: nginx
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 nginx<span style=color:#f92672>]</span><span style=color:#75715e># kubectl apply -f nginx.yml</span>
</span></span></code></pre></div><p>查看部署结果</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 nginx<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod,svc -o wide</span>
</span></span><span style=display:flex><span>NAME                                     READY   STATUS    RESTARTS   AGE     IP           NODE                    NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>pod/nginx-deployment-d44c4d8f4-bftm4     1/1     Running   <span style=color:#ae81ff>0</span>          4m11s   10.100.3.3   node-01.example.local   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>        AGE     SELECTOR
</span></span><span style=display:flex><span>service/kubernetes       ClusterIP   10.200.0.1       &lt;none&gt;        443/TCP        162m    &lt;none&gt;
</span></span><span style=display:flex><span>service/nginx-service    NodePort    10.200.231.164   &lt;none&gt;        80:30004/TCP   4m11s   app<span style=color:#f92672>=</span>nginx
</span></span></code></pre></div><p>根据以上结果可知，nginx 成功部署，且 pod 被调度到了 node-01 节点</p><p><img loading=lazy src=/images/Kubernetes/image-20231002174034317.png alt=image-20231002174034317></p><h3 id=42-部署-tomcat>4.2 部署 tomcat<a hidden class=anchor aria-hidden=true href=#42-部署-tomcat>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 tomcat<span style=color:#f92672>]</span><span style=color:#75715e># pwd</span>
</span></span><span style=display:flex><span>/root/yaml/tomcat
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 tomcat<span style=color:#f92672>]</span><span style=color:#75715e># cat tomcat.yml </span>
</span></span><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: Deployment
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  name: tomcat-deployment
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    apps: tomcat
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      app: tomcat
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        app: tomcat
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>      - name: tomcat
</span></span><span style=display:flex><span>        image: tomcat
</span></span><span style=display:flex><span>        ports:
</span></span><span style=display:flex><span>        - containerPort: <span style=color:#ae81ff>8080</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Service
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    app: tomcat-service-label
</span></span><span style=display:flex><span>  name: tomcat-service
</span></span><span style=display:flex><span>  namespace:
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: NodePort
</span></span><span style=display:flex><span>  ports:
</span></span><span style=display:flex><span>    - name: tomcat-http
</span></span><span style=display:flex><span>      port: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>      protocol: TCP
</span></span><span style=display:flex><span>      targetPort: <span style=color:#ae81ff>8080</span>
</span></span><span style=display:flex><span>      nodePort: <span style=color:#ae81ff>30005</span>
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    app: tomcat
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 tomcat<span style=color:#f92672>]</span><span style=color:#75715e># kubectl apply -f tomcat.yml</span>
</span></span></code></pre></div><p>查看部署结果</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod,svc -o wide</span>
</span></span><span style=display:flex><span>NAME                                     READY   STATUS    RESTARTS   AGE     IP           NODE                    NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>pod/nginx-deployment-d44c4d8f4-bftm4     1/1     Running   <span style=color:#ae81ff>0</span>          4m11s   10.100.3.3   node-01.example.local   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>pod/tomcat-deployment-78c89857d6-9qtr9   1/1     Running   <span style=color:#ae81ff>0</span>          4m14s   10.100.3.2   node-01.example.local   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>        AGE     SELECTOR
</span></span><span style=display:flex><span>service/kubernetes       ClusterIP   10.200.0.1       &lt;none&gt;        443/TCP        162m    &lt;none&gt;
</span></span><span style=display:flex><span>service/nginx-service    NodePort    10.200.231.164   &lt;none&gt;        80:30004/TCP   4m11s   app<span style=color:#f92672>=</span>nginx
</span></span><span style=display:flex><span>service/tomcat-service   NodePort    10.200.206.119   &lt;none&gt;        80:30005/TCP   4m14s   app<span style=color:#f92672>=</span>tomcat
</span></span></code></pre></div><p><img loading=lazy src=/images/Kubernetes/image-20231002174257600.png alt=image-20231002174257600></p><p>生成一个tomcat 临时页面</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 yaml<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod</span>
</span></span><span style=display:flex><span>NAME                                 READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>nginx-deployment-d44c4d8f4-bftm4     1/1     Running   <span style=color:#ae81ff>0</span>          6m18s
</span></span><span style=display:flex><span>tomcat-deployment-78c89857d6-9qtr9   1/1     Running   <span style=color:#ae81ff>0</span>          6m21s
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 yaml<span style=color:#f92672>]</span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 yaml<span style=color:#f92672>]</span><span style=color:#75715e># kubectl exec -it tomcat-deployment-78c89857d6-9qtr9 bash</span>
</span></span><span style=display:flex><span>root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat# cd webapps
</span></span><span style=display:flex><span>root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# mkdir tomcat
</span></span><span style=display:flex><span>root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# echo <span style=color:#e6db74>&#34;Tomcat test page for pod of k8s~&#34;</span> &gt; tomcat/index.html
</span></span><span style=display:flex><span>root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# exit
</span></span><span style=display:flex><span>exit
</span></span></code></pre></div><p><img loading=lazy src=/images/Kubernetes/image-20231002175227287.png alt=image-20231002175227287></p><h3 id=43-从-dashboard-查看结果>4.3 从 dashboard 查看结果<a hidden class=anchor aria-hidden=true href=#43-从-dashboard-查看结果>#</a></h3><p><img loading=lazy src=/images/Kubernetes/image-20231002174505455.png alt=image-20231002174505455></p><h3 id=44-配置-nginx-实现动静分离>4.4 配置 nginx 实现动静分离<a hidden class=anchor aria-hidden=true href=#44-配置-nginx-实现动静分离>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl get pod,svc </span>
</span></span><span style=display:flex><span>NAME                                     READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>pod/net-test-88ff4d957-krc9v             1/1     Running   <span style=color:#ae81ff>0</span>          44m
</span></span><span style=display:flex><span>pod/nginx-deployment-d44c4d8f4-bftm4     1/1     Running   <span style=color:#ae81ff>0</span>          70m
</span></span><span style=display:flex><span>pod/tomcat-deployment-78c89857d6-9qtr9   1/1     Running   <span style=color:#ae81ff>0</span>          70m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>        AGE
</span></span><span style=display:flex><span>service/kubernetes       ClusterIP   10.200.0.1       &lt;none&gt;        443/TCP        3h49m
</span></span><span style=display:flex><span>service/nginx-service    NodePort    10.200.231.164   &lt;none&gt;        80:30004/TCP   70m
</span></span><span style=display:flex><span>service/tomcat-service   NodePort    10.200.206.119   &lt;none&gt;        80:30005/TCP   70m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl exec -it nginx-deployment-d44c4d8f4-bftm4 bash</span>
</span></span><span style=display:flex><span>root@nginx-deployment-d44c4d8f4-bftm4:/# 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>root@nginx-deployment-d44c4d8f4-sfslr:/# cat &gt; /etc/nginx/conf.d/default.conf <span style=color:#e6db74>&lt;&lt; EOF
</span></span></span><span style=display:flex><span><span style=color:#e6db74>server {
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    listen       80;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    listen  [::]:80;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    server_name  localhost;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    location /tomcat {
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        proxy_pass http://tomcat-service.default.svc.example.local;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    }
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    error_page   500 502 503 504  /50x.html;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    location = /50x.html {
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        root   /usr/share/nginx/html;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    }
</span></span></span><span style=display:flex><span><span style=color:#e6db74>}
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>root@nginx-deployment-d44c4d8f4-bftm4:/# nginx -t        
</span></span><span style=display:flex><span>nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
</span></span><span style=display:flex><span>nginx: configuration file /etc/nginx/nginx.conf test is successful
</span></span><span style=display:flex><span>root@nginx-deployment-d44c4d8f4-bftm4:/# nginx -s reload
</span></span><span style=display:flex><span>2023/10/02 11:44:15 <span style=color:#f92672>[</span>notice<span style=color:#f92672>]</span> 997#997: signal process started
</span></span></code></pre></div><p><img loading=lazy src=/images/Kubernetes/image-20231002194611155.png alt=image-20231002194611155></p><h2 id=五k8s-集群管理>五、k8s 集群管理<a hidden class=anchor aria-hidden=true href=#五k8s-集群管理>#</a></h2><h3 id=51-token-管理>5.1 token 管理<a hidden class=anchor aria-hidden=true href=#51-token-管理>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm # 双击 tab 补全得到的结果</span>
</span></span><span style=display:flex><span>alpha       completion  config      init        join        reset       token       upgrade     version     
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm token </span>
</span></span><span style=display:flex><span>create    delete    generate  list
</span></span></code></pre></div><h3 id=52-reset-命令>5.2 reset 命令<a hidden class=anchor aria-hidden=true href=#52-reset-命令>#</a></h3><p>在初始化集群时，如果生成了错误的配置，可以用该命令重置环境</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm reset</span>
</span></span></code></pre></div><p><code>kubeadm reset</code> 命令用于将Kubernetes节点（通常是工作节点）恢复到其初始状态，将节点从Kubernetes集群中分离并清理集群相关的配置和数据。这个命令的主要作用包括：</p><ol><li><p><strong>节点的脱离集群</strong>：<code>kubeadm reset</code> 会将节点从Kubernetes集群中分离。这包括删除节点的证书、从集群中删除节点的信息，并且节点将不再参与集群中的通信和管理。</p></li><li><p><strong>清理配置文件</strong>：它会删除Kubernetes的配置文件，例如kubeconfig文件，以及CNI（容器网络接口）插件的配置，以确保不再影响Kubernetes集群。</p></li><li><p><strong>清理数据</strong>：<code>kubeadm reset</code> 还会清理节点上的Kubernetes数据，包括删除容器、卷、数据存储等，以确保节点不再包含与Kubernetes集群相关的残留数据。</p></li></ol><p>这个命令通常在以下情况下使用：</p><ul><li><p>当你需要卸载或移除节点上的Kubernetes时，可以使用 <code>kubeadm reset</code> 来清理节点，然后重新配置或重新部署Kubernetes。</p></li><li><p>在测试环境中，当你需要重置一个节点以进行新的Kubernetes集群配置时，可以使用 <code>kubeadm reset</code>。</p></li></ul><p>请注意，<code>kubeadm reset</code> 只应该用于节点级别的操作，并且在生产环境中使用时需要谨慎，因为它会删除节点上的Kubernetes相关数据。如果你需要从整个Kubernetes集群中移除节点，请首先使用 <code>kubectl drain</code> 命令将节点上的工作负载迁移到其他节点，然后再使用 <code>kubeadm reset</code> 进行节点的重置和卸载。</p><h3 id=53-查看证书有效期>5.3 查看证书有效期<a hidden class=anchor aria-hidden=true href=#53-查看证书有效期>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm alpha </span>
</span></span><span style=display:flex><span>certs        kubeconfig   kubelet      selfhosting  
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm alpha certs </span>
</span></span><span style=display:flex><span>certificate-key   check-expiration  renew    
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查证书是否过期，可以发现 kubeadm 部署的集群，证书有效期为 365d（一年）</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm alpha certs check-expiration </span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>check-expiration<span style=color:#f92672>]</span> Reading configuration from the cluster...
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>check-expiration<span style=color:#f92672>]</span> FYI: You can look at this config file with <span style=color:#e6db74>&#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
</span></span><span style=display:flex><span>admin.conf                 Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d                                    no      
</span></span><span style=display:flex><span>apiserver                  Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d            ca                      no      
</span></span><span style=display:flex><span>apiserver-etcd-client      Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d            etcd-ca                 no      
</span></span><span style=display:flex><span>apiserver-kubelet-client   Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d            ca                      no      
</span></span><span style=display:flex><span>controller-manager.conf    Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d                                    no      
</span></span><span style=display:flex><span>etcd-healthcheck-client    Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d            etcd-ca                 no      
</span></span><span style=display:flex><span>etcd-peer                  Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d            etcd-ca                 no      
</span></span><span style=display:flex><span>etcd-server                Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d            etcd-ca                 no      
</span></span><span style=display:flex><span>front-proxy-client         Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d            front-proxy-ca          no      
</span></span><span style=display:flex><span>scheduler.conf             Oct 01, <span style=color:#ae81ff>2024</span> 07:58 UTC   364d                                    no      
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED
</span></span><span style=display:flex><span>ca                      Sep 29, <span style=color:#ae81ff>2033</span> 07:58 UTC   9y              no      
</span></span><span style=display:flex><span>etcd-ca                 Sep 29, <span style=color:#ae81ff>2033</span> 07:58 UTC   9y              no      
</span></span><span style=display:flex><span>front-proxy-ca          Sep 29, <span style=color:#ae81ff>2033</span> 07:58 UTC   9y              no 
</span></span></code></pre></div><h3 id=54-更新证书有效期>5.4 更新证书有效期<a hidden class=anchor aria-hidden=true href=#54-更新证书有效期>#</a></h3><p>参考链接：</p><p><a href=https://www.qikqiak.com/post/update-k8s-10y-expire-certs/>https://www.qikqiak.com/post/update-k8s-10y-expire-certs/</a></p><p><a href=https://www.chenshaowen.com/blog/how-to-renew-kubernetes-certs-manually.html>https://www.chenshaowen.com/blog/how-to-renew-kubernetes-certs-manually.html</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm alpha certs renew </span>
</span></span><span style=display:flex><span>admin.conf                apiserver-etcd-client     etcd-healthcheck-client   front-proxy-client        
</span></span><span style=display:flex><span>all                       apiserver-kubelet-client  etcd-peer                 scheduler.conf            
</span></span><span style=display:flex><span>apiserver                 controller-manager.conf   etcd-server  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 更新所有证书</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm alpha certs renew all</span>
</span></span></code></pre></div><p>完成后重启 kube-apiserver、kube-controller、kube-scheduler 这 3个容器即可，我们可以查看 apiserver 的证书的有效期来验证是否更新成功：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># docker ps |egrep &#34;k8s_kube-apiserver|k8s_kube-scheduler|k8s_kube-controller&#34;|awk &#39;{print $1}&#39;|xargs docker restart</span>
</span></span><span style=display:flex><span>c2d987734f5a
</span></span><span style=display:flex><span>043af8733130
</span></span><span style=display:flex><span>5a87240ba97a
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># echo | openssl s_client -showcerts -connect 127.0.0.1:6443 -servername api 2&gt;/dev/null | openssl x509 -noout -enddate</span>
</span></span><span style=display:flex><span>notAfter<span style=color:#f92672>=</span>Oct  <span style=color:#ae81ff>1</span> 13:17:56 <span style=color:#ae81ff>2024</span> GMT
</span></span></code></pre></div><h2 id=六k8s-集群升级>六、k8s 集群升级<a hidden class=anchor aria-hidden=true href=#六k8s-集群升级>#</a></h2><p>kubeadm 部署的集群需要用 kubeadm 来升级，首先需要将 kubeadm 升级到目标版本，然后再继续其他操作。</p><h3 id=61-升级准备>6.1 升级准备<a hidden class=anchor aria-hidden=true href=#61-升级准备>#</a></h3><p>本次升级，目标版本：<code>v1.19.2</code></p><p>查看当前版本</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm version</span>
</span></span><span style=display:flex><span>kubeadm version: &amp;version.Info<span style=color:#f92672>{</span>Major:<span style=color:#e6db74>&#34;1&#34;</span>, Minor:<span style=color:#e6db74>&#34;17&#34;</span>, GitVersion:<span style=color:#e6db74>&#34;v1.17.11&#34;</span>, GitCommit:<span style=color:#e6db74>&#34;ea5f00d93211b7c80247bf607cfa422ad6fb5347&#34;</span>, GitTreeState:<span style=color:#e6db74>&#34;clean&#34;</span>, BuildDate:<span style=color:#e6db74>&#34;2020-08-13T15:17:52Z&#34;</span>, GoVersion:<span style=color:#e6db74>&#34;go1.13.15&#34;</span>, Compiler:<span style=color:#e6db74>&#34;gc&#34;</span>, Platform:<span style=color:#e6db74>&#34;linux/amd64&#34;</span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看 yum 源是否有目标版本</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># yum list kubectl kubeadm kubelet --showduplicates | grep 1.19.2</span>
</span></span><span style=display:flex><span>kubeadm.x86_64                       1.19.2-0                        kubernetes 
</span></span><span style=display:flex><span>kubectl.x86_64                       1.19.2-0                        kubernetes 
</span></span><span style=display:flex><span>kubelet.x86_64                       1.19.2-0                        kubernetes
</span></span></code></pre></div><h3 id=62-升级-master-节点>6.2 升级 master 节点<a hidden class=anchor aria-hidden=true href=#62-升级-master-节点>#</a></h3><p>滚动式升级 master 节点</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 安装部署工具</span>
</span></span><span style=display:flex><span>yum install -y kubelet-1.19.2 kubectl-1.19.2 kubeadm-1.19.2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm version</span>
</span></span><span style=display:flex><span>kubeadm version: &amp;version.Info<span style=color:#f92672>{</span>Major:<span style=color:#e6db74>&#34;1&#34;</span>, Minor:<span style=color:#e6db74>&#34;19&#34;</span>, GitVersion:<span style=color:#e6db74>&#34;v1.19.2&#34;</span>, GitCommit:<span style=color:#e6db74>&#34;f5743093fd1c663cb0cbc89748f730662345d44d&#34;</span>, GitTreeState:<span style=color:#e6db74>&#34;clean&#34;</span>, BuildDate:<span style=color:#e6db74>&#34;2020-09-16T13:38:53Z&#34;</span>, GoVersion:<span style=color:#e6db74>&#34;go1.15&#34;</span>, Compiler:<span style=color:#e6db74>&#34;gc&#34;</span>, Platform:<span style=color:#e6db74>&#34;linux/amd64&#34;</span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p>查看版本升级计划</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm upgrade plan</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upgrade/config<span style=color:#f92672>]</span> Making sure the configuration is correct:
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upgrade/config<span style=color:#f92672>]</span> Reading configuration from the cluster...
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upgrade/config<span style=color:#f92672>]</span> FYI: You can look at this config file with <span style=color:#e6db74>&#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upgrade/config<span style=color:#f92672>]</span> FATAL: this version of kubeadm only supports deploying clusters with the control plane version &gt;<span style=color:#f92672>=</span> 1.18.0. Current version: v1.17.11   <span style=color:#75715e># 版本低于 1.18.0，kubeadm 不支持升级操作</span>
</span></span><span style=display:flex><span>To see the stack trace of this error execute with --v<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span> or higher
</span></span></code></pre></div><p>如果选择的版本符合 kubeadm 的要求，则继续以下操作</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@master-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubeadm upgrade apply v1.19.2</span>
</span></span></code></pre></div><p>升级完成后，可以查看镜像版本</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># docker images</span>
</span></span></code></pre></div><h3 id=63-升级-node-节点>6.3 升级 node 节点<a hidden class=anchor aria-hidden=true href=#63-升级-node-节点>#</a></h3><p>同样是滚动升级的方式进行</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 安装部署工具</span>
</span></span><span style=display:flex><span>yum install -y kubelet-1.19.2 kubectl-1.19.2 kubeadm-1.19.2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 执行升级操作</span>
</span></span><span style=display:flex><span>kubeadm upgrade node --kubelet-version 1.19.2
</span></span></code></pre></div></div><div class=post-reward><div style=padding:0;margin:0;width:100%;font-size:16px;text-align:center><div id=QR style=opacity:0><div id=wechat style=display:inline-block><a class=fancybox rel=group><img id=wechat_qr src=https://senmer.github.io/img/wechat_pay.png alt=wechat_pay></a><p>微信</p></div><div id=alipay style=display:inline-block><a class=fancybox rel=group><img id=alipay_qr src=https://senmer.github.io/img/alipay.png alt=alipay></a><p>支付宝</p></div></div><button id=rewardButton onclick='var qr=document.getElementById("QR");qr.style.opacity==="0"?qr.style.opacity="1":qr.style.opacity="0"'>
<span>🧧 鼓励</span></button></div></div><footer class=post-footer><nav class=paginav><a class=prev href=https://senmer.github.io/zh/posts/tech/ldap/openldap%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/><span class=title>« 上一页</span><br><span>OpenLDAP安装和使用</span>
</a><a class=next href=https://senmer.github.io/zh/posts/tech/kafka/kafka%E7%AE%80%E4%BB%8B%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/><span class=title>下一页 »</span><br><span>Kafka简介与集群部署</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'👉展开评论';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'👇关闭评论';color:var(--content)}</style><div><details class=comments_details open><summary style=display:none></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js></script><script>twikoo.init({envId:"https://hugo-api-khaki.vercel.app/# 填写自己的twikoo id",el:"#tcomment",lang:"zh-CN",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2023
<a href=https://senmer.github.io/zh/ style=color:#939393>WZ's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span><a target=_blank href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null" style=display:inline-block;text-decoration:none;height:20px;color:#939393><img src style="float:left;margin:0 5px 0 0">
</a></span><span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg><span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString(),s=window.getSelection().toString();t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="复制";function i(){t.innerText="已复制！",setTimeout(()=>{t.innerText="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>