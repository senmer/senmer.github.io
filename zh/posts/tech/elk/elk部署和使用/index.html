<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ELK部署和使用 | WZ's Blog</title>
<meta name=keywords content><meta name=description content="一、ELK 简介 ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。 下面"><meta name=author content="wz"><link rel=canonical href=https://senmer.github.io/zh/posts/tech/elk/elk%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BD%BF%E7%94%A8/><link crossorigin=anonymous href=/assets/css/stylesheet.5a2b6d77cc78ad18bcb4914c5c639c7ce5ab55e956c461d4310747892b3f50c2.css integrity="sha256-Wittd8x4rRi8tJFMXGOcfOWrVelWxGHUMQdHiSs/UMI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://senmer.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://senmer.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://senmer.github.io/img/Q.gif><link rel=apple-touch-icon href=https://senmer.github.io/img/Q.gif><link rel=mask-icon href=https://senmer.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4d7c4710a089d70b71310f0e1ec7681b",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="ELK部署和使用"><meta property="og:description" content="一、ELK 简介 ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。 下面"><meta property="og:type" content="article"><meta property="og:url" content="https://senmer.github.io/zh/posts/tech/elk/elk%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BD%BF%E7%94%A8/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-10-08T17:21:41+08:00"><meta property="article:modified_time" content="2023-10-08T17:21:41+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="ELK部署和使用"><meta name=twitter:description content="一、ELK 简介 ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。 下面"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"📚文章","item":"https://senmer.github.io/zh/posts/"},{"@type":"ListItem","position":2,"name":"👨🏻‍💻 技术","item":"https://senmer.github.io/zh/posts/tech/"},{"@type":"ListItem","position":3,"name":"ELK部署和使用","item":"https://senmer.github.io/zh/posts/tech/elk/elk%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BD%BF%E7%94%A8/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ELK部署和使用","name":"ELK部署和使用","description":"一、ELK 简介 ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。 下面","keywords":[""],"articleBody":"一、ELK 简介 ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。\n下面是每个组件的简要介绍：\nElasticsearch： Elasticsearch是一个开源分布式搜索和分析引擎。它用于存储和索引大量的数据，使用户能够快速进行全文搜索、分析和聚合。Elasticsearch的强大之处在于其分布式性能和可扩展性，它能够处理海量数据并提供高效的查询和分析。\nLogstash： Logstash是一个用于收集、处理和转发各种类型数据的数据流处理引擎。它可以从多种来源（如日志文件、消息队列、数据库等）收集数据，经过处理后将数据发送到目标存储（如Elasticsearch）。Logstash可以用于数据清洗、转换、标准化等，以便将数据准备好供后续的搜索和分析。\nKibana： Kibana是一个用于数据可视化和分析的开源工具。它提供了一个用户友好的Web界面，使用户能够创建仪表板、图表和地图来展示Elasticsearch中的数据。通过Kibana，用户可以通过交互式的界面深入分析数据、观察趋势、检测异常等。\nELK的工作流程通常是这样的：Logstash收集和处理各种数据源的日志数据，然后将处理后的数据发送到Elasticsearch进行索引和存储。用户可以使用Kibana来查询数据、创建可视化仪表板，从而更好地理解数据的情况。\n需要注意的是，Elasticsearch 在新版本中也被称为 Elastic Stack，因为除了上述三个核心组件外，Elastic 公司还提供了其他一些附加工具和功能，以进一步增强数据分析和管理的能力。\n二、Elasticsearch 集群部署 2.1 环境初始化 2.1.1 环境准备 主机名 IP 系统 配置 elasticsearch-01 10.0.0.11 CentOS 7.6 2U 4G elasticsearch-02 10.0.0.12 CentOS 7.6 1U 2G elasticsearch-03 10.0.0.13 CentOS 7.6 1U 2G 2.1.2 内核参数及服务调整 # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config # 修改文件句柄数的限制 echo \"* soft nofile 65536\" \u003e\u003e /etc/security/limits.conf echo \"* hard nofile 65536\" \u003e\u003e /etc/security/limits.conf 2.1.3 配置 hosts 解析 # cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 10.0.0.11 elasticsearch-01 10.0.0.12 elasticsearch-02 10.0.0.13 elasticsearch-03 2.1.4 安装必要的软件并同步时间 # 安装基础软件 yum install -y epel-release net-tools vim lrzsz tree screen lsof tcpdump wget ntpdate # 同步时间 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 定时同步 echo \"*/5 * * * * ntpdate time1.aliyun.com \u0026\u003e /dev/null \u0026\u0026 hwclock -w\" \u003e\u003e /var/spool/cron/root systemctl restart crond 2.1.5 配置 java 环境 支持一览表 | Elastic\nyum install java-1.8.0-openjdk -y java -version 2.2 安装 elasticsearch 2.2.1 yum 安装 elasticsearch 7.17 Download Elasticsearch | Elastic\n[Install Elasticsearch with RPM | Elasticsearch Guide 7.17] | Elastic\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch cat \u003e /etc/yum.repos.d/elasticsearch-7.repo \u003c\u003c EOF [elasticsearch] name=Elasticsearch repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=0 autorefresh=1 type=rpm-md EOF yum install -y --enablerepo=elasticsearch elasticsearch 2.2.2 修改配置文件 # cat /etc/elasticsearch/elasticsearch.yml\ncluster.name: elk-cluster node.name: elk-node-01 # 每个节点唯一，根据需要修改 path.data: /apps/elasticsearch/data # 数据存放目录，需要手动创建 path.logs: /apps/elasticsearch/logs bootstrap.memory_lock: true network.host: 0.0.0.0 http.port: 9200 discovery.seed_hosts: [\"10.0.0.11\", \"10.0.0.12\", \"10.0.0.13\"] cluster.initial_master_nodes: [\"10.0.0.11\", \"10.0.0.12\", \"10.0.0.13\"] gateway.recover_after_nodes: 2 action.destructive_requires_name: true 参数解释\ncluster.name: elk-cluster: 设置Elasticsearch集群的名称为\"elk-cluster\"。 node.name: elk-node-01: 设置当前Elasticsearch节点的名称为\"elk-node-01\"。 path.data: /apps/elasticsearch/data 和 path.logs: /apps/elasticsearch/logs: 分别指定Elasticsearch数据和日志文件的存储路径。 bootstrap.memory_lock: true: 这个配置表示Elasticsearch将尝试锁定内存，以提高性能和稳定性。 network.host: 0.0.0.0: 允许Elasticsearch绑定到所有可用的网络接口，以允许来自任何IP地址的连接。 http.port: 9200: 设置Elasticsearch HTTP服务的监听端口为9200，这是默认的HTTP API端口。 discovery.seed_hosts: [\"10.0.0.11\", \"10.0.0.12\", \"10.0.0.13\"]: 指定了Elasticsearch集群的发现节点，这些节点用于启动和发现集群中的其他节点。 cluster.initial_master_nodes: [\"10.0.0.11\", \"10.0.0.12\", \"10.0.0.13\"]: 指定了初始的主节点列表，用于初始化集群。 gateway.recover_after_nodes: 2: 配置在至少有2个节点可用时才允许集群恢复。 action.destructive_requires_name: true: 这个配置要求在执行破坏性操作（如删除索引）时需要提供名称，以防止意外的操作。 2.2.3 修改内存限制 LimitMEMLOCK=infinity 是Systemd服务的配置参数之一，用于限制进程的内存锁定（mlock）资源。这个参数的含义是将内存锁定资源的限制设置为无限制，也就是允许进程锁定任意数量的内存。内存锁定是一种操作，用于将内存分配给进程，并防止操作系统将其交换到磁盘上，从而提高了对内存的快速访问。\n在某些应用程序中，特别是对于需要高性能和低延迟的应用程序，需要将一部分内存锁定，以确保数据始终位于物理内存中，而不会被交换到磁盘上，以减少访问延迟。将LimitMEMLOCK设置为infinity允许进程锁定所需的内存而不受限制。\n请注意，修改此设置可能会影响系统的性能和稳定性，因为不受限制的内存锁定可能导致系统资源不足，因此在进行此类配置更改时需要小心谨慎，并确保了解应用程序的内存使用模式和系统资源限制。\n此外，上述配置片段通常可以在Systemd服务单元文件（通常位于/etc/systemd/system/或/lib/systemd/system/中）中找到，并用于调整特定服务的资源限制。具体的配置文件可能因不同的Linux发行版和应用程序而有所不同。\n注意：要在Service 块中设置，不然不会生效\n# grep LimitMEMLOCK=infinity /usr/lib/systemd/system/elasticsearch.service -B 1 [Service] LimitMEMLOCK=infinity # systemctl daemon-reload 修改堆内存大小\n[Heap size settings | Elasticsearch Guide 8.9] | Elastic\n# grep Xm /etc/elasticsearch/jvm.options -Xms1g -Xmx1g 创建数据存放目录\nmkdir -p /apps/elasticsearch/{data,logs} chown -R elasticsearch.elasticsearch /apps/elasticsearch/ 2.3 启动服务并查看集群状态 Elasticsearch 集群状态用于表示集群的整体健康状况。Elasticsearch 集群可以处于不同的健康状态，这些状态反映了集群中数据分片的可用性和完整性。以下是 Elasticsearch 集群状态的主要介绍：\nGreen（绿色）: 集群处于最佳状态。 所有主分片和复制分片都可用。 集群的数据完整性和可用性都非常高。 所有节点都正常运行，没有故障。 性能正常，没有性能问题。 Yellow（黄色）: 集群状态表示为 “yellow” 时，主分片都可用，但复制分片（副本）可能存在问题。 可能有一些副本分片尚未分配到节点上，或者某些节点不可用。 数据完整性有一定程度的风险，因为复制分片的可用性受到影响。 性能通常良好，但需要关注集群健康状态。 Red（红色）: 集群状态表示为 “red” 时，意味着主分片不可用。 这可能是由于主分片丢失、未分配或者节点故障等问题引起的。 数据的可用性和完整性受到严重威胁，因为主分片无法提供数据访问。 性能可能会受到影响，具体取决于缺失的主分片数量和查询的性质。 2.3.1 启动服务 # systemctl start elasticsearch # systemctl status elasticsearch [root@elasticsearch-01 ~]# ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 :::9200 # 服务监听端口 :::* LISTEN 0 128 :::9300 # 集群通信端口 :::* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* [root@elasticsearch-01 ~]# curl localhost:9200 { \"name\" : \"elk-node-01\",\t# 节点名称 \"cluster_name\" : \"elk-cluster\", \"cluster_uuid\" : \"XXO_Ik9XQo2Y5Uw6UvVS-g\", \"version\" : { \"number\" : \"7.17.13\", # elasticsearch 版本号 \"build_flavor\" : \"default\", \"build_type\" : \"rpm\", \"build_hash\" : \"2b211dbb8bfdecaf7f5b44d356bdfe54b1050c13\", \"build_date\" : \"2023-08-31T17:33:19.958690787Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.11.1\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\"\t# 宣传语 } 2.3.2 查看集群状态 可以利用此接口对 elasticseach 集群状态进行监控\n[root@elasticsearch-01 ~]# curl localhost:9200/_cluster/health?pretty { \"cluster_name\" : \"elk-cluster\", \"status\" : \"green\",\t# 集群监控状态 \"timed_out\" : false, \"number_of_nodes\" : 3, \"number_of_data_nodes\" : 3, \"active_primary_shards\" : 3, \"active_shards\" : 6, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 0, \"delayed_unassigned_shards\" : 0, \"number_of_pending_tasks\" : 0, \"number_of_in_flight_fetch\" : 0, \"task_max_waiting_in_queue_millis\" : 0, \"active_shards_percent_as_number\" : 100.0 } 以下是其中的一些关键字段的解释：\n\"cluster_name\" : \"elk-cluster\": 集群的名称，这个示例中的集群名称为 “elk-cluster”。\n\"status\" : \"green\": 集群的健康状态，这个示例中集群状态为 “green”，表示集群处于最佳状态。\n\"number_of_nodes\" : 3: 集群中的节点数量，这个示例中有3个节点。\n\"number_of_data_nodes\" : 3: 集群中的数据节点数量，这是实际存储数据的节点数，这个示例中也是3个。\n\"active_primary_shards\" : 3: 活动主分片的数量，这是集群中主要负责存储数据的分片数量，这个示例中有3个。\n\"active_shards\" : 6: 所有活动分片的数量，包括主分片和副本分片，这个示例中有6个。\n\"relocating_shards\" : 0: 正在迁移的分片数量，如果你在重新平衡集群或迁移分片，则该值可能会增加。\n\"initializing_shards\" : 0: 正在初始化的分片数量，通常在新分片或节点加入时出现。\n\"unassigned_shards\" : 0: 未分配的分片数量，这是指尚未分配到任何节点的分片数量。在集群状态为 “green” 时，这应该是0。\n\"delayed_unassigned_shards\" : 0: 延迟未分配的分片数量，这是指尚未分配到节点，但由于一些原因而被延迟的分片数量。\n\"number_of_pending_tasks\" : 0: 集群中待处理任务的数量，例如索引创建或删除等操作可能会生成待处理任务。\n\"number_of_in_flight_fetch\" : 0: 目前正在进行的数据获取请求的数量。\n\"task_max_waiting_in_queue_millis\" : 0: 队列中等待的任务的最大等待时间（以毫秒为单位）。\n\"active_shards_percent_as_number\" : 100.0: 活动分片的百分比，作为数字表示。在 “green” 状态下，应该是100%，表示所有分片都是活动的。\n总的来说，这些信息提供了有关 Elasticsearch 集群状态和性能的关键指标，可以用于监控和管理集群。在 “green” 状态下，集群是健康的，数据完整性和可用性都非常高。\n2.3.3 elasticseach 插件 官方提供了一些插件但大部分是收费的，另外也有一些开发爱好者提供的插件，可以实现对 elasticsearch 集群的状态监控与管理配置等功能，Multi Elasticsearch Head 就是其中一个。\n可以通过浏览器的应用商店安装 （chrome 、edge）\nhttps://chrome.google.com/webstore/detail/multi-elasticsearch-head/cpmmilfkofbeimbmgiclohpodggeheim?utm_source=ext_app_menu\n三、 Logstash 部署 Logstash 是一个开源的数据收集引擎，可以水平伸缩，基于 ruby 开发，而且 logstash 整个 ELK当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。\n3.1 环境准备 主机名 IP 系统 配置 logstash 10.0.0.15 CentOS 7.6 2U 4G 3.1.2 关闭不需要的服务 # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config 3.1.2 配置 Java 环境 yum install java-1.8.0-openjdk -y java -version 3.2 安装 logstash [Installing Logstash | Logstash Reference 7.17] | Elastic\n# 导入证书 rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch # 配置 yum 源 cat \u003e /etc/yum.repos.d/logstash-7.repo \u003c\u003c EOF [logstash-7.x] name=Elastic repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md EOF # 安装并启动服务 yum install -y logstash systemctl start logstash.service 3.3 logstash 的使用 Logstash 是一个开源的数据收集引擎，可以水平伸缩，而且 logstash 整个 ELK 当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。\n3.3.1 测试标准输入和标准输出 在Logstash的配置中，“codec” 是\"编解码器\"（Codec）的缩写。编解码器是一种用于将数据编码成特定格式或从特定格式解码数据的组件。在Logstash中，它用于指定输入和输出的数据格式。\n在你提供的配置中，你使用了Elasticsearch输出插件，并指定了\"codec\"选项为\"json\"。这表示你希望将Logstash事件数据编码为JSON格式，然后将其发送到Elasticsearch。这有助于确保数据以JSON格式存储在Elasticsearch中，以便后续查询和分析。\n“codec\"选项的常见值包括：\n“json”：将事件数据编码为JSON格式。\n“plain”：不对事件数据进行编码，保持原始格式。\n“json_lines”：将事件数据编码为一行一条JSON记录的格式。\n“multiline”：用于处理多行日志事件。\n[root@logstash ~]# /usr/share/logstash/bin/logstash -e 'input{ stdin{} } output{ stdout{ codec=\u003erubydebug }}' ... The stdin plugin is now waiting for input: hello { \"message\" =\u003e \"hello\",\t# 消息内容 \"host\" =\u003e \"logstash\",\t# 主机名 \"@timestamp\" =\u003e 2023-09-19T01:16:14.334Z, # 事件发生时间 \"@version\" =\u003e \"1\"\t# 事件版本号，一个事件就是一个 ruby 对象 } ^C 3.3.2 测试输出到文件 [root@logstash ~]# /usr/share/logstash/bin/logstash -e 'input { stdin{} } output{ file { path =\u003e \"/tmp/log-%{+YYYY.MM.dd}.txt\"}}' ... The stdin plugin is now waiting for input: [INFO ] 2023-09-19 09:30:28.836 [Agent thread] agent - Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]} hello world ^C # 输出文本文件 [root@logstash ~]# file /tmp/log-2023.09.19.txt /tmp/log-2023.09.19.txt: ASCII text # 消息内容已输出到文本中，多条消息会追加到文件末尾 [root@logstash ~]# cat /tmp/log-2023.09.19.txt {\"message\":\"hello\",\"@version\":\"1\",\"@timestamp\":\"2023-09-19T01:30:40.576Z\",\"host\":\"logstash\"} {\"message\":\"world\",\"host\":\"logstash\",\"@version\":\"1\",\"@timestamp\":\"2023-09-19T01:33:12.308Z\"} 3.3.3 测试输出到 elasticsearch [root@logstash ~]# /usr/share/logstash/bin/logstash -e 'input { stdin{} } output{ elasticsearch {hosts =\u003e [\"10.0.0.11:9200\"] index =\u003e\"mytest-%{+YYYY.MM.dd}\" }}' ... WARNING: All illegal access operations will be denied in a future release [INFO ] 2023-09-19 10:07:09.728 [[main]-pipeline-manager] javapipeline - Pipeline started {\"pipeline.id\"=\u003e\"main\"} [INFO ] 2023-09-19 10:07:09.770 [Agent thread] agent - Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]} The stdin plugin is now waiting for input: hello world! 在 elasticsearch-01 查看索引\n[root@elasticsearch-01 ~]# curl -s -XGET \"http://localhost:9200/_cat/indices?v\" | grep mytest green open mytest-2023.09.19 qti_NT1sRNyBWrJY-T27zg 1 1 1 0 10.8kb 5.4kb 使用 head 插件 查看\n四、Kibana 部署 Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，基于 TypeScript 语言开发，设计用于和 Elasticsearch 协作,可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作, 你可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。\nKibana 可以使大数据通俗易懂。它很简单，基于浏览器的界面便于你快速创建和分享动态数据仪表板来追踪 Elasticsearch 的实时数据变化。\n4.1 环境准备 主机名 IP 系统 配置 kibana 10.0.0.16 CentOS 7.6 1U 2G # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config 4.2 安装kibana [Install Kibana | Kibana Guide 7.17] | Elastic\n[Install Kibana with RPM | Kibana Guide 7.17] | Elastic\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch cat \u003e /etc/yum.repos.d/kibana-7.repo \u003c\u003c EOF [kibana-7.x] name=Kibana repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md EOF yum install -y kibana 4.3 启动服务并验证 # 修改配置文件 [root@kibana ~]# cat /etc/kibana/kibana.yml server.port: 5601 server.host: \"0.0.0.0\" elasticsearch.hosts: [\"http://10.0.0.11:9200\"] # 启动服务 [root@kibana ~]# systemctl start kibana # 验证端口及服务状态 [root@kibana ~]# ss -ntl|grep 5601 LISTEN 0 128 *:5601 *:* [root@kibana ~]# curl localhost:5601/status -I HTTP/1.1 200 OK x-content-type-options: nosniff referrer-policy: no-referrer-when-downgrade content-security-policy: script-src 'unsafe-eval' 'self'; worker-src blob: 'self'; style-src 'unsafe-inline' 'self' kbn-name: kibana kbn-license-sig: 476866a5c1f8dfa58158ed8c49315635554443bf0f3ae73994b5dfac2c777125 content-type: text/html; charset=utf-8 cache-control: private, no-cache, no-store, must-revalidate content-length: 144960 vary: accept-encoding Date: Tue, 19 Sep 2023 03:14:15 GMT Connection: keep-alive Keep-Alive: timeout=120 服务启动成功后即可通过浏览器登录 kibana 管理索引并查看日志了\n访问方式：http://10.0.0.16:5601/\n可以在 Stack Management –\u003e Index Management 查看到已添加的索引，也可以在 Index pattern 添加索引模式，方便后续在 Discover 界面查看。\n五、Logstash 收集日志 5.1 收集单个日志 注意：logstash 默认以 logstash 用户启动，因为需要保证 logstash 用户对日志文件有对应的权限\n5.1.1 准备配置文件： [root@logstash ~]# cat /etc/logstash/conf.d/system-log.conf input { file { path =\u003e \"/var/log/messages\" # 日志路径 type =\u003e \"system-log\" # 事件的唯一类型 start_position =\u003e \"beginning\" # 第一次收集日志的位置 stat_interval =\u003e \"3\" # 日志收集的间隔时间 } } output { file { path =\u003e \"/tmp/%{type}-%{+YYYY.MM.dd}.log\" } } 5.1.2 修改日志文件权限 [root@logstash ~]# chmod 644 /var/log/messages 5.1.3 修改校验文件语法 [root@logstash ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system-log.conf -t ... . Config Validation Result: OK. Exiting Logstash # 语法校验通过 5.1.4 重启 logstash 验证结果 # 写入一行日志 [root@logstash ~]# echo \"test\" \u003e\u003e /var/log/messages # 成功获取收集到日志信息 [root@logstash ~]# grep test /tmp/system-log-2023.09.19.log {\"@version\":\"1\",\"host\":\"logstash\",\"type\":\"system-log\",\"@timestamp\":\"2023-09-19T07:02:14.221Z\",\"path\":\"/var/log/messages\",\"message\":\"test\"} 5.2 收集多个日志 5.2.1 准备配置文件 [root@logstash ~]# cat /etc/logstash/conf.d/system-log.conf input { file { path =\u003e \"/var/log/messages\" type =\u003e \"system-log\" start_position =\u003e \"beginning\" stat_interval =\u003e \"3\" } file { path =\u003e \"/var/log/secure\" type =\u003e \"secure-log\" start_position =\u003e \"beginning\" stat_interval =\u003e \"3\" } } output { if [type] == \"system-log\" { elasticsearch { hosts=\u003e[\"10.0.0.11:9200\"] index=\u003e\"%{type}-%{+YYYY.MM.dd}\" } } if [type] == \"secure-log\" { elasticsearch { hosts=\u003e[\"10.0.0.11:9200\"] index=\u003e\"%{type}-%{+YYYY.MM.dd}\" } } } 5.2.2 修改日志文件权限 [root@logstash ~]# chmod 644 /var/log/{messages,secure} 5.2.3 校验语法并重启服务 [root@logstash ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system-log.conf -t ... . Config Validation Result: OK. Exiting Logstash 5.2.4 在 elasticsearch 查看索引 [root@elasticsearch-01 ~]# curl -s -XGET \"http://localhost:9200/_cat/indices?v\" | grep log green open secure-log-2023.09.19 fQpud23vSVC7cpFPCITzbw 1 1 2 0 18.3kb 9.1kb green open system-log-2023.09.19 SeqTjpl-SU-n7uXUmmBBKA 1 1 40 0 44.8kb 22.4kb 5.3 在 kibana 查看索引 5.3.1 查看已有索引 5.3.2 添加索引模式 5.3.3 查看结果 5.4 收集 Tomcat 日志 5.4.1 在 logstash 安装tomcat yum install -y tomcat 5.4.2 配置 tomcat 日志格式为 json 格式 # 修改 pattern 为 json 格式 [root@kibana ~]# grep -A 2 localhost_access_log /etc/tomcat/server.xml prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"{\u0026quot;clientip\u0026quot;:\u0026quot;%h\u0026quot;,\u0026quot;ClientUser\u0026quot;:\u0026quot;%l\u0026quot;,\u0026quot;authenticated\u0026quot;:\u0026quot;%u\u0026quot;,\u0026quot;AccessTime\u0026quot;:\u0026quot;%t\u0026quot;,\u0026quot;method\u0026quot;:\u0026quot;%r\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;%s\u0026quot;,\u0026quot;SendBytes\u0026quot;:\u0026quot;%b\u0026quot;,\u0026quot;Query?string\u0026quot;:\u0026quot;%q\u0026quot;,\u0026quot;partner\u0026quot;:\u0026quot;%{Referer}i\u0026quot;,\u0026quot;AgentVersion\u0026quot;:\u0026quot;%{User-Agent}i\u0026quot;}\"/\u003e 重启服务并验证 tomcat 日志格式\n[root@kibana ~]# systemctl start tomcat # 生成日志 [root@kibana ~]# curl localhost:8080 # 成功将日志修改为 json 格式 [root@kibana ~]# tail /var/log/tomcat/localhost_access_log.2023-09-19.txt {\"clientip\":\"0:0:0:0:0:0:0:1\",\"ClientUser\":\"-\",\"authenticated\":\"-\",\"AccessTime\":\"[19/Sep/2023:18:17:31 +0800]\",\"method\":\"GET / HTTP/1.1\",\"status\":\"404\",\"SendBytes\":\"-\",\"Query?string\":\"\",\"partner\":\"-\",\"AgentVersion\":\"curl/7.29.0\"} 可以通过 JSON在线 | JSON解析格式化—SO JSON在线工具 校验日志格式\n5.4.3 准备配置文件 input { file { path =\u003e \"/var/log/tomcat/localhost_access_log.*.txt\" type =\u003e \"tomcat-access-log\" start_position =\u003e \"end\" stat_interval =\u003e \"3\" codec=\u003e \"json\" } } output { if [type] == \"tomcat-access-log\" { elasticsearch { hosts=\u003e[\"10.0.0.11:9200\"] index=\u003e\"%{type}-%{+YYYY.MM.dd}\" } } } 5.4.4 重启服务并生成日志 [root@logstash ~]# chmod +x /var/log/tomcat/ [root@logstash ~]# systemctl restart logstash [root@logstash ~]# curl localhost:8080 5.4.5 查看日志收集结果 5.5 收集 Java 日志 本节内容主要介绍 multiline 插件实现多行匹配，这是一个可以将多行进行合并的插件。有些情况下，Java 应用的日志会很长，在日志文件中以多行的方式呈现，因此需要用此插件来进行多行合并以保证日志的完整性和可读性，所以本节内容的操作是可选的而非必须的。\n[Multiline codec plugin | Logstash Reference 8.10] | Elastic\n5.5.1 在 elasticsearch-01 安装 logstash 这里是直接取用 elasticsearch-01的 java 日志进行演示，因此安装了 logstash\n# 导入证书 rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch # 配置 yum 源 cat \u003e /etc/yum.repos.d/logstash-7.repo \u003c\u003c EOF [logstash-7.x] name=Elastic repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md EOF # 安装并启动服务 yum install -y logstash 5.5.2 测试多行合并效果 5.5.2.1 准备配置文件 [root@elasticsearch-01 ~]# cat /etc/logstash/conf.d/test.conf input { stdin { codec =\u003e multiline { pattern =\u003e \"^\\[\" # 当遇到[开头的行时候将多行进行合并 negate =\u003e true # true 为匹配成功进行操作，false 为不成功进行操作 what =\u003e \"previous\" # 与以前的行合并，如果是下面的行合并就是 next } } } filter { #日志过滤，如果所有的日志都过滤就写这里，如果只针对某一个过滤就写在 input 里面的日志输入里面 } output { stdout { codec =\u003e rubydebug } } 5.5.5.2 检查配置 /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/test.conf -t ... which may change in a future major release of Logstash. To avoid unexpected changes when upgrading Logstash, please explicitly declare your desired ECS Compatibility mode. Configuration OK 5.5.5.3 使用标准输出进行验证 [root@elasticsearch-01 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/test.conf Using bundled JDK: /usr/share/logstash/jdk ... [INFO ] 2023-09-21 11:59:55.717 [[main]-pipeline-manager] javapipeline - Pipeline started {\"pipeline.id\"=\u003e\"main\"} The stdin plugin is now waiting for input: 5.5.3 收集 Java 日志 5.5.3.1 准备配置文件 [root@elasticsearch-01 ~]# cat /etc/logstash/conf.d/java.conf input { file { path =\u003e \"/apps/elasticsearch/logs/elk-cluster.log\" type =\u003e \"java-log\" start_position =\u003e \"beginning\" codec =\u003e multiline { pattern =\u003e \"^\\[\" negate =\u003e true what =\u003e \"previous\" } } } output { if [type] == \"java-log\" { elasticsearch { hosts =\u003e [\"10.0.0.11:9200\"] index=\u003e\"%{type}-%{+YYYY.MM.dd}\" } } } 5.5.3.2 生成 Java 日志文件 重启节点elasticsearch-02，使得集群产生多行错误日志以观察多行合并和的效果\n[root@elasticsearch-02 ~]# systemctl restart elasticsearch.service 生成的部分错误日志：\nless /apps/elasticsearch/logs/elk-cluster.log\n5.5.3.3 成功收集日志 5.5.3.4 通过 kibana 查看结果 添加索引模式 java-log* 后在 Discover 面板查看合并后的日志\n5.6 收集 Nginx 日志 nginx 的日志收集和 Java 类似，核心点在于将日志格式修改为 json 格式，这里仅演示如何修改日志格式。\n在 logstash 安装 nginx\n[root@logstash ~]# yum install -y nginx 修改 nginx 日志为 json 格式\n[root@logstash ~]# grep log_format -A 13 /etc/nginx/nginx.conf log_format main '{\"@timestamp\":\"$time_iso8601\",' '\"host\":\"$server_addr\",' '\"clientip\":\"$remote_addr\",' '\"size\":$body_bytes_sent,' '\"responsetime\":$request_time,' '\"upstreamtime\":\"$upstream_response_time\",' '\"upstreamhost\":\"$upstream_addr\",' '\"http_host\":\"$host\",' '\"url\":\"$uri\",' '\"domain\":\"$host\",' '\"xff\":\"$http_x_forwarded_for\",' '\"referer\":\"$http_referer\",' '\"status\":\"$status\"}'; 重启 nginx 生成日志\n[root@logstash ~]# systemctl start nginx [root@logstash ~]# curl localhost [root@logstash ~]# tail /var/log/nginx/access.log {\"@timestamp\":\"2023-09-21T15:37:49+08:00\",\"host\":\"::1\",\"clientip\":\"::1\",\"size\":4833,\"responsetime\":0.000,\"upstreamtime\":\"-\",\"upstreamhost\":\"-\",\"http_host\":\"localhost\",\"url\":\"/index.html\",\"domain\":\"localhost\",\"xff\":\"-\",\"referer\":\"-\",\"status\":\"200\"} 校验日志格式 JSON在线 | JSON解析格式化—SO JSON在线工具\n5.7 使用 Redis 缓存日志 目标：通过在 redis 客户端部署的 logstash （主机名 log-client） 收集日志，写入 redis （缓存作用），再通过专门的一台 logstash（主机名 logstash）读取 redis 中的日志写入 elasticsearch。\n5.7.1 准备一个客户端服务器 主机名 IP 系统 配置 log-client 10.0.0.9 CentOS 7.6 2U 4G # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config # 修改文件句柄数的限制 echo \"* soft nofile 65536\" \u003e\u003e /etc/security/limits.conf echo \"* hard nofile 65536\" \u003e\u003e /etc/security/limits.conf 安装 redis\n[root@log-client ~]# yum install -y redis # 修改配置文件 [root@log-client ~]# cat /etc/redis.conf bind 0.0.0.0 protected-mode yes port 6379 tcp-backlog 511 timeout 0 tcp-keepalive 300 daemonize yes supervised no pidfile /var/run/redis_6379.pid loglevel notice databases 16 requirepass passwd [root@log-client ~]# systemctl start redis ## 安装 logstash [root@log-client ~]# # 导入证书 [root@log-client ~]# rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch [root@log-client ~]# # 配置 yum 源 [root@log-client ~]# cat \u003e /etc/yum.repos.d/logstash-7.repo \u003c\u003c EOF \u003e [logstash-7.x] \u003e name=Elastic repository for 7.x packages \u003e baseurl=https://artifacts.elastic.co/packages/7.x/yum \u003e gpgcheck=1 \u003e gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch \u003e enabled=1 \u003e autorefresh=1 \u003e type=rpm-md \u003e EOF [root@log-client ~]# yum install -y logstash 5.7.2 收集日志写入 redis [root@log-client ~]# cat /etc/logstash/conf.d/sys-to-redis.conf input { file { path =\u003e \"/var/log/message\" type =\u003e \"system-log\" start_position =\u003e \"beginning\" stat_interval =\u003e \"2\" } } output { if [type] == \"system-log\" { redis { data_type =\u003e \"list\" key =\u003e \"system-log\" host =\u003e \"10.0.0.9\" port =\u003e \"6379\" db =\u003e \"0\" password =\u003e \"passwd\" } } } root@log-client ~]# chmod +r /var/log/messages [root@log-client ~]# ll /var/log/messages -rw-r--r--. 1 root root 596944 Sep 22 11:39 /var/log/messages [root@log-client ~]# systemctl start logstash.service # 成功写入日志 [root@log-client ~]# telnet localhost 6379 ... Escape character is '^]'. auth passwd +OK select 0 +OK keys * *1 $10 system-log # 以list 方式存储 LRANGE system-log 0 0 #查看其中一条消息 *1 $139 {\"path\":\"/var/log/messages\",\"host\":\"log-client\",\"@timestamp\":\"2023-09-22T03:52:48.547Z\",\"type\":\"system-log\",\"@version\":\"1\",\"message\":\"tet\"} 5.7.3 读取 redis 的日志写入 elasticsearch 准备配置文件：\n[root@logstash ~]# cat /etc/logstash/conf.d/redis-to-es.conf input { redis { data_type =\u003e \"list\" key =\u003e \"system-log\" host =\u003e \"10.0.0.9\" port =\u003e \"6379\" db =\u003e \"0\" password =\u003e \"passwd\" } } output { if [type] == \"system-log\" { elasticsearch { hosts =\u003e [\"10.0.0.11:9200\"] index =\u003e \"redis-to-es-%{+YYYY.MM.dd}\" } } } # 重启logstash [root@logstash ~]# systemctl restart logstash 验证结果：\nelasticseach 成功获取到日志信息\nredis 中的消息被消费：\n5.8 使用 Kafka 缓存日志 5.8.1 在 log-clinet 部署 kafka Kafka简介与集群部署 | WZ’s Blog (senmer.github.io)\n5.8.2 将日志写入 Kafka [root@log-client ~]# cat /etc/logstash/conf.d/sys-to-kafka.conf input { file { path =\u003e \"/var/log/messages\" type =\u003e \"system-log\" start_position =\u003e \"beginning\" stat_interval =\u003e \"2\" } } output { if [type] == \"system-log\" { kafka { bootstrap_servers =\u003e \"10.0.0.11:9092\" topic_id =\u003e \"system-log\" } } } # 配置域名解析，kafka 连接 elasticsearch 需要用到 [root@log-client ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 10.0.0.11 elasticsearch-01 10.0.0.12 elasticsearch-02 10.0.0.13 elasticsearch-03 # 重启 logstash [root@log-client ~]# systemctl restart logstash 5.8.3 查看 Kafka 中的 topic 注意：本示例中 Kafka、zookeeper、elasticsearch 集群均安装在（10.0.0.11、10.0.0.12、10.0.0.13）三台主机上\n[root@elasticsearch-01 kafka]# pwd /usr/local/kafka [root@elasticsearch-01 kafka]# ./bin/kafka-topics.sh --list --zookeeper localhost:2181 OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N __consumer_offsets system-log # 成功写入日志 5.8.4 读取 Kafka 中的日志写入 Elasticsearch [root@logstash ~]# cat /etc/logstash/conf.d/kafka-to-es.conf input { kafka { bootstrap_servers =\u003e \"10.0.0.11:9092\" topics =\u003e \"system-log\" consumer_threads =\u003e 1 } } output { elasticsearch { hosts =\u003e [\"10.0.0.11:9200\"] index =\u003e \"kafka-to-es-%{+YYYY.MM.dd}\" } } [root@logstash ~]# systemctl restart logstash.service 5.9 使用 filebeat 收集日志 要在 Filebeat 中使用 conf.d/* 的方式导入配置文件，通常你需要按照以下步骤进行配置：\n创建一个存放额外配置文件的目录，通常命名为 conf.d，并将你的额外配置文件放置在该目录中。这些配置文件可以包含不同输入、过滤器和输出的定义。\n确保 Filebeat 配置文件中包含一个配置项，告诉 Filebeat 去加载 conf.d 目录下的配置文件。通常，你可以使用 filebeat.config.modules 来配置额外配置文件的路径，如下所示：\nfilebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false filebeat.config.inputs: enabled: true path: ${path.config}/conf.d/*.yml # 这里指定额外配置文件的路径 确保你的额外配置文件（位于 conf.d 目录中）具有正确的格式和语法。这些配置文件可以包含输入、过滤器和输出的定义，类似于主配置文件。 以下是一个示例额外配置文件的内容（conf.d/my-custom-input.yml）：\nfilebeat.inputs: - type: log paths: - /var/log/myapp/*.log fields: log_type: myapp-log 保存主配置文件和额外配置文件，并重新启动 Filebeat 服务以使更改生效： sudo systemctl restart filebeat 这样，Filebeat 将加载主配置文件以及位于 conf.d 目录下的所有额外配置文件，并根据这些配置文件来处理日志数据。\n请根据你的实际需求和环境对配置进行自定义，并确保配置文件的正确性和一致性。\nhttps://www.elastic.co/guide/en/beats/filebeat/7.17/setup-repositories.html#_yum\n5.9.1 在 log-client 安装 filebeat [root@log-client ~]# sudo rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch [root@log-client ~]# [root@log-client ~]# cat \u003e /etc/yum.repos.d/filebeat-7.repo \u003c\u003c EOF \u003e [elastic-7.x] \u003e name=Elastic repository for 7.x packages \u003e baseurl=https://artifacts.elastic.co/packages/7.x/yum \u003e gpgcheck=1 \u003e gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch \u003e enabled=1 \u003e autorefresh=1 \u003e type=rpm-md \u003e EOF [root@log-client ~]# sudo yum install filebeat 5.9.2 收集系统日志 5.9.2.1 收集单个系统日志，写入 kafka [root@log-client ~]# cat /etc/filebeat/filebeat.yml lebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true filebeat.inputs: - type: log enabled: true paths: - /var/log/*.log - /var/log/messages exclude_lines: [\"^DBG\"] exclude_files: [\".gz$\"] fields_under_root: true fields: document_type: \"system-log\" output.kafka: hosts: [\"10.0.0.11:9092\", \"10.0.0.12:9092\", \"10.0.0.13:9092\"] topic: \"system-log-filebeat\" partition.round_robin: reachable_only: true required_acks: 1 compression: gzip max_message_bytes: 1000000 [root@log-client ~]# systemctl restart filebeat 2.9.2.2 在 kafka 中查看 topic [root@elasticsearch-01 elasticsearch]# /usr/local/src/kafka_2.12-2.1.0/bin/kafka-topics.sh --list --zookeeper localhost:2181 |grep filebeat ... system-log-filebeat 2.9.2.3 使用 logstash 将 kafka 中的日志写入 elasticsearch [root@logstash ~]# cat /etc/logstash/conf.d/kafka-to-es.conf input { kafka { bootstrap_servers =\u003e \"10.0.0.11:9092\" topics =\u003e \"system-log-filebeat\" consumer_threads =\u003e 1 } } output { elasticsearch { hosts =\u003e [\"10.0.0.11:9200\"] index =\u003e \"syslog-filebeat-%{+YYYY.MM.dd}\" } } [root@logstash ~]# systemctl restart logstash FAQ elk 中用 redis 和用 kafka 缓存日志有何区别 在ELK（Elasticsearch, Logstash, Kibana）堆栈中，使用Redis和Kafka来缓存日志有一些区别，它们分别适用于不同的使用情境和需求：\nRedis缓存日志：\nRedis是一个内存数据库，通常用于缓存和高速读写操作。在ELK中，Redis通常用于缓存日志事件，以便在Logstash和Elasticsearch之间提供快速的缓冲机制。 使用Redis缓存日志的优点包括高速的写入和读取速度，以及简单的设置和配置。 缺点是Redis的存储容量受限于内存大小，可能需要更多的内存来缓存大量的日志事件。此外，Redis不是一个专门设计用于处理日志流的工具，因此在某些情况下可能需要额外的定制。 Kafka缓存日志：\nKafka是一个分布式消息队列，通常用于高吞吐量的数据流处理。在ELK中，Kafka用于接收、缓存和分发日志事件，充当了一个持久性的数据缓冲层。 使用Kafka的优点包括能够处理大规模的数据流，提供数据持久性，以及具备高可用性和可伸缩性。 缺点是Kafka的配置和维护可能相对复杂，因为它是一个分布式系统。此外，它不像Redis那样适用于低延迟要求的场景。 关键区别：\nRedis主要用于瞬时性缓存，适用于需要快速读写操作的场景，但不适用于长期存储。它通常用于解决Logstash和Elasticsearch之间的速度不匹配问题。 Kafka更适合于数据流处理，能够缓存大量数据并确保持久性。它允许多个消费者并行处理数据，因此适用于大规模、高吞吐量的日志处理。 通常情况下，选择使用Redis还是Kafka取决于你的日志处理需求和架构。如果你需要一个简单的缓冲层来解决速度不匹配的问题，Redis可能是更合适的选择。如果你需要处理大量的日志数据，需要持久性和分布式处理能力，那么Kafka可能更适合。此外，还可以考虑将它们结合使用，使用Redis进行短期缓存，然后将日志事件写入Kafka以进行长期存储和分发。\nfilebeat 和 logstash 的区别 Filebeat和Logstash都是用于日志收集和传输的工具，但它们有一些关键区别，主要涉及到它们的用途、特性和性能：\n用途：\nFilebeat：Filebeat是轻量级的数据收集器，专注于从文件和日志位置收集数据并将其发送到目标位置，通常是Elasticsearch或Logstash。它主要用于日志文件的收集和转发。 Logstash：Logstash是一个强大的数据处理引擎，具有数据转换、过滤和丰富功能。它可以用于数据的采集、转换、丰富、过滤和输出。虽然它也可以用于日志收集，但其功能更丰富，可以处理多种数据源和格式。 处理和转换：\nFilebeat：Filebeat通常不对数据进行处理或转换，它负责将原始数据发送到目标位置。它可以对数据进行简单的筛选，但不具备复杂的数据处理功能。 Logstash：Logstash具有强大的数据处理能力，可以对数据进行复杂的转换、过滤、丰富和标准化操作。这使得Logstash在需要对数据进行复杂处理的情况下非常有用。 插件和输出：\nFilebeat：Filebeat的主要目标是将数据发送到Elasticsearch、Logstash或其他目标。它的输出选项相对较少，主要用于数据的传输。 Logstash：Logstash有丰富的插件和输出选项，可以将数据发送到多种目标，包括Elasticsearch、Kafka、Redis、数据库等，同时可以使用各种输入插件来接收数据源。 轻量性和性能：\nFilebeat：Filebeat设计为轻量级，占用较少的系统资源，适用于部署在资源受限的环境中。它适合快速传输日志数据。 Logstash：Logstash相对较重，需要更多的系统资源，特别是在进行大规模数据处理时。它适合处理复杂的数据处理任务。 部署场景：\nFilebeat适用于简单的日志传输和快速的日志收集场景，特别是在需要轻量级解决方案的情况下。 Logstash适用于需要进行数据处理、转换和丰富操作的场景，尤其是当需要处理多种数据源或数据格式时。 通常情况下，你可以根据具体的需求来选择使用Filebeat、Logstash，或者它们的组合，以构建适合你的日志收集和处理架构。要根据特定需求进行选择，以确保系统的效率和性能。\n","wordCount":"9473","inLanguage":"zh","datePublished":"2023-10-08T17:21:41+08:00","dateModified":"2023-10-08T17:21:41+08:00","author":[{"@type":"Person","name":"wz"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://senmer.github.io/zh/posts/tech/elk/elk%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BD%BF%E7%94%A8/"},"publisher":{"@type":"Organization","name":"WZ's Blog","logo":{"@type":"ImageObject","url":"https://senmer.github.io/img/Q.gif"}}}</script></head><body id=top><script>(function(){let e,t=new RegExp("(^| )change-themes=([^;]*)(;|$)");(e=document.cookie.match(t))||((new Date).getHours()>=19||(new Date).getHours()<6?(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark")):(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")))})(),localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://senmer.github.io/zh/ accesskey=h title="WZ's Blog (Alt + H)"><img src=https://senmer.github.io/img/Q.gif alt=logo aria-label=logo height=35>WZ's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://senmer.github.io/zh/search title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://senmer.github.io/zh/ title="🏠 主页"><span>🏠 主页</span></a></li><li><a href=https://senmer.github.io/zh/posts/tech title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://senmer.github.io/zh/categories/ title="🧩 分类"><span>🧩 分类</span></a></li><li><a href=https://senmer.github.io/zh/archives/ title="⏱️ 时间轴"><span>⏱️ 时间轴</span></a></li><li><a href=https://senmer.github.io/zh/about title="🙋🏻‍♂️ 关于"><span>🙋🏻‍♂️ 关于</span></a></li><li><a href=https://senmer.github.io/zh/links title="🤝 友链"><span>🤝 友链</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://senmer.github.io/zh/>🏠 主页</a>&nbsp;»&nbsp;<a href=https://senmer.github.io/zh/posts/>📚文章</a>&nbsp;»&nbsp;<a href=https://senmer.github.io/zh/posts/tech/>👨🏻‍💻 技术</a></div><h1 class=post-title>ELK部署和使用</h1><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2023-10-08
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>9473字
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>19分钟
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>wz
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta></span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://senmer.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:"https://hugo-api-khaki.vercel.app/# 填写自己的twikoo id",region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e4%b8%80elk-%e7%ae%80%e4%bb%8b aria-label="一、ELK 简介">一、ELK 简介</a></li><li><a href=#%e4%ba%8celasticsearch-%e9%9b%86%e7%be%a4%e9%83%a8%e7%bd%b2 aria-label="二、Elasticsearch 集群部署">二、Elasticsearch 集群部署</a><ul><li><a href=#21-%e7%8e%af%e5%a2%83%e5%88%9d%e5%a7%8b%e5%8c%96 aria-label="2.1 环境初始化">2.1 环境初始化</a><ul><li><a href=#211-%e7%8e%af%e5%a2%83%e5%87%86%e5%a4%87 aria-label="2.1.1 环境准备">2.1.1 环境准备</a></li><li><a href=#212-%e5%86%85%e6%a0%b8%e5%8f%82%e6%95%b0%e5%8f%8a%e6%9c%8d%e5%8a%a1%e8%b0%83%e6%95%b4 aria-label="2.1.2 内核参数及服务调整">2.1.2 内核参数及服务调整</a></li><li><a href=#213-%e9%85%8d%e7%bd%ae-hosts-%e8%a7%a3%e6%9e%90 aria-label="2.1.3 配置 hosts 解析">2.1.3 配置 hosts 解析</a></li><li><a href=#214-%e5%ae%89%e8%a3%85%e5%bf%85%e8%a6%81%e7%9a%84%e8%bd%af%e4%bb%b6%e5%b9%b6%e5%90%8c%e6%ad%a5%e6%97%b6%e9%97%b4 aria-label="2.1.4 安装必要的软件并同步时间">2.1.4 安装必要的软件并同步时间</a></li><li><a href=#215-%e9%85%8d%e7%bd%ae-java-%e7%8e%af%e5%a2%83 aria-label="2.1.5 配置 java 环境">2.1.5 配置 java 环境</a></li></ul></li><li><a href=#22-%e5%ae%89%e8%a3%85-elasticsearch aria-label="2.2 安装 elasticsearch">2.2 安装 elasticsearch</a><ul><li><a href=#221-yum-%e5%ae%89%e8%a3%85-elasticsearch-717 aria-label="2.2.1 yum 安装 elasticsearch 7.17">2.2.1 yum 安装 elasticsearch 7.17</a></li><li><a href=#222-%e4%bf%ae%e6%94%b9%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="2.2.2 修改配置文件">2.2.2 修改配置文件</a></li><li><a href=#223-%e4%bf%ae%e6%94%b9%e5%86%85%e5%ad%98%e9%99%90%e5%88%b6 aria-label="2.2.3 修改内存限制">2.2.3 修改内存限制</a></li></ul></li><li><a href=#23-%e5%90%af%e5%8a%a8%e6%9c%8d%e5%8a%a1%e5%b9%b6%e6%9f%a5%e7%9c%8b%e9%9b%86%e7%be%a4%e7%8a%b6%e6%80%81 aria-label="2.3 启动服务并查看集群状态">2.3 启动服务并查看集群状态</a><ul><li><a href=#231-%e5%90%af%e5%8a%a8%e6%9c%8d%e5%8a%a1 aria-label="2.3.1 启动服务">2.3.1 启动服务</a></li><li><a href=#232-%e6%9f%a5%e7%9c%8b%e9%9b%86%e7%be%a4%e7%8a%b6%e6%80%81 aria-label="2.3.2 查看集群状态">2.3.2 查看集群状态</a></li><li><a href=#233-elasticseach-%e6%8f%92%e4%bb%b6 aria-label="2.3.3 elasticseach 插件">2.3.3 elasticseach 插件</a></li></ul></li></ul></li><li><a href=#%e4%b8%89-logstash-%e9%83%a8%e7%bd%b2 aria-label="三、 Logstash 部署">三、 Logstash 部署</a><ul><li><a href=#31-%e7%8e%af%e5%a2%83%e5%87%86%e5%a4%87 aria-label="3.1 环境准备">3.1 环境准备</a><ul><li><a href=#312-%e5%85%b3%e9%97%ad%e4%b8%8d%e9%9c%80%e8%a6%81%e7%9a%84%e6%9c%8d%e5%8a%a1 aria-label="3.1.2 关闭不需要的服务">3.1.2 关闭不需要的服务</a></li><li><a href=#312-%e9%85%8d%e7%bd%ae-java-%e7%8e%af%e5%a2%83 aria-label="3.1.2 配置 Java 环境">3.1.2 配置 Java 环境</a></li></ul></li><li><a href=#32-%e5%ae%89%e8%a3%85-logstash aria-label="3.2 安装 logstash">3.2 安装 logstash</a></li><li><a href=#33-logstash-%e7%9a%84%e4%bd%bf%e7%94%a8 aria-label="3.3 logstash 的使用">3.3 logstash 的使用</a><ul><li><a href=#331-%e6%b5%8b%e8%af%95%e6%a0%87%e5%87%86%e8%be%93%e5%85%a5%e5%92%8c%e6%a0%87%e5%87%86%e8%be%93%e5%87%ba aria-label="3.3.1 测试标准输入和标准输出">3.3.1 测试标准输入和标准输出</a></li><li><a href=#332-%e6%b5%8b%e8%af%95%e8%be%93%e5%87%ba%e5%88%b0%e6%96%87%e4%bb%b6 aria-label="3.3.2 测试输出到文件">3.3.2 测试输出到文件</a></li><li><a href=#333-%e6%b5%8b%e8%af%95%e8%be%93%e5%87%ba%e5%88%b0-elasticsearch aria-label="3.3.3 测试输出到 elasticsearch">3.3.3 测试输出到 elasticsearch</a></li></ul></li></ul></li><li><a href=#%e5%9b%9bkibana-%e9%83%a8%e7%bd%b2 aria-label="四、Kibana 部署">四、Kibana 部署</a><ul><li><a href=#41-%e7%8e%af%e5%a2%83%e5%87%86%e5%a4%87 aria-label="4.1 环境准备">4.1 环境准备</a></li><li><a href=#42-%e5%ae%89%e8%a3%85kibana aria-label="4.2 安装kibana">4.2 安装kibana</a></li><li><a href=#43-%e5%90%af%e5%8a%a8%e6%9c%8d%e5%8a%a1%e5%b9%b6%e9%aa%8c%e8%af%81 aria-label="4.3 启动服务并验证">4.3 启动服务并验证</a></li></ul></li><li><a href=#%e4%ba%94logstash-%e6%94%b6%e9%9b%86%e6%97%a5%e5%bf%97 aria-label="五、Logstash 收集日志">五、Logstash 收集日志</a><ul><li><a href=#51-%e6%94%b6%e9%9b%86%e5%8d%95%e4%b8%aa%e6%97%a5%e5%bf%97 aria-label="5.1 收集单个日志">5.1 收集单个日志</a><ul><li><a href=#511-%e5%87%86%e5%a4%87%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="5.1.1 准备配置文件："><strong>5.1.1 准备配置文件</strong>：</a></li><li><a href=#512-%e4%bf%ae%e6%94%b9%e6%97%a5%e5%bf%97%e6%96%87%e4%bb%b6%e6%9d%83%e9%99%90 aria-label="5.1.2 修改日志文件权限">5.1.2 修改日志文件权限</a></li><li><a href=#513-%e4%bf%ae%e6%94%b9%e6%a0%a1%e9%aa%8c%e6%96%87%e4%bb%b6%e8%af%ad%e6%b3%95 aria-label="5.1.3 修改校验文件语法">5.1.3 修改校验文件语法</a></li><li><a href=#514-%e9%87%8d%e5%90%af-logstash-%e9%aa%8c%e8%af%81%e7%bb%93%e6%9e%9c aria-label="5.1.4 重启 logstash 验证结果">5.1.4 重启 logstash 验证结果</a></li></ul></li><li><a href=#52-%e6%94%b6%e9%9b%86%e5%a4%9a%e4%b8%aa%e6%97%a5%e5%bf%97 aria-label="5.2 收集多个日志">5.2 收集多个日志</a><ul><li><a href=#521-%e5%87%86%e5%a4%87%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="5.2.1 准备配置文件">5.2.1 准备配置文件</a></li><li><a href=#522-%e4%bf%ae%e6%94%b9%e6%97%a5%e5%bf%97%e6%96%87%e4%bb%b6%e6%9d%83%e9%99%90 aria-label="5.2.2 修改日志文件权限">5.2.2 修改日志文件权限</a></li><li><a href=#523--%e6%a0%a1%e9%aa%8c%e8%af%ad%e6%b3%95%e5%b9%b6%e9%87%8d%e5%90%af%e6%9c%8d%e5%8a%a1 aria-label="5.2.3  校验语法并重启服务">5.2.3 校验语法并重启服务</a></li><li><a href=#524-%e5%9c%a8-elasticsearch-%e6%9f%a5%e7%9c%8b%e7%b4%a2%e5%bc%95 aria-label="5.2.4 在 elasticsearch 查看索引">5.2.4 在 elasticsearch 查看索引</a></li></ul></li><li><a href=#53-%e5%9c%a8-kibana-%e6%9f%a5%e7%9c%8b%e7%b4%a2%e5%bc%95 aria-label="5.3 在 kibana 查看索引">5.3 在 kibana 查看索引</a><ul><li><a href=#531-%e6%9f%a5%e7%9c%8b%e5%b7%b2%e6%9c%89%e7%b4%a2%e5%bc%95 aria-label="5.3.1 查看已有索引">5.3.1 查看已有索引</a></li><li><a href=#532-%e6%b7%bb%e5%8a%a0%e7%b4%a2%e5%bc%95%e6%a8%a1%e5%bc%8f aria-label="5.3.2 添加索引模式">5.3.2 添加索引模式</a></li><li><a href=#533-%e6%9f%a5%e7%9c%8b%e7%bb%93%e6%9e%9c aria-label="5.3.3 查看结果">5.3.3 查看结果</a></li></ul></li><li><a href=#54-%e6%94%b6%e9%9b%86-tomcat-%e6%97%a5%e5%bf%97 aria-label="5.4 收集 Tomcat 日志">5.4 收集 Tomcat 日志</a><ul><li><a href=#541-%e5%9c%a8-logstash-%e5%ae%89%e8%a3%85tomcat aria-label="5.4.1 在 logstash 安装tomcat">5.4.1 在 logstash 安装tomcat</a></li><li><a href=#542-%e9%85%8d%e7%bd%ae-tomcat-%e6%97%a5%e5%bf%97%e6%a0%bc%e5%bc%8f%e4%b8%ba-json-%e6%a0%bc%e5%bc%8f aria-label="5.4.2 配置 tomcat 日志格式为 json 格式">5.4.2 配置 tomcat 日志格式为 json 格式</a></li><li><a href=#543-%e5%87%86%e5%a4%87%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="5.4.3 准备配置文件">5.4.3 准备配置文件</a></li><li><a href=#544-%e9%87%8d%e5%90%af%e6%9c%8d%e5%8a%a1%e5%b9%b6%e7%94%9f%e6%88%90%e6%97%a5%e5%bf%97 aria-label="5.4.4 重启服务并生成日志">5.4.4 重启服务并生成日志</a></li><li><a href=#545-%e6%9f%a5%e7%9c%8b%e6%97%a5%e5%bf%97%e6%94%b6%e9%9b%86%e7%bb%93%e6%9e%9c aria-label="5.4.5 查看日志收集结果">5.4.5 查看日志收集结果</a></li></ul></li><li><a href=#55-%e6%94%b6%e9%9b%86-java-%e6%97%a5%e5%bf%97 aria-label="5.5 收集 Java 日志">5.5 收集 Java 日志</a><ul><li><a href=#551-%e5%9c%a8-elasticsearch-01-%e5%ae%89%e8%a3%85-logstash aria-label="5.5.1 在 elasticsearch-01 安装 logstash">5.5.1 在 elasticsearch-01 安装 logstash</a></li><li><a href=#552-%e6%b5%8b%e8%af%95%e5%a4%9a%e8%a1%8c%e5%90%88%e5%b9%b6%e6%95%88%e6%9e%9c aria-label="5.5.2 测试多行合并效果">5.5.2 测试多行合并效果</a><ul><li><a href=#5521-%e5%87%86%e5%a4%87%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="5.5.2.1 准备配置文件">5.5.2.1 准备配置文件</a></li><li><a href=#5552-%e6%a3%80%e6%9f%a5%e9%85%8d%e7%bd%ae aria-label="5.5.5.2 检查配置">5.5.5.2 检查配置</a></li><li><a href=#5553-%e4%bd%bf%e7%94%a8%e6%a0%87%e5%87%86%e8%be%93%e5%87%ba%e8%bf%9b%e8%a1%8c%e9%aa%8c%e8%af%81 aria-label="5.5.5.3 使用标准输出进行验证">5.5.5.3 使用标准输出进行验证</a></li></ul></li><li><a href=#553-%e6%94%b6%e9%9b%86-java-%e6%97%a5%e5%bf%97 aria-label="5.5.3 收集 Java 日志">5.5.3 收集 Java 日志</a><ul><li><a href=#5531-%e5%87%86%e5%a4%87%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="5.5.3.1 准备配置文件">5.5.3.1 准备配置文件</a></li><li><a href=#5532-%e7%94%9f%e6%88%90-java-%e6%97%a5%e5%bf%97%e6%96%87%e4%bb%b6 aria-label="5.5.3.2 生成 Java 日志文件">5.5.3.2 生成 Java 日志文件</a></li><li><a href=#5533-%e6%88%90%e5%8a%9f%e6%94%b6%e9%9b%86%e6%97%a5%e5%bf%97 aria-label="5.5.3.3 成功收集日志">5.5.3.3 成功收集日志</a></li><li><a href=#5534-%e9%80%9a%e8%bf%87-kibana-%e6%9f%a5%e7%9c%8b%e7%bb%93%e6%9e%9c aria-label="5.5.3.4 通过 kibana 查看结果">5.5.3.4 通过 kibana 查看结果</a></li></ul></li></ul></li><li><a href=#56-%e6%94%b6%e9%9b%86-nginx-%e6%97%a5%e5%bf%97 aria-label="5.6 收集 Nginx 日志">5.6 收集 Nginx 日志</a></li><li><a href=#57-%e4%bd%bf%e7%94%a8-redis-%e7%bc%93%e5%ad%98%e6%97%a5%e5%bf%97 aria-label="5.7 使用 Redis 缓存日志">5.7 使用 Redis 缓存日志</a><ul><li><a href=#571-%e5%87%86%e5%a4%87%e4%b8%80%e4%b8%aa%e5%ae%a2%e6%88%b7%e7%ab%af%e6%9c%8d%e5%8a%a1%e5%99%a8 aria-label="5.7.1 准备一个客户端服务器">5.7.1 <strong>准备一个客户端服务器</strong></a></li><li><a href=#572-%e6%94%b6%e9%9b%86%e6%97%a5%e5%bf%97%e5%86%99%e5%85%a5-redis aria-label="5.7.2 收集日志写入 redis">5.7.2 收集日志写入 redis</a></li><li><a href=#573-%e8%af%bb%e5%8f%96-redis-%e7%9a%84%e6%97%a5%e5%bf%97%e5%86%99%e5%85%a5-elasticsearch aria-label="5.7.3 读取 redis 的日志写入 elasticsearch">5.7.3 读取 redis 的日志写入 elasticsearch</a></li></ul></li><li><a href=#58-%e4%bd%bf%e7%94%a8-kafka-%e7%bc%93%e5%ad%98%e6%97%a5%e5%bf%97 aria-label="5.8 使用 Kafka 缓存日志">5.8 使用 Kafka 缓存日志</a><ul><li><a href=#581-%e5%9c%a8-log-clinet-%e9%83%a8%e7%bd%b2-kafka aria-label="5.8.1 在 log-clinet 部署 kafka">5.8.1 在 log-clinet 部署 kafka</a></li><li><a href=#582-%e5%b0%86%e6%97%a5%e5%bf%97%e5%86%99%e5%85%a5-kafka aria-label="5.8.2 将日志写入 Kafka">5.8.2 将日志写入 Kafka</a></li><li><a href=#583-%e6%9f%a5%e7%9c%8b-kafka-%e4%b8%ad%e7%9a%84-topic aria-label="5.8.3 查看 Kafka 中的 topic">5.8.3 查看 Kafka 中的 topic</a></li><li><a href=#584-%e8%af%bb%e5%8f%96-kafka-%e4%b8%ad%e7%9a%84%e6%97%a5%e5%bf%97%e5%86%99%e5%85%a5-elasticsearch aria-label="5.8.4 读取 Kafka 中的日志写入 Elasticsearch">5.8.4 读取 Kafka 中的日志写入 Elasticsearch</a></li></ul></li><li><a href=#59-%e4%bd%bf%e7%94%a8-filebeat-%e6%94%b6%e9%9b%86%e6%97%a5%e5%bf%97 aria-label="5.9 使用 filebeat 收集日志">5.9 使用 filebeat 收集日志</a><ul><li><a href=#591-%e5%9c%a8-log-client-%e5%ae%89%e8%a3%85-filebeat aria-label="5.9.1 在 log-client 安装 filebeat">5.9.1 <strong>在 log-client 安装 filebeat</strong></a></li><li><a href=#592-%e6%94%b6%e9%9b%86%e7%b3%bb%e7%bb%9f%e6%97%a5%e5%bf%97 aria-label="5.9.2 收集系统日志">5.9.2 收集系统日志</a><ul><li><a href=#5921-%e6%94%b6%e9%9b%86%e5%8d%95%e4%b8%aa%e7%b3%bb%e7%bb%9f%e6%97%a5%e5%bf%97%e5%86%99%e5%85%a5-kafka aria-label="5.9.2.1 收集单个系统日志，写入 kafka">5.9.2.1 收集单个系统日志，写入 kafka</a></li><li><a href=#2922-%e5%9c%a8-kafka-%e4%b8%ad%e6%9f%a5%e7%9c%8b-topic aria-label="2.9.2.2 在 kafka 中查看 topic">2.9.2.2 在 kafka 中查看 topic</a></li><li><a href=#2923-%e4%bd%bf%e7%94%a8-logstash-%e5%b0%86-kafka-%e4%b8%ad%e7%9a%84%e6%97%a5%e5%bf%97%e5%86%99%e5%85%a5-elasticsearch aria-label="2.9.2.3 使用 logstash 将 kafka 中的日志写入 elasticsearch">2.9.2.3 使用 logstash 将 kafka 中的日志写入 elasticsearch</a></li></ul></li></ul></li></ul></li><li><a href=#faq aria-label=FAQ>FAQ</a><ul><li><a href=#elk-%e4%b8%ad%e7%94%a8-redis-%e5%92%8c%e7%94%a8-kafka-%e7%bc%93%e5%ad%98%e6%97%a5%e5%bf%97%e6%9c%89%e4%bd%95%e5%8c%ba%e5%88%ab aria-label="elk 中用 redis 和用 kafka 缓存日志有何区别">elk 中用 redis 和用 kafka 缓存日志有何区别</a></li><li><a href=#filebeat-%e5%92%8c-logstash-%e7%9a%84%e5%8c%ba%e5%88%ab aria-label="filebeat 和 logstash 的区别">filebeat 和 logstash 的区别</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=一elk-简介>一、ELK 简介<a hidden class=anchor aria-hidden=true href=#一elk-简介>#</a></h2><p>ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。</p><p>下面是每个组件的简要介绍：</p><ol><li><p><strong>Elasticsearch：</strong> Elasticsearch是一个开源分布式搜索和分析引擎。它用于存储和索引大量的数据，使用户能够快速进行全文搜索、分析和聚合。Elasticsearch的强大之处在于其分布式性能和可扩展性，它能够处理海量数据并提供高效的查询和分析。</p></li><li><p><strong>Logstash：</strong> Logstash是一个用于收集、处理和转发各种类型数据的数据流处理引擎。它可以从多种来源（如日志文件、消息队列、数据库等）收集数据，经过处理后将数据发送到目标存储（如Elasticsearch）。Logstash可以用于数据清洗、转换、标准化等，以便将数据准备好供后续的搜索和分析。</p></li><li><p><strong>Kibana：</strong> Kibana是一个用于数据可视化和分析的开源工具。它提供了一个用户友好的Web界面，使用户能够创建仪表板、图表和地图来展示Elasticsearch中的数据。通过Kibana，用户可以通过交互式的界面深入分析数据、观察趋势、检测异常等。</p></li></ol><p>ELK的工作流程通常是这样的：Logstash收集和处理各种数据源的日志数据，然后将处理后的数据发送到Elasticsearch进行索引和存储。用户可以使用Kibana来查询数据、创建可视化仪表板，从而更好地理解数据的情况。</p><p>需要注意的是，Elasticsearch 在新版本中也被称为 Elastic Stack，因为除了上述三个核心组件外，Elastic 公司还提供了其他一些附加工具和功能，以进一步增强数据分析和管理的能力。</p><h2 id=二elasticsearch-集群部署>二、Elasticsearch 集群部署<a hidden class=anchor aria-hidden=true href=#二elasticsearch-集群部署>#</a></h2><h3 id=21-环境初始化>2.1 环境初始化<a hidden class=anchor aria-hidden=true href=#21-环境初始化>#</a></h3><h4 id=211-环境准备>2.1.1 环境准备<a hidden class=anchor aria-hidden=true href=#211-环境准备>#</a></h4><table><thead><tr><th>主机名</th><th>IP</th><th>系统</th><th>配置</th></tr></thead><tbody><tr><td>elasticsearch-01</td><td>10.0.0.11</td><td>CentOS 7.6</td><td>2U 4G</td></tr><tr><td>elasticsearch-02</td><td>10.0.0.12</td><td>CentOS 7.6</td><td>1U 2G</td></tr><tr><td>elasticsearch-03</td><td>10.0.0.13</td><td>CentOS 7.6</td><td>1U 2G</td></tr></tbody></table><h4 id=212-内核参数及服务调整>2.1.2 内核参数及服务调整<a hidden class=anchor aria-hidden=true href=#212-内核参数及服务调整>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 关闭防火墙</span>
</span></span><span style=display:flex><span>systemctl disable firewalld --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭 NetworkManager</span>
</span></span><span style=display:flex><span>systemctl disable NetworkManager --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭selinux</span>
</span></span><span style=display:flex><span>setenforce <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;/SELINUX/s/enforcing/disabled/&#39;</span> /etc/selinux/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 修改文件句柄数的限制</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;* soft nofile 65536&#34;</span> &gt;&gt; /etc/security/limits.conf
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;* hard nofile 65536&#34;</span> &gt;&gt; /etc/security/limits.conf
</span></span></code></pre></div><h4 id=213-配置-hosts-解析>2.1.3 配置 hosts 解析<a hidden class=anchor aria-hidden=true href=#213-配置-hosts-解析>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># cat /etc/hosts</span>
</span></span><span style=display:flex><span>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
</span></span><span style=display:flex><span>::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
</span></span><span style=display:flex><span>10.0.0.11 elasticsearch-01
</span></span><span style=display:flex><span>10.0.0.12 elasticsearch-02 
</span></span><span style=display:flex><span>10.0.0.13 elasticsearch-03
</span></span></code></pre></div><h4 id=214-安装必要的软件并同步时间>2.1.4 安装必要的软件并同步时间<a hidden class=anchor aria-hidden=true href=#214-安装必要的软件并同步时间>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 安装基础软件</span>
</span></span><span style=display:flex><span>yum install -y epel-release net-tools vim lrzsz tree screen lsof tcpdump wget ntpdate
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 同步时间</span>
</span></span><span style=display:flex><span>cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定时同步</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;*/5 * * * * ntpdate time1.aliyun.com &amp;&gt; /dev/null &amp;&amp; hwclock -w&#34;</span> &gt;&gt; /var/spool/cron/root
</span></span><span style=display:flex><span>systemctl restart crond
</span></span></code></pre></div><h4 id=215-配置-java-环境>2.1.5 配置 java 环境<a hidden class=anchor aria-hidden=true href=#215-配置-java-环境>#</a></h4><p><a href=https://www.elastic.co/cn/support/matrix#matrix_jvm>支持一览表 | Elastic</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install java-1.8.0-openjdk -y
</span></span><span style=display:flex><span>java -version
</span></span></code></pre></div><h3 id=22-安装-elasticsearch>2.2 安装 elasticsearch<a hidden class=anchor aria-hidden=true href=#22-安装-elasticsearch>#</a></h3><h4 id=221-yum-安装-elasticsearch-717>2.2.1 yum 安装 elasticsearch 7.17<a hidden class=anchor aria-hidden=true href=#221-yum-安装-elasticsearch-717>#</a></h4><p><a href=https://www.elastic.co/cn/downloads/elasticsearch>Download Elasticsearch | Elastic</a></p><p>[Install Elasticsearch with RPM | Elasticsearch Guide <a href=https://www.elastic.co/guide/en/elasticsearch/reference/7.17/rpm.html#rpm-repo>7.17] | Elastic</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cat &gt; /etc/yum.repos.d/elasticsearch-7.repo <span style=color:#e6db74>&lt;&lt; EOF
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[elasticsearch]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Elasticsearch repository for 7.x packages
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=https://artifacts.elastic.co/packages/7.x/yum
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=0
</span></span></span><span style=display:flex><span><span style=color:#e6db74>autorefresh=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>type=rpm-md
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>yum install -y --enablerepo<span style=color:#f92672>=</span>elasticsearch elasticsearch
</span></span></code></pre></div><h4 id=222-修改配置文件>2.2.2 修改配置文件<a hidden class=anchor aria-hidden=true href=#222-修改配置文件>#</a></h4><p><code># cat /etc/elasticsearch/elasticsearch.yml</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cluster.name: elk-cluster
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>node.name: elk-node-01 <span style=color:#75715e># 每个节点唯一，根据需要修改</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>path.data: /apps/elasticsearch/data <span style=color:#75715e># 数据存放目录，需要手动创建</span>
</span></span><span style=display:flex><span>path.logs: /apps/elasticsearch/logs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>bootstrap.memory_lock: true
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>network.host: 0.0.0.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>http.port: <span style=color:#ae81ff>9200</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>discovery.seed_hosts: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11&#34;</span>, <span style=color:#e6db74>&#34;10.0.0.12&#34;</span>, <span style=color:#e6db74>&#34;10.0.0.13&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cluster.initial_master_nodes: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11&#34;</span>, <span style=color:#e6db74>&#34;10.0.0.12&#34;</span>, <span style=color:#e6db74>&#34;10.0.0.13&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gateway.recover_after_nodes: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>action.destructive_requires_name: true
</span></span></code></pre></div><p><strong>参数解释</strong></p><ul><li><code>cluster.name: elk-cluster</code>: 设置Elasticsearch集群的名称为"elk-cluster"。</li><li><code>node.name: elk-node-01</code>: 设置当前Elasticsearch节点的名称为"elk-node-01"。</li><li><code>path.data: /apps/elasticsearch/data</code> 和 <code>path.logs: /apps/elasticsearch/logs</code>: 分别指定Elasticsearch数据和日志文件的存储路径。</li><li><code>bootstrap.memory_lock: true</code>: 这个配置表示Elasticsearch将尝试锁定内存，以提高性能和稳定性。</li><li><code>network.host: 0.0.0.0</code>: 允许Elasticsearch绑定到所有可用的网络接口，以允许来自任何IP地址的连接。</li><li><code>http.port: 9200</code>: 设置Elasticsearch HTTP服务的监听端口为9200，这是默认的HTTP API端口。</li><li><code>discovery.seed_hosts: ["10.0.0.11", "10.0.0.12", "10.0.0.13"]</code>: 指定了Elasticsearch集群的发现节点，这些节点用于启动和发现集群中的其他节点。</li><li><code>cluster.initial_master_nodes: ["10.0.0.11", "10.0.0.12", "10.0.0.13"]</code>: 指定了初始的主节点列表，用于初始化集群。</li><li><code>gateway.recover_after_nodes: 2</code>: 配置在至少有2个节点可用时才允许集群恢复。</li><li><code>action.destructive_requires_name: true</code>: 这个配置要求在执行破坏性操作（如删除索引）时需要提供名称，以防止意外的操作。</li></ul><h4 id=223-修改内存限制>2.2.3 修改内存限制<a hidden class=anchor aria-hidden=true href=#223-修改内存限制>#</a></h4><blockquote><p><code>LimitMEMLOCK=infinity</code> 是Systemd服务的配置参数之一，用于限制进程的内存锁定（mlock）资源。这个参数的含义是将内存锁定资源的限制设置为无限制，也就是允许进程锁定任意数量的内存。内存锁定是一种操作，用于将内存分配给进程，并防止操作系统将其交换到磁盘上，从而提高了对内存的快速访问。</p><p>在某些应用程序中，特别是对于需要高性能和低延迟的应用程序，需要将一部分内存锁定，以确保数据始终位于物理内存中，而不会被交换到磁盘上，以减少访问延迟。将<code>LimitMEMLOCK</code>设置为infinity允许进程锁定所需的内存而不受限制。</p><p>请注意，修改此设置可能会影响系统的性能和稳定性，因为不受限制的内存锁定可能导致系统资源不足，因此在进行此类配置更改时需要小心谨慎，并确保了解应用程序的内存使用模式和系统资源限制。</p><p>此外，上述配置片段通常可以在Systemd服务单元文件（通常位于<code>/etc/systemd/system/</code>或<code>/lib/systemd/system/</code>中）中找到，并用于调整特定服务的资源限制。具体的配置文件可能因不同的Linux发行版和应用程序而有所不同。</p></blockquote><p><strong>注意：要在Service 块中设置，不然不会生效</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># grep LimitMEMLOCK=infinity /usr/lib/systemd/system/elasticsearch.service -B 1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>Service<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>LimitMEMLOCK<span style=color:#f92672>=</span>infinity
</span></span><span style=display:flex><span><span style=color:#75715e># systemctl daemon-reload</span>
</span></span></code></pre></div><p><strong>修改堆内存大小</strong></p><p>[Heap size settings | Elasticsearch Guide <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html>8.9] | Elastic</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># grep Xm /etc/elasticsearch/jvm.options</span>
</span></span><span style=display:flex><span>-Xms1g
</span></span><span style=display:flex><span>-Xmx1g
</span></span></code></pre></div><p><strong>创建数据存放目录</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mkdir -p /apps/elasticsearch/<span style=color:#f92672>{</span>data,logs<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>chown -R elasticsearch.elasticsearch /apps/elasticsearch/
</span></span></code></pre></div><h3 id=23-启动服务并查看集群状态>2.3 启动服务并查看集群状态<a hidden class=anchor aria-hidden=true href=#23-启动服务并查看集群状态>#</a></h3><blockquote><p>Elasticsearch 集群状态用于表示集群的整体健康状况。Elasticsearch 集群可以处于不同的健康状态，这些状态反映了集群中数据分片的可用性和完整性。以下是 Elasticsearch 集群状态的主要介绍：</p><ol><li><strong>Green（绿色）</strong>:<ul><li>集群处于最佳状态。</li><li>所有主分片和复制分片都可用。</li><li>集群的数据完整性和可用性都非常高。</li><li>所有节点都正常运行，没有故障。</li><li>性能正常，没有性能问题。</li></ul></li><li><strong>Yellow（黄色）</strong>:<ul><li>集群状态表示为 &ldquo;yellow&rdquo; 时，主分片都可用，但复制分片（副本）可能存在问题。</li><li>可能有一些副本分片尚未分配到节点上，或者某些节点不可用。</li><li>数据完整性有一定程度的风险，因为复制分片的可用性受到影响。</li><li>性能通常良好，但需要关注集群健康状态。</li></ul></li><li><strong>Red（红色）</strong>:<ul><li>集群状态表示为 &ldquo;red&rdquo; 时，意味着主分片不可用。</li><li>这可能是由于主分片丢失、未分配或者节点故障等问题引起的。</li><li>数据的可用性和完整性受到严重威胁，因为主分片无法提供数据访问。</li><li>性能可能会受到影响，具体取决于缺失的主分片数量和查询的性质。</li></ul></li></ol></blockquote><h4 id=231-启动服务>2.3.1 启动服务<a hidden class=anchor aria-hidden=true href=#231-启动服务>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># systemctl start elasticsearch</span>
</span></span><span style=display:flex><span><span style=color:#75715e># systemctl status elasticsearch</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># ss -ntl</span>
</span></span><span style=display:flex><span>State      Recv-Q Send-Q                     Local Address:Port                                    Peer Address:Port              
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>128</span>                                    *:22                                                 *:*                  
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>100</span>                            127.0.0.1:25                                                 *:*                  
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>128</span>                                   :::9200   <span style=color:#75715e># 服务监听端口                                           :::*                  </span>
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>128</span>                                   :::9300   <span style=color:#75715e># 集群通信端口                                           :::*                  </span>
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>128</span>                                   :::22                                                :::*                  
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>100</span>                                  ::1:25                                                :::* 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># curl localhost:9200</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;name&#34;</span> : <span style=color:#e6db74>&#34;elk-node-01&#34;</span>,	<span style=color:#75715e># 节点名称</span>
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;cluster_name&#34;</span> : <span style=color:#e6db74>&#34;elk-cluster&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;cluster_uuid&#34;</span> : <span style=color:#e6db74>&#34;XXO_Ik9XQo2Y5Uw6UvVS-g&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;version&#34;</span> : <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;number&#34;</span> : <span style=color:#e6db74>&#34;7.17.13&#34;</span>, 	<span style=color:#75715e># elasticsearch 版本号</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;build_flavor&#34;</span> : <span style=color:#e6db74>&#34;default&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;build_type&#34;</span> : <span style=color:#e6db74>&#34;rpm&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;build_hash&#34;</span> : <span style=color:#e6db74>&#34;2b211dbb8bfdecaf7f5b44d356bdfe54b1050c13&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;build_date&#34;</span> : <span style=color:#e6db74>&#34;2023-08-31T17:33:19.958690787Z&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;build_snapshot&#34;</span> : false,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;lucene_version&#34;</span> : <span style=color:#e6db74>&#34;8.11.1&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;minimum_wire_compatibility_version&#34;</span> : <span style=color:#e6db74>&#34;6.8.0&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;minimum_index_compatibility_version&#34;</span> : <span style=color:#e6db74>&#34;6.0.0-beta1&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;tagline&#34;</span> : <span style=color:#e6db74>&#34;You Know, for Search&#34;</span>	<span style=color:#75715e># 宣传语</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h4 id=232-查看集群状态>2.3.2 查看集群状态<a hidden class=anchor aria-hidden=true href=#232-查看集群状态>#</a></h4><blockquote><p>可以利用此接口对 elasticseach 集群状态进行监控</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># curl localhost:9200/_cluster/health?pretty</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;cluster_name&#34;</span> : <span style=color:#e6db74>&#34;elk-cluster&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;status&#34;</span> : <span style=color:#e6db74>&#34;green&#34;</span>,	<span style=color:#75715e># 集群监控状态</span>
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;timed_out&#34;</span> : false,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;number_of_nodes&#34;</span> : 3,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;number_of_data_nodes&#34;</span> : 3,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;active_primary_shards&#34;</span> : 3,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;active_shards&#34;</span> : 6,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;relocating_shards&#34;</span> : 0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;initializing_shards&#34;</span> : 0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;unassigned_shards&#34;</span> : 0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;delayed_unassigned_shards&#34;</span> : 0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;number_of_pending_tasks&#34;</span> : 0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;number_of_in_flight_fetch&#34;</span> : 0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;task_max_waiting_in_queue_millis&#34;</span> : 0,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;active_shards_percent_as_number&#34;</span> : 100.0
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p>以下是其中的一些关键字段的解释：</p><ol><li><p><code>"cluster_name" : "elk-cluster"</code>: 集群的名称，这个示例中的集群名称为 &ldquo;elk-cluster&rdquo;。</p></li><li><p><code>"status" : "green"</code>: 集群的健康状态，这个示例中集群状态为 &ldquo;green&rdquo;，表示集群处于最佳状态。</p></li><li><p><code>"number_of_nodes" : 3</code>: 集群中的节点数量，这个示例中有3个节点。</p></li><li><p><code>"number_of_data_nodes" : 3</code>: 集群中的数据节点数量，这是实际存储数据的节点数，这个示例中也是3个。</p></li><li><p><code>"active_primary_shards" : 3</code>: 活动主分片的数量，这是集群中主要负责存储数据的分片数量，这个示例中有3个。</p></li><li><p><code>"active_shards" : 6</code>: 所有活动分片的数量，包括主分片和副本分片，这个示例中有6个。</p></li><li><p><code>"relocating_shards" : 0</code>: 正在迁移的分片数量，如果你在重新平衡集群或迁移分片，则该值可能会增加。</p></li><li><p><code>"initializing_shards" : 0</code>: 正在初始化的分片数量，通常在新分片或节点加入时出现。</p></li><li><p><code>"unassigned_shards" : 0</code>: 未分配的分片数量，这是指尚未分配到任何节点的分片数量。在集群状态为 &ldquo;green&rdquo; 时，这应该是0。</p></li><li><p><code>"delayed_unassigned_shards" : 0</code>: 延迟未分配的分片数量，这是指尚未分配到节点，但由于一些原因而被延迟的分片数量。</p></li><li><p><code>"number_of_pending_tasks" : 0</code>: 集群中待处理任务的数量，例如索引创建或删除等操作可能会生成待处理任务。</p></li><li><p><code>"number_of_in_flight_fetch" : 0</code>: 目前正在进行的数据获取请求的数量。</p></li><li><p><code>"task_max_waiting_in_queue_millis" : 0</code>: 队列中等待的任务的最大等待时间（以毫秒为单位）。</p></li><li><p><code>"active_shards_percent_as_number" : 100.0</code>: 活动分片的百分比，作为数字表示。在 &ldquo;green&rdquo; 状态下，应该是100%，表示所有分片都是活动的。</p></li></ol><p>总的来说，这些信息提供了有关 Elasticsearch 集群状态和性能的关键指标，可以用于监控和管理集群。在 &ldquo;green&rdquo; 状态下，集群是健康的，数据完整性和可用性都非常高。</p><h4 id=233-elasticseach-插件>2.3.3 elasticseach 插件<a hidden class=anchor aria-hidden=true href=#233-elasticseach-插件>#</a></h4><p>官方提供了一些插件但大部分是收费的，另外也有一些开发爱好者提供的插件，可以实现对 elasticsearch 集群的状态监控与管理配置等功能，Multi Elasticsearch Head 就是其中一个。</p><p>可以通过浏览器的应用商店安装 （chrome 、edge）</p><p><a href="https://chrome.google.com/webstore/detail/multi-elasticsearch-head/cpmmilfkofbeimbmgiclohpodggeheim?utm_source=ext_app_menu">https://chrome.google.com/webstore/detail/multi-elasticsearch-head/cpmmilfkofbeimbmgiclohpodggeheim?utm_source=ext_app_menu</a></p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919164446667.png alt=image-20230919164446667></p><h2 id=三-logstash-部署>三、 Logstash 部署<a hidden class=anchor aria-hidden=true href=#三-logstash-部署>#</a></h2><p>Logstash 是一个开源的数据收集引擎，可以水平伸缩，基于 ruby 开发，而且 logstash 整个 ELK当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。</p><h3 id=31-环境准备>3.1 环境准备<a hidden class=anchor aria-hidden=true href=#31-环境准备>#</a></h3><table><thead><tr><th>主机名</th><th>IP</th><th>系统</th><th>配置</th></tr></thead><tbody><tr><td>logstash</td><td>10.0.0.15</td><td>CentOS 7.6</td><td>2U 4G</td></tr></tbody></table><h4 id=312-关闭不需要的服务>3.1.2 关闭不需要的服务<a hidden class=anchor aria-hidden=true href=#312-关闭不需要的服务>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 关闭防火墙</span>
</span></span><span style=display:flex><span>systemctl disable firewalld --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭 NetworkManager</span>
</span></span><span style=display:flex><span>systemctl disable NetworkManager --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭selinux</span>
</span></span><span style=display:flex><span>setenforce <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;/SELINUX/s/enforcing/disabled/&#39;</span> /etc/selinux/config
</span></span></code></pre></div><h4 id=312-配置-java-环境>3.1.2 配置 Java 环境<a hidden class=anchor aria-hidden=true href=#312-配置-java-环境>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install java-1.8.0-openjdk -y
</span></span><span style=display:flex><span>java -version
</span></span></code></pre></div><h3 id=32-安装-logstash>3.2 安装 logstash<a hidden class=anchor aria-hidden=true href=#32-安装-logstash>#</a></h3><p>[Installing Logstash | Logstash Reference <a href=https://www.elastic.co/guide/en/logstash/7.17/installing-logstash.html#_yum>7.17] | Elastic</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 导入证书</span>
</span></span><span style=display:flex><span>rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span><span style=display:flex><span><span style=color:#75715e># 配置 yum 源</span>
</span></span><span style=display:flex><span>cat &gt; /etc/yum.repos.d/logstash-7.repo <span style=color:#e6db74>&lt;&lt; EOF
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[logstash-7.x]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Elastic repository for 7.x packages
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=https://artifacts.elastic.co/packages/7.x/yum
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>autorefresh=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>type=rpm-md
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 安装并启动服务</span>
</span></span><span style=display:flex><span>yum install -y logstash
</span></span><span style=display:flex><span>systemctl start logstash.service
</span></span></code></pre></div><h3 id=33-logstash-的使用>3.3 logstash 的使用<a hidden class=anchor aria-hidden=true href=#33-logstash-的使用>#</a></h3><p>Logstash 是一个开源的数据收集引擎，可以水平伸缩，而且 logstash 整个 ELK 当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。</p><h4 id=331-测试标准输入和标准输出>3.3.1 测试标准输入和标准输出<a hidden class=anchor aria-hidden=true href=#331-测试标准输入和标准输出>#</a></h4><blockquote><p>在Logstash的配置中，&ldquo;codec&rdquo; 是"编解码器"（Codec）的缩写。编解码器是一种用于将数据编码成特定格式或从特定格式解码数据的组件。在Logstash中，它用于指定输入和输出的数据格式。</p><p>在你提供的配置中，你使用了Elasticsearch输出插件，并指定了"codec"选项为"json"。这表示你希望将Logstash事件数据编码为JSON格式，然后将其发送到Elasticsearch。这有助于确保数据以JSON格式存储在Elasticsearch中，以便后续查询和分析。</p><p>&ldquo;codec"选项的常见值包括：</p><ul><li><p>&ldquo;json&rdquo;：将事件数据编码为JSON格式。</p></li><li><p>&ldquo;plain&rdquo;：不对事件数据进行编码，保持原始格式。</p></li><li><p>&ldquo;json_lines&rdquo;：将事件数据编码为一行一条JSON记录的格式。</p></li><li><p>&ldquo;multiline&rdquo;：用于处理多行日志事件。</p></li></ul></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># /usr/share/logstash/bin/logstash -e &#39;input{ stdin{} } output{ stdout{ codec=&gt;rubydebug }}&#39;</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>The stdin plugin is now waiting <span style=color:#66d9ef>for</span> input:
</span></span><span style=display:flex><span>hello
</span></span><span style=display:flex><span><span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>       <span style=color:#e6db74>&#34;message&#34;</span> <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;hello&#34;</span>,	<span style=color:#75715e># 消息内容</span>
</span></span><span style=display:flex><span>          <span style=color:#e6db74>&#34;host&#34;</span> <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;logstash&#34;</span>,	<span style=color:#75715e># 主机名</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;@timestamp&#34;</span> <span style=color:#f92672>=</span>&gt; 2023-09-19T01:16:14.334Z, <span style=color:#75715e># 事件发生时间</span>
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#34;@version&#34;</span> <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;1&#34;</span>	<span style=color:#75715e># 事件版本号，一个事件就是一个 ruby 对象</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>^C
</span></span></code></pre></div><h4 id=332-测试输出到文件>3.3.2 测试输出到文件<a hidden class=anchor aria-hidden=true href=#332-测试输出到文件>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e>#  /usr/share/logstash/bin/logstash -e &#39;input { stdin{} } output{ file { path =&gt; &#34;/tmp/log-%{+YYYY.MM.dd}.txt&#34;}}&#39;</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>The stdin plugin is now waiting <span style=color:#66d9ef>for</span> input:
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>INFO <span style=color:#f92672>]</span> 2023-09-19 09:30:28.836 <span style=color:#f92672>[</span>Agent thread<span style=color:#f92672>]</span> agent - Pipelines running <span style=color:#f92672>{</span>:count<span style=color:#f92672>=</span>&gt;1, :running_pipelines<span style=color:#f92672>=</span>&gt;<span style=color:#f92672>[</span>:main<span style=color:#f92672>]</span>, :non_running_pipelines<span style=color:#f92672>=</span>&gt;<span style=color:#f92672>[]}</span>
</span></span><span style=display:flex><span>hello
</span></span><span style=display:flex><span>world
</span></span><span style=display:flex><span>^C
</span></span><span style=display:flex><span><span style=color:#75715e># 输出文本文件</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># file /tmp/log-2023.09.19.txt </span>
</span></span><span style=display:flex><span>/tmp/log-2023.09.19.txt: ASCII text
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 消息内容已输出到文本中，多条消息会追加到文件末尾</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /tmp/log-2023.09.19.txt </span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#e6db74>&#34;hello&#34;</span>,<span style=color:#e6db74>&#34;@version&#34;</span>:<span style=color:#e6db74>&#34;1&#34;</span>,<span style=color:#e6db74>&#34;@timestamp&#34;</span>:<span style=color:#e6db74>&#34;2023-09-19T01:30:40.576Z&#34;</span>,<span style=color:#e6db74>&#34;host&#34;</span>:<span style=color:#e6db74>&#34;logstash&#34;</span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#e6db74>&#34;world&#34;</span>,<span style=color:#e6db74>&#34;host&#34;</span>:<span style=color:#e6db74>&#34;logstash&#34;</span>,<span style=color:#e6db74>&#34;@version&#34;</span>:<span style=color:#e6db74>&#34;1&#34;</span>,<span style=color:#e6db74>&#34;@timestamp&#34;</span>:<span style=color:#e6db74>&#34;2023-09-19T01:33:12.308Z&#34;</span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h4 id=333-测试输出到-elasticsearch>3.3.3 测试输出到 elasticsearch<a hidden class=anchor aria-hidden=true href=#333-测试输出到-elasticsearch>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># /usr/share/logstash/bin/logstash -e &#39;input { stdin{} } output{ elasticsearch {hosts =&gt; [&#34;10.0.0.11:9200&#34;] index =&gt;&#34;mytest-%{+YYYY.MM.dd}&#34; }}&#39;</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>WARNING: All illegal access operations will be denied in a future release
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>INFO <span style=color:#f92672>]</span> 2023-09-19 10:07:09.728 <span style=color:#f92672>[[</span>main<span style=color:#f92672>]</span>-pipeline-manager<span style=color:#f92672>]</span> javapipeline - Pipeline started <span style=color:#f92672>{</span><span style=color:#e6db74>&#34;pipeline.id&#34;</span><span style=color:#f92672>=</span>&gt;<span style=color:#e6db74>&#34;main&#34;</span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>INFO <span style=color:#f92672>]</span> 2023-09-19 10:07:09.770 <span style=color:#f92672>[</span>Agent thread<span style=color:#f92672>]</span> agent - Pipelines running <span style=color:#f92672>{</span>:count<span style=color:#f92672>=</span>&gt;1, :running_pipelines<span style=color:#f92672>=</span>&gt;<span style=color:#f92672>[</span>:main<span style=color:#f92672>]</span>, :non_running_pipelines<span style=color:#f92672>=</span>&gt;<span style=color:#f92672>[]}</span>
</span></span><span style=display:flex><span>The stdin plugin is now waiting <span style=color:#66d9ef>for</span> input:
</span></span><span style=display:flex><span>hello world!
</span></span></code></pre></div><p><strong>在 elasticsearch-01 查看索引</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># curl -s -XGET &#34;http://localhost:9200/_cat/indices?v&#34; | grep mytest</span>
</span></span><span style=display:flex><span>green  open   mytest-2023.09.19                qti_NT1sRNyBWrJY-T27zg   <span style=color:#ae81ff>1</span>   <span style=color:#ae81ff>1</span>          <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>0</span>     10.8kb          5.4kb
</span></span></code></pre></div><p><strong>使用 head 插件 查看</strong></p><h2 id=image-20230919164925784imageselk部署和使用image-20230919164925784png><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919164925784.png alt=image-20230919164925784></h2><h2 id=四kibana-部署>四、Kibana 部署<a hidden class=anchor aria-hidden=true href=#四kibana-部署>#</a></h2><p>Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，基于 TypeScript 语言开发，设计用于和 Elasticsearch 协作,可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作, 你可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。</p><p>Kibana 可以使大数据通俗易懂。它很简单，基于浏览器的界面便于你快速创建和分享动态数据仪表板来追踪 Elasticsearch 的实时数据变化。</p><h3 id=41-环境准备>4.1 环境准备<a hidden class=anchor aria-hidden=true href=#41-环境准备>#</a></h3><table><thead><tr><th>主机名</th><th>IP</th><th>系统</th><th>配置</th></tr></thead><tbody><tr><td>kibana</td><td>10.0.0.16</td><td>CentOS 7.6</td><td>1U 2G</td></tr></tbody></table><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 关闭防火墙</span>
</span></span><span style=display:flex><span>systemctl disable firewalld --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭 NetworkManager</span>
</span></span><span style=display:flex><span>systemctl disable NetworkManager --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭selinux</span>
</span></span><span style=display:flex><span>setenforce <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;/SELINUX/s/enforcing/disabled/&#39;</span> /etc/selinux/config
</span></span></code></pre></div><h3 id=42-安装kibana>4.2 安装kibana<a hidden class=anchor aria-hidden=true href=#42-安装kibana>#</a></h3><p>[Install Kibana | Kibana Guide <a href=https://www.elastic.co/guide/en/kibana/7.17/install.html>7.17] | Elastic</a></p><p>[Install Kibana with RPM | Kibana Guide <a href=https://www.elastic.co/guide/en/kibana/7.17/rpm.html>7.17] | Elastic</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cat &gt; /etc/yum.repos.d/kibana-7.repo <span style=color:#e6db74>&lt;&lt; EOF
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[kibana-7.x]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Kibana repository for 7.x packages
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=https://artifacts.elastic.co/packages/7.x/yum
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>autorefresh=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>type=rpm-md
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>yum install -y kibana
</span></span></code></pre></div><h3 id=43-启动服务并验证>4.3 启动服务并验证<a hidden class=anchor aria-hidden=true href=#43-启动服务并验证>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 修改配置文件</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/kibana/kibana.yml </span>
</span></span><span style=display:flex><span>server.port: <span style=color:#ae81ff>5601</span>
</span></span><span style=display:flex><span>server.host: <span style=color:#e6db74>&#34;0.0.0.0&#34;</span>
</span></span><span style=display:flex><span>elasticsearch.hosts: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;http://10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 启动服务</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl start kibana</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 验证端口及服务状态</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># ss -ntl|grep 5601</span>
</span></span><span style=display:flex><span>LISTEN     <span style=color:#ae81ff>0</span>      <span style=color:#ae81ff>128</span>          *:5601                     *:*                  
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># curl localhost:5601/status -I</span>
</span></span><span style=display:flex><span>HTTP/1.1 <span style=color:#ae81ff>200</span> OK
</span></span><span style=display:flex><span>x-content-type-options: nosniff
</span></span><span style=display:flex><span>referrer-policy: no-referrer-when-downgrade
</span></span><span style=display:flex><span>content-security-policy: script-src <span style=color:#e6db74>&#39;unsafe-eval&#39;</span> <span style=color:#e6db74>&#39;self&#39;</span>; worker-src blob: <span style=color:#e6db74>&#39;self&#39;</span>; style-src <span style=color:#e6db74>&#39;unsafe-inline&#39;</span> <span style=color:#e6db74>&#39;self&#39;</span>
</span></span><span style=display:flex><span>kbn-name: kibana
</span></span><span style=display:flex><span>kbn-license-sig: 476866a5c1f8dfa58158ed8c49315635554443bf0f3ae73994b5dfac2c777125
</span></span><span style=display:flex><span>content-type: text/html; charset<span style=color:#f92672>=</span>utf-8
</span></span><span style=display:flex><span>cache-control: private, no-cache, no-store, must-revalidate
</span></span><span style=display:flex><span>content-length: <span style=color:#ae81ff>144960</span>
</span></span><span style=display:flex><span>vary: accept-encoding
</span></span><span style=display:flex><span>Date: Tue, <span style=color:#ae81ff>19</span> Sep <span style=color:#ae81ff>2023</span> 03:14:15 GMT
</span></span><span style=display:flex><span>Connection: keep-alive
</span></span><span style=display:flex><span>Keep-Alive: timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>120</span>
</span></span></code></pre></div><p>服务启动成功后即可通过浏览器登录 kibana 管理索引并查看日志了</p><p>访问方式：<code>http://10.0.0.16:5601/</code></p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919163054561.png alt=image-20230919163054561></p><p>可以在 Stack Management &ndash;> Index Management 查看到已添加的索引，也可以在 Index pattern 添加索引模式，方便后续在 Discover 界面查看。</p><h2 id=五logstash-收集日志>五、Logstash 收集日志<a hidden class=anchor aria-hidden=true href=#五logstash-收集日志>#</a></h2><h3 id=51-收集单个日志>5.1 收集单个日志<a hidden class=anchor aria-hidden=true href=#51-收集单个日志>#</a></h3><p><strong>注意：logstash 默认以 logstash 用户启动，因为需要保证 logstash 用户对日志文件有对应的权限</strong></p><h4 id=511-准备配置文件><strong>5.1.1 准备配置文件</strong>：<a hidden class=anchor aria-hidden=true href=#511-准备配置文件>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/system-log.conf </span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/var/log/messages&#34;</span> <span style=color:#75715e># 日志路径</span>
</span></span><span style=display:flex><span>    type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span> <span style=color:#75715e># 事件的唯一类型</span>
</span></span><span style=display:flex><span>    start_position <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;beginning&#34;</span> <span style=color:#75715e># 第一次收集日志的位置</span>
</span></span><span style=display:flex><span>    stat_interval <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;3&#34;</span> <span style=color:#75715e># 日志收集的间隔时间</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/tmp/%{type}-%{+YYYY.MM.dd}.log&#34;</span> 
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h4 id=512-修改日志文件权限>5.1.2 修改日志文件权限<a hidden class=anchor aria-hidden=true href=#512-修改日志文件权限>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># chmod 644 /var/log/messages</span>
</span></span></code></pre></div><h4 id=513-修改校验文件语法>5.1.3 修改校验文件语法<a hidden class=anchor aria-hidden=true href=#513-修改校验文件语法>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system-log.conf -t</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>. Config Validation Result: OK. Exiting Logstash <span style=color:#75715e># 语法校验通过</span>
</span></span></code></pre></div><h4 id=514-重启-logstash-验证结果>5.1.4 重启 logstash 验证结果<a hidden class=anchor aria-hidden=true href=#514-重启-logstash-验证结果>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 写入一行日志</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># echo &#34;test&#34; &gt;&gt; /var/log/messages</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 成功获取收集到日志信息</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># grep test /tmp/system-log-2023.09.19.log </span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;@version&#34;</span>:<span style=color:#e6db74>&#34;1&#34;</span>,<span style=color:#e6db74>&#34;host&#34;</span>:<span style=color:#e6db74>&#34;logstash&#34;</span>,<span style=color:#e6db74>&#34;type&#34;</span>:<span style=color:#e6db74>&#34;system-log&#34;</span>,<span style=color:#e6db74>&#34;@timestamp&#34;</span>:<span style=color:#e6db74>&#34;2023-09-19T07:02:14.221Z&#34;</span>,<span style=color:#e6db74>&#34;path&#34;</span>:<span style=color:#e6db74>&#34;/var/log/messages&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#e6db74>&#34;test&#34;</span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h3 id=52-收集多个日志>5.2 收集多个日志<a hidden class=anchor aria-hidden=true href=#52-收集多个日志>#</a></h3><h4 id=521-准备配置文件>5.2.1 准备配置文件<a hidden class=anchor aria-hidden=true href=#521-准备配置文件>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/system-log.conf</span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/var/log/messages&#34;</span> 
</span></span><span style=display:flex><span>    type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span>
</span></span><span style=display:flex><span>    start_position <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;beginning&#34;</span> 
</span></span><span style=display:flex><span>    stat_interval <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span> 
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/var/log/secure&#34;</span>
</span></span><span style=display:flex><span>    type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;secure-log&#34;</span>
</span></span><span style=display:flex><span>    start_position <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;beginning&#34;</span>
</span></span><span style=display:flex><span>    stat_interval <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span>type<span style=color:#f92672>]</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;system-log&#34;</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    elasticsearch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      hosts<span style=color:#f92672>=</span>&gt;<span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>      index<span style=color:#f92672>=</span>&gt;<span style=color:#e6db74>&#34;%{type}-%{+YYYY.MM.dd}&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span>type<span style=color:#f92672>]</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;secure-log&#34;</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    elasticsearch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      hosts<span style=color:#f92672>=</span>&gt;<span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>      index<span style=color:#f92672>=</span>&gt;<span style=color:#e6db74>&#34;%{type}-%{+YYYY.MM.dd}&#34;</span>
</span></span><span style=display:flex><span>     <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h4 id=522-修改日志文件权限>5.2.2 修改日志文件权限<a hidden class=anchor aria-hidden=true href=#522-修改日志文件权限>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># chmod 644 /var/log/{messages,secure}</span>
</span></span></code></pre></div><h4 id=523--校验语法并重启服务>5.2.3 校验语法并重启服务<a hidden class=anchor aria-hidden=true href=#523--校验语法并重启服务>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system-log.conf -t</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>. Config Validation Result: OK. Exiting Logstash
</span></span></code></pre></div><h4 id=524-在-elasticsearch-查看索引>5.2.4 在 elasticsearch 查看索引<a hidden class=anchor aria-hidden=true href=#524-在-elasticsearch-查看索引>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># curl -s -XGET &#34;http://localhost:9200/_cat/indices?v&#34; | grep  log</span>
</span></span><span style=display:flex><span>green  open   secure-log-2023.09.19            fQpud23vSVC7cpFPCITzbw   <span style=color:#ae81ff>1</span>   <span style=color:#ae81ff>1</span>          <span style=color:#ae81ff>2</span>            <span style=color:#ae81ff>0</span>     18.3kb          9.1kb
</span></span><span style=display:flex><span>green  open   system-log-2023.09.19            SeqTjpl-SU-n7uXUmmBBKA   <span style=color:#ae81ff>1</span>   <span style=color:#ae81ff>1</span>         <span style=color:#ae81ff>40</span>            <span style=color:#ae81ff>0</span>     44.8kb         22.4kb
</span></span></code></pre></div><h3 id=53-在-kibana-查看索引>5.3 在 kibana 查看索引<a hidden class=anchor aria-hidden=true href=#53-在-kibana-查看索引>#</a></h3><h4 id=531-查看已有索引>5.3.1 查看已有索引<a hidden class=anchor aria-hidden=true href=#531-查看已有索引>#</a></h4><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919165931459.png alt=image-20230919165931459></p><h4 id=532-添加索引模式>5.3.2 添加索引模式<a hidden class=anchor aria-hidden=true href=#532-添加索引模式>#</a></h4><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919170325911.png alt=image-20230919170325911></p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919170459491.png alt=image-20230919170459491></p><h4 id=533-查看结果>5.3.3 查看结果<a hidden class=anchor aria-hidden=true href=#533-查看结果>#</a></h4><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919170641576.png alt=image-20230919170641576></p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230919170751287.png alt=image-20230919170751287></p><h3 id=54-收集-tomcat-日志>5.4 收集 Tomcat 日志<a hidden class=anchor aria-hidden=true href=#54-收集-tomcat-日志>#</a></h3><h4 id=541-在-logstash-安装tomcat>5.4.1 在 logstash 安装tomcat<a hidden class=anchor aria-hidden=true href=#541-在-logstash-安装tomcat>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install -y tomcat 
</span></span></code></pre></div><h4 id=542-配置-tomcat-日志格式为-json-格式>5.4.2 配置 tomcat 日志格式为 json 格式<a hidden class=anchor aria-hidden=true href=#542-配置-tomcat-日志格式为-json-格式>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 修改 pattern 为 json 格式 </span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># grep -A 2 localhost_access_log /etc/tomcat/server.xml </span>
</span></span><span style=display:flex><span>               prefix<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;localhost_access_log.&#34;</span> suffix<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;.txt&#34;</span>
</span></span><span style=display:flex><span>               pattern<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;{&amp;quot;clientip&amp;quot;:&amp;quot;%h&amp;quot;,&amp;quot;ClientUser&amp;quot;:&amp;quot;%l&amp;quot;,&amp;quot;authenticated&amp;quot;:&amp;quot;%u&amp;quot;,&amp;quot;AccessTime&amp;quot;:&amp;quot;%t&amp;quot;,&amp;quot;method&amp;quot;:&amp;quot;%r&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;%s&amp;quot;,&amp;quot;SendBytes&amp;quot;:&amp;quot;%b&amp;quot;,&amp;quot;Query?string&amp;quot;:&amp;quot;%q&amp;quot;,&amp;quot;partner&amp;quot;:&amp;quot;%{Referer}i&amp;quot;,&amp;quot;AgentVersion&amp;quot;:&amp;quot;%{User-Agent}i&amp;quot;}&#34;</span>/&gt;
</span></span></code></pre></div><p>重启服务并验证 tomcat 日志格式</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl start tomcat</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 生成日志</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># curl localhost:8080 </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 成功将日志修改为 json 格式</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@kibana ~<span style=color:#f92672>]</span><span style=color:#75715e># tail /var/log/tomcat/localhost_access_log.2023-09-19.txt </span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;clientip&#34;</span>:<span style=color:#e6db74>&#34;0:0:0:0:0:0:0:1&#34;</span>,<span style=color:#e6db74>&#34;ClientUser&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;authenticated&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;AccessTime&#34;</span>:<span style=color:#e6db74>&#34;[19/Sep/2023:18:17:31 +0800]&#34;</span>,<span style=color:#e6db74>&#34;method&#34;</span>:<span style=color:#e6db74>&#34;GET / HTTP/1.1&#34;</span>,<span style=color:#e6db74>&#34;status&#34;</span>:<span style=color:#e6db74>&#34;404&#34;</span>,<span style=color:#e6db74>&#34;SendBytes&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;Query?string&#34;</span>:<span style=color:#e6db74>&#34;&#34;</span>,<span style=color:#e6db74>&#34;partner&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;AgentVersion&#34;</span>:<span style=color:#e6db74>&#34;curl/7.29.0&#34;</span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p>可以通过 <a href=https://www.sojson.com/>JSON在线 | JSON解析格式化—SO JSON在线工具</a> 校验日志格式</p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230920174042735.png alt=image-20230920174042735></p><h4 id=543-准备配置文件>5.4.3 准备配置文件<a hidden class=anchor aria-hidden=true href=#543-准备配置文件>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/var/log/tomcat/localhost_access_log.*.txt&#34;</span>
</span></span><span style=display:flex><span>    type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;tomcat-access-log&#34;</span>
</span></span><span style=display:flex><span>    start_position <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;end&#34;</span>
</span></span><span style=display:flex><span>    stat_interval <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span>    codec<span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;json&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span>type<span style=color:#f92672>]</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;tomcat-access-log&#34;</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    elasticsearch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      hosts<span style=color:#f92672>=</span>&gt;<span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>      index<span style=color:#f92672>=</span>&gt;<span style=color:#e6db74>&#34;%{type}-%{+YYYY.MM.dd}&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h4 id=544-重启服务并生成日志>5.4.4 重启服务并生成日志<a hidden class=anchor aria-hidden=true href=#544-重启服务并生成日志>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># chmod +x /var/log/tomcat/</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl restart logstash</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># curl localhost:8080</span>
</span></span></code></pre></div><h4 id=545-查看日志收集结果>5.4.5 查看日志收集结果<a hidden class=anchor aria-hidden=true href=#545-查看日志收集结果>#</a></h4><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230921112431405.png alt=image-20230921112431405></p><h3 id=55-收集-java-日志>5.5 收集 Java 日志<a hidden class=anchor aria-hidden=true href=#55-收集-java-日志>#</a></h3><blockquote><p>本节内容主要介绍 multiline 插件实现多行匹配，这是一个可以将多行进行合并的插件。有些情况下，Java 应用的日志会很长，在日志文件中以多行的方式呈现，因此需要用此插件来进行多行合并以保证日志的完整性和可读性，所以本节内容的操作是可选的而非必须的。</p></blockquote><p>[Multiline codec plugin | Logstash Reference <a href=https://www.elastic.co/guide/en/logstash/current/plugins-codecs-multiline.html>8.10] | Elastic</a></p><h4 id=551-在-elasticsearch-01-安装-logstash>5.5.1 在 elasticsearch-01 安装 logstash<a hidden class=anchor aria-hidden=true href=#551-在-elasticsearch-01-安装-logstash>#</a></h4><p>这里是直接取用 elasticsearch-01的 java 日志进行演示，因此安装了 logstash</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 导入证书</span>
</span></span><span style=display:flex><span>rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span><span style=display:flex><span><span style=color:#75715e># 配置 yum 源</span>
</span></span><span style=display:flex><span>cat &gt; /etc/yum.repos.d/logstash-7.repo <span style=color:#e6db74>&lt;&lt; EOF
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[logstash-7.x]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Elastic repository for 7.x packages
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=https://artifacts.elastic.co/packages/7.x/yum
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>autorefresh=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>type=rpm-md
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 安装并启动服务</span>
</span></span><span style=display:flex><span>yum install -y logstash
</span></span></code></pre></div><h4 id=552-测试多行合并效果>5.5.2 测试多行合并效果<a hidden class=anchor aria-hidden=true href=#552-测试多行合并效果>#</a></h4><h5 id=5521-准备配置文件>5.5.2.1 准备配置文件<a hidden class=anchor aria-hidden=true href=#5521-准备配置文件>#</a></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/test.conf</span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  stdin <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    codec <span style=color:#f92672>=</span>&gt; multiline <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      pattern <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;^\[&#34;</span> 	 <span style=color:#75715e># 当遇到[开头的行时候将多行进行合并</span>
</span></span><span style=display:flex><span>      negate <span style=color:#f92672>=</span>&gt; true 	 <span style=color:#75715e># true 为匹配成功进行操作，false 为不成功进行操作</span>
</span></span><span style=display:flex><span>      what <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;previous&#34;</span> <span style=color:#75715e># 与以前的行合并，如果是下面的行合并就是 next</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>filter <span style=color:#f92672>{</span> <span style=color:#75715e>#日志过滤，如果所有的日志都过滤就写这里，如果只针对某一个过滤就写在 input 里面的日志输入里面</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  stdout <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    codec <span style=color:#f92672>=</span>&gt; rubydebug
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h5 id=5552-检查配置>5.5.5.2 检查配置<a hidden class=anchor aria-hidden=true href=#5552-检查配置>#</a></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/test.conf -t
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span> which may change in a future major release of Logstash. To avoid unexpected changes when upgrading Logstash, please explicitly declare your desired ECS Compatibility mode.
</span></span><span style=display:flex><span>Configuration OK
</span></span></code></pre></div><h5 id=5553-使用标准输出进行验证>5.5.5.3 使用标准输出进行验证<a hidden class=anchor aria-hidden=true href=#5553-使用标准输出进行验证>#</a></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/test.conf </span>
</span></span><span style=display:flex><span>Using bundled JDK: /usr/share/logstash/jdk
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>INFO <span style=color:#f92672>]</span> 2023-09-21 11:59:55.717 <span style=color:#f92672>[[</span>main<span style=color:#f92672>]</span>-pipeline-manager<span style=color:#f92672>]</span> javapipeline - Pipeline started <span style=color:#f92672>{</span><span style=color:#e6db74>&#34;pipeline.id&#34;</span><span style=color:#f92672>=</span>&gt;<span style=color:#e6db74>&#34;main&#34;</span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>The stdin plugin is now waiting <span style=color:#66d9ef>for</span> input:
</span></span></code></pre></div><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230921121935966.png alt=image-20230921121935966></p><h4 id=553-收集-java-日志>5.5.3 收集 Java 日志<a hidden class=anchor aria-hidden=true href=#553-收集-java-日志>#</a></h4><h5 id=5531-准备配置文件>5.5.3.1 准备配置文件<a hidden class=anchor aria-hidden=true href=#5531-准备配置文件>#</a></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/java.conf </span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/apps/elasticsearch/logs/elk-cluster.log&#34;</span>
</span></span><span style=display:flex><span>    type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;java-log&#34;</span>
</span></span><span style=display:flex><span>    start_position <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;beginning&#34;</span> 
</span></span><span style=display:flex><span>    codec <span style=color:#f92672>=</span>&gt; multiline <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      pattern <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;^\[&#34;</span> 
</span></span><span style=display:flex><span>      negate <span style=color:#f92672>=</span>&gt; true
</span></span><span style=display:flex><span>      what <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;previous&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span>type<span style=color:#f92672>]</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;java-log&#34;</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    elasticsearch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      hosts <span style=color:#f92672>=</span>&gt; <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>      index<span style=color:#f92672>=</span>&gt;<span style=color:#e6db74>&#34;%{type}-%{+YYYY.MM.dd}&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h5 id=5532-生成-java-日志文件>5.5.3.2 生成 Java 日志文件<a hidden class=anchor aria-hidden=true href=#5532-生成-java-日志文件>#</a></h5><p>重启节点elasticsearch-02，使得集群产生多行错误日志以观察多行合并和的效果</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-02 ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl restart elasticsearch.service</span>
</span></span></code></pre></div><p>生成的部分错误日志：</p><p><code>less /apps/elasticsearch/logs/elk-cluster.log</code></p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230921150830839.png alt=image-20230921150830839></p><h5 id=5533-成功收集日志>5.5.3.3 成功收集日志<a hidden class=anchor aria-hidden=true href=#5533-成功收集日志>#</a></h5><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230921151058451.png alt=image-20230921151058451></p><h5 id=5534-通过-kibana-查看结果>5.5.3.4 通过 kibana 查看结果<a hidden class=anchor aria-hidden=true href=#5534-通过-kibana-查看结果>#</a></h5><p>添加索引模式 <code>java-log*</code> 后在 Discover 面板查看合并后的日志</p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230921151839562.png alt=image-20230921151839562></p><h3 id=56-收集-nginx-日志>5.6 收集 Nginx 日志<a hidden class=anchor aria-hidden=true href=#56-收集-nginx-日志>#</a></h3><p><strong>nginx 的日志收集和 Java 类似，核心点在于将日志格式修改为 json 格式，这里仅演示如何修改日志格式。</strong></p><p><strong>在 logstash 安装 nginx</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># yum install -y nginx</span>
</span></span></code></pre></div><p><strong>修改 nginx 日志为 json</strong> 格式</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># grep log_format -A 13 /etc/nginx/nginx.conf</span>
</span></span><span style=display:flex><span>    log_format  main  <span style=color:#e6db74>&#39;{&#34;@timestamp&#34;:&#34;$time_iso8601&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;host&#34;:&#34;$server_addr&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;clientip&#34;:&#34;$remote_addr&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;size&#34;:$body_bytes_sent,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;responsetime&#34;:$request_time,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;upstreamtime&#34;:&#34;$upstream_response_time&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;upstreamhost&#34;:&#34;$upstream_addr&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;http_host&#34;:&#34;$host&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;url&#34;:&#34;$uri&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;domain&#34;:&#34;$host&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;xff&#34;:&#34;$http_x_forwarded_for&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;referer&#34;:&#34;$http_referer&#34;,&#39;</span>
</span></span><span style=display:flex><span>		      <span style=color:#e6db74>&#39;&#34;status&#34;:&#34;$status&#34;}&#39;</span>;
</span></span></code></pre></div><p><strong>重启 nginx 生成日志</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl start nginx</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># curl localhost</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># tail /var/log/nginx/access.log </span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;@timestamp&#34;</span>:<span style=color:#e6db74>&#34;2023-09-21T15:37:49+08:00&#34;</span>,<span style=color:#e6db74>&#34;host&#34;</span>:<span style=color:#e6db74>&#34;::1&#34;</span>,<span style=color:#e6db74>&#34;clientip&#34;</span>:<span style=color:#e6db74>&#34;::1&#34;</span>,<span style=color:#e6db74>&#34;size&#34;</span>:4833,<span style=color:#e6db74>&#34;responsetime&#34;</span>:0.000,<span style=color:#e6db74>&#34;upstreamtime&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;upstreamhost&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;http_host&#34;</span>:<span style=color:#e6db74>&#34;localhost&#34;</span>,<span style=color:#e6db74>&#34;url&#34;</span>:<span style=color:#e6db74>&#34;/index.html&#34;</span>,<span style=color:#e6db74>&#34;domain&#34;</span>:<span style=color:#e6db74>&#34;localhost&#34;</span>,<span style=color:#e6db74>&#34;xff&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;referer&#34;</span>:<span style=color:#e6db74>&#34;-&#34;</span>,<span style=color:#e6db74>&#34;status&#34;</span>:<span style=color:#e6db74>&#34;200&#34;</span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p><strong>校验日志格式</strong> <a href=https://www.sojson.com/>JSON在线 | JSON解析格式化—SO JSON在线工具</a></p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230921154017383.png alt=image-20230921154017383></p><h3 id=57-使用-redis-缓存日志>5.7 使用 Redis 缓存日志<a hidden class=anchor aria-hidden=true href=#57-使用-redis-缓存日志>#</a></h3><blockquote><p>目标：通过在 redis 客户端部署的 logstash （主机名 log-client） 收集日志，写入 redis （缓存作用），再通过专门的一台 logstash（主机名 logstash）读取 redis 中的日志写入 elasticsearch。</p></blockquote><h4 id=571-准备一个客户端服务器>5.7.1 <strong>准备一个客户端服务器</strong><a hidden class=anchor aria-hidden=true href=#571-准备一个客户端服务器>#</a></h4><table><thead><tr><th>主机名</th><th>IP</th><th>系统</th><th>配置</th></tr></thead><tbody><tr><td>log-client</td><td>10.0.0.9</td><td>CentOS 7.6</td><td>2U 4G</td></tr></tbody></table><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 关闭防火墙</span>
</span></span><span style=display:flex><span>systemctl disable firewalld --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭 NetworkManager</span>
</span></span><span style=display:flex><span>systemctl disable NetworkManager --now
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭selinux</span>
</span></span><span style=display:flex><span>setenforce <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;/SELINUX/s/enforcing/disabled/&#39;</span> /etc/selinux/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 修改文件句柄数的限制</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;* soft nofile 65536&#34;</span> &gt;&gt; /etc/security/limits.conf
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;* hard nofile 65536&#34;</span> &gt;&gt; /etc/security/limits.conf
</span></span></code></pre></div><p><strong>安装 redis</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># yum install -y redis</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 修改配置文件</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/redis.conf </span>
</span></span><span style=display:flex><span>bind 0.0.0.0
</span></span><span style=display:flex><span>protected-mode yes
</span></span><span style=display:flex><span>port <span style=color:#ae81ff>6379</span>
</span></span><span style=display:flex><span>tcp-backlog <span style=color:#ae81ff>511</span>
</span></span><span style=display:flex><span>timeout <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>tcp-keepalive <span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span>daemonize yes
</span></span><span style=display:flex><span>supervised no
</span></span><span style=display:flex><span>pidfile /var/run/redis_6379.pid
</span></span><span style=display:flex><span>loglevel notice
</span></span><span style=display:flex><span>databases <span style=color:#ae81ff>16</span>
</span></span><span style=display:flex><span>requirepass passwd 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl start redis</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## 安装 logstash</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># # 导入证书</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># # 配置 yum 源</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># cat &gt; /etc/yum.repos.d/logstash-7.repo &lt;&lt; EOF</span>
</span></span><span style=display:flex><span>&gt; <span style=color:#f92672>[</span>logstash-7.x<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>&gt; name<span style=color:#f92672>=</span>Elastic repository <span style=color:#66d9ef>for</span> 7.x packages
</span></span><span style=display:flex><span>&gt; baseurl<span style=color:#f92672>=</span>https://artifacts.elastic.co/packages/7.x/yum
</span></span><span style=display:flex><span>&gt; gpgcheck<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>&gt; gpgkey<span style=color:#f92672>=</span>https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span><span style=display:flex><span>&gt; enabled<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>&gt; autorefresh<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>&gt; type<span style=color:#f92672>=</span>rpm-md
</span></span><span style=display:flex><span>&gt; EOF
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># yum install -y logstash</span>
</span></span></code></pre></div><h4 id=572-收集日志写入-redis>5.7.2 收集日志写入 redis<a hidden class=anchor aria-hidden=true href=#572-收集日志写入-redis>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/sys-to-redis.conf</span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/var/log/message&#34;</span>
</span></span><span style=display:flex><span>    type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span>
</span></span><span style=display:flex><span>    start_position <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;beginning&#34;</span>
</span></span><span style=display:flex><span>    stat_interval <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;2&#34;</span> 
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span>type<span style=color:#f92672>]</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;system-log&#34;</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    redis <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      data_type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;list&#34;</span> 
</span></span><span style=display:flex><span>      key <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span> 
</span></span><span style=display:flex><span>      host <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;10.0.0.9&#34;</span> 
</span></span><span style=display:flex><span>      port <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;6379&#34;</span> 
</span></span><span style=display:flex><span>      db <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;0&#34;</span> 
</span></span><span style=display:flex><span>      password <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;passwd&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># chmod +r /var/log/messages</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># ll /var/log/messages</span>
</span></span><span style=display:flex><span>-rw-r--r--. <span style=color:#ae81ff>1</span> root root <span style=color:#ae81ff>596944</span> Sep <span style=color:#ae81ff>22</span> 11:39 /var/log/messages
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl start logstash.service </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 成功写入日志</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># telnet localhost 6379</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>Escape character is <span style=color:#e6db74>&#39;^]&#39;</span>.
</span></span><span style=display:flex><span>auth passwd
</span></span><span style=display:flex><span>+OK
</span></span><span style=display:flex><span><span style=color:#66d9ef>select</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>+OK
</span></span><span style=display:flex><span>keys *
</span></span><span style=display:flex><span>*1
</span></span><span style=display:flex><span>$10
</span></span><span style=display:flex><span>system-log <span style=color:#75715e># 以list 方式存储</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>LRANGE system-log <span style=color:#ae81ff>0</span> <span style=color:#ae81ff>0</span>   <span style=color:#75715e>#查看其中一条消息</span>
</span></span><span style=display:flex><span>*1
</span></span><span style=display:flex><span>$139
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;path&#34;</span>:<span style=color:#e6db74>&#34;/var/log/messages&#34;</span>,<span style=color:#e6db74>&#34;host&#34;</span>:<span style=color:#e6db74>&#34;log-client&#34;</span>,<span style=color:#e6db74>&#34;@timestamp&#34;</span>:<span style=color:#e6db74>&#34;2023-09-22T03:52:48.547Z&#34;</span>,<span style=color:#e6db74>&#34;type&#34;</span>:<span style=color:#e6db74>&#34;system-log&#34;</span>,<span style=color:#e6db74>&#34;@version&#34;</span>:<span style=color:#e6db74>&#34;1&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#e6db74>&#34;tet&#34;</span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h4 id=573-读取-redis-的日志写入-elasticsearch>5.7.3 读取 redis 的日志写入 elasticsearch<a hidden class=anchor aria-hidden=true href=#573-读取-redis-的日志写入-elasticsearch>#</a></h4><p><strong>准备配置文件：</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/redis-to-es.conf </span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  redis <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    data_type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;list&#34;</span> 
</span></span><span style=display:flex><span>    key <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span> 
</span></span><span style=display:flex><span>    host <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;10.0.0.9&#34;</span> 
</span></span><span style=display:flex><span>    port <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;6379&#34;</span> 
</span></span><span style=display:flex><span>    db <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;0&#34;</span> 
</span></span><span style=display:flex><span>    password <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;passwd&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span>type<span style=color:#f92672>]</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;system-log&#34;</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    elasticsearch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      hosts <span style=color:#f92672>=</span>&gt; <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>      index <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;redis-to-es-%{+YYYY.MM.dd}&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 重启logstash</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl restart logstash</span>
</span></span></code></pre></div><p><strong>验证结果：</strong></p><p>elasticseach 成功获取到日志信息</p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230925093137893.png alt=image-20230925093137893></p><p>redis 中的消息被消费：</p><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230925093250415.png alt=image-20230925093250415></p><h3 id=58-使用-kafka-缓存日志>5.8 使用 Kafka 缓存日志<a hidden class=anchor aria-hidden=true href=#58-使用-kafka-缓存日志>#</a></h3><h4 id=581-在-log-clinet-部署-kafka>5.8.1 在 log-clinet 部署 kafka<a hidden class=anchor aria-hidden=true href=#581-在-log-clinet-部署-kafka>#</a></h4><p><a href=https://senmer.github.io/zh/posts/tech/kafka/kafka%E7%AE%80%E4%BB%8B%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/>Kafka简介与集群部署 | WZ&rsquo;s Blog (senmer.github.io)</a></p><h4 id=582-将日志写入-kafka>5.8.2 将日志写入 Kafka<a hidden class=anchor aria-hidden=true href=#582-将日志写入-kafka>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/sys-to-kafka.conf </span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  file <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    path <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;/var/log/messages&#34;</span>
</span></span><span style=display:flex><span>    type <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span>
</span></span><span style=display:flex><span>    start_position <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;beginning&#34;</span>
</span></span><span style=display:flex><span>    stat_interval <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;2&#34;</span> 
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span>type<span style=color:#f92672>]</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;system-log&#34;</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    kafka <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      bootstrap_servers <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;10.0.0.11:9092&#34;</span> 
</span></span><span style=display:flex><span>      topic_id <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span>   
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 配置域名解析，kafka 连接 elasticsearch 需要用到</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/hosts</span>
</span></span><span style=display:flex><span>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
</span></span><span style=display:flex><span>::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>10.0.0.11 elasticsearch-01 
</span></span><span style=display:flex><span>10.0.0.12 elasticsearch-02 
</span></span><span style=display:flex><span>10.0.0.13 elasticsearch-03
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 重启 logstash</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl restart logstash</span>
</span></span></code></pre></div><h4 id=583-查看-kafka-中的-topic>5.8.3 查看 Kafka 中的 topic<a hidden class=anchor aria-hidden=true href=#583-查看-kafka-中的-topic>#</a></h4><p>注意：本示例中 Kafka、zookeeper、elasticsearch 集群均安装在（10.0.0.11、10.0.0.12、10.0.0.13）三台主机上</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 kafka<span style=color:#f92672>]</span><span style=color:#75715e># pwd</span>
</span></span><span style=display:flex><span>/usr/local/kafka
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 kafka<span style=color:#f92672>]</span><span style=color:#75715e># ./bin/kafka-topics.sh --list --zookeeper localhost:2181</span>
</span></span><span style=display:flex><span>OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, <span style=color:#66d9ef>then</span> you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads<span style=color:#f92672>=</span>N
</span></span><span style=display:flex><span>__consumer_offsets
</span></span><span style=display:flex><span>system-log <span style=color:#75715e># 成功写入日志</span>
</span></span></code></pre></div><h4 id=584-读取-kafka-中的日志写入-elasticsearch>5.8.4 读取 Kafka 中的日志写入 Elasticsearch<a hidden class=anchor aria-hidden=true href=#584-读取-kafka-中的日志写入-elasticsearch>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/kafka-to-es.conf </span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  kafka <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    bootstrap_servers <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;10.0.0.11:9092&#34;</span>
</span></span><span style=display:flex><span>    topics <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log&#34;</span>
</span></span><span style=display:flex><span>    consumer_threads <span style=color:#f92672>=</span>&gt; <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  elasticsearch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    hosts <span style=color:#f92672>=</span>&gt; <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>    index <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;kafka-to-es-%{+YYYY.MM.dd}&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl restart logstash.service</span>
</span></span></code></pre></div><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20230926110427460.png alt=image-20230926110427460></p><h3 id=59-使用-filebeat-收集日志>5.9 使用 filebeat 收集日志<a hidden class=anchor aria-hidden=true href=#59-使用-filebeat-收集日志>#</a></h3><p>要在 Filebeat 中使用 <code>conf.d/*</code> 的方式导入配置文件，通常你需要按照以下步骤进行配置：</p><ol><li><p>创建一个存放额外配置文件的目录，通常命名为 <code>conf.d</code>，并将你的额外配置文件放置在该目录中。这些配置文件可以包含不同输入、过滤器和输出的定义。</p></li><li><p>确保 Filebeat 配置文件中包含一个配置项，告诉 Filebeat 去加载 <code>conf.d</code> 目录下的配置文件。通常，你可以使用 <code>filebeat.config.modules</code> 来配置额外配置文件的路径，如下所示：</p></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>filebeat.config.modules</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>path</span>: <span style=color:#ae81ff>${path.config}/modules.d/*.yml</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>reload.enabled</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>filebeat.config.inputs</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>path</span>: <span style=color:#ae81ff>${path.config}/conf.d/*.yml </span> <span style=color:#75715e># 这里指定额外配置文件的路径</span>
</span></span></code></pre></div><ol start=3><li>确保你的额外配置文件（位于 <code>conf.d</code> 目录中）具有正确的格式和语法。这些配置文件可以包含输入、过滤器和输出的定义，类似于主配置文件。</li></ol><p>以下是一个示例额外配置文件的内容（<code>conf.d/my-custom-input.yml</code>）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>filebeat.inputs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>type</span>: <span style=color:#ae81ff>log</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>paths</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>/var/log/myapp/*.log</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>fields</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>log_type</span>: <span style=color:#ae81ff>myapp-log</span>
</span></span></code></pre></div><ol start=4><li>保存主配置文件和额外配置文件，并重新启动 Filebeat 服务以使更改生效：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl restart filebeat
</span></span></code></pre></div><p>这样，Filebeat 将加载主配置文件以及位于 <code>conf.d</code> 目录下的所有额外配置文件，并根据这些配置文件来处理日志数据。</p><p>请根据你的实际需求和环境对配置进行自定义，并确保配置文件的正确性和一致性。</p><p><a href=https://www.elastic.co/guide/en/beats/filebeat/7.17/setup-repositories.html#_yum>https://www.elastic.co/guide/en/beats/filebeat/7.17/setup-repositories.html#_yum</a></p><h4 id=591-在-log-client-安装-filebeat>5.9.1 <strong>在 log-client 安装 filebeat</strong><a hidden class=anchor aria-hidden=true href=#591-在-log-client-安装-filebeat>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># cat &gt; /etc/yum.repos.d/filebeat-7.repo &lt;&lt; EOF</span>
</span></span><span style=display:flex><span>&gt; <span style=color:#f92672>[</span>elastic-7.x<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>&gt; name<span style=color:#f92672>=</span>Elastic repository <span style=color:#66d9ef>for</span> 7.x packages
</span></span><span style=display:flex><span>&gt; baseurl<span style=color:#f92672>=</span>https://artifacts.elastic.co/packages/7.x/yum
</span></span><span style=display:flex><span>&gt; gpgcheck<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>&gt; gpgkey<span style=color:#f92672>=</span>https://artifacts.elastic.co/GPG-KEY-elasticsearch
</span></span><span style=display:flex><span>&gt; enabled<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>&gt; autorefresh<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>&gt; type<span style=color:#f92672>=</span>rpm-md
</span></span><span style=display:flex><span>&gt; EOF
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># sudo yum install filebeat</span>
</span></span></code></pre></div><h4 id=592-收集系统日志>5.9.2 收集系统日志<a hidden class=anchor aria-hidden=true href=#592-收集系统日志>#</a></h4><h5 id=5921-收集单个系统日志写入-kafka>5.9.2.1 收集单个系统日志，写入 kafka<a hidden class=anchor aria-hidden=true href=#5921-收集单个系统日志写入-kafka>#</a></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/filebeat/filebeat.yml</span>
</span></span><span style=display:flex><span>lebeat.config.modules:
</span></span><span style=display:flex><span>  path: <span style=color:#e6db74>${</span>path.config<span style=color:#e6db74>}</span>/modules.d/*.yml
</span></span><span style=display:flex><span>  reload.enabled: true
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>filebeat.inputs:
</span></span><span style=display:flex><span>  - type: log
</span></span><span style=display:flex><span>    enabled: true
</span></span><span style=display:flex><span>    paths:
</span></span><span style=display:flex><span>      - /var/log/*.log
</span></span><span style=display:flex><span>      - /var/log/messages
</span></span><span style=display:flex><span>    exclude_lines: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;^DBG&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>    exclude_files: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;.gz</span>$<span style=color:#e6db74>&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>    fields_under_root: true
</span></span><span style=display:flex><span>    fields:
</span></span><span style=display:flex><span>      document_type: <span style=color:#e6db74>&#34;system-log&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output.kafka:
</span></span><span style=display:flex><span>  hosts: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9092&#34;</span>, <span style=color:#e6db74>&#34;10.0.0.12:9092&#34;</span>, <span style=color:#e6db74>&#34;10.0.0.13:9092&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>  topic: <span style=color:#e6db74>&#34;system-log-filebeat&#34;</span>
</span></span><span style=display:flex><span>  partition.round_robin:
</span></span><span style=display:flex><span>    reachable_only: true
</span></span><span style=display:flex><span>  required_acks: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  compression: gzip
</span></span><span style=display:flex><span>  max_message_bytes: <span style=color:#ae81ff>1000000</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@log-client ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl restart filebeat</span>
</span></span></code></pre></div><h5 id=2922-在-kafka-中查看-topic>2.9.2.2 在 kafka 中查看 topic<a hidden class=anchor aria-hidden=true href=#2922-在-kafka-中查看-topic>#</a></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@elasticsearch-01 elasticsearch<span style=color:#f92672>]</span><span style=color:#75715e># /usr/local/src/kafka_2.12-2.1.0/bin/kafka-topics.sh  --list --zookeeper localhost:2181 |grep filebeat</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>system-log-filebeat
</span></span></code></pre></div><h5 id=2923-使用-logstash-将-kafka-中的日志写入-elasticsearch>2.9.2.3 使用 logstash 将 kafka 中的日志写入 elasticsearch<a hidden class=anchor aria-hidden=true href=#2923-使用-logstash-将-kafka-中的日志写入-elasticsearch>#</a></h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># cat /etc/logstash/conf.d/kafka-to-es.conf </span>
</span></span><span style=display:flex><span>input <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  kafka <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    bootstrap_servers <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;10.0.0.11:9092&#34;</span>
</span></span><span style=display:flex><span>    topics <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;system-log-filebeat&#34;</span>
</span></span><span style=display:flex><span>    consumer_threads <span style=color:#f92672>=</span>&gt; <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  elasticsearch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    hosts <span style=color:#f92672>=</span>&gt; <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;10.0.0.11:9200&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>    index <span style=color:#f92672>=</span>&gt; <span style=color:#e6db74>&#34;syslog-filebeat-%{+YYYY.MM.dd}&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@logstash ~<span style=color:#f92672>]</span><span style=color:#75715e># systemctl restart logstash</span>
</span></span></code></pre></div><p><img loading=lazy src=/images/ELK%e9%83%a8%e7%bd%b2%e5%92%8c%e4%bd%bf%e7%94%a8//image-20231007165803012.png alt=image-20231007165803012></p><h2 id=faq>FAQ<a hidden class=anchor aria-hidden=true href=#faq>#</a></h2><h3 id=elk-中用-redis-和用-kafka-缓存日志有何区别>elk 中用 redis 和用 kafka 缓存日志有何区别<a hidden class=anchor aria-hidden=true href=#elk-中用-redis-和用-kafka-缓存日志有何区别>#</a></h3><p>在ELK（Elasticsearch, Logstash, Kibana）堆栈中，使用Redis和Kafka来缓存日志有一些区别，它们分别适用于不同的使用情境和需求：</p><ol><li><p>Redis缓存日志：</p><ul><li>Redis是一个内存数据库，通常用于缓存和高速读写操作。在ELK中，Redis通常用于缓存日志事件，以便在Logstash和Elasticsearch之间提供快速的缓冲机制。</li><li>使用Redis缓存日志的优点包括高速的写入和读取速度，以及简单的设置和配置。</li><li>缺点是Redis的存储容量受限于内存大小，可能需要更多的内存来缓存大量的日志事件。此外，Redis不是一个专门设计用于处理日志流的工具，因此在某些情况下可能需要额外的定制。</li></ul></li><li><p>Kafka缓存日志：</p><ul><li>Kafka是一个分布式消息队列，通常用于高吞吐量的数据流处理。在ELK中，Kafka用于接收、缓存和分发日志事件，充当了一个持久性的数据缓冲层。</li><li>使用Kafka的优点包括能够处理大规模的数据流，提供数据持久性，以及具备高可用性和可伸缩性。</li><li>缺点是Kafka的配置和维护可能相对复杂，因为它是一个分布式系统。此外，它不像Redis那样适用于低延迟要求的场景。</li></ul></li></ol><p>关键区别：</p><ul><li>Redis主要用于瞬时性缓存，适用于需要快速读写操作的场景，但不适用于长期存储。它通常用于解决Logstash和Elasticsearch之间的速度不匹配问题。</li><li>Kafka更适合于数据流处理，能够缓存大量数据并确保持久性。它允许多个消费者并行处理数据，因此适用于大规模、高吞吐量的日志处理。</li></ul><p>通常情况下，选择使用Redis还是Kafka取决于你的日志处理需求和架构。如果你需要一个简单的缓冲层来解决速度不匹配的问题，Redis可能是更合适的选择。如果你需要处理大量的日志数据，需要持久性和分布式处理能力，那么Kafka可能更适合。此外，还可以考虑将它们结合使用，使用Redis进行短期缓存，然后将日志事件写入Kafka以进行长期存储和分发。</p><h3 id=filebeat-和-logstash-的区别>filebeat 和 logstash 的区别<a hidden class=anchor aria-hidden=true href=#filebeat-和-logstash-的区别>#</a></h3><p>Filebeat和Logstash都是用于日志收集和传输的工具，但它们有一些关键区别，主要涉及到它们的用途、特性和性能：</p><ol><li><p>用途：</p><ul><li>Filebeat：Filebeat是轻量级的数据收集器，专注于从文件和日志位置收集数据并将其发送到目标位置，通常是Elasticsearch或Logstash。它主要用于日志文件的收集和转发。</li><li>Logstash：Logstash是一个强大的数据处理引擎，具有数据转换、过滤和丰富功能。它可以用于数据的采集、转换、丰富、过滤和输出。虽然它也可以用于日志收集，但其功能更丰富，可以处理多种数据源和格式。</li></ul></li><li><p>处理和转换：</p><ul><li>Filebeat：Filebeat通常不对数据进行处理或转换，它负责将原始数据发送到目标位置。它可以对数据进行简单的筛选，但不具备复杂的数据处理功能。</li><li>Logstash：Logstash具有强大的数据处理能力，可以对数据进行复杂的转换、过滤、丰富和标准化操作。这使得Logstash在需要对数据进行复杂处理的情况下非常有用。</li></ul></li><li><p>插件和输出：</p><ul><li>Filebeat：Filebeat的主要目标是将数据发送到Elasticsearch、Logstash或其他目标。它的输出选项相对较少，主要用于数据的传输。</li><li>Logstash：Logstash有丰富的插件和输出选项，可以将数据发送到多种目标，包括Elasticsearch、Kafka、Redis、数据库等，同时可以使用各种输入插件来接收数据源。</li></ul></li><li><p>轻量性和性能：</p><ul><li>Filebeat：Filebeat设计为轻量级，占用较少的系统资源，适用于部署在资源受限的环境中。它适合快速传输日志数据。</li><li>Logstash：Logstash相对较重，需要更多的系统资源，特别是在进行大规模数据处理时。它适合处理复杂的数据处理任务。</li></ul></li><li><p>部署场景：</p><ul><li>Filebeat适用于简单的日志传输和快速的日志收集场景，特别是在需要轻量级解决方案的情况下。</li><li>Logstash适用于需要进行数据处理、转换和丰富操作的场景，尤其是当需要处理多种数据源或数据格式时。</li></ul></li></ol><p>通常情况下，你可以根据具体的需求来选择使用Filebeat、Logstash，或者它们的组合，以构建适合你的日志收集和处理架构。要根据特定需求进行选择，以确保系统的效率和性能。</p></div><div class=post-reward><div style=padding:0;margin:0;width:100%;font-size:16px;text-align:center><div id=QR style=opacity:0><div id=wechat style=display:inline-block><a class=fancybox rel=group><img id=wechat_qr src=https://senmer.github.io/img/wechat_pay.png alt=wechat_pay></a><p>微信</p></div><div id=alipay style=display:inline-block><a class=fancybox rel=group><img id=alipay_qr src=https://senmer.github.io/img/alipay.png alt=alipay></a><p>支付宝</p></div></div><button id=rewardButton onclick='var qr=document.getElementById("QR");qr.style.opacity==="0"?qr.style.opacity="1":qr.style.opacity="0"'>
<span>🧧 鼓励</span></button></div></div><footer class=post-footer><nav class=paginav><a class=next href=https://senmer.github.io/zh/posts/tech/vpn/openvpn%E5%90%AF%E7%94%A8ldap+googleauthenticator%E8%AE%A4%E8%AF%81/><span class=title>下一页 »</span><br><span>OpenVPN启用LDAP+GoogleAuthenticator认证</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'👉展开评论';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'👇关闭评论';color:var(--content)}</style><div><details class=comments_details open><summary style=display:none></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js></script><script>twikoo.init({envId:"https://hugo-api-khaki.vercel.app/# 填写自己的twikoo id",el:"#tcomment",lang:"zh-CN",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg><span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString(),s=window.getSelection().toString();t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="复制";function i(){t.innerText="已复制！",setTimeout(()=>{t.innerText="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>